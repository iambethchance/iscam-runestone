<?xml version="1.0" encoding="UTF-8"?>
<section xml:id="investigation4-9" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Inference for Paired Designs</title>
  
  <exercises xml:id="exercises-4-9" hidden-label="yes">
  <title>Investigation 4.9: Speed It Up (cont.)</title>

  <introduction>
    <p>Recall that student researchers wanted to compare the mean typing speed with and without up-tempo music.</p>
    <p><m>H_0: \mu_{music} - \mu_{nomusic} = 0</m> (no difference in the long run average speed)</p>
    <p><m>H_a: \mu_{music} - \mu_{nomusic} > 0</m> (on average typing speed is faster with up-tempo music)</p>
    <p>Below are the results from the students' paired design.</p>
    
    <image source="images/Inv4.9results.png" width="70%">
      <description>Summary statistics and dotplots for typing speeds with and without music</description>
    </image>
  </introduction>
  
  <exercise xml:id="inv4-9-a" label="I4.9.1">
    <title>Compare to Previous Results</title>
    <statement>
      <p>Compare these results to the results in <xref ref="inv-4-8-speed">Investigation 4.8</xref>. What has changed? Will these changes impact the p-value? If so, how?</p>
    </statement>
    <response/>
    <solution>
      <p>The sample sizes are larger which would lower the <em>p</em>-value. The standard deviations have changed a bit but in general are similar in magnitude to before. The sample means have changed a bit, but in general are similar in magnitude to before. If anything, the difference in mean typing speed between the two groups is a bit smaller which would raise the <em>p</em>-value.</p>
    </solution>
  </exercise>
  
  <exercise xml:id="inv4-9-b" label="I4.9.2">
    <title>Can We Use Previous Methods?</title>
    <statement>
      <p>Explain why we can't do a randomization test or a two-sample <em>t</em>-test with these data.</p>
    </statement>
    <response/>
    <solution>
      <p>We don't have "two samples." We have just one sample, the two observations are each individual should not be considered as unrelated to each other.</p>
    </solution>
  </exercise>
  
  <assemblage>
    <title>Key Idea</title>
    <p>When the data are <em>paired</em> (e.g., repeat observations on the same observational unit) we should not treat the two samples as independent. This ignores the information that two measurements were taken for each observational unit (we couldn't mix up the values in the second column without altering the information in the data).</p>
  </assemblage>
  
  <p>As suggested in <xref ref="inv4-8-j">Investigation 4.8, Checkpoint I4.8.10</xref>, we can use the <em>differences</em> as the response variable.</p>
  
  <image source="images/Inv4.9diffs.png" width="70%">
    <description>Distribution of differences in typing speeds (no music - music)</description>
  </image>
  
  <exercise xml:id="inv4-9-c" label="I4.9.3">
    <title>Distribution of Differences</title>
    <statement>
      <p>Summarize what you learn about the distribution of differences.</p>
    </statement>
    <response/>
    <solution>
      <p>The distribution of differences in typing speeds is slightly skewed to the right with a mean difference of 2.62 wpm and a standard deviation of 5.71 wpm. There are a couple of participants that performed much worse for one of the tests (<m>\sim</m> 10 wpm), one with the music condition and one with the no music condition.</p>
    </solution>
  </exercise>
  
  <exercise xml:id="inv4-9-d" label="I4.9.4">
    <title>Mean of Differences vs. Difference in Means</title>
    <statement>
      <p>How does the mean of the differences (<m>\bar{x}_{diff}</m>) compare to the difference in means (<m>\bar{x}_{music} - \bar{x}_{nomusic}</m>)?</p>
    </statement>
    <choices randomize="no">
      <choice correct="yes">
        <statement><p>Equal to</p></statement>
        <feedback><p>Correct! <m>63.588 - 66.206 = -2.62</m>, the same as the mean of differences.</p></feedback>
      </choice>
      <choice>
        <statement><p>Greater than</p></statement>
        <feedback><p>Calculate the difference in means and compare.</p></feedback>
      </choice>
      <choice>
        <statement><p>Less than</p></statement>
        <feedback><p>Calculate the difference in means and compare.</p></feedback>
      </choice>
    </choices>
  </exercise>
  
  <exercise xml:id="inv4-9-e" label="I4.9.5">
    <title>Standard Deviation Comparison</title>
    <statement>
      <p>How does the standard deviation of the differences compare to the standard deviations of the original typing speeds in the two groups?</p>
    </statement>
    <choices randomize="no">
      <choice>
        <statement><p>Greater than</p></statement>
        <feedback><p>Compare the SD of differences (5.71) to the original SDs (14.1 and 13.8).</p></feedback>
      </choice>
      <choice correct="yes">
        <statement><p>Less than</p></statement>
        <feedback><p>Correct! The standard deviation of the differences (5.71) is much smaller than the original SDs of 14.1 and 13.8, showing the pairing was effective.</p></feedback>
      </choice>
      <choice>
        <statement><p>Equal to</p></statement>
        <feedback><p>Compare the SD of differences (5.71) to the original SDs (14.1 and 13.8).</p></feedback>
      </choice>
    </choices>
  </exercise>
  
  <exercise xml:id="inv4-9-f" label="I4.9.6">
    <title>Parameter and Hypotheses</title>
    <statement>
      <p>Define an appropriate parameter for investigating whether comparing typing speeds with and without music. State a null and an alternative hypothesis about this parameter.</p>
    </statement>
    <response/>
    <solution>
      <p>Let <m>\mu_d</m> = the population mean difference in typing speed, nomusic - music</p>
      <p><md alignment="alignat">
        <mrow>H_0: \mu_d = 0 \amp\text{ (the typing speeds are the same for both conditions)}</mrow>
        <mrow>H_a: \mu_d \neq 0 \amp\text{ (The typing speeds are not the same for both conditions.)}</mrow>
      </md></p>
    </solution>
  </exercise>
  
  <p>It actually doesn't matter whether we use the "difference in means" or the "mean difference" as our statistic/parameter. What is important is how we estimate the chance variation in that statistic, assuming the null hypothesis is true.</p>
  
  <p><alert>Simulation</alert></p>
  
  <exercise xml:id="inv4-9-g" label="I4.9.7">
    <title>Simulation Design</title>
    <statement>
      <p>Outline (pseudo-code) how you could use a coin to simulate a randomization test for paired data to compare the two sets of measurements to assess how unusual it is for the average difference in typing speeds to be at least this extreme just by chance. Keep in mind that you want the simulation to mimic the randomization process used in the study design, assuming the presence/absence of music does not affect typing speed.</p>
    </statement>
    <response/>
    <solution>
      <p>For each participant, we could randomly determine which of their typing speed measurements was measured with music and which without music. To do this, we would flip a coin. If the coin lands heads up, change the sign of the difference (so switch the music and no-music results). If the coin lands tails up, keep the results with their original labels (the difference would not change). Flip the coin for all 34 participants, find the (new) difference for each person and find the mean of these differences, <m>\bar{x}_d</m>. Repeat this "swapping" process a large number of times and look at the distribution of the <m>\bar{x}_d</m> values. Then count how many of these simulated <m>\bar{x}_d</m> values are at least as extreme as the <m>-2.62</m> we observed in our study (where "as extreme" would mean <m>\bar{x} > 2.62</m> and <m>\bar{x} \lt -2.62</m> for our two-sided alternative).</p>
      <p>Pseudo code:</p>
      <pre>
for i:1 to 1000
  for j: 1 to n
    multiplier = flip a coin (-1,1) w/ prob 0.5
    newdifference[j] = multiplier*olddiff[j]
  end loop
  calculate meandiff[i]=mean(newdifference)
end loop
pvalue=2*sum(meandiff[i] > 2.62) /1000
      </pre>
    </solution>
  </exercise>
  
  <p>Copy and paste the original raw data (<url href="http://www.rossmanchance.com/iscam2/data/TypingMusic.txt" visual="rossmanchance.com/iscam2/data/TypingMusic.txt"><c>TypingMusic.txt</c></url>) into the <url href="https://www.rossmanchance.com/applets/2021/matchedpairs/MatchedPairs.htm">Matched Pairs applet</url>:</p>
  
  <sidebyside widths="48% 48%">
    <stack>
      <p><ul><li>View the data window, with one column for the speeds with music and a second column for the speeds without music (each row is one person). You can also include an initial column of identifiers (e.g., student IDs or initials). The dotplots should then show both sets of data, connecting the paired observations, and their differences.</li></ul></p>
    </stack>
    <image source="images/Inv4.9applet1.png" width="100%">
      <description>Matched Pairs applet showing data input</description>
    </image>
  </sidebyside>
  
  <exercise xml:id="inv4-9-h" label="I4.9.8">
    <title>Track the observations as they are shuffled</title>
    <statement>
      <p>What do you notice about the high outliers (fastest typers) in each condition?</p>
    </statement>
    <response/>
    <solution>
      <p>You may notice that for each pair, you always get one result in each condition, but they can flop which condition.</p>
    </solution>
  </exercise>
  
  <p><ul>
    <li><p>Check the Randomize box and press Randomize. For each pair, the applet will virtually "flip a coin" and if the coin lands heads, the two observations for that person will change positions. The new dotplots and the new set of differences for these rearranged values will be displayed. The mean of these differences will appear in the bottom dotplot.</p></li>
    <li><p>Uncheck Animate. Press Randomize four more times to get a sense of the variability in the mean difference from repetition to repetition. Change the number of repetitions from 1 to 995 (for a total of 1000) and press Randomize.</p></li>
  </ul></p>
  
  <exercise label="inv4-9-example-results">
    <title>Example results</title>
    <statement>
      <p></p>
    </statement>
    <solution>
      <image source="images/Inv4.9solsh.png" width="70%">
        <description>Distribution of 1000 simulated mean differences from re-randomizations</description>
      </image>
    </solution>
  </exercise>
  
  <exercise xml:id="inv4-9-i" label="I4.9.9">
    <title>Interpret Randomization Distribution</title>
    <statement>
      <p>Explain what distribution is being displayed in the bottom (grey) dotplot (what order of subtraction did the applet use?).</p>
    </statement>
    <response/>
    <solution>
      <p>This is the distribution of 1000 simulated <m>\bar{x}_d</m> values from 1000 re-randomizations where <m>\bar{x}_d</m> is calculated by subtracting the with-music speed from the no-music speed.</p>
    </solution>
  </exercise>
  
  <exercise xml:id="inv4-9-j" label="I4.9.10">
    <title>Mean of Distribution</title>
    <statement>
      <p>Where is the mean of the distribution of the average differences? Why should you expect that?</p>
    </statement>
    <response/>
    <solution>
      <p>The center is 0. This is expected because the groups are equally likely to end up with the higher mean.</p>
    </solution>
  </exercise>
  
  <exercise xml:id="inv4-9-k" label="I4.9.11">
    <title>Assess Observed Value</title>
    <statement>
      <p>How surprising does our observed value for the mean difference appear to be, under the simulation's assumption that presence/absence of up-tempo music does not affect typing speed?</p>
    </statement>
    <response/>
    <solution>
      <p>The average difference observed by the student researchers (2.618) falls in the upper right tail of the distribution. It does appear to be a bit unlikely to happen under the assumption that presence/absence of music does not affect typing speed.</p>
    </solution>
  </exercise>
  
  <exercise xml:id="inv4-9-l" label="I4.9.12">
    <title>p-value and Conclusion</title>
    <statement>
      <p>Use the applet to determine the proportion of simulated Average Differences that are more extreme than what we observed, and report the empirical <em>p</em>-value. What conclusion will you come to based on this <em>p</em>-value? Can you draw a cause-and-effect conclusion? For what population?</p>
    </statement>
    <hint>
      <p>Be sure to consider the alternative hypothesis when deciding what to consider as "more extreme."</p>
    </hint>
    <response/>
    <solution>
      <p>Example results:</p>
      <image source="images/Inv4.9solsk.jpg" width="70%">
        <description>Randomization test results from applet</description>
      </image>
      <p>Because the applet used a different direction of subtraction, we want to find the proportion of simulated values that are 2.618 or larger. With an approximate <em>p</em>-value of 0.0053 <m>\lt</m> 0.05, we reject the null hypothesis and find statistically significant evidence in favor of the alternative hypothesis, that long-run average typing speed is larger with the up-tempo music. We can draw a cause-and-effect conclusion with this small <em>p</em>-value, because the student employed random assignment in the ordering of the conditions. We don't have a lot of information about how the sample was selected, but it does not appear to be random sampling and we should be cautious in generalizing these results beyond the musicians and athletes at this university.</p>
    </solution>
  </exercise>
  
  <p><alert>Mathematical Model</alert></p>
  
  <exercise xml:id="inv4-9-m" label="I4.9.13">
    <title>Normal Distribution Model</title>
    <statement>
      <p>Does the randomization distribution appear that it would be reasonably well-modeled by a normal distribution?</p>
    </statement>
    <choices randomize="no">
      <choice correct="yes">
        <statement><p>Yes</p></statement>
        <feedback><p>Correct! The randomization distribution appears reasonably symmetric and bell-shaped.</p></feedback>
      </choice>
      <choice>
        <statement><p>No</p></statement>
        <feedback><p>Look at the shape of the randomization distribution in the applet.</p></feedback>
      </choice>
    </choices>
  </exercise>
  
  <exercise xml:id="inv4-9-m2" label="I4.9.13b">
    <title><em>t</em>-Distribution Model</title>
    <statement>
      <p>If you change the Statistic from Avg Difference to <em>t</em>-statistic (and check the Overlay <em>t</em> distribution box), do the standardized statistics appear well-modeled by a <em>t</em>-distribution?</p>
    </statement>
    <choices randomize="no">
      <choice correct="yes">
        <statement><p>Yes</p></statement>
        <feedback>
          <p>Correct! The <em>t</em>-distribution overlays the randomization distribution well.</p>
          <image source="images/Inv4.9solsl.png" width="70%">
            <description>Example of t-distribution overlay</description>
          </image>
        </feedback>
      </choice>
      <choice>
        <statement><p>No</p></statement>
        <feedback><p>Check the overlay of the <em>t</em>-distribution on the randomization distribution in the applet.</p></feedback>
      </choice>
    </choices>
  </exercise>
  
  <assemblage>
    <title>Definitions: Paired <em>t</em>-test</title>
    <p>A <term>paired <em>t</em>-test</term> standardizes the mean of the differences from a matched-pairs design.</p>
    <p><me>t = \frac{\bar{x}_{diff} - 0}{s_{diff}/\sqrt{n_{diff}}}</me></p>
    <p>where <m>\bar{x}_{diff}</m> is the sample mean of differences and <m>s_{diff}</m> is the sample standard deviation of the differences. The standardized statistic above assumes the hypothesized difference is zero, but this can be changed.</p>
    <p><alert>Technical conditions:</alert> When the distribution of differences is normally distributed or the sample size is large (e.g., <m>n > 30</m> pairs of observations), this <em>t</em>-statistic is well modeled by a <em>t</em>-distribution with <m>n - 1</m> degrees of freedom.</p>
    <p>A <term>paired <em>t</em>-confidence interval</term> for <m>\mu_d</m> has the form <me>\bar{x}_{diff} \pm t_{n-1}^* \times (s_{diff}/\sqrt{n_{diff}})</me></p>
    <p><alert>Note:</alert> These are a special case of the one-sample <em>t</em>-procedures that can be applied to a single sample of quantitative data (see <xref ref="investigation2-5">Investigation 2.5</xref>). In this case, variable of interest is the difference in the quantitative response for each observational unit pair.</p>
  </assemblage>
  
  <exercise xml:id="inv4-9-n" label="I4.9.14">
    <title>Calculate and Interpret <em>t</em>-statistic</title>
    <statement>
      <p>Use the summary statistics to calculate, by hand, and then interpret the value of this standardized statistic.</p>
    </statement>
    <response/>
    <solution>
      <p><m>t = \frac{2.618 - 0}{5.71/\sqrt{34}} \approx 2.67</m></p>
      <p>Interpretation: Our <m>\bar{x}_d</m> is 2.67 standard errors above the hypothesized <m>\mu_d</m> of 0.</p>
    </solution>
  </exercise>
  
  <exercise xml:id="inv4-9-o" label="I4.9.15">
    <title>Compare p-values</title>
    <statement>
      <p>Using the Overlay <em>t</em> distribution in the applet, how does the <em>p</em>-value compare to the empirical <em>p</em>-value from the simulated paired-randomization test? Do the <em>t</em>-procedures appear to be valid for these data?</p>
    </statement>
    <response/>
    <solution>
      <p>The standardized statistic is 2.68 and the <em>p</em>-value is 0.006. This is very similar to the <em>p</em>-value from the randomization test (0.005).</p>
      <image source="tech_images/inv4-9-tbi.png" width="70%">
        <description>Theory-based inference results</description>
      </image>
    </solution>
  </exercise>
  
  <exercise xml:id="inv4-9-p" label="I4.9.16">
    <title>Confidence Interval</title>
    <statement>
      <p>Use the check box to display the 95% CI for average difference. Report and interpret this interval in context. Is the confidence interval consistent with the p-value? What additional information is provided by the confidence interval?</p>
    </statement>
    <response/>
    <solution>
      <p>95% CI: (0.66, 4.57), The long-run average difference in typing speeds (no music-music) is estimated to fall between 0.66 and 4.57 wpm with 95% confidence. We would have enough evidence to conclude that there is an effect of music, as this interval does not include zero. This is consistent with a <em>p</em>-value of 0.006. The additional information provided by the confidence interval is a plausible range for the mean difference in typing speed.</p>
    </solution>
  </exercise>
  
  <exercise xml:id="inv4-9-q" label="I4.9.17">
    <title>Verify with Software</title>
    <statement>
      <p>Verify your results using software.</p>
    </statement>
    <response/>
    <hint>
      <title>R</title>
      <p><alert>In R:</alert> you can use the t.test command as before but specify the data are paired, e.g.,</p>
      <pre>
> t.test(WithMusic, NoMusic, alternative="greater", conf.level = .95, paired=TRUE)
      </pre>
      <p>OR with stacked data</p>
      <pre>
> t.test(speed~condition, alt="greater", paired=TRUE)
      </pre>
    </hint>
    <hint>
      <title>JMP</title>
      <p><alert>In JMP:</alert></p>
      <ul>
        <li><p>Choose Analyze > Specialized Modeling > Matched Pairs</p></li>
        <li><p>Specify the two columns in the Y, Paired Response box and press OK</p></li>
      </ul>
      <p>The output will include the standardized statistic (t-Ratio), <em>p</em>-values, and confidence interval endpoints.</p>
    </hint>
    <solution>
      <p><alert>R output:</alert></p>
      <image source="images/Inv4.9solspR.png" width="70%">
        <description>R output for paired t-test</description>
      </image>
      <p><alert>JMP output:</alert></p>
      <image source="images/Inv4.9solspJMP.png" width="60%">
        <description>JMP output for paired t-test</description>
      </image>
    </solution>
  </exercise>
  
  <p><alert>Discussion</alert>: To compare two groups on a quantitative variable, a more powerful study design than randomly assigning individuals to two groups, if possible, is to pair individuals (or take two measurements on each individual) and measure both responses in each pair (See Example 4.4). This pairing accounts for the variability from individual to individual and allows for a more direct comparison between the two conditions of interest. For example, if two measurements are taken on each individual, there should not be any other systematic differences between the measurements other than the treatment effect. Randomizing will still be important in determining the order of the two treatments, thereby eliminating order as a potential confounding variable. By accounting for the variability in individuals, this should increase the power of the test of significance, making it easier to detect a difference between the two conditions if one really exists. To analyze such data, perform a matched-pairs randomization test or a (one sample) <em>t</em>-test on the differences.</p>
  
  <p><alert>Note:</alert> The standard error of the difference in means is equivalent to <m>SE(\bar{X}_1 - \bar{X}_2) = \sqrt{\frac{s_1^2 + s_2^2 - 2rs_1s_2}{n}}</m>, which shows how the positive correlation between the two sets of measurements (<m>r</m>) reduces the estimated standard error of the statistic.</p>
  
  <assemblage>
    <title>Study Conclusions</title>
    <p>A paired experiment comparing typing speeds with and without up-tempo classical music (Overture to Candide performed by the London Symphony Orchestra) found participants were significantly faster on average with the music. A paired <em>t</em>-test on the mean difference give a one-sided p-value of 0.006, similar to the simulation-based p-value using "random swapping" of the speeds to represent no difference between the two treatment conditions. We are 95% confident that participants like those in this study (e.g., college students, music students or athletes willing to help out a friend) type, on average, 0.63 to 4.61 more words per minute when listening to the up-tempo music. This evidence is much stronger than when we only compared the participants on their first tests, because of both effectively doubling the sample size and also reducing the amount of "unexplained variation" in the response variable. The person-to-person variation in typing speeds was around 15 wpm, compared to the person-to-person variation in difference in typing speeds which was around 5 wpm. A further analysis could compare the average improvement with music between the music students and the athletes.</p>
  </assemblage>
  
  <subsection xml:id="practice-4-9a">
    <title>Practice Problem 4.9A</title>
    
    <exercise xml:id="practice-4-9a-1" label="P4.9A.1">
      <title>Power with SD = 15</title>
      <statement>
        <p>Use statistical software to determine the power of detecting a difference of 5 wpm in a two-sample <em>t</em>-test if the sample standard deviations are 15 wpm. (You can assume a 5% level of significance and a one-sided alternative, as well as a total sample size of 34.)</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-4-9a-2" label="P4.9A.2">
      <title>Power with SD = 5</title>
      <statement>
        <p>Repeat (a) assuming the sample standard deviations are 5 wpm.</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-4-9a-3" label="P4.9A.3">
      <title>Power for Paired <em>t</em>-test</title>
      <statement>
        <p>Use statistical software to determine the power of detecting a difference of 5 wpm in a one-sample paired <em>t</em>-test assuming the sample standard deviation of the differences is 5 wpm.</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-4-9a-4" label="P4.9A.4">
      <title>Compare Power</title>
      <statement>
        <p>How does the power of the paired <em>t</em>-test compare to the power of the two-sample <em>t</em>-test? (Cite appropriate evidence.)</p>
      </statement>
      <response/>
    </exercise>
    
  </subsection>
  
  <subsection xml:id="practice-4-9b">
    <title>Practice Problem 4.9B</title>
    
    <introduction>
      <p>Scientists have long been interested in whether there are physiological indicators of diseases such as schizophrenia. In a <url href="https://www.nejm.org/doi/full/10.1056/nejm199003223221201">1990 study</url> by Suddath et. al., reported in Ramsey and Schafer (2002), researchers used magnetic resonance imaging to measure the volumes of various regions of the brain for a sample of 15 monozygotic twins, where one twin was affected by schizophrenia and other not ("unaffected"). The twins were found in a search through the United States and Canada, the ages ranged from 25 to 44 years, with 8 male and 7 female pairs. The data (in cubic centimeters) for the left hippocampus region of the brain are in <url href="http://www.rossmanchance.com/iscam2/data/hippocampus.txt" visual="rossmanchance.com/iscam2/data/hippocampus.txt"><c>hippocampus.txt</c></url>. The primary research question is whether the data provide evidence of a difference in hippocampus volumes between those affected by schizophrenia and those unaffected.</p>
    </introduction>
    
    <exercise xml:id="practice-4-9b-1" label="P4.9B.1">
      <title>Calculate Differences</title>
      <statement>
        <p>Calculate the difference in hippocampus volumes for each pair of twins (unaffected <m>-</m> affected).</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-4-9b-2" label="P4.9B.2">
      <title>Confidence Interval and Validity</title>
      <statement>
        <p>Calculate and interpret a 95% confidence interval for the mean volume difference using the paired <em>t</em>-interval. Also comment on the validity of this procedure.</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-4-9b-3" label="P4.9B.3">
      <title>Statistical Significance</title>
      <statement>
        <p>Based on this confidence interval, is there statistically significant evidence that the mean difference in left hippocampus volumes is different from zero? Explain.</p>
      </statement>
      <response/>
    </exercise>
    
  </subsection>
  
</section>
