<?xml version="1.0" encoding="UTF-8"?>
<pretext>
  <article xml:id="iscam">
    <title>ISCAM: Investigating Statistical Concepts, Applications, and Methods</title>
    <docinfo>
      <document-id>iscam</document-id>
      <blurb shelf="Mathematics">Introductory statistics text with active learning for mathematically inclined students</blurb>
    </docinfo>
    
    <section xml:id="to-the-student">
      <title>To the Student</title>
      
      <p>Statistics is a mathematical science.</p>
      
      <p>Although this is a very short sentence, perhaps a self-evident one, and certainly one of the shortest that you will find in this book, we want to draw your attention to several things about it:</p>
      
      <ul>
        <li><p>We use the singular "is" and not the plural "are." It is certainly grammatically correct and more common usage to say "statistics are...", but that use of the term refers to statistics as numerical values. In this sentence we mean statistics as a field of study, one that has its own concepts and techniques, and one that can be exciting to study and practice.</p></li>
        
        <li><p>We use "mathematical" as an adjective. Statistics certainly makes use of much mathematics, but it is a separate discipline and not a branch of mathematics. Many, perhaps most, of the concepts and methods in statistics are mathematical in nature, but there are also many that do not involve mathematics. You will see an example of this early in the book as you study the difference between observational studies and controlled experiments. You will find that even in cases where the mathematical aspects of two situations may be identical, the scope of one's conclusions depends crucially on how the data were collected, a statistical rather than a mathematical consideration.</p></li>
        
        <li><p>We use the noun "science." Statistics is the science of gaining insight from data. Data are (notice the plural here) pieces of information (often but not always numerical) gathered on people or objects or processes. The science of statistics involves all aspects of inquiry about data. Well-designed studies begin with a research question or hypothesis, devise a plan for collecting data to address that issue, proceed to gather the data and analyze them, and then often make inferences about how the findings generalize beyond the particular group being studied. Statistics concerns itself with all phases of this process and therefore encompasses the scientific method.</p></li>
      </ul>
      
      <p>In these materials, our goal is to introduce you to this practice of statistics, to help you think about the applications of statistics and to study the mathematical underpinnings of the statistical methods. Most of all, we hope you will find fun and engaging examples. Statistics is a vitally important subject, and also fun to study and practice, largely because it brings you into contact with all kinds of interesting questions. You will analyze data from medical studies, legal cases, psychology experiments, sociological studies, and many other contexts. To paraphrase the late statistician John Tukey, "the best thing about statistics is that it allows you to play in everyone's backyard." You never know what you might learn in a statistics class!</p>
      
      <p>One of the first features you will notice about these materials is that you will play the active role of investigator. You will read about an actual study and consider the research question, and then we will lead you to discover and apply the appropriate tools for carrying out the analysis. A primary reason for the investigative nature of these materials is that we strongly believe that you will better understand and retain the concepts if you build your own knowledge and are engaged in the context. Be sure to also pay attention to the Study Conclusions to see how to effectively convey statistical information and to the Practice Problems for testing your understanding. Key terms are also hyperlinked (though some pdf viewers change the # to %23, so you need to change back or just go to the main glossary link).</p>
      
      <p>Though you will only scratch the surface of the statistical methods used in practice, you will learn fundamental concepts (such as variability, randomness, confidence, and significance) that are an integral part of many statistical analyses. A distinct emphasis will be the focus on how the data are collected and how this determines the scope of conclusions that you can draw from the data.</p>
      
    </section>
    
    <section xml:id="preliminaries">
      <title>Preliminaries</title>
    
    <subsection xml:id="invA">
      <title>Investigation A: Hurricanes and Climate Change</title>
      
      <p>One of the concerns with climate change is an increased number of tropical storms (including hurricanes and major hurricanes). In particular, in the "Atlantic Basin," scientists have tracked the number of "named storms" since 1851. 
      According to the <url href="https://www.nhc.noaa.gov/climo/" target="_blank">National Hurricane Center</url>:</p>
      
      <ul>
        <li><term>Tropical Storm</term><idx><h>tropical storm</h><h>a tropical cyclone with maximum sustained winds of 39 to 73 mph</h></idx>: A tropical cyclone with maximum sustained winds of 39 to 73 mph (34 to 63 knots).</li>
        <li><term>Hurricane</term><idx><h>hurricane</h><h>a tropical cyclone with maximum sustained winds of 74 mph or higher</h></idx>: A tropical cyclone with maximum sustained winds of 74 mph (64 knots) or higher. In the western North Pacific, hurricanes are called typhoons; similar storms in the Indian Ocean and South Pacific Ocean are called cyclones.</li>
        <li><term>Major Hurricane</term><idx><h>major hurricane</h><h>a tropical cyclone with max sustained winds of 111 mph or higher</h></idx>: A tropical cyclone with max sustained winds of 111 mph (96 knots) or higher.</li>
      </ul>
      
      <figure xml:id="fig-noaa-table">
        <image source="NOAA.png" width="70%">
          <description>Snippet from NOAA data table showing storm classifications</description>
        </image>
        <caption>Snippet from the <url href="https://www.nhc.noaa.gov/climo/images/AtlanticStormTotalsTable.pdf" target="_blank">NOAA data table</url></caption>
      </figure>
      
      <p>In 2020, scientists were alarmed because there were 14 recorded hurricanes, compared to 6 in 2019.</p>
      
      <figure xml:id="fig-first-graph">
        <image source="firstgraph.png" width="70%">
          <description>Graph showing hurricane counts for 2019 and 2020</description>
        </image>
      </figure>
      
      <exercise xml:id="hurricane-ex-a" label="A.1">
        <title>Calculate Percentage Change</title>
        <statement>
          <p>Calculate the percentage change in the number of tropical hurricanes between these two years.</p>
        </statement>
        <hint>
          <p>The formula for percentage change is: <m>\frac{\text{new value} - \text{old value}}{\text{old value}} \times 100\%</m></p>
        </hint>
        <answer>
          <p><m>\frac{14-6}{6} \times 100\% = 133.3\%</m> increase</p>
        </answer>
        <response/>
      </exercise>
      
      <exercise xml:id="hurricane-ex-b" label="A.2">
        <title>Evaluate the Evidence</title>
        <statement>
          <p>Does this convince you that climate change is leading to an increase in the number of hurricanes (in the Atlantic)? If so, explain why. If not, explain what additional information you would want to know.</p>
        </statement>
        <hint>
          <p>Consider: Is comparing just two years enough evidence? What about natural year-to-year variation?</p>
        </hint>
        <solution>
          <p>Just because one year saw a large increase doesn't necessarily reflect an increasing trend. It's also hard to know whether this is a "large" increase when we don't have information on how much this value tends to vary from year to year. We can't draw any causal conclusions because other things could have changed in that time frame. We also need to keep in mind that "number of hurricanes" is just one possible reflection of "climate change."</p>
        </solution>
        <response/>
      </exercise>
      
      <p>Below is a dotplot of the annual number of hurricanes from 1851 to 2024 <m>(n = 174)</m>.</p>
      
      <figure xml:id="fig-hurricane-dotplot">
        <image source="hurricanedotplot.png" width="80%">
          <description>Dotplot showing the distribution of annual number of hurricanes from 1851 to 2024</description>
        </image>
        <caption>Source: <url href="https://www.stormfax.com/huryear.htm">https://www.stormfax.com/huryear.htm</url></caption>
      </figure>
      
      <exercise xml:id="hurricane-ex-c" label="A.3">
        <title>Interpret the Dotplot</title>
        <statement>
          <p>What does one dot in the above graph represent?</p>
        </statement>
        <hint>
          <p>Each dot represents data from one observational unit. What is being measured over time here?</p>
        </hint>
        <answer>
          <p>One dot represents the number of hurricanes in one year.</p>
        </answer>
        <response/>
      </exercise>
      
      <p>A year with 14 hurricanes is certainly close to record setting, but we expect there to be some variation from year to year. Below is a timeplot of the number of hurricanes each year.</p>
      
      <figure xml:id="fig-hurricane-timeplot">
        <image source="hurricanetimeplot.png" width="80%">
          <description>Timeplot showing the number of hurricanes each year from 1851 to 2024</description>
        </image>
      </figure>
      
      <exercise xml:id="hurricane-ex-d" label="A.4">
        <title>Compare Graph Types</title>
        <statement>
          <p>What additional information is provided by this graph and why is that helpful?</p>
        </statement>
        <hint>
          <p>Think about what a timeplot shows that a dotplot doesn't - how does it arrange the data differently?</p>
        </hint>
        <answer>
          <p>Now we know which year each value corresponds to and we might see a gradual increasing trend overall since about 1970. We also see that the change from 6 to 14 is a rather large change between years.</p>
        </answer>
        <response/>
      </exercise>
      
      <exercise xml:id="hurricane-ex-e" label="A.5">
        <title>Assess Reported Mean</title>
        <statement>
          <p>The stormfax website reports the mean number of hurricanes between 1991-2020 to be 7. Does that appear consistent with the graph? Why do you think they chose that subset of years?</p>
        </statement>
        <hint>
          <p>Consider what's special about the 1991-2020 period. Is it the most recent data? Why might recent data be more relevant?</p>
        </hint>
        <solution>
          <p>This is consistent with the time plot. If we were to put a horizontal line at a height that goes through the middle of the values, 7 appears a reasonable value for that height. Perhaps they wanted to look at more recent data for more direct comparison with current data (opinions may vary).</p>
        </solution>
        <response/>
      </exercise>
      
      <p>Oftentimes a mean or average is reported, but with no measure of spread or variability. If all the years between 1991-2020 had between 6 and 8 hurricanes, we would react very differently to 14 hurricanes in one year than if all the years between 1991-2020 had between 2 and 15 hurricanes.</p>
      
      <assemblage xml:id="def-standard-deviation">
        <title>Terminology Detour: Standard Deviation</title>
        <p>The most common measure of the variability in a distribution of data is the <term>standard deviation</term><idx><h>standard deviation</h><h>the square root of the variance; a measure of spread in the outcomes of a distribution; roughly the average deviation from the mean of the distribution</h></idx>.</p>
        <p><me>s = \sqrt{\frac{\sum_{i=1}^n (y_i - \bar{y})^2}{n-1}}</me></p>
        <p>We can roughly interpret the standard deviation as the average "deviation" of the data values in the distribution from the mean of the distribution. Another interpretation: If we were to predict 7 as the number of hurricanes in a year between 1991-2020, the standard deviation would approximate the average "prediction error" for those years.</p>
      </assemblage>
      
      <p>Below is a dotplot of the data from 1991-2020 (<m>n = 31</m>).</p>
      
      <figure xml:id="fig-hurricane-dotplot-recent">
        <image source="hurricanedotplot2.png" width="80%">
          <description>Dotplot showing the distribution of annual number of hurricanes from 1991 to 2020</description>
        </image>
      </figure>
      
      <exercise xml:id="hurricane-ex-f" label="A.6">
        <title>Compare Subset to Full Dataset</title>
        <statement>
          <p>Conjecture: The mean is actually 7.2 hurricanes for this dataset. Do you think that is larger or smaller or quite similar to the mean for the full dataset? Explain your reasoning.</p>
        </statement>
        <hint>
          <p>Look at the timeplot - does the 1991-2020 period appear different from earlier decades?</p>
        </hint>
        <solution>
          <p>Answers will vary, but one might think the average is a bit higher in this more recent time frame than across the entire data set.</p>
        </solution>
        <response/>
      </exercise>
      
      <exercise xml:id="hurricane-ex-g" label="A.7">
        <title>Estimate Standard Deviation</title>
        <statement>
          <p>Conjecture: Provide a guess of the value of the standard deviation of these 31 values.</p>
        </statement>
        <hint>
          <p>Look at the dotplot - what's a typical distance from the mean of 7.2? Most values fall within what range?</p>
        </hint>
        <solution>
          <p>About half or a little more than half of the values appear to fall between 4 and 10, so maybe a standard deviation of around 3 hurricanes?</p>
        </solution>
        <response/>
      </exercise>
      
      <exercise xml:id="hurricane-ex-h" label="A.8">
        <title>Compare Standard Deviations</title>
        <statement>
          <p>Conjecture: How do you think the standard deviation from (g) compares to the standard deviation of the full dataset? Explain your reasoning.</p>
        </statement>
        <hint>
          <p>Compare the spread in the 1991-2020 dotplot to the spread in the full 1851-2024 dotplot.</p>
        </hint>
        <solution>
          <p>The largest values (e.g., 14, 15) are in this subset and the spread in the values does appear larger in the more recent years than overall (fewer values in the 3 to 7 range compared to the full dataset?).</p>
        </solution>
        <response/>
      </exercise>
      
      <p>We will often use the standard deviation as a "ruler" to help us measure distances of observations from the mean of the distribution.</p>
      
      <exercise xml:id="hurricane-ex-i" label="A.9">
        <title>Standardize the Value</title>
        <statement>
          <p>If we use a mean of 7.2 and a standard deviation of 3.3 hurricanes, how many standard deviations away from the mean is a value of 14 hurricanes? Above or below the mean?</p>
        </statement>
        <hint>
          <p>Calculate: <m>\frac{14 - 7.2}{3.3}</m></p>
        </hint>
        <answer>
          <p><m>\frac{14 - 7.2}{3.3} = 2.06</m> standard deviations above the mean</p>
        </answer>
        <response/>
      </exercise>
      
      <assemblage xml:id="def-standardizing">
        <title>Terminology Detour: Standardizing</title>
        <p>The general formula for standardizing an observation's position in the distribution is:</p>
        <p><me>\frac{\text{observation value} - \text{mean of distribution}}{\text{standard deviation of distribution}}</me></p>
        <p>We will often consider a value far from the mean of a distribution if it is more than two standard deviations away.</p>
      </assemblage>
      
      <p>In this investigation, you have just touched on one piece of information related to climate change. In fact, scientists are less concerned about the number of storms but in the intensity of the storms and how warming of the surface ocean may be leading to more destructive storms. Looking at a single year in isolation or even a pair of years creates a very incomplete picture of trends over time, and while we expect some natural variation from year-to-year, the question to scientists is whether the overall trend being observed is larger than what we can reasonably attributed to natural variation.</p>
      
      <insight xml:id="points-to-keep-in-mind">
        <title>Points to keep in mind</title>
        <ul>
          <li>It's important to determine which variables are most relevant to the research question and whether you can collect the data you need to answer the question.</li>
          <li>Simple graphs can be very informative, but you should also take care in considering the most meaningful variable representation of what you are studying even before you begin graphing.</li>
          <li>It is imperative to consider variability and to think about possible sources of variation. Sometimes you may be able to explain and "control for" a source of variation. Often you will have to dig deeper into reasons for unusual observations and whether it is appropriate to remove them from the analysis.</li>
          <li>The quality of your inferences will depend A LOT on the quality of the data that are collected. Not much can be learned from poorly or improperly collected data or data from a completely different time period.</li>
        </ul>
      </insight>
      
      <paragraphs xml:id="discussion-a">
        <title>Discussion</title>
        <p>When exploring a research question, one of the first steps is to define the variable involved, e.g., the number of hurricanes. This is an example of <term>quantitative variables</term>, as opposed to a <term>categorical variable</term> like whether the storm has winds over 74 mph. Dotplots are good choices for visualizing a quantitative variable for a small dataset. When looking at a distribution of a single quantitative variable like this, we are often interested in three key features:</p>
        <ul>
          <li><em>Center</em>: What would you consider a "typical" value in the distribution?</li>
          <li><em>Variability</em>: How clustered together or consistent are the observations? Or are they far apart?</li>
          <li><em>Shape</em>: Are some values more common than others? Are the values symmetric about the center?</li>
          <li>Are there any <em>unusual observations</em> that don't follow the overall pattern? Are there any explanations for these values?</li>
        </ul>
        <p>To summarize the center of the distribution, we often report the <term>mean</term><idx><h>mean</h><h>the average of all numerical values in the data set</h></idx> (the arithmetic average of all the numerical values in the data set) and/or the <term>median</term><idx><h>median</h><h>a value such that at least 50% of the observations in the data set are smaller than that value and at least 50% of the observations in the data set are larger than that value</h></idx> (a middle value such that 50% of the data values are smaller and 50% are larger).</p>
      </paragraphs>
      
      <p>With most investigations we will also provide a follow-up practice problem or two for you to try on your own to assess your understanding of the material.</p>
      
      <subsection xml:id="practiceA">
        <title>Practice Problem A.A</title>
        
        <p><url href="https://www.rossmanchance.com/applets/2021/descstats/Dotplot.htm" target="_blank">Open the Descriptive Statistics applet</url> to complete this practice problem.</p>
        
        <image source="descriptivestatistics-screenshot.png" width="100%">
          <description>Screenshot of Descriptive Statistics applet interface</description>
          <url href="https://www.rossmanchance.com/applets/2021/descstats/Dotplot.htm" target="_blank"/>
        </image>
        
        <p>From the <url href="https://www.rossmanchance.com/iscam3/files.html" target="_blank">ISCAM data files and applets page</url> (Chapter 0), you can view the data in <url href="https://www.rossmanchance.com/iscam4/data/AtlanticStorms.txt" target="_blank">AtlanticStorms.txt</url>. Use your mouse (or ctrl-A) to highlight all four columns and then copy and paste these data to your clipboard. In the Descriptive Statistics applet, clear the existing data (press <em>Clear</em>), click in the Paste data box and paste the data from your clipboard. Press the <em>Use Data</em> button. [Alternatively, this dataset is listed in the Select data pull-down menu as Atlantic Storms.] Use the Quantitative Variable pull-down menu to select the Number of Hurricanes variable (Hurricanes).</p>
        
        <assemblage>
          <title>Shape of Distributions</title>
          <p>The shape of a distribution is often classified as <term>symmetric</term><idx><h>symmetric</h><h>a distribution with a mirror image on each side of the center</h></idx> (mirror image on each side of the center) or <term>skewed</term><idx><h>skewed</h><h>a distribution with a longer tail on one side</h></idx>.</p>
          <ul>
            <li>Distributions with a longer right tail are labeled <term>skewed to the right</term></li>
            <li>Distributions with a longer left tail are labeled <term>skewed to the left</term></li>
          </ul>
          <p>The <term>skewness statistic</term> measures the lack of asymmetry in a distribution (due values above the mean extend further than values below the mean on average) using a <m>(y_i-\bar{y})^3</m> term. Positive values indicate a skewed right distribution, negative values indicate skewed left, and values near 0 indicate a symmetric distribution.</p>
        </assemblage>
        
        <exercise xml:id="practice-a2a-a" label="PPA.1">
          <statement>
            <p>Based on the graph, would you consider the "number of hurricanes" distribution to be symmetric, skewed to the right or skewed to the left? Check the Skewness statistic box, does the value agree with your judgement from the graph?</p>
          </statement>
          <response/>
        </exercise>
        
        <assemblage>
          <title>Mean and Median</title>
          <p>If there are <m>n</m> numerical values and we refer to them as <m>y_1, y_2, \ldots, y_n</m>,</p>
          <p>The <term>mean</term>, <m>\bar{y}</m>, is the average of all numerical values in the data set: <me>\bar{y} = \frac{\sum_{i=1}^n y_i}{n}</me></p>
          <p>The <term>median</term> is a value such that 50% of the data lies below and 50% of the data lies above that value: median position: <m>(n+1)/2</m></p>
        </assemblage>
        
        <!-- <figure xml:id="fig-hurricane-dotplot-recent-3">
          <image source="hurricanedotplot3.png" width="80%">
            <description>Dotplot showing the distribution of annual number of hurricanes from 1991 to 2020</description>
          </image>
        </figure> -->
        
        <exercise xml:id="practice-a2a-b" label="PPA.2">
          <statement>
            <p>Explore the mean and median:</p>
            <ul>
              <li>Check the box next to Guess for the Mean. Move the red line to where you think the mean of the distribution is.</li>
              <li>Check the box next to Guess for the Median. Move the blue line to where you think the median of the distribution is.</li>
              <li>Now check Actual for both. Which is larger, the mean or the median?</li>
            </ul>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-a2a-c" label="PPA.3">
          <statement>
            <p>Check the box for Guess for the standard deviation. Use your mouse to move one of the edges of the red rectangle to a distance that you think is representative of a "typical distance from the mean" (some values are closer, some are further). Then check the Actual box. How did you do?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-a2a-d" label="PPA.4">
          <statement>
            <p>How does the standard deviation of the full dataset compare to the 3.3 value for the years 1991-2020? Summarize what this tells us about the behavior of hurricanes.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
    
    <subsection xml:id="investigationB">
      <title>Investigation B: Random Babies</title>
      
      <p>In the previous investigation, you looked at historical data for a subset of homes from a larger population. In this investigation, the goal is to explore a <em>random</em> process. We apologize in advance for the absurd but memorable process below. Other examples of a random process are coin flipping or lead measurements taken at different times from the same house.</p>
      
      <p>Suppose that on one night at a certain hospital, four mothers give birth to four babies. As a very sick joke, the hospital staff decides to return babies to their mothers completely at random. Our goal is to look for the pattern of outcomes from this process, with regard to the issue of how many mothers get the correct baby. This enables us to investigate the underlying properties of this child-returning process, such as the probability that at least one mother receives her own baby.</p>
      
      <exercise xml:id="random-babies-ex-a" label="B.1">
        <title>Initial Prediction</title>
        <statement>
          <p>Before we proceed, what do you think is more likely to happen: that no mothers get the correct baby, or that all four mothers get the correct baby? Write down your initial guess and explain your reasoning.</p>
        </statement>
        <response/>
      </exercise>
      
      <p>Because it is clearly not feasible to actually carry out this horrible child-returning process over and over again, we will instead <em>simulate</em> the random process to investigate what would happen in the long run. Suppose the four babies were named Murphy Miller, Wallis Williams, Bari Brown, and Shea Smith. Take four index cards and write the first name of each baby on a different card. Now take a sheet of paper and divide it into four regions, one for each mom. Next shuffle the index cards, face down, and randomly deal the babies back to the mothers. Flip the cards over and count the number of moms who received the correct baby.</p>
      
      <exercise xml:id="random-babies-ex-b" label="B.2">
        <title>Conduct Physical Simulation</title>
        <statement>
          <p>Carry out this physical simulation at least 5 times and record your results. How many mothers received the correct baby in each trial?</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-c" label="B.3">
        <title>Identify Common Outcomes</title>
        <statement>
          <p>What was the most common outcome across your trials? What was the least common?</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-d" label="B.4">
        <title>Check Extreme Outcomes</title>
        <statement>
          <p>Did any of your trials result in all four mothers receiving the correct baby? Did any result in exactly three mothers receiving the correct baby?</p>
        </statement>
        <hint>
          <p>Think about whether it's even possible for exactly three mothers to get the correct baby.</p>
        </hint>
        <response/>
      </exercise>
      
      <paragraphs xml:id="simulation-analysis-b">
        <title>Simulation Analysis</title>
        
        <p>Now let's use technology to simulate this process many more times. <url href="https://www.rossmanchance.com/applets/2021/randombabies/RandomBabies.html?hideExtras=1" target="_blank">Open the Random Babies applet</url> and follow these steps:</p>
        
        <sidebyside widths="60% 35%" margins="0% 5%">
          <stack>
            <ul>
              <li>Press <alert>Randomize</alert>. Notice that the applet randomly returns babies to mothers and determines how many babies are returned to the correct home (by matching diaper colors). The applet also counts and graphs the resulting number of matches.</li>
              <li>Uncheck the <alert>Animate</alert> box and press <alert>Randomize</alert> a few more times. You should see the results accumulate in the table and the histogram.</li>
              <li>Click on the histogram bar representing the outcome of zero mothers receiving the correct baby. This shows you a "time plot" of the proportion of trials with 0 matches vs. the number of trials.</li>
              <li>Set the <alert>Number of trials</alert> to 100 and press <alert>Randomize</alert> a few times, noticing how the behavior of this graph changes.</li>
            </ul>
          </stack>
          
          <image source="randombabies-screenshot.png" width="100%">
            <description>Screenshot of Random Babies applet</description>
          </image>
        </sidebyside>
      </paragraphs>
      
      <exercise xml:id="random-babies-ex-e" label="B.5">
        <title>Run Applet Simulation</title>
        <statement>
          <p>Run the applet for at least 1000 trials total. What proportion of your trials resulted in zero mothers receiving the correct baby?</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-f" label="B.6">
        <title>Estimate Probability</title>
        <statement>
          <p>Based on your simulation results, estimate the probability that at least one mother receives the correct baby.</p>
        </statement>
        <hint>
          <p>Think about the complement: if at least one mother gets the correct baby, that's the opposite of zero mothers getting the correct baby.</p>
        </hint>
        <response/>
      </exercise>
      
      <assemblage xml:id="def-random-process">
        <title>Definition: Random Process and Probability</title>
        <p>A <term>random process</term><idx><h>random process</h><h>generates observations according to a random mechanism</h></idx> generates observations according to a random mechanism, like a coin toss. Whereas we can't predict each individual outcome with certainty, we do expect to see a long-run pattern to the results.</p>
        
        <p>The <term>probability</term><idx><h>probability</h><h>the long-run proportion of times an event occurs</h></idx> of a random event occurring is the <alert>long-run proportion</alert> (or <alert>relative frequency</alert>) of times that the event would occur if the random process were repeated over and over under identical conditions.</p>
        
        <p>You can <em>approximate</em> a probability by simulating (i.e., artificially recreating) the process many times. Simulation leads to an <em>empirical estimate</em> of the probability, which is the proportion of times that the event occurs in the simulated repetitions of the random process. Increasing the number of repetitions generally results in more accurate estimates of the long-run probabilities.</p>
      </assemblage>
      
      <exercise xml:id="random-babies-ex-g" label="B.7">
        <title>Compare to Initial Guess</title>
        <statement>
          <p>How does your empirical estimate from the simulation compare to your initial guess in checkpoint B.1?</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-h" label="B.8">
        <title>Understand Variability</title>
        <statement>
          <p>If you were to run another 1000 trials, would you expect to get exactly the same proportion of trials with zero matches? Explain.</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-i" label="B.9">
        <title>Analyze Running Proportion</title>
        <statement>
          <p>Look at the time plot showing the running proportion of trials with 0 matches. What do you notice about the behavior of this proportion as the number of trials increases?</p>
        </statement>
        <hint>
          <p>Does the proportion stabilize or continue to vary wildly?</p>
        </hint>
        <response/>
      </exercise>
      
      <paragraphs xml:id="exact-analysis-b">
        <title>Exact Mathematical Analysis</title>
        
        <p>One disadvantage to using simulation to estimate a probability like this is that everyone will potentially obtain a different estimate. Even with a very large number of trials, your result will still only be an estimate of the actual long-run probability. For this particular scenario however, we can determine exact theoretical probabilities.</p>
        
        <p>First, let's list all possible outcomes for returning four babies to their mothers at random. We can organize our work by letting 1234 represent the outcome where the first baby went to the first mother, the second baby to the second mother, the third baby to the third mother, and the fourth baby to the fourth mother. In this scenario, all four mothers get the correct baby. As another example, 1243 means that the first two mothers get the right baby, but the third and fourth mothers have their babies switched.</p>
      </paragraphs>
      
      <assemblage xml:id="def-sample-space">
        <title>Definition: Sample Space</title>
        <p>A <term>sample space</term><idx><h>sample space</h><h>a list of all possible outcomes of a random process</h></idx> is a list of all possible outcomes of a random process.</p>
      </assemblage>
      
      <p>All of the possible outcomes are listed below:</p>
      
      <p><alert>Sample Space:</alert></p>
      <table xml:id="table-sample-space-babies">
        <tabular>
          <row><cell>1234</cell><cell>1243</cell><cell>1324</cell><cell>1342</cell><cell>1423</cell><cell>1432</cell></row>
          <row><cell>2134</cell><cell>2143</cell><cell>2314</cell><cell>2341</cell><cell>2413</cell><cell>2431</cell></row>
          <row><cell>3124</cell><cell>3142</cell><cell>3214</cell><cell>3241</cell><cell>3412</cell><cell>3421</cell></row>
          <row><cell>4123</cell><cell>4132</cell><cell>4213</cell><cell>4231</cell><cell>4312</cell><cell>4321</cell></row>
        </tabular>
      </table>
      
      <p>In this case, returning the babies to the mothers completely at random implies that the outcomes in our sample space are equally likely to occur (<em>outcome probability</em> = 1 / <em>number of possible outcomes</em>).</p>
      
      <exercise xml:id="random-babies-ex-j" label="B.10">
        <title>Count Sample Space</title>
        <statement>
          <p>How many possible outcomes are there in the sample space? What is the probability of any one specific outcome (e.g., 1234)?</p>
        </statement>
        <answer>
          <p>There are 24 possible outcomes. Each has probability 1/24 <m>\approx 0.0417</m>.</p>
        </answer>
        <response/>
      </exercise>
      
      <p>You could have determined the number of possible outcomes without having to list them first. For the first mother to receive a baby, she could receive any one of the four babies. Then there are three babies to choose from in giving a baby to the second mother. The third mother receives one of the two remaining babies and then the last baby goes to the fourth mother. Because the number of possibilities at one stage of this process does not depend on the outcome (which baby) of earlier stages, the total number of possibilities is the product <m>4 \times 3 \times 2 \times 1 = 24</m>. This is also known as <m>4!</m>, read "4 factorial." Because the above outcomes are equally likely, the probability of any one of the above outcomes occurring is <m>1/24</m>. Although these 24 outcomes are equally likely, we were more interested above in the probability of 0 matches, 1 match, etc.</p>
      
      <assemblage xml:id="def-random-variable">
        <title>Definition: Random Variable</title>
        <p>A <term>random variable</term><idx><h>random variable</h><h>maps outcomes of a random process to numerical values</h></idx> maps each possible outcome of the random process (the sample space) to a numerical value. We can then talk about the <em>probability distribution</em> of the random variable. These random variables are usually denoted by capital roman letters, e.g., <m>X</m>, <m>Y</m>. A random variable is <term>discrete</term><idx><h>discrete random variable</h><h>a random variable with countable possible values</h></idx> if you can list each individual value that can be observed for the random variable.</p>
      </assemblage>
      
      <exercise xml:id="random-babies-ex-k" label="B.11">
        <statement>
          <p>Define the random variable <m>X</m> to be the number of mothers who receive the correct baby. What are the possible values of <m>X</m>?</p>
        </statement>
        <answer>
          <p>The possible values are 0, 1, 2, and 4. (Note: 3 is not possible!)</p>
        </answer>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-l" label="B.12">
        <statement>
          <p>Go through the sample space and count how many outcomes result in each possible value of <m>X</m> (0, 1, 2, or 4 matches).</p>
        </statement>
        <hint>
          <p>For each outcome like 1234 or 2143, count how many positions match (first baby to first mother, second to second, etc.)</p>
        </hint>
        <response/>
      </exercise>
      
      <assemblage xml:id="probability-rule-equally-likely">
        <title>Probability Rule</title>
        <p>When the outcomes in the sample space are equally likely, the probability of any one of a set of outcomes (an event) occurring is the number of outcomes in that set divided by the total number of outcomes in the sample space.</p>
      </assemblage>
      
      <exercise xml:id="random-babies-ex-m" label="B.13">
        <statement>
          <p>Calculate the exact probability of each possible value of <m>X</m>. Create a probability distribution table showing <m>P(X = 0)</m>, <m>P(X = 1)</m>, <m>P(X = 2)</m>, and <m>P(X = 4)</m>.</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-n" label="B.14">
        <title>Compare to Simulation</title>
        <statement>
          <p>How do your exact probabilities compare to the empirical estimates you obtained from the simulation?</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-o" label="B.15">
        <title>Calculate Exact Probability</title>
        <statement>
          <p>Calculate the exact probability that at least one mother receives the correct baby.</p>
        </statement>
        <hint>
          <p>Use the complement rule: <m>P(\text{at least one match}) = 1 - P(\text{zero matches})</m></p>
        </hint>
        <response/>
      </exercise>
      
      <assemblage xml:id="probability-rules">
        <title>Probability Rules</title>
        <p><ul>
          <li><p>The sum of the probabilities for all possible outcomes equals one.</p></li>
          <li><p><term>Complement rule</term><idx><h>complement rule</h><h>probability of not A equals 1 minus probability of A</h></idx>: The probability of an event happening is one minus the probability of the event not happening.</p></li>
          <li><p><term>Addition rule for disjoint events</term><idx><h>addition rule</h><h>for mutually exclusive events, sum the probabilities</h></idx>: The probability of at least one of several events is the sum of the probabilities of those events as long as there are no outcomes in common across the events (i.e., the events are <term>mutually exclusive</term> or <term>disjoint</term>).</p></li>
        </ul></p>
      </assemblage>
      
      <p>We can also consider the <term>expected value</term><idx><h>expected value</h><h>the long-run average value of a random variable</h></idx> of the number of matches, which is interpreted as the long-run average value of the random variable. For a discrete random variable, <m>X</m>, we can calculate the expected value of the random variable <m>X</m>, denoted <m>E(X)</m>, by employing the idea of a weighted average of the different possible values of the random variable, but now the "weights" will be given by the probabilities of those values:</p>
      
      <p><me>E(X) = \sum (\text{value}) \times (\text{probability of value})</me></p>
      
      <exercise xml:id="random-babies-ex-p" label="B.16">
        <statement>
          <p>Calculate the expected value <m>E(X)</m> for the number of mothers who receive the correct baby.</p>
        </statement>
        <hint>
          <p>Use the formula: <m>E(X) = 0 \times P(X=0) + 1 \times P(X=1) + 2 \times P(X=2) + 4 \times P(X=4)</m></p>
        </hint>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-q" label="B.17">
        <title>Interpret Expected Value</title>
        <statement>
          <p>Interpret the expected value in context. Does this mean that in any given trial, we expect this many mothers to receive the correct baby?</p>
        </statement>
        <response/>
      </exercise>
      
      <p>Notice that if we wanted to compute the average number of matches, say after 1000 trials, we would look at a weighted average:</p>
      
      <p><me>\bar{x} = \frac{1 + 0 + 2 + 0 + \cdots}{1000} = \frac{(\# \text{ of } 0\text{s}) \times 0 + (\# \text{ of } 1\text{s}) \times 1 + (\# \text{ of } 2\text{s}) \times 2 + (\# \text{ of } 4\text{s}) \times 4}{1000}</me></p>
      
      <p>But from the results we saw above, each term <m>(\#)/1000</m> converges to the probability of that outcome as we increase the number of repetitions, giving us the above formula for <m>E(X)</m>. So we will interpret the expected value as the long-run mean of the outcomes.</p>
      
      <p>Another property of a random variable is its <term>variance</term><idx><h>variance</h><h>measures variability in values of a random variable</h></idx>. This measures how variable the values of the random variable will be. For a discrete random variable, <m>X</m>, we can again use a type of weighted average, based on the probabilities of each value and the squared distances between the possible values of the random variable and the expected value.</p>
      
      <p><me>\text{Var}(X) = \sum_{\text{all possible values}} (\text{value} - E(X))^2 \times (\text{probability of value})</me></p>
      
      <exercise xml:id="random-babies-ex-r" label="B.18">
        <statement>
          <p>Calculate the variance of <m>X</m>.</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-s" label="B.19">
        <statement>
          <p>Calculate the standard deviation of <m>X</m> (the square root of the variance). Interpret this value in context.</p>
        </statement>
        <response/>
      </exercise>
      
      <p>We will interpret this standard deviation similarly to how we did in Investigation A: how far the outcomes tend to be from the expected value. Here we are talking in terms of the probability model; in Investigation A we were talking in terms of the historical data.</p>
      
      <exercise xml:id="random-babies-ex-t" label="B.20">
        <title>Verify with Simulation</title>
        <statement>
          <p>Go back to the Random Babies applet and run a large number of simulations (at least 10,000). Calculate the mean and standard deviation of your simulated results. How do these compare to the theoretical expected value and standard deviation you calculated?</p>
        </statement>
        <response/>
      </exercise>
      
      <paragraphs xml:id="discussion-b">
        <title>Discussion</title>
        
        <p>Notice that we have used two methods to answer questions about this random process:</p>
        <ul>
          <li><em>Simulation</em> â€“ repeating the process under identical conditions a large number of times and seeing how often different outcomes occur.</li>
          <li><em>Exact mathematical calculations</em> using basic rules of probability and counting.</li>
        </ul>
        
        <p>This approach of looking at the analysis using both simulation and exact approaches will be a theme in this course. We will also consider some approximate mathematical models as well. You should consider these multiple approaches as a way to assess the appropriateness of each method. You should also be aware of situations where one method may be preferable to another and why.</p>
      </paragraphs>
      
      <subsection xml:id="practiceBA">
        <title>Practice Problem B.A</title>
        
        <p>Suppose three executives (Ari, Brooklyn, and Carson) drop their cell phones in an elevator and blindly pick them back up at random.</p>
        
        <exercise xml:id="practice-ba-a" label="PPB.A.1">
          <statement>
            <p>Write out the sample space using <em>ABC</em> notation for the outcomes.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-ba-b" label="PPB.A.2">
          <statement>
            <p>Carry out the exact analysis to determine the probability of at least one executive receiving his or her own phone.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-ba-c" label="PPB.A.3">
          <statement>
            <p>Calculate the expected number of matches for 3 executives. How does this compare to the case with 4 mothers?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-ba-d" label="PPB.A.4">
          <statement>
            <p>Use the <url href="https://www.rossmanchance.com/applets/2021/randombabies/RandomBabies.html?hideExtras=1" target="_blank">Random Babies applet</url> to check your results.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practiceBB">
        <title>Practice Problem B.B</title>
        
        <p>Reconsider the Random Babies scenario. Now suppose there were 8 mothers involved in this random process.</p>
        
        <exercise xml:id="practice-bb-a" label="PPB.B.1">
          <statement>
            <p>Calculate the (exact) probability that all 8 mothers receive the correct baby. [<em>Hint</em>: First determine how many possible outcomes there are for returning 8 babies to their mothers.]</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bb-b" label="PPB.B.2">
          <statement>
            <p>Calculate the probability that exactly 7 mothers receive the correct baby.</p>
          </statement>
          <hint>
            <p>Think carefully: is it possible for exactly 7 mothers to get the correct baby?</p>
          </hint>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bb-c" label="PPB.B.3">
          <statement>
            <p>Using the <url href="https://www.rossmanchance.com/applets/2021/randombabies/RandomBabies.html?hideExtras=1" target="_blank">Random Babies applet</url>, approximate the probability that at least one of the 8 mothers receives the correct baby. How does your approximation compare to the probability of this event with 4 mothers?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bb-d" label="PPB.B.4">
          <statement>
            <p>Using the Random Babies applet, approximate the expected value for the number of the eight mothers receiving the correct baby. How does your approximation compare to the situation with 4 mothers?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practiceBC">
        <title>Practice Problem B.C</title>
        
        <p>An American Roulette wheel consists of 18 black slots, 18 red slots, and 2 green slots. A ball is rolled while the wheel is spun and players can bet on which slot or type of slot the ball will end up in.</p>
        
        <exercise xml:id="practice-bc-a" label="PPB.C.1">
          <statement>
            <p>A common bet is color. If someone bets $1 on red, and the ball lands in any of the 18 red slots, the player wins $2 (a net profit of $1). What is the probability they will win their bet on red?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bc-b" label="PPB.C.2">
          <statement>
            <p>Include a one-sentence interpretation of the probability you calculated in (a).</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bc-c" label="PPB.C.3">
          <statement>
            <p>Another common bet is a number. If the ball lands on the chosen number, the player makes a profit of $35. What is the probability someone wins if they bet on a number?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bc-d" label="PPB.C.4">
          <statement>
            <p>Below are two graphs showing the average net winnings over 1000 simulated plays of a color bet and of a number bet. [<em>Hint:</em> What happened on the first 50 or so number bets?] Explain how you think the expected value (long-run average winnings) of each bet compares. Do they have the same sign?</p>
            <image source="roulette.png" width="70%">
              <description>Graph showing cumulative average net winnings over 1000 simulated plays for color bet (blue line) and number bet (red dashed line)</description>
            </image>
          </statement>
          <hint>
            <p>Look at where the graphs appear to be stabilizing as the number of plays increases. What does the long-run average appear to be approaching for each bet?</p>
          </hint>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bc-e" label="PPB.C.5">
          <statement>
            <p>Explain which bet displays a larger standard deviation.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
    
    <subsection xml:id="investigationC">
      <title>Investigation C: Modelling Hurricanes</title>
      
      <p>A model is an artificial representation or a simplification of something more complicated, like a toy airplane. Models can be useful in making predictions (e.g., weather models) or to help us better understand the phenomena under study. For example, what factors impact the severity of a hurricane?</p>
      
      <p>Visit <url href="https://scied.ucar.edu/interactive/make-hurricane">https://scied.ucar.edu/interactive/make-hurricane</url></p>
      
      <p><ul>
        <li><p>Move the red hurricane symbol to a circle on the map and read what happens.</p></li>
        <li><p>Switch between the Sea Surface Temperature, Moisture, and Wind maps to see the data for each circle.</p></li>
        <li><p>Which circles create the strongest hurricanes? Why?</p></li>
      </ul></p>
      
      <exercise xml:id="inv-c-a" label="IC.1">
        <title>Explain Hurricane Formation</title>
        <statement>
          <p>In your own words, explain how sea surface temperature, moisture, and wind interact to create strong hurricanes - or weaken them.</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="inv-c-b" label="IC.2">
        <title>Evaluate Model Accuracy</title>
        <statement>
          <p>Explain how you could evaluate the accuracy of this model of hurricane strength. What would you do next if you decided the model was not appropriate?</p>
        </statement>
        <response/>
      </exercise>
      
      <p>In this course, you will encounter two main types of models: <term>statistical models</term> and <term>probability/simulation models</term>. For example, the Random Babies simulation in Investigation B, allowed you to simulate hypothetical data to estimate probabilities of different events. As long as the model valid, we can predict that all four mothers receiving the correct babies would not happen very often in the long run. Most models rely on simplifying assumptions, like babies being returned <q>completely at random.</q></p>
      
      <p>The graphs below show histograms of the hurricane data with different probability models (red curves).</p>
      
      <figure xml:id="fig-hurricane-histograms">
        <sidebyside widths="45% 45%" margins="5%">
          <image source="hurhist1.png">
            <description>Histogram of hurricane data with probability model overlay (red curve)</description>
          </image>
          <image source="hurrhis2.png">
            <description>Histogram of hurricane data with alternative probability model overlay (red curve)</description>
          </image>
        </sidebyside>
      </figure>
      
      <exercise xml:id="inv-c-c" label="IC.3">
        <title>Compare Graphical Displays</title>
        <statement>
          <p>Describe the difference between a histogram and a dotplot. When might histograms be more useful?</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="inv-c-d" label="IC.4">
        <title>Select Best Model</title>
        <statement>
          <p>Which model (red curve) do you consider a better match to the observed data?</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="inv-c-e" label="IC.5">
        <title>Define Statistical Model</title>
        <statement>
          <p>What does the term <q>model</q> mean in this situation? Why would such a model be useful? What assumptions would you need to make? [Hint: Which do you consider more likely, a year with 13 hurricanes or with 14?]</p>
        </statement>
        <response/>
      </exercise>
      
      <p>To get an idea of a statistical model, you will collect some data:</p>
      
      <p><ul>
        <li><p>Using a measurement tool provided by your instructor, measure the circumference of a tennis ball.</p></li>
      </ul></p>
      
      <exercise xml:id="inv-c-measurement" label="IC.measurement">
        <title>Record Your Measurement</title>
        <statement>
          <p>Record your measurement here (to the nearest hundredths place): <var width="10"/> cm</p>
        </statement>
      </exercise>
      
      <exercise xml:id="inv-c-f" label="IC.6">
        <title>Examine Measurement Variation</title>
        <statement>
          <p>Did everyone in class find the same value? What are some possible explanations for different measurements?</p>
        </statement>
        <response/>
      </exercise>
      
      <p>We can think of these measurements as observations from a random process, which we can summarize with a statistical model. If we consider 28.5cm the <q>true value,</q> then we can write our statistical model as</p>
      
      <p>Measurement recorded = 28.5 + random error</p>
      
      <exercise xml:id="inv-c-g" label="IC.7">
        <title>Estimate Measurement Error</title>
        <statement>
          <p>How could we estimate the likely amount of random error in your class's measurement process?</p>
        </statement>
        <response/>
      </exercise>
      
      <p>Much of what scientists do is try to measure, explain, and minimize the amount of random variation.</p>
      
      <exercise xml:id="inv-c-h" label="IC.8">
        <title>Reduce Measurement Error</title>
        <statement>
          <p>Suggest a way to reduce the measurement error in your class's process.</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="inv-c-i" label="IC.9">
        <title>Understand Measurement Model</title>
        <statement>
          <p>What does the term <q>model</q> mean here? Why would such a model be useful? What assumptions need to be made?</p>
        </statement>
        <response/>
      </exercise>
      
      <subsection xml:id="practiceCA">
        <title>Practice Problem C.A</title>
        
        <p>Researchers often compare data generated from a model to observed data to help validate the model. If the model's data reasonably matches the observed data, that helps confirm that they (the model builders) understand the underlying data generating process.</p>
        
        <p>Open this app to model the tennis ball measurement random process: <url href="https://iambethchance.shinyapps.io/Modeling8/">https://iambethchance.shinyapps.io/Modeling8/</url></p>
        
        <exercise xml:id="practice-ca-a" label="PPC.A.1">
          <statement>
            <p>Suggest and label four possible sources of variation in the tennis ball measurements. Enter them as the four pie charts and conjecture sizes and probabilities for those sources (e.g., right now, Spinner 1 assumes a perfect measurement with 0.50 probability, a -.1 cm error with 0.25 probability and a +.1 cm error with 0.25 probability). Include a screen capture of your random process.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-ca-b" label="PPC.A.2">
          <statement>
            <p>Simulate one measurement by pressing the Simulate data button. What did you find for the total random error across your four sources? Will this be the same every time?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-ca-c" label="PPC.A.3">
          <statement>
            <p>Generate the same number of measurements as we took in class. Compare the simulated data to the actual data from class (e.g., shape, center, spread). What looks similar and what looks different?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-ca-d" label="PPC.A.4">
          <statement>
            <p>Suggest a way to adjust the model that you think will lead to simulated data that better matches the observed data. Briefly justify your choice.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practiceCB">
        <title>Practice Problem C.B</title>
        
        <p>Suppose human body temperatures can be modelled with a normal distribution with mean 98.6<degree/>F. Suppose you take repeated measures of your temperature over several days.</p>
        
        <exercise xml:id="practice-cb-a" label="PPC.B.1">
          <statement>
            <p>Which distribution below do you think is more believable? Briefly justify your choice.</p>
            <image source="PPC.B.png" width="80%">
              <description>Four histograms labeled A, B, C, and D showing different distributions of body temperature measurements centered around 98.6 degrees Fahrenheit</description>
            </image>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-cb-b" label="PPC.B.2">
          <statement>
            <p>Explain why you might be suspicious if someone told you Distribution D was their results.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-cb-c" label="PPC.B.3">
          <statement>
            <p>Suggest four possible sources of variation in your body temperature measurements.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-cb-d" label="PPC.B.4">
          <statement>
            <p>Distributions A-C have the same mean (98.6) but different spread or variability. Which of the graphs above has the largest standard deviation? Approximate the value of each standard deviation by interpreting the standard deviation as a <q>typical</q> deviation from the mean.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-cb-e" label="PPC.B.5">
          <statement>
            <p>The 4 distributions are all <q>bell-shaped and symmetric.</q> Do you think actual repeated body measurements on the same individual will behave this way? Briefly explain your reasoning.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-cb-f" label="PPC.B.6">
          <statement>
            <p>Suppose I randomly select one of the temperatures from Distribution C. Approximate the probability that the temperature is larger than 99<degree/>F. Interpret your probability in context.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
  </section>
  
  <section xml:id="chapter1">
    <title>Chapter 1: Analyzing One Categorical variable</title>
    ANALYZING ONE CATEGORICAL VARIABLE

<p>In this chapter, you will begin to analyze results from statistical studies
 and focus on the process of statistical inference. In particular, you will 
 learn how to assess evidence against a particular claim about a random process.</p>
    <subsection xml:id="investigation1-1">
      <title>Investigation 1.1: Friend or Foe?</title>
      
      <introduction>
        <p>In a study reported in the November 2007 issue of <em>Nature</em>, researchers investigated whether infants take into account an individual's actions towards others in evaluating that individual as appealing or aversive, perhaps laying the foundation for social interaction (<url href="https://pubmed.ncbi.nlm.nih.gov/18033298/">Hamlin, Wynn, and Bloom, 2007</url>). In other words, do children who aren't even yet talking still form impressions as to someone's friendliness based on their actions?</p>
        
            <p>In one component of the study, sixteen 10-month-old infants were shown a <q>climber</q> character (a piece of wood with <q>googly</q> eyes glued onto it) that could not make it up a hill in two tries.</p>
            
            <aside>
              <title>Video Demonstrations</title>
              <p><url href="https://www.youtube.com/watch?v=WqEV9Otdp58">Video 1: Helper behavior</url></p>
              <p><url href="https://www.youtube.com/watch?v=YX6PTixcS5I">Video 2: Hinder behavior</url></p>
              <p><url href="https://www.youtube.com/watch?v=dijiqWrUOx0">Video 3: Infant choice</url></p>
              <p>More videos: <url href="http://campuspress.yale.edu/infantlab/media/">Yale Infant Lab</url></p>
            </aside>
            
            <p>Then the infants were shown two scenarios for the climber's next try, one where the climber was pushed to the top of the hill by another character (the <q>helper</q> toy) and one where the climber was pushed back down the hill by another character (the <q>hinderer</q> toy). The infant was alternately shown these two scenarios several times.</p>
            
       <sidebyside widths="58% 38%" margins="0% 4%" valign="top">
          <stack>
  
            <p>Then the child was presented with both pieces of wood (the helper and the hinderer characters) and asked to pick one to play with.</p>
          </stack>
          <image source="images/infant.GIF" width="100%">
            <description>Infant choosing between helper and hinderer toys</description>
          </image>
        </sidebyside>
      </introduction>
      
      <paragraphs>
        <title>Collecting the Data</title>
        
        <assemblage xml:id="def-sample">
          <title>Definitions: Sample and Sample Size</title>
          <p>A <term>sample</term> is a collection of observed outcomes generated by repeated realizations a random process. The set of observations should reflect the typical behavior, and the variability inherent in that process. A study's <term>sample size</term> is the number of outcomes observed.</p>
        </assemblage>
        
        <exercise xml:id="inv1-1-a" label="I1.1.1">
          <title>Identify the Sample</title>
          <statement>
            <p>Identify the sample in this study.</p>
          </statement>
          <hint>
            <p>The sample consists of the observational units from which data were collected.</p>
          </hint>
          <answer>
            <p>The sample is the observations from the 16 infants.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-b" label="I1.1.2">
          <title>Assess Independence Assumption</title>
          <statement>
            <p>Do you think it is reasonable to model these observations as independent realizations of the random process under <q>identical conditions</q>? Explain.</p>
          </statement>
          <hint>
            <p>Consider whether the infants can be viewed as interchangeable and whether each infant's choice was measured separately.</p>
          </hint>
          <answer>
            <p>Opinions will vary, but if we consider the infants as interchangeable (no differences between them) and the infants' choices were all measured separately, that this modeling assumption seems appropriate. In particular, we need to be willing to model each infant as having the same probability of picking the helper toy.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-c" label="I1.1.3">
          <title>Explain Experimental Controls</title>
          <statement>
            <p>Why is it important that the researchers varied the colors and shapes of the wooden characters and even on which side the toys were presented to the infants?</p>
          </statement>
          <hint>
            <p>Think about other factors besides the helping/hindering behavior that might influence an infant's choice.</p>
          </hint>
          <answer>
            <p>This is to control for (or at least balance out) any other factors that could be influencing the infants' choices.</p>
          </answer>
          <response/>
        </exercise>
        
        <assemblage xml:id="def-variable-types">
          <title>Definition: Variables</title>
          <p>The measurements we are taking define the <term>variable</term>. We classify the type of variable as <term>categorical</term> (assigning each observational unit to a category) or <term>quantitative</term> (assigning each observational unit a numerical measurement). A special type of categorical variable is a <term>binary variable</term>, which has just two possible outcomes (often labeled <q>success</q> and <q>failure</q>).</p>
        </assemblage>
        
        <exercise xml:id="inv1-1-d" label="I1.1.4">
          <title>Identify the Variable</title>
          <statement>
            <p>What is the variable we are measuring about each observation?</p>
          </statement>
          <hint>
            <p>Think about what information is recorded for each infant.</p>
          </hint>
          <answer>
            <p>Variable = which toy does the infant choose to play with.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-d2" label="I1.1.4b">
          <title>Classify Variable Type</title>
          <statement>
            <p>Is this variable quantitative or categorical?</p>
          </statement>
          <choices randomize="no">
            <choice correct="yes">
              <statement>
                <p>Categorical</p>
              </statement>
              <feedback>
                <p>Correct! The variable records which category (Helper or Hinderer) each infant chose, making it a categorical variable.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>Quantitative</p>
              </statement>
              <feedback>
                <p>Not quite. A quantitative variable would be a numerical measurement. Here we're recording which toy was chosen, which is a category.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>Think about whether the data is a number or a category.</p>
          </hint>
        </exercise>
        
        <assemblage xml:id="def-research-question">
          <title>Definition: Research Question</title>
          <p>A <term>research question</term> often looks for patterns in a variable or compares a variable across different groups or looks for a relationship between variables.</p>
        </assemblage>
        
        <exercise xml:id="inv1-1-e" label="I1.1.5">
          <title>State Research Question</title>
          <statement>
            <p>What research question is of interest here?</p>
          </statement>
          <hint>
            <p>What question are the researchers trying to answer about infant behavior?</p>
          </hint>
          <answer>
            <p>The research question is whether infants in general (assuming identical infants from a random process) are more likely to pick the helper toy than the hinderer toy in the long run.</p>
          </answer>
          <response/>
        </exercise>
      </paragraphs>
      
      <paragraphs>
        <title>Summarizing the Observed Data</title>
        
        <p>To summarize the distribution of a categorical variable, we can simply count how many are in each category and make a <term>bar graph</term><idx><h>bar graph</h><h>graphical display of categorical data with bars for each category</h></idx> to display the results, one bar for each outcome, with heights representing the number of observations in each category, separating the bars to indicate distinct categories.</p>
        
        <exercise xml:id="inv1-1-f" label="I1.1.6">
          <title>Create Bar Graph</title>
          <statement>
            <p>The <q>raw data</q> can be found on the course webpage as a txt file (<url href="https://www.rossmanchance.com/iscam3/data/InfantData.txt">InfantData.txt</url>). How many do you see of each possible outcome? Sketch the bar graph. Give your graph an <q>active title,</q> a concise sentence stating the main message/key takeaways from the graph.</p>
          </statement>
          <hint>
            <p>Count how many infants chose each toy. A bar graph should have bars for each category (Helper and Hinderer) with heights representing the counts.</p>
          </hint>
          <answer>
            <p>14/16 = 0.875</p>
            <p>Active title: A majority of infants preferred the helper toy.</p>
            <image source="tech_images/ch1solsbargraph.jpg" width="70%">
              <description>Bar graph showing 14 infants chose Helper toy and 2 chose Hinderer toy</description>
            </image>
          </answer>
          <response/>
        </exercise>
        
        <paragraphs xml:id="tech-detour-loading">
          <title>Technology Detour - Loading in a Data File</title>
          
          <exercise xml:id="tech-detour-r-loading-rstudio" label="Loading Data - RStudio">
            <title>Loading Data - RStudio</title>
            <statement>
              <p>In RStudio, choose <c>Import Dataset > From Text (readr)</c> and enter the URL, then press <c>Import</c>.</p>
              <ul>
                <li><p>Example URL: <url href="https://www.rossmanchance.com/iscam3/data/InfantData.txt">https://www.rossmanchance.com/iscam3/data/InfantData.txt</url></p></li>
                <li><p>Keep <c>First Row as Names</c> checked</p></li>
                <li><p>For ISCAM files, change the <c>Delimiter</c> to <c>Tab</c></p></li>
                <li><p>Press <c>Update</c> to preview the data</p></li>
                <li><p>You can set the dataset name</p></li>
              </ul>
              
              <note>
                <title>RStudio Reminder</title>
                <p>With other data files, you may need to consider how <q>missing values</q> are coded. The Import Dataset dialog gives you a preview so you can check that the data looks correct before importing.</p>
              </note>
            </statement>
            <solution>
              <p>After importing, you should see the data appear in your Environment pane (upper right) and a data viewer window will open showing the contents of the file. The data table should show one column named <c>choice</c> with 16 rows containing either "Helper" or "Hinderer".</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-r-loading" label="Loading Data - R">
            <title>Loading Data - R</title>
            <statement>
              <p><alert>Files from the Web</alert></p>
              <p>Open the InfantData.txt (raw data) link from the data files page, select all, copy, and then in R use the following command. Keep in mind that R is case sensitive:</p>
              
              <p><em>PC:</em></p>
              <program language="r" interactive="sage">
                <input>
InfantData = read.table("clipboard", header=TRUE)
                </input>
              </program>
              
              <p><em>Mac:</em></p>
              <program language="r" interactive="sage">
                <input>
InfantData = read.table(pipe("pbpaste"), header=TRUE)
                </input>
              </program>
              
              <p>You can also use a URL (in quotes). The <c>header</c> command indicates the variables have names.</p>
              
              <p><alert>Text Files on Your Computer</alert></p>
              <program language="r" interactive="sage">
                <input>
InfantData = read.table(file.choose(), header=T)
                </input>
              </program>
              
              <p>To see the data, type:</p>
              <program language="r" interactive="sage">
                <input>
View(InfantData)
# or
head(InfantData)
                </input>
              </program>
              
              <p>Next you can <q>attach</q> the file to be able to use variable names directly:</p>
              <program language="r" interactive="sage">
                <input>
attach(InfantData)    # Now R knows what the "choice" variable is
                </input>
              </program>
              
              <p>Or you need to clarify to R which datafile you are using (e.g., <c>InfantData$choice</c>).</p>
              
              <p><alert>Other Input Options</alert></p>
              <p>Depending on how the data you are pasting is formatted, you may need additional arguments:</p>
              <ul>
                <li><p><c>sep="\t"</c> - separated by tabs</p></li>
                <li><p><c>na.strings="*"</c> - how to code missing values</p></li>
                <li><p><c>strip.white=TRUE</c> - strip extra white space</p></li>
              </ul>
              
              <note>
                <title>R Reminder</title>
                <p>R is case sensitive! <c>InfantData</c> and <c>infantdata</c> are different objects. Always check your data after loading with <c>View()</c> or <c>head()</c> to make sure it loaded correctly. Using <c>attach()</c> lets you reference column names directly, but be careful - if you have multiple datasets loaded, this can cause confusion.</p>
              </note>
            </statement>
            <solution>
              <p>After running <c>head(InfantData)</c>, you should see output similar to:</p>
              <pre>
     choice
1    Helper
2    Helper
3    Helper
4    Helper
5    Helper
6  Hinderer
              </pre>
              <p>This shows the first 6 observations of the data. The full dataset contains 16 observations total.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-jmp-loading" label="Loading Data - JMP">
            <title>Loading Data - JMP</title>
            <statement>
              <p><alert>Method 1: Copy and Paste</alert></p>
              <p>Choose <c>File > New > Data table</c>. Open the <url href="https://www.rossmanchance.com/iscam2/data/InfantData.txt" target="_blank">InfantData.txt</url> (raw data) link from the <url href="https://www.rossmanchance.com/iscam4/files.html" target="_blank">data files page</url> and select all the observations and the variable name and copy the data into the clipboard. Return to the data table in JMP and select <c>Edit > Paste with Column Names</c>.</p>
              
              <p><alert>Method 2: Open File</alert></p>
              <p>If the .txt file is saved on your computer, you can choose <c>File > Open</c> and use the pull-down menu to change the file type.</p>
              
              <note>
                <title>JMP Reminder</title>
                <p>When using <c>Paste with Column Names</c>, make sure you include the header row (variable names) in your selection. JMP will automatically detect the data types for each column. Always check the data table after importing to ensure everything looks correct.</p>
              </note>
            </statement>
            <solution>
              <p>After pasting or opening the file, you should see a data table with one column labeled <c>choice</c> containing 16 rows. The column should be recognized as a Character data type. The values should alternate between "Helper" and "Hinderer" entries.</p>
              <image source="tech_images/JMPdatatable.png" width="70%">
                <description>JMP data table showing the choice column with 16 rows of Helper and Hinderer values</description>
              </image>
            </solution>
          </exercise>
        </paragraphs>
        
        <paragraphs xml:id="tech-detour-tallying">
          <title>Technology Detour - Tallying the Outcomes</title>
          
          <exercise xml:id="tech-detour-r" label="R">
            <title>Tallying the Outcomes - R</title>
            <statement>
              <p>To count the number of correct and incorrect responses, type:</p>
              <program language="r" interactive="sage">
                <input>
table(InfantData)
                </input>
              </program>
              
              <note>
                <title>R Reminder</title>
                <p>The <c>table()</c> function automatically counts the frequency of each unique value in your data. Make sure your data is loaded before running this command.</p>
              </note>
            </statement>
            <solution>
              <p>The output should show:</p>
              <pre>
choice
  Helper Hinderer 
      14        2
              </pre>
              <p>This indicates that 14 infants chose the Helper toy and 2 chose the Hinderer toy.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-jmp" label="JMP">
            <title>Tallying the Outcomes - JMP</title>
            <statement>
              <p>Choose <c>Analyze > Tabulate</c>. In the new window, drag the <c>choice</c> column to either the Drop Zone for columns or for rows. Press <c>Done</c>.</p>
              
              <image source="tech_images/JMPtabulate.png" width="70%">
                <description>JMP Tabulate window showing counts: Helper 14, Hinderer 2</description>
              </image>
              
              <note>
                <title>JMP Reminder</title>
                <p>Look for the red triangle (<q>hot spot</q>) menus in JMP windows - they provide additional options and actions. Dragging variables to different zones (rows vs. columns) changes how your table is organized.</p>
              </note>
            </statement>
            <solution>
              <p>The Tabulate output should display a table showing the counts for each category:</p>
              <ul>
                <li><p>Helper: 14</p></li>
                <li><p>Hinderer: 2</p></li>
                <li><p>Total (N): 16</p></li>
              </ul>
              <p>The exact layout depends on whether you placed the variable in rows or columns, but the counts will be the same.</p>
              <image source="tech_images/JMPtable.png" width="50%">
                <description>JMP frequency table showing choice categories and their counts</description>
              </image>
            </solution>
          </exercise>
        </paragraphs>
        
        <paragraphs xml:id="tech-detour-bargraphs">
          <title>Technology Detour - Bar Graphs</title>
          
          <exercise xml:id="tech-detour-r-bargraph-raw" label="Bar Graphs - R (raw data)">
            <title>Bar Graphs - R (raw data)</title>
            <statement>
              <p>You need to pass the tabled data into the barplot function:</p>
              <program language="r" interactive="sage">
                <input>
barplot(table(InfantData), xlab="Choice", ylab="Frequency")
                </input>
              </program>
              <p>You may need to toggle to the R Graphics Window to see the graph window. Now you can use R to export the graph to a file or you can Copy and Paste or use a screen capture.</p>
              
              <note>
                <title>R Reminder</title>
                <p>The <c>xlab</c> and <c>ylab</c> arguments add labels to your axes. Always label your graphs to make them interpretable! You can nest the <c>table()</c> function inside <c>barplot()</c> to go directly from raw data to a graph.</p>
              </note>
            </statement>
            <solution>
              <p>You should see a bar graph with two bars:</p>
              <ul>
                <li><p>A bar for "Helper" with height 14</p></li>
                <li><p>A bar for "Hinderer" with height 2</p></li>
              </ul>
              <p>The x-axis should be labeled "Choice" and the y-axis should be labeled "Frequency". The bars should have gaps between them to indicate these are categorical data.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-r-bargraph-summary" label="Bar Graphs - R (summary data)">
            <title>Bar Graphs - R (summary data)</title>
            <statement>
              <p>If you already (or only) have the summarized data (the number of successes and failures), you can type:</p>
              <program language="r" interactive="sage">
                <input>
barplot(c(14, 2), names.arg=c("Helper", "Hinderer"))
                </input>
              </program>
              
              <note>
                <title>R Reminder</title>
                <p>The <c>c()</c> function creates a vector (list) of values. The <c>names.arg</c> parameter assigns category labels to each bar. The order matters - the first count gets the first label!</p>
              </note>
            </statement>
            <solution>
              <p>You should see a bar graph identical to the one created from raw data:</p>
              <ul>
                <li><p>A bar labeled "Helper" with height 14</p></li>
                <li><p>A bar labeled "Hinderer" with height 2</p></li>
              </ul>
              <p>This method is useful when you only have summary statistics rather than the full dataset.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-jmp-bargraph-summary" label="Bar Graphs - JMP (summary data)">
            <title>Bar Graphs - JMP (summary data)</title>
            <statement>
              <p><alert>Method 1: From Tabulate Window</alert></p>
              <p>In the Tabulate window (from above), use the red down arrow in the upper left corner (<q>hot spot</q>) and select <c>Show Chart</c>. Best when using the Drop zone for rows.</p>
              
              <image source="tech_images/bargraphJMP1.png" width="50%">
                <description>JMP Tabulate window with Show Chart option</description>
              </image>
              
              <p><alert>Method 2: Graph Builder</alert></p>
              <p>If you have the categories and counts in a data window, choose <c>Graph > Graph Builder</c>. Drag the variable names to the x-axis and the counts to the y-axis. Press the 7th icon to convert the chart to a bar graph.</p>
              
              <image source="tech_images/bargraphJMP2.png" width="50%">
                <description>JMP Graph Builder interface for creating bar graphs from summary data</description>
              </image>
              
              <note>
                <title>JMP Reminder</title>
                <p>Graph Builder is JMP's most flexible graphing tool. The icons at the top let you switch between different graph types. Drag and drop variables to different zones to change what the graph displays.</p>
              </note>
            </statement>
            <solution>
              <p>You should see a bar graph showing two bars with the frequency counts clearly labeled. The Helper bar should be noticeably taller (14) than the Hinderer bar (2). The graph should automatically include axis labels and a legend if needed.</p>
              <image source="tech_images/JMPbargraph2.png" width="70%">
                <description>JMP bar graph created from summary data showing Helper and Hinderer counts</description>
              </image>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-jmp-bargraph-raw" label="Bar Graphs - JMP (raw data)">
            <title>Bar Graphs - JMP (raw data)</title>
            <statement>
              <p><alert>Method 1: Graph Builder</alert></p>
              <p>From the Data Table window, select <c>Graph > Graph Builder</c>. Drag the Choice variable to the X-axis. Hover until the X-region shows the group labels and then let go. Press the 7th (<q>Bar</q>) icon to convert the chart to a bar graph.</p>
              
              <image source="tech_images/bargraphJMP3.png" width="50%">
                <description>JMP Graph Builder showing dragging variable to X-axis</description>
              </image>
              
              <image source="tech_images/bargraphJMP4.png" width="50%">
                <description>JMP Graph Builder with Bar chart icon selected</description>
              </image>
              
              <p><alert>Method 2: Distribution Platform</alert></p>
              <p>Choose <c>Analyze > Distribution</c>. With the choice column highlighted, press the <c>Y, Columns</c> button (or drag to the white box). Press <c>OK</c>.</p>
              
              <image source="tech_images/bargraphJMP6.png" width="50%">
                <description>JMP Distribution output with frequency chart</description>
              </image>
              
              <p>You have lots of options here (using the hot spots), like turning the graph horizontal, adding an axis (putting it on the left), adding labels, separating bars, etc.</p>
              
              <image source="tech_images/bargraphJMP7.png" width="50%">
                <description>JMP Distribution hot spot menu options</description>
              </image>
              
              <note>
                <title>JMP Reminder</title>
                <p>The Distribution platform is great for exploring categorical data. Use the red triangle hot spots to customize your graph - you can make bars horizontal, add counts/percentages, change colors, and more. Experiment with the options to make your graph publication-ready!</p>
              </note>
            </statement>
            <solution>
              <p>Either method should produce a bar graph showing the distribution of choices. You should see:</p>
              <ul>
                <li><p>Two distinct bars for Helper and Hinderer</p></li>
                <li><p>The Helper bar should be approximately 7 times taller than the Hinderer bar (14 vs 2)</p></li>
                <li><p>Frequency counts labeled on or near the bars</p></li>
                <li><p>Clear axis labels and category names</p></li>
              </ul>
              <p>Using the Distribution platform gives you more statistical output beyond just the graph, including percentages and other summary statistics.</p>
              <image source="tech_images/JMPbargraph1.png" width="50%">
                <description>JMP bar graph showing Helper and Hinderer distribution</description>
              </image>
            </solution>
          </exercise>
        </paragraphs>
      </paragraphs>
      
      <paragraphs>
        <title>Drawing Conclusions Beyond the Sample</title>
        
        <p>Clearly a majority/more than half of the infants chose the helper toy in this sample of 16 infants. But does that convince us that infants in general are more likely to pick the helper toy in the long run? In other words, what is the probability that an infant will choose the helper toy?</p>
        
        <p><em>Model assumption:</em> Note we are assuming each infant has the same probability of picking the helper toy, we just don't know the value of that probability.</p>
        
        <exercise xml:id="inv1-1-g" label="I1.1.7">
          <title>Researchers' Hypothesis</title>
          <statement>
            <p>What do the researchers think is true about the value of this probability (e.g., do they think it is larger or smaller than 0.50)?</p>
          </statement>
          <choices randomize="no">
            <choice correct="yes">
              <statement>
                <p>Larger than 0.50</p>
              </statement>
              <feedback>
                <p>Correct! The researchers hypothesize that infants prefer the helper toy, which would mean the probability of choosing the helper is greater than 0.50.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>Smaller than 0.50</p>
              </statement>
              <feedback>
                <p>Not quite. If infants preferred the hinderer toy, the probability would be less than 0.50, but that's not what the researchers think.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>Equal to 0.50</p>
              </statement>
              <feedback>
                <p>Not quite. A probability of 0.50 would mean infants choose equally between the two toys, which is not the researchers' hypothesis.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>Consider what the research hypothesis is about infant preferences for the helper toy.</p>
          </hint>
        </exercise>
        
        <exercise xml:id="inv1-1-h" label="I1.1.8">
          <title>Consider Chance Explanation</title>
          <statement>
            <p>Is it possible that in the long run infants just choose equally between the two toys (e.g., the probability an infant will choose the helper toy is 0.5) and we just happened to see more than half choose the helper toy in our sample?</p>
          </statement>
          <choices randomize="no">
            <choice correct="yes">
              <statement>
                <p>Yes</p>
              </statement>
              <feedback>
                <p>Correct! It's possible that the true probability is 0.50 and we just observed an unusual sample by chance.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>No</p>
              </statement>
              <feedback>
                <p>Actually, it is possible. Random samples can vary, and we might see more than half choose the helper toy even if the true probability is 0.50.</p>
              </feedback>
            </choice>
          </choices>
        </exercise>
        
        <exercise xml:id="inv1-1-i" label="I1.1.9">
          <title>Rule Out Color Preference</title>
          <statement>
            <p>Is it plausible that the observed majority occurred because infants just prefer the color blue?</p>
          </statement>
          <choices randomize="no">
            <choice>
              <statement>
                <p>Yes</p>
              </statement>
              <feedback>
                <p>Not quite. The researchers varied the colors, shapes, and positions of the toys to balance out these factors, so color preference is not a plausible explanation.</p>
              </feedback>
            </choice>
            <choice correct="yes">
              <statement>
                <p>No</p>
              </statement>
              <feedback>
                <p>Correct! We are not considering color, shape, or position as the explanation because these factors were balanced in the design of the study.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>Recall why the researchers varied colors, shapes, and positions.</p>
          </hint>
        </exercise>
        
        <p>So that leaves us with two explanations for the majority we observed:</p>
        <p><ol>
          <li><p>There is something to the theory that infants are genuinely more likely to pick the helper toy (for some reason).</p></li>
          <li><p>Infants choose equally between the two toys in the long run and we happened to get <q>lucky</q> and had an unusual sample where most of the infants in our sample picking the helper toy.</p></li>
        </ol></p>
        
        <exercise xml:id="inv1-1-j" label="I1.1.10">
          <title>Choose Between Explanations</title>
          <statement>
            <p>So for the two possibilities we are still considering, how might you choose between them? In particular, how might you convince someone whether or not option (2) is plausible based on this study?</p>
          </statement>
          <hint>
            <p>Think about what makes an outcome unusual or typical when choices are made randomly.</p>
          </hint>
          <answer>
            <p>We would need to convince someone that if these results were just happening "randomly," it would be unusual to get 14 infants picking the helper toy.</p>
          </answer>
          <response/>
        </exercise>
        
        <p>Our analysis approach is going to be to assume the second explanation is true (similar to how in a legal trial we assume a defendant is innocent), and then see whether our data are consistent or inconsistent with that assumption. To do this, we need to investigate the values we expect to see for the number choosing the helper toy when 16 infants are equally choosing between the two toys. As you saw with the Random Babies (Investigation B), we can simulate the outcomes of a random process to help us determine which outcomes are more or less likely to occur.</p>
        
        <exercise xml:id="inv1-1-k" label="I1.1.11">
          <title>Design a Simulation</title>
          <statement>
            <p>Suggest a method for carrying out a simulation of 16 infants picking equally between the two toys.</p>
          </statement>
          <hint>
            <p>Think about a simple physical randomization device that gives two equally likely outcomes.</p>
          </hint>
          <answer>
            <p>We could toss a coin for each infant, letting heads represent choosing the helper toy and tails represent choosing the hinderer toy. This makes the two choices equally likely on each toss. Then use 16 coins or toss one coin 16 times to represent the 16 infants. (We are assuming these are equivalent, that the observational units are identical.) These results will help us assess the variability in the outcomes of 16 infants "just by chance." This will help us decide whether 14 is a typical outcome or an unusual outcome when we know for a fact that the "infants" choose equally (in the long run) between the two toys.</p>
          </answer>
          <response/>
        </exercise>
      </paragraphs>
      
      <paragraphs>
        <title>Simulation</title>
        
        <p>For a 50-50 simulation model, we can flip a fair coin. We can arbitrarily define <q>heads</q> to be choosing the helper toy and <q>tails</q> to be choosing the hinderer toy. We will repeat the random process 16 times to represent the 16 infants, and we will count how many times we flip heads, representing an infant choosing the helper toy. The chart below shows this mapping of the real world, which we saw one instance of, and the simulation model, which we can easily repeat many times. Keep in mind that in the simulation model, we know the probability of heads is 0.50.</p>
        
        <table xml:id="table-simulation-model">
          <title>Mapping real world to simulation model</title>
          <tabular halign="left" top="medium" bottom="medium" left="medium" right="medium">
            <row header="yes" bottom="medium" left="medium" right="medium">
              <cell right="medium"></cell>
              <cell right="medium">Real world</cell>
              <cell>Simulation model</cell>
            </row>
            <row bottom="minor" left="medium" right="medium">
              <cell right="medium">One observation</cell>
              <cell right="medium">Infant choice</cell>
              <cell>Coin toss</cell>
            </row>
            <row bottom="minor" left="medium" right="medium">
              <cell right="medium">Sample</cell>
              <cell right="medium">16 infants</cell>
              <cell>16 coin tosses</cell>
            </row>
            <row bottom="minor" left="medium" right="medium">
              <cell right="medium">Success</cell>
              <cell right="medium">Picks helper toy</cell>
              <cell>Lands heads</cell>
            </row>
            <row left="medium" right="medium">
              <cell right="medium">Probability of <q>success</q></cell>
              <cell right="medium">Unknown</cell>
              <cell>0.50</cell>
            </row>
          </tabular>
        </table>
        
        <exercise xml:id="inv1-1-l" label="I1.1.12">
          <title>Conduct Coin Toss Simulation</title>
          <statement>
            <p>Flip a coin 16 times, representing the 16 infants in the study (one repetition of this random process). Tally the results below and count how many of the 16 chose the helper toy:</p>
            <p><em><q>Could have been</q> outcomes</em></p>
            <p>Heads (helper toy): <var width="5"/></p>
            <p>Tails (hinderer toy): <var width="5"/></p>
            <p>Total number of heads in 16 tosses: <var width="5"/></p>
          </statement>
          <hint>
            <p>Flip a coin 16 times and count the number of heads and tails. The totals should add to 16.</p>
          </hint>
          <answer>
            <p>Results will vary by class. Below is one possible set of results:</p>
            <image source="tech_images/ch1solsdotplot.jpg" width="70%">
              <description>Dotplot showing distribution of class simulation results for number of heads in 16 coin tosses</description>
            </image>
          </answer>
        </exercise>
        
        <exercise xml:id="inv1-1-m" label="I1.1.13">
          <title>Combine Class Results</title>
          <statement>
            <p>Combine your simulation results for each repetition with your classmates' on the scale below. Create a dotplot by placing a dot above the numerical result found by each person's set of 16 tosses.</p>
          </statement>
          <hint>
            <p>Each person in class should contribute one dot to the class dotplot, placed above their number of heads out of 16.</p>
          </hint>
          <answer>
            <p>Results will vary by class. See image in the previous exercise for an example dotplot.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-n" label="I1.1.14">
          <title>Describe Simulation Variability</title>
          <statement>
            <p>Did everyone get the same number of heads every time? What is an average or typical number of heads in a set of 16 tosses? Is this what you expected? Explain.</p>
          </statement>
          <hint>
            <p>Look at the center of the dotplot. What value appears most frequently or is in the middle of the distribution?</p>
          </hint>
          <answer>
            <p>No, there will be variability across the sets of 16 tosses, but 8 heads is an average or typical number of heads.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-o" label="I1.1.15">
          <title>Assess Unusualness</title>
          <statement>
            <p>Does 14 heads appear to be an unusual outcome for 16 observations from a process where heads should appear 50% of the time in the long run?</p>
          </statement>
          <hint>
            <p>Look at your class dotplot. How often did values as extreme as 14 (or more) occur? Is 14 in the "tail" or center of the distribution?</p>
          </hint>
          <answer>
            <p>Answers will vary, but 14 does appear to be somewhat unusual, not occurring very often, in the "tail" of the distribution.</p>
          </answer>
          <response/>
        </exercise>
        
        <p>We really need to simulate this hypothetical random selection process hundreds, preferably thousands of times. This would be very tedious and time-consuming with coins, so let's turn to technology.</p>
        
        <exercise xml:id="inv1-1-p" label="I1.1.16">
          <statement>
            <p>Use the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url> to simulate these 16 infants making this helper/hinderer choice, still assuming that infants have no real preference and so are equally likely to choose either toy.</p>
            <p><ul>
              <li><p>Keep the Probability of heads set to 0.5.</p></li>
              <li><p>Set the Number of Tosses to 16.</p></li>
              <li><p>Keep the Number of repetitions at 1 for now.</p></li>
              <li><p>Press Draw Samples.</p></li>
            </ul></p>
            <p>Report the number of heads (i.e., the number of infants who choose the helper toy) for this <q>could have been</q> (under the assumption of no preference) outcome.</p>
            <p>Number of heads: <var width="5"/></p>
          </statement>
          <hint>
            <p>The applet will simulate flipping 16 coins and count the number of heads for you automatically.</p>
          </hint>
          <answer>
            <p>Results will vary.</p>
          </answer>
        </exercise>
        
        <exercise xml:id="inv1-1-q" label="I1.1.17">
          <title>Repeat Simulation Multiple Times</title>
          <statement>
            <p>Uncheck the Show animation box and press Draw Samples four more times, each time recording the number of the 16 infants who choose the helper toy. Did you get the same number of heads all five times?</p>
          </statement>
          <choices randomize="no">
            <choice>
              <statement>
                <p>Yes</p>
              </statement>
              <feedback>
                <p>Actually, random processes typically produce different results each time. You should see variation in the number of heads across the five repetitions.</p>
              </feedback>
            </choice>
            <choice correct="yes">
              <statement>
                <p>No</p>
              </statement>
              <feedback>
                <p>Correct! There should be variation in the results across the repetitions. This variability is a natural characteristic of random processes.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>Each repetition simulates a new set of 16 coin flips. Think about whether random processes produce identical results every time.</p>
          </hint>
        </exercise>
        
        <exercise xml:id="inv1-1-r" label="I1.1.18">
          <title>Generate Null Distribution</title>
          <statement>
            <p>Now change the Number of repetitions to 1995 and press Draw Samples, to produce a total of 2,000 repetitions of this random process of tossing a coin 16 times. For the dotplot you have created, what does each dot represent (i.e., what would you need to do to add another dot to the graph)?</p>
          </statement>
          <hint>
            <p>Think about what you did to create one dot in the physical coin-flipping activity.</p>
          </hint>
          <answer>
            <p>Each dot in the dotplot represents the number of heads in 16 coin tosses (representing the choices of a set of 16 infants).</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-r2" label="I1.1.18b">
          <title>Classify Graph Variable</title>
          <statement>
            <p>Is the graph variable (number of heads) quantitative or categorical?</p>
          </statement>
          <choices randomize="no">
            <choice correct="yes">
              <statement>
                <p>Quantitative</p>
              </statement>
              <feedback>
                <p>Correct! The variable "number of heads" is quantitative because it represents a numerical count that can be measured and has meaningful numerical values.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>Categorical</p>
              </statement>
              <feedback>
                <p>Not quite. The number of heads is a count (0, 1, 2, ..., 16), which makes it quantitative rather than categorical. Categorical variables assign observations to categories, not numerical values.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>What does the horizontal axis represent? Is it counting something or assigning categories?</p>
          </hint>
        </exercise>
        
        <exercise xml:id="inv1-1-s" label="I1.1.19">
          <title>Draw Conclusion</title>
          <statement>
            <p>Now that we have a better picture of the long-run behavior of this process, discuss whether you would consider option 2 before (j): <q>Infants choose equally between the two toys in the long run and we happened to get 'lucky' and find most of the infants in our sample picking the helper toy</q> to be a plausible conclusion for this study. Explain your reasoning as if to a skeptic.</p>
          </statement>
          <hint>
            <p>Look at how often 14 or more heads occurred in your 2,000 simulated repetitions. Is this common or rare? What does this tell you about the plausibility of the "no preference" assumption?</p>
          </hint>
          <answer>
            <p>Because it is very unlikely for us to have seen results at least as extreme as what we observed (14 successes) under the assumption of 50-50 chance, we have evidence against this claim and instead in favor of the claim that there is something other than random chance at play in this sample.</p>
          </answer>
          <response/>
        </exercise>
      </paragraphs>
      
      <paragraphs>
        <title>Discussion</title>
        
        <p>Returning to our legal trial analogy, if you decide that the observed <q>data</q> is unlikely to occur by chance alone, you are going to <q>reject</q> the assumption of <q>innocence</q> (and say we have evidence the defendant is guilty). If you decide the data/evidence is not unusual by chance alone, then you <q>fail to reject</q> that assumption (and we say we don't have evidence the defendant is guilty <mdash/> we aren't proving the defendant innocent, just that the evidence is not inconsistent with that assumption, <q>not guilty</q>).</p>
        
        <p>So based on these simulation results, we would say the data (14 helper choices out of 16 trials) is unusual under the assumption that infants genuinely have no preference and are choosing blindly when presenting the toys. This evidence convinces us that <q>There is something to the theory that infants are genuinely more likely to pick the helper toy (for some reason)</q> is the more believable explanation for why so many of the infants in this study picked the helper toy over the hinderer toy. We haven't proven this is true, but based on the strong majority these researchers saw, even for this small sample size of 16, we would consider the evidence convincing (<q>beyond a reasonable doubt</q>) that, in the long run, the probability of choosing the helper toy in this random process is greater than 0.5. Because the researchers controlled for other possible explanations for the observed preference results like color and handedness, we will conclude that there is convincing evidence that infants really do have a genuine preference for the helper toy over the hindering toy.</p>
      </paragraphs>
      
      <assemblage xml:id="study-conclusions-1-1">
        <title>Study Conclusions</title>
        
        <p>In a study of <q>social evaluation,</q> researchers explored whether pre-verbal infants have a preference for a <q>helping</q> toy over a <q>hindering</q> toy. Treating the 16 infants as identical observations from a random process with equal probability of success/failure, we find that getting 14 infants choosing the helper toy is not consistent with the types of values we expect to see when we have <q>infants</q> choosing equally between the two toys. This means that the researchers' data provide strong statistical evidence to reject this <q>no preference</q> model and conclude that the infants' choices are actually governed by a process where there is a genuine preference for the helper toy (or at least that it's more complicated than each infant flipping a coin to decide). Of course, this conclusion depends on the assumption of <q>identical infants</q> and that these 16 infants' choices are representative of the larger process of viewing the videos and selecting a toy. Also keep in mind that not all infants had a clear preference for either object.</p>
      </assemblage>
      
      <subsection xml:id="practice1-1A">
        <title>Practice Problem 1.1A</title>
        
        <p>In a second experiment, the same events were repeated but the object climbing the hill no longer had the googly eyes attached. The researchers wanted to see whether the preference was made based on a social evaluation more than a perceptual preference. Suppose 8 of 12 (different) infants chose the push-up toy.</p>
        
        <exercise xml:id="practice-1-1a-a" label="PP1.1A.1">
          <statement>
            <p>If you were to use a coin to carry out a simulation analysis to evaluate these results: how many times would you flip the coin for one repetition <mdash/> 6, 8, 10, 12, 16, or 1000?</p>
          </statement>
          <choices randomize="no">
            <choice>
              <statement>
                <p>6</p>
              </statement>
              <feedback>
                <p>Not quite. Think about how many infants were in this experiment.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>8</p>
              </statement>
              <feedback>
                <p>Close, but this is the number who chose the push-up toy, not the total number of infants.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>10</p>
              </statement>
              <feedback>
                <p>Not quite. Check the problem statement for the total number of infants in the experiment.</p>
              </feedback>
            </choice>
            <choice correct="yes">
              <statement>
                <p>12</p>
              </statement>
              <feedback>
                <p>Correct! You need to flip the coin 12 times to represent the 12 different infants in this experiment, just like we flipped 16 times to represent the 16 infants in the original study.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>16</p>
              </statement>
              <feedback>
                <p>Not quite. That was the sample size in the original study, but this experiment has a different number of infants.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>1000</p>
              </statement>
              <feedback>
                <p>Not quite. 1000 would be the number of repetitions we might do, not the number of coin flips per repetition.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>How many infants participated in this second experiment? Each coin flip represents one infant's choice.</p>
          </hint>
        </exercise>
        
        <exercise xml:id="practice-1-1a-b" label="PP1.1A.2">
          <statement>
            <p>Use the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url> to decide whether it is plausible that when the googly eyes are removed infants do not have a genuine preference between the two toys. What do you conclude?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-1B">
        <title>Practice Problem 1.1B</title>
        
        <p>In 2019, the home team won 54 of the first 88 games of the Premier Soccer League season. Consider these games as a sample from a random process (all games that could have occurred in first 3 months).</p>
        
        <exercise xml:id="practice-1-1b-a" label="PP1.1B.1">
          <statement>
            <p>Could we use a coin tossing simulation to model this random process? What would each coin toss represent? What are we assuming about the process? How many times would we toss the coin for one repetition? Define what is meant by <q>probability of success</q> in this context.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-1b-b" label="PP1.1B.2">
          <statement>
            <p>Use the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url> to decide whether these data provide convincing statistical evidence that the home team is more likely than the visiting team to win in the long run. Justify your conclusion.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-1b-c" label="PP1.1B.3">
          <statement>
            <p>At the beginning of the 2020 season, fans were not allowed at the games due to the Coronavirus pandemic. For the first three months of this season, the home team won 40 of 87 matches. Decide whether these data provide convincing statistical evidence that the home team is more likely than the visiting team to win when no fans are present. Justify your conclusion.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
    
    <subsection xml:id="investigation1-2">
      <title>Investigation 1.2: Can Wolves Understand Human Cues?</title>
      
      <sidebyside widths="58% 38%">
        <stack>
          <p>Previous research has demonstrated that domesticated dogs can be trained to understand human cues, such as looking or pointing at an object. But it was not clear how the animals would perform with "behavioral cues" showing intent such as reaching for, but not obtaining, or trying to open an object.</p>
          
        </stack>
        <image source="images/wolf.jpg" width="100%"/>
      </sidebyside>
          <p><url href="https://www.nature.com/articles/s41598-017-12055-6#MOESM1">Lampe et al. (2017)</url> gave captive wolves, pack dogs living in identical conditions to the wolves, and pet dogs living with families a series of "object-choice tasks." A table was placed outside a fenced compartment, and a container was placed at each end of the table, one containing food and one empty. The experimenter would give the cue as to which container had the food and then the animal would touch one of the two targets next to the containers. A 6-year-old female timber wolf, Yukon, chose the intended container in 6 of the 8 trials with behavioral cues.</p>
      
      <exercise xml:id="inv1-2-a" label="I1.2.1">
        <title>Identify Sample and Process</title>
        <statement>
          <p>Identify the sample/random process for this study.</p>
        </statement>
        <response/>
        <hint>
          <p>What is the sample size?</p>
        </hint>
        <solution>
          <p>The random process is the repeated trials given to Yukon (<m>n = 8</m>).</p>
        </solution>
      </exercise>
      

      <exercise xml:id="inv1-2-b" label="I1.2.2">
        <title>Identify the Variable</title>
        <statement>
          <p>Identify the variable of interest for this process.</p>
        </statement>
        <response/>
        <hint>
          <p>The variable is the measurements recorded for each observation.</p>
        </hint>
        <solution>
          <p>The variable is whether or not Yukon picks the cued container.</p>
        </solution>
      </exercise>

      <exercise xml:id="inv1-2-b2" label="I1.2.2b">
        <title>Classify Variable Type</title>
        <statement>
          <p>Is this variable quantitative or categorical?</p>
        </statement>
        <choices randomize="no">
          <choice correct="yes">
            <statement>
              <p>Categorical</p>
            </statement>
            <feedback>
              <p>Correct! The variable records which category (cued or not cued) Yukon chose, making it a categorical variable.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>Quantitative</p>
            </statement>
            <feedback>
              <p>Not quite. A quantitative variable would be a numerical measurement. Here we're recording which container was chosen, which is a category.</p>
            </feedback>
          </choice>
        </choices>
        <hint>
          <p>Think about whether the data is a number or a category.</p>
        </hint>
        <solution>
          <p>The variable is categorical.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="inv1-2-c" label="I1.2.3">
        <title>Expected Success Rate</title>
        <statement>
          <p>If Yukon was purely guessing, how often would you expect her to identify the correct container?</p>
        </statement>
        <choices randomize="no">
          <choice correct="yes">
            <statement>
              <p>about 50% of the time</p>
            </statement>
            <feedback>
              <p>Correct! With two equally likely options, we would expect Yukon to choose correctly about half the time by chance.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>about 33% of the time</p>
            </statement>
            <feedback>
              <p>This would be the probability if there were three equally likely options.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>about 75% of the time</p>
            </statement>
            <feedback>
              <p>This would mean Yukon has some understanding of the cues, not just guessing.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>about 25% of the time</p>
            </statement>
            <feedback>
              <p>This would be the probability if there were four equally likely options.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>never</p>
            </statement>
            <feedback>
              <p>Even when guessing, there's a chance of being correct.</p>
            </feedback>
          </choice>
        </choices>
        <solution>
          <p>About 50% of the time.</p>
        </solution>
      </exercise>
      
      <p>We will think of the sample of 8 attempts as identical observations from a random process, and we are choosing between two possibilities:</p>
      <p><ol>
        <li><p>Yukon can understand behavioral cues,</p></li>
        <li><p>Yukon does not consistently understand behavioral cues and is guessing randomly.</p></li>
      </ol></p>
      
      <assemblage xml:id="def-hypotheses">
        <title>Definition: Hypotheses</title>
        <p>In drawing conclusions beyond our sample data to the underlying random process, we will often be choosing between two competing claims about the underlying process:</p>
        <p><ul>
          <li><p>The <term>null hypothesis</term><idx><h>null hypothesis</h><h>the "by chance alone" explanation</h></idx>, which is the "by chance alone" explanation;</p></li>
          <li><p>The <term>alternative hypothesis</term><idx><h>alternative hypothesis</h><h>what researchers hope to show</h></idx>, which is usually what the researchers are hoping to show.</p></li>
        </ul></p>
        
        <p>In Investigation 1.1, the null hypothesis was that infants (in general) choose equally among the two toys in the long run. The alternative hypothesis was that infants have a genuine preference for the helper toy.</p>
      </assemblage>
      
        <aside>
          <title>How to use matching questions</title>
          <p>Drag the descriptions from the left to match them with the correct answer on the right.</p>
        </aside>
      <exercise xml:id="inv1-2-d" label="I1.2.4">
        <title>State Hypotheses</title>
        <statement>
          <p>Identify the above possibilities as the null and alternative hypotheses.</p>
        </statement>
        <matches>
          <match order="1">
            <premise>Yukon does not consistently understand behavioral cues and is guessing randomly</premise>
            <response>Null Hypothesis</response>
          </match>
          <match order="2">
            <premise>Yukon can understand behavioral cues</premise>
            <response>Alternative Hypothesis</response>
          </match>
        </matches>
        <solution>
          <p><b>Null:</b> Yukon does not consistently understand behavioral cues and is guessing randomly between the 2 containers.</p>
          <p><b>Alternative:</b> Yukon can understand behavioral cues.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="inv1-2-e" label="I1.2.5">
        <title>Plan the Simulation</title>
        <statement>
          <p>So our simulation model is going to assume the null hypothesis is true and we will see how unusual it is to find 6 successes and 2 failures in 8 attempts. Can we use "coin tossing" again? How many times will we toss the coin?</p>
        </statement>
        <response/>
        <solution>
          <p>Yes, we can use coin tosses again with heads = top side down and tails = top side up. We want to use 8 tosses for each repetition and count how many heads we have.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="inv1-2-f" label="I1.2.6">
        <statement>
          <p>Use the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url> to carry out 1,000 repetitions of the simulation. Check the Summary Statistics box and report the mean and standard deviation of your simulated distribution of "could have been" outcomes.</p>
          <p>Mean: <var width="5"/> <br/>
          Standard deviation: <var width="5"/></p>
        </statement>
        <response/>
        <solution>
          <p>Example results:</p>
          <ul>
            <li>Histogram</li>
            <li>Description automatically generated with low confidence</li>
          </ul>
          <p>The mean number of heads is about 4 (half of 8) and the standard deviation of the number of heads is about 1.5.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="inv1-2-g" label="I1.2.7">
        <title>Evaluate Surprise Level</title>
        <statement>
          <p>Based on your simulation results, which assumes Yukon is guessing, should we be very surprised to see 6 correct guesses? Explain/support your reasoning.</p>
        </statement>
        <response/>
        <solution>
          <p>An outcome of 6 heads does not appear to be in the tail of the distribution.</p>
        </solution>
      </exercise>
      
      <paragraphs>
        <title>Measuring "Rareness"</title>
        
        <p>In Investigation 1.1, the observed result (14) was pretty far in the tail of the distribution and you probably agreed that we could consider it unusual. This result (6 out of 8) is not as inconsistent with the null hypothesis; so where do we "draw the line"? First, we need agree on a measure of "rareness." We could just calculate the theoretical probability of 6 heads in 8 tosses (0.1094), but keep in mind that if we have a larger sample size (e.g., 100 tosses), then any individual outcome (e.g., 62 heads) will have a small probability. So we want to judge how extreme our observation is relative to the other observations in the simulated distribution. One way to do this is to count how many outcomes are as or even more extreme (even further from the expected value) than the observed outcome. For example, if we tell you that only 1% of rattlesnakes are longer than 2.5 meters, then you know to be very surprised to see a 3-meter rattlesnake and you may even begin to think that what you are looking at is not a rattlesnake at all!</p>
        
        <exercise xml:id="inv1-2-h" label="I1.2.8">
          <title>Calculate P-value</title>
          <statement>
            <p>In the applet, enter 6 in the Count samples box and keep the "as extreme as" button to greater than or equal to, <m>\geq</m>. Report the proportion of the repetitions with 6 or more heads (correct choices).</p>
            <p>In 1,000 repetitions, assuming the probability of choosing correctly is 0.50, we found <var width="5"/> % of repetitions of 8 attempts to result in 6 or more successes.</p>
          </statement>
          <response/>
          <solution>
            <p>Results will vary but should be around 0.15, or 15% of repetitions resulting in 6 or more heads.</p>
          </solution>
        </exercise>
        
        <p>Notice that we consider the direction of the alternative hypothesis to help us determine which outcomes we consider "more extreme" than our observed outcome. This tail probability you found in (h) is referred to as the p-value.</p>
        
        <assemblage xml:id="def-pvalue-null-distribution">
          <title>Definition: Null Distribution and P-value</title>
          <p>Because the simulation assumes the null hypothesis to be true, we can refer to the distribution you simulated as the <term>null distribution</term><idx><h>null distribution</h><h>distribution assuming null hypothesis is true</h></idx>. When you determine the proportion of the results in the null distribution that are at least as extreme as the observed result, you are estimating a probability. We will refer to this probability as the <term>p-value</term><idx><h>p-value</h><h>probability of results as extreme as observed, assuming null hypothesis</h></idx>. We use the p-value to evaluate the strength of evidence against the null hypothesis.</p>
          
          <p>The smaller the p-value, the stronger the evidence against the null hypothesis. There are no hard-and-fast cut-off values for gauging the smallness of a p-value, but generally speaking:</p>
          <p><ul>
            <li><p>A p-value above 0.10 constitutes little or no evidence against the null hypothesis.</p></li>
            <li><p>A p-value below 0.10 but above 0.05 constitutes moderate evidence against the null hypothesis.</p></li>
            <li><p>A p-value below 0.05 but above 0.01 constitutes strong evidence against the null hypothesis.</p></li>
            <li><p>A p-value below 0.01 constitutes very strong evidence against the null hypothesis.</p></li>
          </ul></p>
        </assemblage>
        
        <exercise xml:id="inv1-2-i" label="I1.2.9">
          <title>Compare P-values</title>
          <statement>
            <p>Did everyone in your class obtain the same p-value? <em>(If not, are you surprised?)</em></p>
          </statement>
          <choices randomize="no">
            <choice>
              <statement>
                <p>Yes</p>
              </statement>
              <feedback>
                <p>Actually, because we're using simulation, each person's results will vary slightly.</p>
              </feedback>
            </choice>
            <choice correct="yes">
              <statement>
                <p>No</p>
              </statement>
              <feedback>
                <p>Correct! The p-value will vary slightly across simulations because of the random nature of the process.</p>
              </feedback>
            </choice>
          </choices>
          <solution>
            <p>No, the p-value will vary slightly across the simulations.</p>
          </solution>
        </exercise>
        
        <p>Because we are assuming a random process, we can use probability rules to calculate an "exact" value for the p-value. In fact, we have been assuming a very special random process, a binomial process.</p>
      </paragraphs>
      
      <paragraphs>
        <title>Probability Detour â€“ Binomial Random Variables</title>
        
        <assemblage xml:id="def-binomial-random-variable">
          <title>Definition: Binomial Random Variable</title>
          <p>A <term>Binomial random variable</term><idx><h>binomial random variable</h><h>counts successes in independent trials</h></idx> counts the number of successes in a random process with the following properties:</p>
          <p><ul>
            <li><p>Each trial results in either "success" or "failure" (we have a binary categorical variable).</p></li>
            <li><p>The trials are independent: The outcome of one trial does not change the probability of success on the next trial.</p></li>
            <li><p>The probability of success, <m>\pi</m>, is constant across the trials.</p></li>
            <li><p>There are a fixed number of trials, <m>n</m>.</p></li>
          </ul></p>
          
          <p>If the number of successes, <m>X</m>, is a binomial random variable, then we can say <m>X \sim \text{Binomial}(n, \pi)</m>.</p>
        </assemblage>
        
        <p>Because we are assuming the null hypothesis to be true, we are treating each attempt as an identical repetition of a random process with a probability of success of 0.50 for each attempt (always two containers to choose from), and one attempt outcome does not impact the probability of success on the next attempt (e.g., a screen was lowered between attempts and the location of the food randomized each time) so the attempts are independent. We are counting <m>X</m>, the observed number of correct choices in the <m>n = 8</m> trials. So <m>X \sim</m> (is distributed as) <m>\text{Binomial}(8, 0.50)</m> and we want to determine the probability of observing 6 or more successes in 8 attempts by chance alone, <m>P(X \geq 6)</m>. We will illustrate this calculation next, and then turn to technology to find binomial probabilities.</p>
        
        <paragraphs>
          <title>Calculating Binomial Probabilities</title>
          
          <exercise xml:id="inv1-2-j" label="I1.2.10">
            <title>Calculate Single Outcome Probability</title>
            <statement>
              <p>Let S represent Success and F represent Failure. Consider one particular outcome for the 8 trials with 6 successes: SSFSSSFS. Because we are assuming the trials are independent, we can find the probability of this event by multiplying together the probabilities of the individual outcomes in the event.</p>
              <p><md>
                <mrow>P(\text{SSFSSSFS}) \amp = P(S) \times P(S) \times P(F) \times P(S)</mrow>
                <mrow>\amp \quad \times P(S) \times P(S) \times P(F) \times P(S)</mrow>
              </md></p>
              <p>What is the calculated product? <var width="5"/></p>
            </statement>
            <response/>
            <solution>
              <p>0.58</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-k" label="I1.2.11">
            <title>Count Arrangements</title>
            <statement>
              <p>But there are other possible outcomes that would also result in 6 successes and 2 failures (for example, SFSSSSSF). How many ways are there to arrange the 6 successes among the 8 slots?</p>
              <p>This is where the binomial coefficient comes in handy. This <term>binomial coefficient</term><idx><h>binomial coefficient</h><h>counts ways to select k items from n</h></idx>, denoted by <m>C(n, k)</m> or <m>\binom{n}{k} = \frac{n!}{k!(n-k)!}</m>, counts the number of ways there are to select <m>k</m> items from a set of <m>n</m> items. In this case, we want to find the number of ways to select 6 spots from the 8 trials for the successes:</p>
              <p><me>C(8, 6) = \frac{8!}{6!2!}</me></p>
              <p>What is the calculated result? <var width="5"/></p>
            </statement>
            <response/>
            <solution>
              <p>28</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-l" label="I1.2.12">
            <title>Calculate Probability for 6 Successes</title>
            <statement>
              <p>Because the 28 outcomes corresponding to 6 successes are mutually exclusive (can't occur simultaneously), we can find the probability of at least one of them happening by adding all of the probabilities together:</p>
              <p><me>P(\text{SSFSSSFS}) + P(\text{SFSSSSSF}) + \ldots = 28 \times (0.5^8)</me></p>
              <p>What is the calculated product? <var width="5"/></p>
              <p>In general, the binomial probability of obtaining <m>k</m> successes in a sequence of <m>n</m> independent trials with success probability <m>\pi</m> on each trial is:</p>
              <p><me>P(X = k) = \binom{n}{k} \pi^k (1-\pi)^{n-k}</me></p>
              <p>where <m>\binom{n}{k} = \frac{n!}{k!(n-k)!}</m></p>
            </statement>
            <response/>
            <solution>
              <p>0.1094</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-m" label="I1.2.13">
            <title>Calculate Complete P-value</title>
            <statement>
              <p>Is the number you found in (l) our p-value for this study? If not, how would we find the p-value?</p>
            </statement>
            <response/>
            <solution>
              <p>No, so far we have found P(X = 6), but the p-value is defined as P(X &gt; 6).</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-n" label="I1.2.14">
            <statement>
              <p>In the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url>, check the Exact Binomial box. (Optional: See Technology Detour below.) How does the binomial distribution match up to your earlier simulation results? How does the binomial (or "exact") p-value compare to what you simulated earlier? Did everyone in class obtain the same "exact" p-value?</p>
            </statement>
            <response/>
            <solution>
              <p>0.1445. This should be similar to the simulation results and everyone would obtain the same calculated value.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-o" label="I1.2.15">
            <title>Interpret P-value</title>
            <statement>
              <p>Write a one-sentence interpretation of this p-value in this context. Key components to include: what random process is being repeated, what is the null hypothesis that we are assuming to be true, what is the observed result we are considering, which outcomes are we considering to be more extreme?</p>
            </statement>
            <response/>
            <solution>
              <p>If we were to repeatedly examine samples of 8 attempts from wolves who do not understand the communication cues, we would expect 6 or more wolves to pick the correct container for about 14% of those samples by chance alone.</p>
            </solution>
          </exercise>
        </paragraphs>
      </paragraphs>
      
      <paragraphs>
        <title>Conclusions</title>
        
        <exercise xml:id="inv1-2-p" label="I1.2.16">
          <title>State Conclusion</title>
          <statement>
            <p>Based on this analysis, do these data provide convincing evidence that wolves can understand behavioral cues?</p>
          </statement>
          <response/>
          <solution>
            <p>No, a p-value of 0.14 is not strong evidence against the null hypothesis. It is plausible that Yukon would do as well in 8 trials even if she didn't understand the cue and was simply guessing.</p>
          </solution>
        </exercise>
      </paragraphs>
      
      <assemblage xml:id="study-conclusions-1-2">
        <title>Study Conclusions</title>
        <p>If we assume Yukon is guessing between the two containers, regardless of the cue, then finding 6 or more successes in 8 trials is actually not very surprising (binomial p-value = 0.1445); about 14% of samples from a 50/50 process would show 6 or more successes in 8 trials. This does not provide convincing evidence that Yukon can perform "above chance," but there is not information about whether other wolves or other cues would show better performance.</p>
      </assemblage>
      
      <subsection xml:id="practice1-2A">
        <title>Practice Problem 1.2A</title>
        
        <p>When Yukon was given "communicative cues" (looking at the container, pointing to the container) instead of behavioral cues, she was correct in 7 out of 8 attempts. Does this outcome provide convincing evidence that wolves understand communicative cues?</p>
        
        <exercise xml:id="practice-1-2a-a" label="PP1.2A.1">
          <statement>
            <p>State the null and alternative hypotheses for this study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2a-b" label="PP1.2A.2">
          <statement>
            <p>Report both a simulation-based and the exact p-value. Include a one-sentence interpretation of the p-value in this context.</p>
            <p>Simulation-based p-value: <var width="5"/></p>
            <p>Exact p-value: <var width="5"/></p>
            <p>Interpretation: The probability of <var width="30"/> assuming <var width="30"/>.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2a-c" label="PP1.2A.3">
          <statement>
            <p>Summarize your analysis and the conclusions you would draw from this study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2a-d" label="PP1.2A.4">
          <statement>
            <p>Across the 12 wolves in the study, in the 64 trials with communicative cues, the wolves understood the cue 41 times. What is the new p-value for these results? Explain why this would not be an appropriate analysis.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-2B">
        <title>Practice Problem 1.2B</title>
        
        <p>A study in Psychonomic Bulletin and Review (<url href="https://psycnet.apa.org/record/2007-18366-015" target="_blank">Lea, Thomas, Lamkin, <ampersand/> Bell, 2007</url>) presented evidence that "people use facial prototypes when they encounter different names." Similar to one of the experiments they conducted, you will be asked to match photos of two faces to the names Tim and Bob. The researchers wrote that their participants "overwhelmingly agreed" on which face belonged to Tim. You will conduct a similar study in class to see whether your class also agrees with which face is Tim's more than you would expect from random chance (here "random chance" = there is no facial prototyping and people pick a name for the face on the left at random).</p>
        
        <exercise xml:id="practice-1-2b-a" label="PP1.2B.1">
          <statement>
            <p>What is the sample/random process and variable in this study? What assumptions are we making about this process?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2b-b" label="PP1.2B.2">
          <statement>
            <p>State the null and alternative hypotheses for this study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2b-c" label="PP1.2B.3">
          <statement>
            <p>Report the count, proportion, and percentage "correctly" identifying Tim's face in your class.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2b-d" label="PP1.2B.4">
          <statement>
            <p>Use the applet or the technology instructions below to obtain a binomial p-value. What do you conclude about the null hypothesis?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2b-e" label="PP1.2B.5">
          <statement>
            <p>Do you think the properties of the binomial random variable are met here? What assumptions need to be made?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <paragraphs xml:id="tech-detour-binomial">
        <title>Technology Detour â€“ Calculating Binomial Probabilities</title>
        
        <exercise xml:id="tech-detour-r-binomial" label="Binomial Probabilities - R">
          <title>Calculating Binomial Probabilities in R</title>
          <statement>
            <p>Make sure you have the ISCAM Workspace loaded.</p>
            <p>The <c>iscambinomprob</c> function takes the following inputs:</p>
            <p><ul>
              <li><p><c>k</c> = the observed value you want to calculate the probability about</p></li>
              <li><p><c>n</c> = the sample size of the binomial distribution</p></li>
              <li><p><c>prob</c> = the probability of success in the binomial distribution</p></li>
              <li><p><c>lower.tail</c> = TRUE if you want the probability less than or equal to the observed value, FALSE if want the probability greater than or equal to the observed value</p></li>
            </ul></p>
            
            <p>For the Friend or Foe study, in the Console at the prompt, type:</p>
            <program language="r" interactive="sage">
              <input>
iscambinomprob(k=14, n=16, prob=.5, lower.tail=FALSE)
              </input>
            </program>
            <p>or</p>
            <program language="r" interactive="sage">
              <input>
iscambinomprob(14, 16, .5, FALSE)
              </input>
            </program>
            <p>(Yes, "false" needs to be capitalized)</p>
            
            <p>You should see both the probability appear in the Console window and a shaded graph open in a separate Graphics window. (You may have to toggle windows to see this Graphics window.)</p>
            
            <note>
              <title>R Reminder</title>
              <p>The <c>iscambinomprob</c> function is part of the ISCAM package. Make sure to load the package first with <c>library(iscam)</c>. The <c>lower.tail</c> parameter controls the direction: FALSE gives you <m>P(X \geq k)</m>, TRUE gives you <m>P(X \leq k)</m>.</p>
            </note>
          </statement>
          <solution>
            <p>For the Friend or Foe study with 14 successes out of 16 trials, the binomial p-value should be very small (approximately 0.0021), indicating strong evidence against the null hypothesis that infants are choosing randomly between the two toys.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="tech-detour-jmp-binomial" label="Binomial Probabilities - JMP">
          <title>Calculating Binomial Probabilities in JMP</title>
          <statement>
            <p>Using the Distribution Calculator in the <url href="http://www.rossmanchance.com/iscam4/data/ISCAM_Journal.jrn" download="ISCAM_Journal.jrn" target="_blank">ISCAM Journal File</url> (Download this file to your computer and then open the .jrn file to launch JMP.)</p>
            <p><ol>
              <li><p>Select Binomial from the Distribution pull down menu.</p></li>
              <li><p>Specify the values of the probability of success (<m>\pi</m>) and n (the sample size).</p></li>
              <li><p>Leave the Type of Calculation as is.</p></li>
              <li><p>Select Probability Option <m>X \geq Q_a</m> but specify <m>Q_a</m> to equal <m>k-1</m> (e.g., 13).</p></li>
              <li><p>Press Enter.</p></li>
            </ol></p>
            
            <note>
              <title>JMP Reminder</title>
              <p>In JMP's Distribution Calculator, you need to subtract 1 from your observed value when using the <m>\geq</m> option because JMP calculates <m>P(X > Q_a)</m> as <m>P(X \geq Q_a + 1)</m>. So to get <m>P(X \geq 14)</m>, you enter 13 as <m>Q_a</m>.</p>
            </note>
          </statement>
          <solution>
            <p>The JMP Distribution Calculator will display both the probability value and a visual representation of the binomial distribution with the tail area shaded. For finding <m>P(X \geq 14)</m> when <m>n=16</m> and <m>\pi=0.5</m>, enter 13 for <m>Q_a</m> to get the correct p-value of approximately 0.0021.</p>
          </solution>
        </exercise>
      </paragraphs>
    </subsection>
    
    <subsection xml:id="investigation-1-3">
      <title>Investigation 1.3: Are You Clairvoyant?</title>
      
      <introduction>
        <p>A standard test for extra-sensory perception (ESP) asks subjects to identify which of five symbols (e.g., circle, plus, square, diamond, waves) is on the front of a card, viewed by the experimenter but not the subject. The experimenter concentrates on the symbol and a <q>hit</q> is when the subject correctly identifies the symbol being viewed by the experimenter. The subject is given several trials, with the viewed symbol randomly determined for each of the trials, with no discernible pattern.</p>
        
        <figure xml:id="fig-esp-cards">
          <caption>ESP Test Symbols</caption>
          <image source="esp.png" width="60%">
            <description>Five ESP test symbols: circle, plus sign, square, diamond, and wavy lines</description>
          </image>
        </figure>
      </introduction>
      
      <p>Online tests are available as well. Go to <url href="http://www.psychicscience.org/esp3.aspx" target="_blank">www.psychicscience.org/esp3.aspx</url> to test your clairvoyance (predicting what's about to happen rather than reading what someone else is thinking). Scroll down to Advanced ESP Test and review the 5 possible symbols, then press Start. Click on the card that you believe is about to be shown. Repeat for 10 rounds, keeping tracking of the number of hits in your first 10 attempts.</p>
      
      <exercise xml:id="I1-3-1" label="I1.3.1">
        <title>Conduct the ESP Test</title>
        <statement>
          <p>How many hits did you get? <var width="10" /></p>
        </statement>
      </exercise>
      
      <exercise xml:id="I1-3-2" label="I1.3.2">
        <title>Identify Sample and Variable</title>
        <statement>
          <p>Identify the sample and variable for this random process.</p>
        </statement>
        <response/>
        <hint>
          <p>What is the sample size? What was measured about each observation?</p>
        </hint>
        <solution>
          <p>The random process is the repeated attempts to identify the symbol correctly. The sample size is the 10 trials. Variable = correct/incorrect identification (categorical). The sample size is 10.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-3" label="I1.3.3">
        <title>Binomial Random Process</title>
        <statement>
          <p>Do you consider it reasonable to model your observations as coming from a binomial random process? Explain your reasoning.</p>
        </statement>
        <response/>
        <hint>
          <p>Consider the four conditions for a binomial process: two outcomes, independence, fixed number of trials, and constant probability.</p>
        </hint>
        <solution>
          <p>If the target symbols are randomly selected (equally likely), the student uses the same method each time, and the student is not more likely to correctly identify some symbols more than others (e.g., guessing each time) then a binomial process does seem reasonable.</p>
        </solution>
      </exercise>
      
      <assemblage xml:id="terminology-statistic-parameter">
        <title>Terminology Detour: Statistic vs. Parameter</title>
        
        <p>In analyzing data, it is important to differentiate between a <term>statistic</term> and the <term>parameter</term>. The observed statistic is a (known) numerical value that summarizes the observed results, whereas the parameter is the same numerical summary but applied to the underlying random process that generated the data. The value of the statistic is what we observe in the study, whereas the value of the parameter is rarely known.</p>
        
        <p>In Investigation 1.1, the statistic could be either the number (14) or the proportion (0.875) of infants who chose the helper toy. The parameter would then be the long-run probability of an infant picking the helper toy. In the case of a binomial random variable, we will use the symbol <m>\pi</m> (lower case Greek letter for <q>p</q>) to represent this unknown process probability.</p>
      </assemblage>
      
      <exercise xml:id="I1-3-4" label="I1.3.4">
        <title>Identify the Parameter</title>
        <statement>
          <p>Identify (in words) the parameter of interest for this study.</p>
        </statement>
        <response/>
        <hint>
          <p>A parameter describes a long-run probability or proportion for the entire process, not just your sample result.</p>
        </hint>
        <solution>
          <p>The parameter is your probability of correct identification (the long-run probability of correctly identifying the symbol).</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-4b" label="I1.3.4b">
        <title>Parameter Symbol</title>
        <statement>
          <p>What symbol will we use to represent this parameter?</p>
        </statement>
        <hint>
          <p>Look for the Greek letter used for a process probability in a binomial distribution.</p>
        </hint>
        <choices randomize="no">
          <choice>
            <statement><p><m>\hat{p}</m></p></statement>
            <feedback><p>This is the symbol for the sample proportion (statistic), not the population parameter.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p><m>\pi</m></p></statement>
            <feedback><p>Correct! We use <m>\pi</m> to represent the probability of success in a binomial process.</p></feedback>
          </choice>
          <choice>
            <statement><p><m>\mu</m></p></statement>
            <feedback><p>This is the symbol for a population mean, not a probability.</p></feedback>
          </choice>
          <choice>
            <statement><p><em>p</em></p></statement>
            <feedback><p>While <em>p</em> is sometimes used for probability, we use the Greek letter <m>\pi</m> for the process probability parameter.</p></feedback>
          </choice>
        </choices>
        <solution>
          <p>We use <m>\pi</m> to represent your probability of correct identification.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-5" label="I1.3.5">
        <title>State the Null Hypothesis</title>
        <statement>
          <p>The null hypothesis is that you aren't clairvoyant and are guessing every time. State this as a null hypothesis using symbols and words.</p>
          <p><em>Tip: Type "pi" for the Greek letter. Format as: H_0: pi = value</em></p>
        </statement>
        <response/>
        <hint>
          <p>If guessing randomly among 5 symbols, what is the probability of guessing correctly?</p>
        </hint>
        <solution>
          <p><m>H_0: \pi = 0.20</m> (you have a 1 in 5 chance of guessing correctly)</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-6" label="I1.3.6">
        <title>State the Alternative Hypothesis</title>
        <statement>
          <p>State the alternative hypothesis using symbols and words.</p>
          <p><em>Tip: Type "pi" for the Greek letter. Use greater than, less than, or not equal to. Format as: H_a: pi &gt; value</em></p>
          <aside>
            <p>Notice that the hypothesized values for <m>\pi</m> in the null and alternative can't <q>overlap;</q> they are competing statements about <m>\pi</m>.</p>
          </aside>
        </statement>
        <response/>
        <hint>
          <p>If you are clairvoyant, would your probability of correct identification be higher or lower than random guessing?</p>
        </hint>
        <solution>
          <p><m>H_a: \pi > 0.20</m> (you have a higher probability of predicting correctly)</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-7" label="I1.3.7">
          <title>Simulation Method</title>
          <statement>
            <p>Assume the null hypothesis is true and let the random variable <m>C</m> denote the number of correct identifications (hits) in 10 attempts. If we were to simulate this random process, could we toss coins? If not, suggest another way we could generate simulated results assuming the null hypothesis to be true. (e.g., what would you want an applet to do?)</p>
          </statement>
          <response/>
          <hint>
            <p>Coin tosses give 50/50 probability. Does your null hypothesis assume 50% chance of success?</p>
          </hint>
          <solution>
            <p>We can model <m>C</m> with the binomial distribution:</p>
            <p><ul>
              <li><p>Each trial has two outcomes: correct match or not</p></li>
              <li><p>The trials are independent (the cards are shuffled in between attempts and the symbols are placed at random with no patterns from trial to trial)</p></li>
              <li><p>There are a fixed number of attempts (<m>n = 10</m>)</p></li>
              <li><p>The probability of success (if someone is guessing) is the same for each trial (<m>= 0.20</m> if using 5 cards each trial). We aren't changing the number of cards or anything else from trial-to-trial.</p></li>
            </ul></p>
            <p>We can't toss a coin because we are not assuming 50/50 for success/failure. To model 0.20 we could use spinners.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-3-8" label="Null distribution predictions">
          <title>Null Distribution Predictions</title>
          <statement>
            <p>Where do you think your null distribution will be centered? What are the largest and smallest possible values for the number of correct identifications in 10 attempts? What are the largest and smallest values you think you will see in the simulation?</p>
          </statement>
          <response/>
          <hint>
            <p>Use the probability from the null hypothesis times the number of attempts to find the expected value.</p>
          </hint>
          <solution>
            <p>On average, if someone is guessing, we would <q>expect</q> to see <m>\frac{1}{5}(10) = 2</m> correct answers (in the long run). <m>E(C) = 10(0.20) = 2</m> if assuming 5 cards.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-3-9" label="Applet simulation">
          <title>Carry Out the Simulation</title>
          <statement>
            <p>In the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url>, specify the values for <m>\pi</m> and <m>n</m>. Carry out one repetition of the simulation. Explain the simulation process in your own words.</p>
          </statement>
          <response/>
          <hint>
            <p>Set pi to your null hypothesis value and n to the number of attempts you made.</p>
          </hint>
          <solution>
            <p>Results will vary. The applet should generate 10 spinners (each a 0.20 probability of success = landing in the blue region) and then record the number of successes in those 10 spins.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-3-10" label="Theoretical mean SD">
          <title>Theoretical Mean and Standard Deviation</title>
          <statement>
            <p>Then check the Exact Binomial box to see the null distribution after infinitely many repetitions. Press the Reset button to remove the one simulated result and check the Summary Statistics box. What are the theoretical values for the mean and standard deviation of the null distribution?</p>
            
            <p>Mean = <var width="5" /></p>
            <p>Std Dev = <var width="5" /></p>
          </statement>
          <response/>
          <hint>
            <p>Look for the values displayed in the Summary Statistics section of the applet after pressing Reset.</p>
          </hint>
          <solution>
            <p>After pressing Reset to remove the one simulated trial, you should find Mean = 2.000, SD = 1.265.</p>
          </solution>
        </exercise>
        
        <assemblage xml:id="binomial-formulas">
          <title>Binomial Distribution Formulas</title>
          <p>It can be shown that when <m>X</m> is Binomial(<m>n</m>, <m>\pi</m>), the expected value is <m>E(X) = n \times \pi</m> and the variance is <m>V(X) = n\pi(1 - \pi)</m>. (See Exploration B for more discussion of expected value and variance of a random variable.)</p>
        </assemblage>
        
        <exercise xml:id="I1-3-11" label="Verify calculations">
          <title>Verify the Calculations</title>
          <statement>
            <p>Verify these calculations match the applet output and remember that the standard deviation is the square root of the variance.</p>
          </statement>
          <response/>
          <hint>
            <p>Use the formulas provided in the previous question with n=10 and pi=0.20.</p>
          </hint>
          <solution>
            <p><m>E(C) = 10(0.2) = 2.00</m> and <m>SD(C) = \sqrt{10 \times 0.2 \times 0.8} = 1.265</m>.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-3-12" label="Result in tail">
          <title>Result in the Tail?</title>
          <statement>
            <p>Was your statistic from Checkpoint 3.77 (your number of hits) in the direction specified by the alternative hypothesis? If it was, is it in one of the tails (outer edges) of the null distribution from Checkpoint 3.86?</p>
          </statement>
          <response/>
          <hint>
            <p>Compare your number of hits to the mean of the distribution. Is it larger (right tail) or smaller (left tail)?</p>
          </hint>
          <solution>
            <p>Results will vary, but quite possible your results were below the expected value.</p>
          </solution>
        </exercise>
      
      <p>If your observed number of successes was below the mean, then you can conclude that your data do not provide evidence in favor of the alternative hypothesis and you should not start your own psychic hotline! But if your result was above the mean, then we would like to measure the strength of evidence against the null hypothesis. You have already seen how to do that using a p-value.</p>
      
      <exercise xml:id="I1-3-13" label="I1.3.13">
        <title>Explore p-value Threshold</title>
        <statement>
          <p>Use the applet to explore how many hits a subject would need in 10 attempts for the p-value to be below 0.05.</p>
        </statement>
        <response/>
        <hint>
          <p>Use your mouse to drag the red line.</p>
        </hint>
        <solution>
          <p>A subject would need at least 5 hits in 10 attempts for the p-value to be below 0.05 (specifically, P(X â‰¥ 5) = 0.0328).</p>
        </solution>
      </exercise>
      
      <paragraphs xml:id="alternative-measure-rareness">
        <title>An Alternative Measure of Rareness</title>
        
        <p>As an alternative to the p-value, another measure of where an observation falls in a distribution is <q>how many standard deviations</q> it is from the mean of the distribution.</p>
        
        <figure xml:id="fig-ruler">
          <caption>A number line showing distances from the null hypothesis mean</caption>
          <image source="images/ruler.png" width="70%">
            <description>A ruler or number line showing the distance scale for evaluating deviations from the hypothesized mean.</description>
          </image>
        </figure>
        
        <p><me>\frac{\text{observed number of hits} - \text{expected value}}{\text{standard deviation}} </me></p>
        
        <exercise xml:id="I1-3-14" label="I1.3.14">
          <title>Standardize Your Result</title>
          <statement>
            <p>How many standard deviations was your observed result from the expected value for the binomial distribution?</p>
          </statement>
          <response/>
          <hint>
            <p>Use the formula: (observed - expected) / standard deviation. Substitute your number of hits for observed, and use the mean and SD from Checkpoint 3.86.</p>
          </hint>
          <solution>
            <p>The standardized statistic expresses the distance in <q>standard deviations away</q> from the hypothesized value of <m>\pi</m>. A negative value means the distance is below the mean; a positive value means the distance is above the mean.</p>
          </solution>
        </exercise>
        
        <p>This calculation is often referred to as <term>standardizing the statistic</term>.</p>
        
        <p>Again, there are no hard and fast rules for what constitutes a large value here, but generally, when we have a fairly symmetric distribution, values more than 2 standard deviations above or below the expected value (mean) are considered extreme.</p>
      </paragraphs>
        
        <exercise xml:id="I1-3-15" label="I1.3.15">
            <title>Standardizing 5 Hits</title>
            <statement>
              <p>How many standard deviations from the mean (expected value) would 5 hits be?</p>
            </statement>
            <response/>
            <hint>
              <p>Use the same formula as the previous question: (5 - 2) / 1.265. What does this value tell you?</p>
            </hint>
            <solution>
              <p>A standardized statistic of 1 means that the sample result is one standard deviation above the mean of 2. Because the SD is 1.265, 1 SD above the mean is at <m>2 + 1.265 = 3.265</m>. Rounding to the nearest whole number, that would correspond to 3 correct identifications. (Or you could solve: <m>(x - 2)/1.265 = 1</m> to find <m>x = 3.265</m>.)</p>
            </solution>
          </exercise>
          
          <exercise xml:id="I1-3-16" label="I1.3.16">
            <title>Distribution for 25 Attempts</title>
            <statement>
              <p>Suppose you don't know whether or not someone is clairvoyant and you plan to give the person 25 attempts. What are the theoretical expected number and standard deviation for the random variable <m>C</m>, the number of hits when <m>n = 25</m> assuming they are just guessing each time? How do they compare to the values you found in (j)?</p>
            </statement>
            <response/>
            <hint>
              <p>Use the binomial formulas with n = 25 and pi = 0.20. Expected value = n Ã— pi, and SD = square root of n Ã— pi Ã— (1 - pi).</p>
            </hint>
            <solution>
              <p>Expected value = <m>5</m>, SD = <m>2</m></p>
              <p>Note: You can check these in the applet. Because the value of <m>n</m> has changed, both have increased. The larger the sample size, the more variability in the distribution.</p>
            </solution>
          </exercise>
          
          <p>How many hits would someone need to get correct in 25 attempts to convince you they aren't simply guessing? Let's consider two ways to decide.</p>
          
          <exercise xml:id="I1-3-17" label="I1.3.17">
            <title>Approach 1: P-value Threshold</title>
            <statement>
              <p><alert>Approach 1:</alert> What value for <m>c</m> would give you a probability below 0.05 of obtaining that many or more hits? In other words, what is the smallest value of <m>c</m> so <m>P(C \geq c) &lt; 0.05</m>?</p>
            </statement>
            <response/>
            <hint>
              <p>Use the applet to find probabilities for different values of c.</p>
            </hint>
            <solution>
              <p>We need to find <m>c</m> such that <m>P(C \geq c) &lt; 0.05</m>. Using the applet:
                <ul>
                  <li><p><m>P(C \geq 8) = 0.109</m> (too large)</p></li>
                  <li><p><m>P(C \geq 9) = 0.048</m> (this will work!)</p></li>
                </ul>
              So if someone had 9 or more correct, we might choose to consider that statistically significant.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="I1-3-17b" label="I1.3.17b">
            <title>Approach 2: Standard Deviations</title>
            <statement>
              <p><alert>Approach 2:</alert> What is the smallest value of <m>c</m> that is at least 2 standard deviations from the expected value?</p>
            </statement>
            <response/>
            <hint>
              <p>Use the expected value and standard deviation from Checkpoint 3.93.</p>
            </hint>
            <solution>
              <p>The observed value would need to be more than <m>5 + 2(2) = 9</m>.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="I1-3-18" label="Compare approaches">
            <title>Compare the Two Approaches</title>
            <statement>
              <p>How do your answers for these two approaches compare?</p>
            </statement>
            <response/>
            <hint>
              <p>Look at the values of c you found in both approaches. Are they the same or very close? What does this suggest about the relationship between p-values and standard deviations?</p>
            </hint>
            <solution>
              <p>It is not a coincidence that the value of 9 appears in both and is close to the expected value + 2 SD. It turns out that with a <q>large enough</q> sample size, if a standardized statistic is about 2 SD from the mean, the p-value will be close to 0.05. We will develop this idea much more carefully when we turn to the normal approximation to the binomial.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="I1-3-19" label="Four symbols">
            <title>Test with Four Symbols</title>
            <statement>
              <p>Suppose you changed the test to use only 4 symbols. Does this change the expected number or standard deviation for the number of hits when a subject is guessing? How many would someone need to identify correctly to convince you they could perform better than guessing in the long-run?</p>
            </statement>
            <response/>
            <hint>
              <p>With 4 symbols, the probability of guessing correctly changes to 1/4 = 0.25. Recalculate the expected value and SD using this new probability, then find how many hits would be 2 SD above the mean.</p>
            </hint>
            <solution>
              <p>This would increase the probability of a correct guess to 0.25, and so the probability model would need to change as well. If there are only 4 cards, the probability of a correct guess increases to 0.25. So, with 25 attempts, the expected value would be <m>25(0.25) = 6.25</m> with an SD of <m>\sqrt{25(0.25)(0.75)} = 2.17</m>. So <m>6.25 + 2(2.17) = 10.59 \approx 11</m>. Notice that this <q>cutoff</q> value went up (10 or 11 vs. 9). This is because guessing is more likely to do well so we need more evidence that someone is not guessing. Also, using the applet, <m>P(C \geq 10) = 0.097</m> and <m>P(C \geq 11) = 0.044</m>.</p>
            </solution>
          </exercise>
      
      <paragraphs xml:id="investigation-1-3-summary">
        <title>Summary</title>
        
        <p>The number of correct answers in 25 attempts, for someone who is guessing, can be modeled with a binomial distribution (assuming the probability of a correct answer is 0.20 each time and there is no pattern from attempt to attempt). In this case, the hypothesized value for the probability of <q>success</q> will be 0.20 rather than 0.5 due to the five cards to choose from, which we could model with spinners rather than coin tosses. If someone is simply guessing, in the long run they will guess correctly by chance alone 20% of the time. This means that if we give someone 25 attempts, we expect them to answer correctly <m>0.20 \times 25 = 5</m> times (on average, in the long run), with a standard deviation of <m>\sqrt{25(0.20)(0.80)} = 2</m> hits in 25 attempts. Keep in mind that the <q>statistical significance</q> of an outcome will depend on both the mean and the standard deviation of the null distribution. In this case, someone would need 9 or more hits to be more than 2 standard deviations above the mean, which corresponds to a p-value of 0.048. (It is not a coincidence that the 0.05 cut-off gives very similar results to the 2SD cut-off.)</p>
      </paragraphs>
      
      <subsection xml:id="practice1-3A">
        <title>Practice Problem 1.3A</title>
        
        <exercise xml:id="PP1-3A-1" label="PP1.3A.1">
          <title>Six Symbols: Distribution Changes</title>
          <statement>
            <p>Suppose the test had consisted of 6 symbols instead of 5 (with <m>n = 25</m> still). How will that change the binomial distribution? [You should comment on both the mean and the standard deviation.]</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3A-2" label="PP1.3A.2">
          <title>Six Symbols: Surprising Outcome</title>
          <statement>
            <p>Would an outcome of 9 correct guesses be more or less surprising in this case (vs. 5 symbols)?</p>
            <p><ul>
              <li><p>Will the probability of 9 or more correct identifications be larger or smaller than with 5 symbols?</p></li>
              <li><p>Will the outcome of 9 be more or fewer standard deviations from the mean than with 5 symbols?</p></li>
            </ul></p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3A-3" label="PP1.3A.3">
          <title>Ten Symbols</title>
          <statement>
            <p>What about 10 symbols? What are the mean and standard deviation of the binomial distribution? Would an outcome of 9 or more correct identifications be more or less surprising than with 5 symbols?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3A-4" label="PP1.3A.4">
          <title>Shape of Distribution</title>
          <statement>
            <p>How does the shape of the binomial distribution change as you lower <m>\pi</m>? Explain why.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-3B">
        <title>Practice Problem 1.3B</title>
        
        <p>Return to the wolf (Yukon). In another study, Yukon correctly understood a communicative cue in 7 of 8 attempts.</p>
        
        <exercise xml:id="PP1-3B-1" label="PP1.3B.1">
          <title>Parameter and Statistic</title>
          <statement>
            <p>Identify (in words) the parameter and statistic in that study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3B-2" label="PP1.3B.2">
          <title>Standardized Result</title>
          <statement>
            <p>How many standard deviations did the observed statistic fall above the expected value assuming Yukon picks equally between the two containers regardless of the cue in the long run?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3B-3" label="PP1.3B.3">
          <title>Surprising Outcome?</title>
          <statement>
            <p>Would her performance be considered a surprising outcome when the null hypothesis is true? Explain.</p>
          </statement>
          <response/>
        </exercise>
        
        <p>Return to the infants choosing a helper toy over a hinderer toy 14 times out of 16 choices.</p>
        
        <exercise xml:id="PP1-3B-4" label="PP1.3B.4">
          <title>Infant Study: Parameter and Statistic</title>
          <statement>
            <p>Identify (in words) the parameter and statistic in that study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3B-5" label="PP1.3B.5">
          <title>Infant Study: Standardized Result</title>
          <statement>
            <p>How many standard deviations did the observed statistic fall above the expected value assuming infants choose equally between the two types of toys?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3B-6" label="PP1.3B.6">
          <title>Infant Study: Time Variable</title>
          <statement>
            <p>In the infant study, researchers also looked at the amount of time the infants spent watching the two videos (to see whether one captured their attention more than the other). Identify a possible parameter of interest for this new variable.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-3C">
        <title>Practice Problem 1.3C</title>
        
        <p>Suppose you select 100 students at your school to estimate the proportion who prefer Coke to Pepsi.</p>
        
        <exercise xml:id="PP1-3C-1" label="PP1.3C.1">
          <title>Random Process</title>
          <statement>
            <p>Identify the random process of interest.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3C-2" label="PP1.3C.2">
          <title>The Sample</title>
          <statement>
            <p>Identify the sample in the study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3C-3" label="PP1.3C.3">
          <title>Parameter of Interest</title>
          <statement>
            <p>Define the parameter of interest in the study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3C-4" label="PP1.3C.4">
          <title>The Statistic</title>
          <statement>
            <p>Define the statistic in the study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3C-5" label="PP1.3C.5">
          <title>Average Number of States</title>
          <statement>
            <p>Suppose you want to estimate the average number of states visited by students at your school. Define the parameter of interest.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
  </section>
  </article>
</pretext>
