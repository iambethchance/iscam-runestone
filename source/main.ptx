<?xml version="1.0" encoding="UTF-8"?>
<pretext>
  <article xml:id="iscam">
    <title>ISCAM: Investigating Statistical Concepts, Applications, and Methods</title>
    <docinfo>
      <document-id>iscam</document-id>
      <blurb shelf="Mathematics">Introductory statistics text with active learning for mathematically inclined students</blurb>
    </docinfo>
    
    <section xml:id="to-the-student">
      <title>To the Student</title>
      
      <p>Statistics is a mathematical science.</p>
      
      <p>Although this is a very short sentence, perhaps a self-evident one, and certainly one of the shortest that you will find in this book, we want to draw your attention to several things about it:</p>
      
      <ul>
        <li><p>We use the singular "is" and not the plural "are." It is certainly grammatically correct and more common usage to say "statistics are...", but that use of the term refers to statistics as numerical values. In this sentence we mean statistics as a field of study, one that has its own concepts and techniques, and one that can be exciting to study and practice.</p></li>
        
        <li><p>We use "mathematical" as an adjective. Statistics certainly makes use of much mathematics, but it is a separate discipline and not a branch of mathematics. Many, perhaps most, of the concepts and methods in statistics are mathematical in nature, but there are also many that do not involve mathematics. You will see an example of this early in the book as you study the difference between observational studies and controlled experiments. You will find that even in cases where the mathematical aspects of two situations may be identical, the scope of one's conclusions depends crucially on how the data were collected, a statistical rather than a mathematical consideration.</p></li>
        
        <li><p>We use the noun "science." Statistics is the science of gaining insight from data. Data are (notice the plural here) pieces of information (often but not always numerical) gathered on people or objects or processes. The science of statistics involves all aspects of inquiry about data. Well-designed studies begin with a research question or hypothesis, devise a plan for collecting data to address that issue, proceed to gather the data and analyze them, and then often make inferences about how the findings generalize beyond the particular group being studied. Statistics concerns itself with all phases of this process and therefore encompasses the scientific method.</p></li>
      </ul>
      
      <p>In these materials, our goal is to introduce you to this practice of statistics, to help you think about the applications of statistics and to study the mathematical underpinnings of the statistical methods. Most of all, we hope you will find fun and engaging examples. Statistics is a vitally important subject, and also fun to study and practice, largely because it brings you into contact with all kinds of interesting questions. You will analyze data from medical studies, legal cases, psychology experiments, sociological studies, and many other contexts. To paraphrase the late statistician John Tukey, "the best thing about statistics is that it allows you to play in everyone's backyard." You never know what you might learn in a statistics class!</p>
      
      <p>One of the first features you will notice about these materials is that you will play the active role of investigator. You will read about an actual study and consider the research question, and then we will lead you to discover and apply the appropriate tools for carrying out the analysis. A primary reason for the investigative nature of these materials is that we strongly believe that you will better understand and retain the concepts if you build your own knowledge and are engaged in the context. Be sure to also pay attention to the Study Conclusions to see how to effectively convey statistical information and to the Practice Problems for testing your understanding. Key terms are also hyperlinked (though some pdf viewers change the # to %23, so you need to change back or just go to the main glossary link).</p>
      
      <p>Though you will only scratch the surface of the statistical methods used in practice, you will learn fundamental concepts (such as variability, randomness, confidence, and significance) that are an integral part of many statistical analyses. A distinct emphasis will be the focus on how the data are collected and how this determines the scope of conclusions that you can draw from the data.</p>
      
    </section>
    
    <section xml:id="preliminaries">
      <title>Preliminaries</title>
    
    <subsection xml:id="invA">
      <title>Investigation A: Hurricanes and Climate Change</title>
      
      <p>One of the concerns with climate change is an increased number of tropical storms (including hurricanes and major hurricanes). In particular, in the "Atlantic Basin," scientists have tracked the number of "named storms" since 1851. 
      According to the <url href="https://www.nhc.noaa.gov/climo/" target="_blank">National Hurricane Center</url>:</p>
      
      <ul>
        <li><term>Tropical Storm</term><idx><h>tropical storm</h><h>a tropical cyclone with maximum sustained winds of 39 to 73 mph</h></idx>: A tropical cyclone with maximum sustained winds of 39 to 73 mph (34 to 63 knots).</li>
        <li><term>Hurricane</term><idx><h>hurricane</h><h>a tropical cyclone with maximum sustained winds of 74 mph or higher</h></idx>: A tropical cyclone with maximum sustained winds of 74 mph (64 knots) or higher. In the western North Pacific, hurricanes are called typhoons; similar storms in the Indian Ocean and South Pacific Ocean are called cyclones.</li>
        <li><term>Major Hurricane</term><idx><h>major hurricane</h><h>a tropical cyclone with max sustained winds of 111 mph or higher</h></idx>: A tropical cyclone with max sustained winds of 111 mph (96 knots) or higher.</li>
      </ul>
      
      <figure xml:id="fig-noaa-table">
        <image source="NOAA.png" width="70%">
          <description>Snippet from NOAA data table showing storm classifications</description>
        </image>
        <caption>Snippet from the <url href="https://www.nhc.noaa.gov/climo/images/AtlanticStormTotalsTable.pdf" target="_blank">NOAA data table</url></caption>
      </figure>
      
      <p>In 2020, scientists were alarmed because there were 14 recorded hurricanes, compared to 6 in 2019.</p>
      
      <figure xml:id="fig-first-graph">
        <image source="firstgraph.png" width="70%">
          <description>Graph showing hurricane counts for 2019 and 2020</description>
        </image>
      </figure>
      
      <exercise xml:id="hurricane-ex-a" label="A.1">
        <title>Calculate Percentage Change</title>
        <statement>
          <p>Calculate the percentage change in the number of tropical hurricanes between these two years.</p>
        </statement>
        <hint>
          <p>The formula for percentage change is: <m>\frac{\text{new value} - \text{old value}}{\text{old value}} \times 100\%</m></p>
        </hint>
        <answer>
          <p><m>\frac{14-6}{6} \times 100\% = 133.3\%</m> increase</p>
        </answer>
        <response/>
      </exercise>
      
      <exercise xml:id="hurricane-ex-b" label="A.2">
        <title>Evaluate the Evidence</title>
        <statement>
          <p>Does this convince you that climate change is leading to an increase in the number of hurricanes (in the Atlantic)? If so, explain why. If not, explain what additional information you would want to know.</p>
        </statement>
        <hint>
          <p>Consider: Is comparing just two years enough evidence? What about natural year-to-year variation?</p>
        </hint>
        <solution>
          <p>Just because one year saw a large increase doesn't necessarily reflect an increasing trend. It's also hard to know whether this is a "large" increase when we don't have information on how much this value tends to vary from year to year. We can't draw any causal conclusions because other things could have changed in that time frame. We also need to keep in mind that "number of hurricanes" is just one possible reflection of "climate change."</p>
        </solution>
        <response/>
      </exercise>
      
      <p>Below is a dotplot of the annual number of hurricanes from 1851 to 2024 <m>(n = 174)</m>.</p>
      
      <figure xml:id="fig-hurricane-dotplot">
        <image source="hurricanedotplot.png" width="80%">
          <description>Dotplot showing the distribution of annual number of hurricanes from 1851 to 2024</description>
        </image>
        <caption>Source: <url href="https://www.stormfax.com/huryear.htm">https://www.stormfax.com/huryear.htm</url></caption>
      </figure>
      
      <exercise xml:id="hurricane-ex-c" label="A.3">
        <title>Interpret the Dotplot</title>
        <statement>
          <p>What does one dot in the above graph represent?</p>
        </statement>
        <hint>
          <p>Each dot represents data from one observational unit. What is being measured over time here?</p>
        </hint>
        <answer>
          <p>One dot represents the number of hurricanes in one year.</p>
        </answer>
        <response/>
      </exercise>
      
      <p>A year with 14 hurricanes is certainly close to record setting, but we expect there to be some variation from year to year. Below is a timeplot of the number of hurricanes each year.</p>
      
      <figure xml:id="fig-hurricane-timeplot">
        <image source="hurricanetimeplot.png" width="80%">
          <description>Timeplot showing the number of hurricanes each year from 1851 to 2024</description>
        </image>
      </figure>
      
      <exercise xml:id="hurricane-ex-d" label="A.4">
        <title>Compare Graph Types</title>
        <statement>
          <p>What additional information is provided by this graph and why is that helpful?</p>
        </statement>
        <hint>
          <p>Think about what a timeplot shows that a dotplot doesn't - how does it arrange the data differently?</p>
        </hint>
        <answer>
          <p>Now we know which year each value corresponds to and we might see a gradual increasing trend overall since about 1970. We also see that the change from 6 to 14 is a rather large change between years.</p>
        </answer>
        <response/>
      </exercise>
      
      <exercise xml:id="hurricane-ex-e" label="A.5">
        <title>Assess Reported Mean</title>
        <statement>
          <p>The stormfax website reports the mean number of hurricanes between 1991-2020 to be 7. Does that appear consistent with the graph? Why do you think they chose that subset of years?</p>
        </statement>
        <hint>
          <p>Consider what's special about the 1991-2020 period. Is it the most recent data? Why might recent data be more relevant?</p>
        </hint>
        <solution>
          <p>This is consistent with the time plot. If we were to put a horizontal line at a height that goes through the middle of the values, 7 appears a reasonable value for that height. Perhaps they wanted to look at more recent data for more direct comparison with current data (opinions may vary).</p>
        </solution>
        <response/>
      </exercise>
      
      <p>Oftentimes a mean or average is reported, but with no measure of spread or variability. If all the years between 1991-2020 had between 6 and 8 hurricanes, we would react very differently to 14 hurricanes in one year than if all the years between 1991-2020 had between 2 and 15 hurricanes.</p>
      
      <assemblage xml:id="def-standard-deviation">
        <title>Terminology Detour: Standard Deviation</title>
        <p>The most common measure of the variability in a distribution of data is the <term>standard deviation</term><idx><h>standard deviation</h><h>the square root of the variance; a measure of spread in the outcomes of a distribution; roughly the average deviation from the mean of the distribution</h></idx>.</p>
        <p><me>s = \sqrt{\frac{\sum_{i=1}^n (y_i - \bar{y})^2}{n-1}}</me></p>
        <p>We can roughly interpret the standard deviation as the average "deviation" of the data values in the distribution from the mean of the distribution. Another interpretation: If we were to predict 7 as the number of hurricanes in a year between 1991-2020, the standard deviation would approximate the average "prediction error" for those years.</p>
      </assemblage>
      
      <p>Below is a dotplot of the data from 1991-2020 (<m>n = 31</m>).</p>
      
      <figure xml:id="fig-hurricane-dotplot-recent">
        <image source="hurricanedotplot2.png" width="80%">
          <description>Dotplot showing the distribution of annual number of hurricanes from 1991 to 2020</description>
        </image>
      </figure>
      
      <exercise xml:id="hurricane-ex-f" label="A.6">
        <title>Compare Subset to Full Dataset</title>
        <statement>
          <p>Conjecture: The mean is actually 7.2 hurricanes for this dataset. Do you think that is larger or smaller or quite similar to the mean for the full dataset? Explain your reasoning.</p>
        </statement>
        <hint>
          <p>Look at the timeplot - does the 1991-2020 period appear different from earlier decades?</p>
        </hint>
        <solution>
          <p>Answers will vary, but one might think the average is a bit higher in this more recent time frame than across the entire data set.</p>
        </solution>
        <response/>
      </exercise>
      
      <exercise xml:id="hurricane-ex-g" label="A.7">
        <title>Estimate Standard Deviation</title>
        <statement>
          <p>Conjecture: Provide a guess of the value of the standard deviation of these 31 values.</p>
        </statement>
        <hint>
          <p>Look at the dotplot - what's a typical distance from the mean of 7.2? Most values fall within what range?</p>
        </hint>
        <solution>
          <p>About half or a little more than half of the values appear to fall between 4 and 10, so maybe a standard deviation of around 3 hurricanes?</p>
        </solution>
        <response/>
      </exercise>
      
      <exercise xml:id="hurricane-ex-h" label="A.8">
        <title>Compare Standard Deviations</title>
        <statement>
          <p>Conjecture: How do you think the standard deviation from (g) compares to the standard deviation of the full dataset? Explain your reasoning.</p>
        </statement>
        <hint>
          <p>Compare the spread in the 1991-2020 dotplot to the spread in the full 1851-2024 dotplot.</p>
        </hint>
        <solution>
          <p>The largest values (e.g., 14, 15) are in this subset and the spread in the values does appear larger in the more recent years than overall (fewer values in the 3 to 7 range compared to the full dataset?).</p>
        </solution>
        <response/>
      </exercise>
      
      <p>We will often use the standard deviation as a "ruler" to help us measure distances of observations from the mean of the distribution.</p>
      
      <exercise xml:id="hurricane-ex-i" label="A.9">
        <title>Standardize the Value</title>
        <statement>
          <p>If we use a mean of 7.2 and a standard deviation of 3.3 hurricanes, how many standard deviations away from the mean is a value of 14 hurricanes? Above or below the mean?</p>
        </statement>
        <hint>
          <p>Calculate: <m>\frac{14 - 7.2}{3.3}</m></p>
        </hint>
        <answer>
          <p><m>\frac{14 - 7.2}{3.3} = 2.06</m> standard deviations above the mean</p>
        </answer>
        <response/>
      </exercise>
      
      <assemblage xml:id="def-standardizing">
        <title>Terminology Detour: Standardizing</title>
        <p>The general formula for standardizing an observation's position in the distribution is:</p>
        <p><me>\frac{\text{observation value} - \text{mean of distribution}}{\text{standard deviation of distribution}}</me></p>
        <p>We will often consider a value far from the mean of a distribution if it is more than two standard deviations away.</p>
      </assemblage>
      
      <p>In this investigation, you have just touched on one piece of information related to climate change. In fact, scientists are less concerned about the number of storms but in the intensity of the storms and how warming of the surface ocean may be leading to more destructive storms. Looking at a single year in isolation or even a pair of years creates a very incomplete picture of trends over time, and while we expect some natural variation from year-to-year, the question to scientists is whether the overall trend being observed is larger than what we can reasonably attributed to natural variation.</p>
      
      <insight xml:id="points-to-keep-in-mind">
        <title>Points to keep in mind</title>
        <ul>
          <li>It's important to determine which variables are most relevant to the research question and whether you can collect the data you need to answer the question.</li>
          <li>Simple graphs can be very informative, but you should also take care in considering the most meaningful variable representation of what you are studying even before you begin graphing.</li>
          <li>It is imperative to consider variability and to think about possible sources of variation. Sometimes you may be able to explain and "control for" a source of variation. Often you will have to dig deeper into reasons for unusual observations and whether it is appropriate to remove them from the analysis.</li>
          <li>The quality of your inferences will depend A LOT on the quality of the data that are collected. Not much can be learned from poorly or improperly collected data or data from a completely different time period.</li>
        </ul>
      </insight>
      
      <paragraphs xml:id="discussion-a">
        <title>Discussion</title>
        <p>When exploring a research question, one of the first steps is to define the variable involved, e.g., the number of hurricanes. This is an example of <term>quantitative variables</term>, as opposed to a <term>categorical variable</term> like whether the storm has winds over 74 mph. Dotplots are good choices for visualizing a quantitative variable for a small dataset. When looking at a distribution of a single quantitative variable like this, we are often interested in three key features:</p>
        <ul>
          <li><em>Center</em>: What would you consider a "typical" value in the distribution?</li>
          <li><em>Variability</em>: How clustered together or consistent are the observations? Or are they far apart?</li>
          <li><em>Shape</em>: Are some values more common than others? Are the values symmetric about the center?</li>
          <li>Are there any <em>unusual observations</em> that don't follow the overall pattern? Are there any explanations for these values?</li>
        </ul>
        <p>To summarize the center of the distribution, we often report the <term>mean</term><idx><h>mean</h><h>the average of all numerical values in the data set</h></idx> (the arithmetic average of all the numerical values in the data set) and/or the <term>median</term><idx><h>median</h><h>a value such that at least 50% of the observations in the data set are smaller than that value and at least 50% of the observations in the data set are larger than that value</h></idx> (a middle value such that 50% of the data values are smaller and 50% are larger).</p>
      </paragraphs>
      
      <p>With most investigations we will also provide a follow-up practice problem or two for you to try on your own to assess your understanding of the material.</p>
      
      <subsection xml:id="practiceA">
        <title>Practice Problem A.A</title>
        
        <p><url href="https://www.rossmanchance.com/applets/2021/descstats/Dotplot.htm" target="_blank">Open the Descriptive Statistics applet</url> to complete this practice problem.</p>
        
        <image source="descriptivestatistics-screenshot.png" width="100%">
          <description>Screenshot of Descriptive Statistics applet interface</description>
          <url href="https://www.rossmanchance.com/applets/2021/descstats/Dotplot.htm" target="_blank"/>
        </image>
        
        <p>From the <url href="https://www.rossmanchance.com/iscam3/files.html" target="_blank">ISCAM data files and applets page</url> (Chapter 0), you can view the data in <url href="https://www.rossmanchance.com/iscam4/data/AtlanticStorms.txt" target="_blank">AtlanticStorms.txt</url>. Use your mouse (or ctrl-A) to highlight all four columns and then copy and paste these data to your clipboard. In the Descriptive Statistics applet, clear the existing data (press <em>Clear</em>), click in the Paste data box and paste the data from your clipboard. Press the <em>Use Data</em> button. [Alternatively, this dataset is listed in the Select data pull-down menu as Atlantic Storms.] Use the Quantitative Variable pull-down menu to select the Number of Hurricanes variable (Hurricanes).</p>
        
        <assemblage>
          <title>Shape of Distributions</title>
          <p>The shape of a distribution is often classified as <term>symmetric</term><idx><h>symmetric</h><h>a distribution with a mirror image on each side of the center</h></idx> (mirror image on each side of the center) or <term>skewed</term><idx><h>skewed</h><h>a distribution with a longer tail on one side</h></idx>.</p>
          <ul>
            <li>Distributions with a longer right tail are labeled <term>skewed to the right</term></li>
            <li>Distributions with a longer left tail are labeled <term>skewed to the left</term></li>
          </ul>
          <p>The <term>skewness statistic</term> measures the lack of asymmetry in a distribution (due values above the mean extend further than values below the mean on average) using a <m>(y_i-\bar{y})^3</m> term. Positive values indicate a skewed right distribution, negative values indicate skewed left, and values near 0 indicate a symmetric distribution.</p>
        </assemblage>
        
        <exercise xml:id="practice-a2a-a" label="PPA.1">
          <statement>
            <p>Based on the graph, would you consider the "number of hurricanes" distribution to be symmetric, skewed to the right or skewed to the left? Check the Skewness statistic box, does the value agree with your judgement from the graph?</p>
          </statement>
          <hint>
            <p>Look at the tails of the distribution. Which side extends further? A positive skewness value indicates right skew, negative indicates left skew, and values near 0 indicate symmetry.</p>
          </hint>
          <solution>
            <p>The distribution appears to be skewed to the right, with a longer tail extending toward the higher values. The skewness statistic should be positive, confirming this visual assessment.</p>
          </solution>
          <response/>
        </exercise>
        
        <assemblage>
          <title>Mean and Median</title>
          <p>If there are <m>n</m> numerical values and we refer to them as <m>y_1, y_2, \ldots, y_n</m>,</p>
          <p>The <term>mean</term>, <m>\bar{y}</m>, is the average of all numerical values in the data set: <me>\bar{y} = \frac{\sum_{i=1}^n y_i}{n}</me></p>
          <p>The <term>median</term> is a value such that 50% of the data lies below and 50% of the data lies above that value: median position: <m>(n+1)/2</m></p>
        </assemblage>
        
        <!-- <figure xml:id="fig-hurricane-dotplot-recent-3">
          <image source="hurricanedotplot3.png" width="80%">
            <description>Dotplot showing the distribution of annual number of hurricanes from 1991 to 2020</description>
          </image>
        </figure> -->
        
        <exercise xml:id="practice-a2a-b" label="PPA.2">
          <statement>
            <p>Explore the mean and median:</p>
            <ul>
              <li>Check the box next to Guess for the Mean. Move the red line to where you think the mean of the distribution is.</li>
              <li>Check the box next to Guess for the Median. Move the blue line to where you think the median of the distribution is.</li>
              <li>Now check Actual for both. Which is larger, the mean or the median?</li>
            </ul>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-a2a-c" label="PPA.3">
          <statement>
            <p>Check the box for Guess for the standard deviation. Use your mouse to move one of the edges of the red rectangle to a distance that you think is representative of a "typical distance from the mean" (some values are closer, some are further). Then check the Actual box. How did you do?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-a2a-d" label="PPA.4">
          <statement>
            <p>How does the standard deviation of the full dataset compare to the 3.3 value for the years 1991-2020? Summarize what this tells us about the behavior of hurricanes.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
    
    <subsection xml:id="investigationB">
      <title>Investigation B: Random Babies</title>
      
      <p>In the previous investigation, you looked at historical data for a subset of homes from a larger population. In this investigation, the goal is to explore a <em>random</em> process. We apologize in advance for the absurd but memorable process below. Other examples of a random process are coin flipping or lead measurements taken at different times from the same house.</p>
      
      <p>Suppose that on one night at a certain hospital, four mothers give birth to four babies. As a very sick joke, the hospital staff decides to return babies to their mothers completely at random. Our goal is to look for the pattern of outcomes from this process, with regard to the issue of how many mothers get the correct baby. This enables us to investigate the underlying properties of this child-returning process, such as the probability that at least one mother receives her own baby.</p>
      
      <exercise xml:id="random-babies-ex-a" label="B.1">
        <title>Initial Prediction</title>
        <statement>
          <p>Before we proceed, what do you think is more likely to happen: that no mothers get the correct baby, or that all four mothers get the correct baby? Write down your initial guess and explain your reasoning.</p>
        </statement>
        <response/>
      </exercise>
      
      <p>Because it is clearly not feasible to actually carry out this horrible child-returning process over and over again, we will instead <em>simulate</em> the random process to investigate what would happen in the long run. Suppose the four babies were named Murphy Miller, Wallis Williams, Bari Brown, and Shea Smith. Take four index cards and write the first name of each baby on a different card. Now take a sheet of paper and divide it into four regions, one for each mom. Next shuffle the index cards, face down, and randomly deal the babies back to the mothers. Flip the cards over and count the number of moms who received the correct baby.</p>
      
      <p>Carry out this physical simulation at least 5 times and record your results.</p>
      
      <exercise xml:id="random-babies-ex-b" label="B.2">
        <title>Conduct Physical Simulation</title>
        <statement>
          <p>How many mothers received the correct baby in each trial?</p>
        </statement>
        <hint>
          <p>Record the number of matches (0, 1, 2, or 4) for each of your 5 trials.</p>
        </hint>
        <solution>
          <p>Answers will vary, but most trials should result in 0 or 1 match. Zero matches and one match are the most common outcomes.</p>
        </solution>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-c" label="B.3">
        <title>Identify Common Outcomes</title>
        <statement>
          <p>What was the most common outcome across your trials? What was the least common?</p>
        </statement>
        <hint>
          <p>Look at your results from the previous question - which number of matches appeared most frequently?</p>
        </hint>
        <solution>
          <p>The most common outcomes are typically 0 or 1 match. Having all 4 mothers receive the correct baby (4 matches) is very rare, as is having exactly 2 matches.</p>
        </solution>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-d" label="B.4">
        <title>Check Extreme Outcomes</title>
        <statement>
          <p>Did any of your trials result in all four mothers receiving the correct baby? Did any result in exactly three mothers receiving the correct baby?</p>
        </statement>
        <hint>
          <p>Think about whether it's even possible for exactly three mothers to get the correct baby.</p>
        </hint>
        <solution>
          <p>It is very unlikely that all four mothers received the correct baby in just 5 trials. More importantly, it is <em>impossible</em> for exactly three mothers to receive the correct baby - if three mothers get the right baby, the fourth mother must also get the right baby!</p>
        </solution>
        <response/>
      </exercise>
      
      <paragraphs xml:id="simulation-analysis-b">
        <title>Simulation Analysis</title>
        
        <p>Now let's use technology to simulate this process many more times. <url href="https://www.rossmanchance.com/applets/2021/randombabies/RandomBabies.html?hideExtras=1" target="_blank">Open the Random Babies applet</url> and follow these steps:</p>
        
        <sidebyside widths="60% 35%" margins="0% 5%">
          <stack>
            <ul>
              <li>Press <alert>Randomize</alert>. Notice that the applet randomly returns babies to mothers and determines how many babies are returned to the correct home (by matching diaper colors). The applet also counts and graphs the resulting number of matches.</li>
              <li>Uncheck the <alert>Animate</alert> box and press <alert>Randomize</alert> a few more times. You should see the results accumulate in the table and the histogram.</li>
              <li>Click on the histogram bar representing the outcome of zero mothers receiving the correct baby. This shows you a "time plot" of the proportion of trials with 0 matches vs. the number of trials.</li>
              <li>Set the <alert>Number of trials</alert> to 100 and press <alert>Randomize</alert> a few times, noticing how the behavior of this graph changes.</li>
            </ul>
          </stack>
          
          <image source="randombabies-screenshot.png" width="100%">
            <description>Screenshot of Random Babies applet</description>
          </image>
        </sidebyside>
      </paragraphs>
      
      <p>Run the applet for at least 1000 trials total.</p>
      
      <exercise xml:id="random-babies-ex-e" label="B.5">
        <title>Run Applet Simulation</title>
        <statement>
          <p>What proportion of your trials resulted in zero mothers receiving the correct baby?</p>
        </statement>
        <hint>
          <p>Count the number of trials with 0 matches and divide by 1000.</p>
        </hint>
        <solution>
          <p>The proportion should be around 0.375. The exact theoretical probability is 9/24 = 0.375.</p>
        </solution>
        <answer>
          <p>0.375</p>
        </answer>
      </exercise>
      
      <exercise xml:id="random-babies-ex-f" label="B.6">
        <title>Estimate Probability</title>
        <statement>
          <p>Based on your simulation results, estimate the probability that at least one mother receives the correct baby.</p>
          <p>Probability = <var width="10" /></p>
        </statement>
        <setup>
          <var>
            <condition number="0.625" tolerance="0.05">
              <feedback>
                <p>Correct! If about 37.5% of trials had zero matches, then about 62.5% had at least one match. So <m>P(\text{at least one match}) \approx 1 - 0.375 = 0.625</m>.</p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. Think about the complement: if at least one mother gets the correct baby, that's the opposite of zero mothers getting the correct baby. Use <m>1 - P(\text{zero matches})</m>.</p>
              </feedback>
            </condition>
          </var>
        </setup>
        <hint>
          <p>Think about the complement: if at least one mother gets the correct baby, that's the opposite of zero mothers getting the correct baby.</p>
        </hint>
      </exercise>
      
      <assemblage xml:id="def-random-process">
        <title>Definition: Random Process and Probability</title>
        <p>A <term>random process</term><idx><h>random process</h><h>generates observations according to a random mechanism</h></idx> generates observations according to a random mechanism, like a coin toss. Whereas we can't predict each individual outcome with certainty, we do expect to see a long-run pattern to the results.</p>
        
        <p>The <term>probability</term><idx><h>probability</h><h>the long-run proportion of times an event occurs</h></idx> of a random event occurring is the <alert>long-run proportion</alert> (or <alert>relative frequency</alert>) of times that the event would occur if the random process were repeated over and over under identical conditions.</p>
        
        <p>You can <em>approximate</em> a probability by simulating (i.e., artificially recreating) the process many times. Simulation leads to an <em>empirical estimate</em> of the probability, which is the proportion of times that the event occurs in the simulated repetitions of the random process. Increasing the number of repetitions generally results in more accurate estimates of the long-run probabilities.</p>
      </assemblage>
      
      <exercise xml:id="random-babies-ex-g" label="B.7">
        <title>Compare to Initial Guess</title>
        <statement>
          <p>How does your empirical estimate from the simulation compare to your initial guess in checkpoint 2.20 (where you predicted whether zero matches or all four matches was more likely)?</p>
        </statement>
        <hint>
          <p>In checkpoint 2.20, you predicted whether it was more likely that no mothers get the correct baby or that all four mothers get the correct baby. Compare that prediction to what you observed in the simulation.</p>
        </hint>
        <solution>
          <p>Most people initially guess that having all four mothers get the correct baby is less likely than zero matches, and the simulation confirms this intuition. Zero matches occurs about 37.5% of the time, while all four matches occurs only about 4.2% of the time.</p>
        </solution>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-h" label="B.8">
        <title>Understand Variability</title>
        <statement>
          <p>If you were to run another 1000 trials, would you expect to get exactly the same proportion of trials with zero matches? Explain.</p>
        </statement>
        <hint>
          <p>Think about natural variability in random processes.</p>
        </hint>
        <solution>
          <p>No, we would not expect to get exactly the same proportion. Due to random variability, the proportion will fluctuate somewhat from one set of 1000 trials to another. However, we would expect it to be close to the true probability (around 37.5%).</p>
        </solution>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-i" label="B.9">
        <title>Analyze Running Proportion</title>
        <statement>
          <p>Look at the time plot showing the running proportion of trials with 0 matches. What do you notice about the behavior of this proportion as the number of trials increases?</p>
        </statement>
        <hint>
          <p>Does the proportion stabilize or continue to vary wildly?</p>
        </hint>
        <solution>
          <p>As the number of trials increases, the running proportion tends to stabilize and converge to the true probability (around 0.375). The proportion varies more with fewer trials but becomes more consistent with more trials.</p>
        </solution>
        <response/>
      </exercise>
      
      <paragraphs xml:id="exact-analysis-b">
        <title>Exact Mathematical Analysis</title>
        
        <p>One disadvantage to using simulation to estimate a probability like this is that everyone will potentially obtain a different estimate. Even with a very large number of trials, your result will still only be an estimate of the actual long-run probability. For this particular scenario however, we can determine exact theoretical probabilities.</p>
        
        <p>First, let's list all possible outcomes for returning four babies to their mothers at random. We can organize our work by letting 1234 represent the outcome where the first baby went to the first mother, the second baby to the second mother, the third baby to the third mother, and the fourth baby to the fourth mother. In this scenario, all four mothers get the correct baby. As another example, 1243 means that the first two mothers get the right baby, but the third and fourth mothers have their babies switched.</p>
      </paragraphs>
      
      <assemblage xml:id="def-sample-space">
        <title>Definition: Sample Space</title>
        <p>A <term>sample space</term><idx><h>sample space</h><h>a list of all possible outcomes of a random process</h></idx> is a list of all possible outcomes of a random process.</p>
      </assemblage>
      
      <p>All of the possible outcomes are listed below:</p>
      
      <p><alert>Sample Space:</alert></p>
      <table xml:id="table-sample-space-babies">
        <tabular>
          <row><cell>1234</cell><cell>1243</cell><cell>1324</cell><cell>1342</cell><cell>1423</cell><cell>1432</cell></row>
          <row><cell>2134</cell><cell>2143</cell><cell>2314</cell><cell>2341</cell><cell>2413</cell><cell>2431</cell></row>
          <row><cell>3124</cell><cell>3142</cell><cell>3214</cell><cell>3241</cell><cell>3412</cell><cell>3421</cell></row>
          <row><cell>4123</cell><cell>4132</cell><cell>4213</cell><cell>4231</cell><cell>4312</cell><cell>4321</cell></row>
        </tabular>
      </table>
      
      <p>In this case, returning the babies to the mothers completely at random implies that the outcomes in our sample space are equally likely to occur (<em>outcome probability</em> = 1 / <em>number of possible outcomes</em>).</p>
      
      <exercise xml:id="random-babies-ex-j" label="B.10">
        <title>Count Sample Space</title>
        <statement>
          <p>How many possible outcomes are there in the sample space? What is the probability of any one specific outcome (e.g., 1234)?</p>
          <p>Number of outcomes = <var width="5" /></p>
          <p>Probability = <var width="10" /></p>
        </statement>
        <setup>
          <var>
            <condition number="24">
              <feedback>
                <p>There are 24 possible outcomes in the sample space.</p>
              </feedback>
            </condition>
          </var>
          <var>
            <condition number="0.0417" tolerance="0.001">
              <feedback>
                <p>Each outcome has probability 1/24 â‰ˆ 0.0417.</p>
              </feedback>
            </condition>
          </var>
        </setup>
        <hint>
          <p>Count the total number of entries in the sample space table above. If all outcomes are equally likely, divide 1 by the total number of outcomes.</p>
        </hint>
      </exercise>
      
      <p>You could have determined the number of possible outcomes without having to list them first. For the first mother to receive a baby, she could receive any one of the four babies. Then there are three babies to choose from in giving a baby to the second mother. The third mother receives one of the two remaining babies and then the last baby goes to the fourth mother. Because the number of possibilities at one stage of this process does not depend on the outcome (which baby) of earlier stages, the total number of possibilities is the product <m>4 \times 3 \times 2 \times 1 = 24</m>. This is also known as <m>4!</m>, read "4 factorial." Because the above outcomes are equally likely, the probability of any one of the above outcomes occurring is <m>1/24</m>. Although these 24 outcomes are equally likely, we were more interested above in the probability of 0 matches, 1 match, etc.</p>
      
      <assemblage xml:id="def-random-variable">
        <title>Definition: Random Variable</title>
        <p>A <term>random variable</term><idx><h>random variable</h><h>maps outcomes of a random process to numerical values</h></idx> maps each possible outcome of the random process (the sample space) to a numerical value. We can then talk about the <em>probability distribution</em> of the random variable. These random variables are usually denoted by capital roman letters, e.g., <m>X</m>, <m>Y</m>. A random variable is <term>discrete</term><idx><h>discrete random variable</h><h>a random variable with countable possible values</h></idx> if you can list each individual value that can be observed for the random variable.</p>
      </assemblage>
      
      <exercise xml:id="random-babies-ex-k" label="B.11">
        <title>Identify Possible Values</title>
        <statement>
          <p>Define the random variable <m>X</m> to be the number of mothers who receive the correct baby. What are the possible values of <m>X</m>?</p>
        </statement>
        <hint>
          <p>Consider: Can you have 0 matches? 1 match? 2 matches? What about 3 matches - is that possible?</p>
        </hint>
        <answer>
          <p>The possible values are 0, 1, 2, and 4. (Note: 3 is not possible!)</p>
        </answer>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-l" label="B.12">
        <title>Count Outcomes for Each Value</title>
        <statement>
          <p>Go through the sample space and count how many outcomes result in each possible value of <m>X</m> (0, 1, 2, 3, or 4 matches).</p>
          <p>
            <tabular>
              <row header="yes">
                <cell>Number of Matches</cell>
                <cell>0</cell>
                <cell>1</cell>
                <cell>2</cell>
                <cell>3</cell>
                <cell>4</cell>
              </row>
              <row>
                <cell>Count</cell>
                <cell><var width="3" /></cell>
                <cell><var width="3" /></cell>
                <cell><var width="3" /></cell>
                <cell><var width="3" /></cell>
                <cell><var width="3" /></cell>
              </row>
            </tabular>
          </p>
        </statement>
        <setup>
          <var>
            <condition number="9">
              <feedback>
                <p>Correct! There are 9 outcomes with 0 matches.</p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. Count how many of the 24 outcomes have 0 matches.</p>
              </feedback>
            </condition>
          </var>
          <var>
            <condition number="8">
              <feedback>
                <p>Correct! There are 8 outcomes with 1 match.</p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. Count how many of the 24 outcomes have exactly 1 match.</p>
              </feedback>
            </condition>
          </var>
          <var>
            <condition number="6">
              <feedback>
                <p>Correct! There are 6 outcomes with 2 matches.</p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. Count how many of the 24 outcomes have exactly 2 matches.</p>
              </feedback>
            </condition>
          </var>
          <var>
            <condition number="0">
              <feedback>
                <p>Correct! It's impossible to have exactly 3 matches - if 3 mothers get the right baby, the 4th must too!</p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. Think carefully: if 3 mothers get the right baby, what about the 4th?</p>
              </feedback>
            </condition>
          </var>
          <var>
            <condition number="1">
              <feedback>
                <p>Correct! There is 1 outcome with 4 matches (1234).</p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. How many outcomes have all 4 matches? Look for 1234.</p>
              </feedback>
            </condition>
          </var>
        </setup>
        <hint>
          <p>For each outcome like 1234 or 2143, count how many positions match (first baby to first mother, second to second, etc.)</p>
        </hint>
      </exercise>
      
      <assemblage xml:id="probability-rule-equally-likely">
        <title>Probability Rule</title>
        <p>When the outcomes in the sample space are equally likely, the probability of any one of a set of outcomes (an event) occurring is the number of outcomes in that set divided by the total number of outcomes in the sample space.</p>
      </assemblage>
      
      <p>Calculate the exact probability of each possible value of <m>X</m>.</p>
      
      <exercise xml:id="random-babies-ex-m" label="B.13">
        <title>Create Probability Distribution</title>
        <statement>
          <p>Create a probability distribution table showing <m>P(X = 0)</m>, <m>P(X = 1)</m>, <m>P(X = 2)</m>, <m>P(X = 3)</m>, and <m>P(X = 4)</m>.</p>
          <p>
            <tabular>
              <row header="yes">
                <cell><m>X</m></cell>
                <cell>0</cell>
                <cell>1</cell>
                <cell>2</cell>
                <cell>3</cell>
                <cell>4</cell>
              </row>
              <row>
                <cell><m>P(X)</m></cell>
                <cell><var width="8" /></cell>
                <cell><var width="8" /></cell>
                <cell><var width="8" /></cell>
                <cell><var width="8" /></cell>
                <cell><var width="8" /></cell>
              </row>
            </tabular>
          </p>
        </statement>
        <setup>
          <var>
            <condition number="0.375" tolerance="0.001">
              <feedback>
                <p>Correct! <m>P(X = 0) = 9/24 = 0.375</m></p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. Divide the count of outcomes with 0 matches by 24.</p>
              </feedback>
            </condition>
          </var>
          <var>
            <condition number="0.333" tolerance="0.001">
              <feedback>
                <p>Correct! <m>P(X = 1) = 8/24 \approx 0.333</m></p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. Divide the count of outcomes with 1 match by 24.</p>
              </feedback>
            </condition>
          </var>
          <var>
            <condition number="0.25" tolerance="0.001">
              <feedback>
                <p>Correct! <m>P(X = 2) = 6/24 = 0.25</m></p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. Divide the count of outcomes with 2 matches by 24.</p>
              </feedback>
            </condition>
          </var>
          <var>
            <condition number="0">
              <feedback>
                <p>Correct! <m>P(X = 3) = 0</m> (impossible to have exactly 3 matches)</p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. Remember, it's impossible to have exactly 3 matches!</p>
              </feedback>
            </condition>
          </var>
          <var>
            <condition number="0.0417" tolerance="0.001">
              <feedback>
                <p>Correct! <m>P(X = 4) = 1/24 \approx 0.0417</m></p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. Divide the count of outcomes with 4 matches by 24.</p>
              </feedback>
            </condition>
          </var>
        </setup>
        <hint>
          <p>Divide the count for each value by 24 (the total number of outcomes).</p>
        </hint>
      </exercise>
      
      <exercise xml:id="random-babies-ex-n" label="B.14">
        <title>Compare to Simulation</title>
        <statement>
          <p>How do your exact probabilities compare to the empirical estimates you obtained from the simulation?</p>
        </statement>
        <hint>
          <p>Look at the proportions from your 1000 trials - are they close to the theoretical probabilities?</p>
        </hint>
        <solution>
          <p>The simulation results should be fairly close to the exact probabilities, especially with 1000 or more trials. Small differences are expected due to random variability in the simulation.</p>
        </solution>
        <response/>
      </exercise>
      
      <exercise xml:id="random-babies-ex-o" label="B.15">
        <title>Calculate Exact Probability</title>
        <statement>
          <p>Calculate the exact probability that at least one mother receives the correct baby.</p>
          <p>Probability = <var width="10" /></p>
        </statement>
        <setup>
          <var>
            <condition number="0.625" tolerance="0.01">
              <feedback>
                <p>Correct! <m>P(\text{at least one match}) = 1 - P(X = 0) = 1 - 9/24 = 15/24 = 0.625</m></p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. Use the complement rule: <m>P(\text{at least one match}) = 1 - P(\text{zero matches})</m></p>
              </feedback>
            </condition>
          </var>
        </setup>
        <hint>
          <p>Use the complement rule: <m>P(\text{at least one match}) = 1 - P(\text{zero matches})</m></p>
        </hint>
      </exercise>
      
      <assemblage xml:id="probability-rules">
        <title>Probability Rules</title>
        <p><ul>
          <li><p>The sum of the probabilities for all possible outcomes equals one.</p></li>
          <li><p><term>Complement rule</term><idx><h>complement rule</h><h>probability of not A equals 1 minus probability of A</h></idx>: The probability of an event happening is one minus the probability of the event not happening.</p></li>
          <li><p><term>Addition rule for disjoint events</term><idx><h>addition rule</h><h>for mutually exclusive events, sum the probabilities</h></idx>: The probability of at least one of several events is the sum of the probabilities of those events as long as there are no outcomes in common across the events (i.e., the events are <term>mutually exclusive</term> or <term>disjoint</term>).</p></li>
        </ul></p>
      </assemblage>
      
      <p>We can also consider the <term>expected value</term><idx><h>expected value</h><h>the long-run average value of a random variable</h></idx> of the number of matches, which is interpreted as the long-run average value of the random variable. For a discrete random variable, <m>X</m>, we can calculate the expected value of the random variable <m>X</m>, denoted <m>E(X)</m>, by employing the idea of a weighted average of the different possible values of the random variable, but now the "weights" will be given by the probabilities of those values:</p>
      
      <p><me>E(X) = \sum (\text{value}) \times (\text{probability of value})</me></p>
      
      <exercise xml:id="random-babies-ex-p" label="B.16">
        <title>Calculate Expected Value</title>
        <statement>
          <p>Calculate the expected value <m>E(X)</m> for the number of mothers who receive the correct baby.</p>
          <p><m>E(X)</m> = <var width="10" /></p>
        </statement>
        <setup>
          <var>
            <condition number="1" tolerance="0.01">
              <feedback>
                <p>Correct! <m>E(X) = 0(9/24) + 1(8/24) + 2(6/24) + 4(1/24) = 0 + 8/24 + 12/24 + 4/24 = 24/24 = 1</m>. The expected number of matches is 1.</p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. Use the formula: <m>E(X) = 0 \times P(X=0) + 1 \times P(X=1) + 2 \times P(X=2) + 4 \times P(X=4)</m></p>
              </feedback>
            </condition>
          </var>
        </setup>
        <hint>
          <p>Use the formula: <m>E(X) = 0 \times P(X=0) + 1 \times P(X=1) + 2 \times P(X=2) + 4 \times P(X=4)</m></p>
        </hint>
      </exercise>
      
      <exercise xml:id="random-babies-ex-q" label="B.17">
        <title>Interpret Expected Value</title>
        <statement>
          <p>Interpret the expected value in context. Does this mean that in any given trial, we expect this many mothers to receive the correct baby?</p>
        </statement>
        <hint>
          <p>Remember that expected value is a long-run average, not a prediction for a single trial.</p>
        </hint>
        <solution>
          <p>The expected value of 1 means that in the long run, on average, 1 mother will receive the correct baby per trial. This does NOT mean that in any single trial we expect exactly 1 match - in fact, we could get 0, 1, 2, or 4 matches. The expected value is the average across many trials.</p>
        </solution>
        <response/>
      </exercise>
      
      <p>Notice that if we wanted to compute the average number of matches, say after 1000 trials, we would look at a weighted average:</p>
      
      <p><me>\bar{x} = \frac{1 + 0 + 2 + 0 + \cdots}{1000} = \frac{(\# \text{ of } 0\text{s}) \times 0 + (\# \text{ of } 1\text{s}) \times 1 + (\# \text{ of } 2\text{s}) \times 2 + (\# \text{ of } 4\text{s}) \times 4}{1000}</me></p>
      
      <p>But from the results we saw above, each term <m>(\#)/1000</m> converges to the probability of that outcome as we increase the number of repetitions, giving us the above formula for <m>E(X)</m>. So we will interpret the expected value as the long-run mean of the outcomes.</p>
      
      <p>Another property of a random variable is its <term>variance</term><idx><h>variance</h><h>measures variability in values of a random variable</h></idx>. This measures how variable the values of the random variable will be. For a discrete random variable, <m>X</m>, we can again use a type of weighted average, based on the probabilities of each value and the squared distances between the possible values of the random variable and the expected value.</p>
      
      <p><me>\text{Var}(X) = \sum_{\text{all possible values}} (\text{value} - E(X))^2 \times (\text{probability of value})</me></p>
      
      <exercise xml:id="random-babies-ex-r" label="B.18">
        <title>Calculate Variance</title>
        <statement>
          <p>Calculate the variance of <m>X</m>.</p>
          <p><m>\text{Var}(X)</m> = <var width="10" /></p>
        </statement>
        <setup>
          <var>
            <condition number="1" tolerance="0.01">
              <feedback>
                <p>Correct! <m>\text{Var}(X) = (0-1)^2(9/24) + (1-1)^2(8/24) + (2-1)^2(6/24) + (4-1)^2(1/24) = 1(9/24) + 0(8/24) + 1(6/24) + 9(1/24) = 9/24 + 6/24 + 9/24 = 24/24 = 1</m></p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Incorrect. Use the formula: <m>\text{Var}(X) = (0-1)^2(9/24) + (1-1)^2(8/24) + (2-1)^2(6/24) + (4-1)^2(1/24)</m></p>
              </feedback>
            </condition>
          </var>
        </setup>
        <hint>
          <p>Use the formula: <m>\text{Var}(X) = (0-1)^2(9/24) + (1-1)^2(8/24) + (2-1)^2(6/24) + (4-1)^2(1/24)</m></p>
        </hint>
      </exercise>
      
      <exercise xml:id="random-babies-ex-s" label="B.19">
        <title>Calculate Standard Deviation</title>
        <statement>
          <p>Calculate the standard deviation of <m>X</m> (the square root of the variance). Interpret this value in context.</p>
        </statement>
        <hint>
          <p>The standard deviation is <m>\sqrt{\text{Var}(X)}</m></p>
        </hint>
        <solution>
          <p><m>SD(X) = \sqrt{1} = 1</m>. The standard deviation of 1 means that the number of matches typically varies by about 1 from the expected value of 1 match.</p>
        </solution>
        <response/>
      </exercise>
      
      <p>We will interpret this standard deviation similarly to how we did in Investigation A: how far the outcomes tend to be from the expected value. Here we are talking in terms of the probability model; in Investigation A we were talking in terms of the historical data.</p>
      
      <exercise xml:id="random-babies-ex-t" label="B.20">
        <title>Verify with Simulation</title>
        <statement>
          <p>Go back to the Random Babies applet and run a large number of simulations (at least 10,000). Calculate the mean and standard deviation of your simulated results. How do these compare to the theoretical expected value and standard deviation you calculated?</p>
        </statement>
        <hint>
          <p>The simulated mean should be close to E(X) = 1, and the simulated SD should be close to SD(X) = 1.</p>
        </hint>
        <solution>
          <p>With a large number of simulations (10,000+), the mean should be very close to 1.0 and the standard deviation should be very close to 1.0, matching the theoretical values.</p>
        </solution>
        <response/>
      </exercise>
      
      <paragraphs xml:id="discussion-b">
        <title>Discussion</title>
        
        <p>Notice that we have used two methods to answer questions about this random process:</p>
        <ul>
          <li><em>Simulation</em> â€“ repeating the process under identical conditions a large number of times and seeing how often different outcomes occur.</li>
          <li><em>Exact mathematical calculations</em> using basic rules of probability and counting.</li>
        </ul>
        
        <p>This approach of looking at the analysis using both simulation and exact approaches will be a theme in this course. We will also consider some approximate mathematical models as well. You should consider these multiple approaches as a way to assess the appropriateness of each method. You should also be aware of situations where one method may be preferable to another and why.</p>
      </paragraphs>
      
      <subsection xml:id="practiceBA">
        <title>Practice Problem B.A</title>
        
        <p>Suppose three executives (Ari, Brooklyn, and Carson) drop their cell phones in an elevator and blindly pick them back up at random.</p>
        
        <exercise xml:id="practice-ba-a" label="PPB.A.1">
          <statement>
            <p>Write out the sample space using <em>ABC</em> notation for the outcomes.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-ba-b" label="PPB.A.2">
          <statement>
            <p>Carry out the exact analysis to determine the probability of at least one executive receiving his or her own phone.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-ba-c" label="PPB.A.3">
          <statement>
            <p>Calculate the expected number of matches for 3 executives. How does this compare to the case with 4 mothers?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-ba-d" label="PPB.A.4">
          <statement>
            <p>Use the <url href="https://www.rossmanchance.com/applets/2021/randombabies/RandomBabies.html?hideExtras=1" target="_blank">Random Babies applet</url> to check your results.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practiceBB">
        <title>Practice Problem B.B</title>
        
        <p>Reconsider the Random Babies scenario. Now suppose there were 8 mothers involved in this random process.</p>
        
        <exercise xml:id="practice-bb-a" label="PPB.B.1">
          <statement>
            <p>Calculate the (exact) probability that all 8 mothers receive the correct baby. [<em>Hint</em>: First determine how many possible outcomes there are for returning 8 babies to their mothers.]</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bb-b" label="PPB.B.2">
          <statement>
            <p>Calculate the probability that exactly 7 mothers receive the correct baby.</p>
          </statement>
          <hint>
            <p>Think carefully: is it possible for exactly 7 mothers to get the correct baby?</p>
          </hint>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bb-c" label="PPB.B.3">
          <statement>
            <p>Using the <url href="https://www.rossmanchance.com/applets/2021/randombabies/RandomBabies.html?hideExtras=1" target="_blank">Random Babies applet</url>, approximate the probability that at least one of the 8 mothers receives the correct baby. How does your approximation compare to the probability of this event with 4 mothers?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bb-d" label="PPB.B.4">
          <statement>
            <p>Using the Random Babies applet, approximate the expected value for the number of the eight mothers receiving the correct baby. How does your approximation compare to the situation with 4 mothers?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practiceBC">
        <title>Practice Problem B.C</title>
        
        <p>An American Roulette wheel consists of 18 black slots, 18 red slots, and 2 green slots. A ball is rolled while the wheel is spun and players can bet on which slot or type of slot the ball will end up in.</p>
        
        <exercise xml:id="practice-bc-a" label="PPB.C.1">
          <statement>
            <p>A common bet is color. If someone bets $1 on red, and the ball lands in any of the 18 red slots, the player wins $2 (a net profit of $1). What is the probability they will win their bet on red?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bc-b" label="PPB.C.2">
          <statement>
            <p>Include a one-sentence interpretation of the probability you calculated in (a).</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bc-c" label="PPB.C.3">
          <statement>
            <p>Another common bet is a number. If the ball lands on the chosen number, the player makes a profit of $35. What is the probability someone wins if they bet on a number?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bc-d" label="PPB.C.4">
          <statement>
            <p>Below are two graphs showing the average net winnings over 1000 simulated plays of a color bet and of a number bet. [<em>Hint:</em> What happened on the first 50 or so number bets?] Explain how you think the expected value (long-run average winnings) of each bet compares. Do they have the same sign?</p>
            <image source="roulette.png" width="70%">
              <description>Graph showing cumulative average net winnings over 1000 simulated plays for color bet (blue line) and number bet (red dashed line)</description>
            </image>
          </statement>
          <hint>
            <p>Look at where the graphs appear to be stabilizing as the number of plays increases. What does the long-run average appear to be approaching for each bet?</p>
          </hint>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-bc-e" label="PPB.C.5">
          <statement>
            <p>Explain which bet displays a larger standard deviation.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
    
    <subsection xml:id="investigationC">
      <title>Investigation C: Modelling Hurricanes</title>
      
      <p>A model is an artificial representation or a simplification of something more complicated, like a toy airplane. Models can be useful in making predictions (e.g., weather models) or to help us better understand the phenomena under study. For example, what factors impact the severity of a hurricane?</p>
      
      <p>Visit <url href="https://scied.ucar.edu/interactive/make-hurricane">https://scied.ucar.edu/interactive/make-hurricane</url></p>
      
      <p><ul>
        <li><p>Move the red hurricane symbol to a circle on the map and read what happens.</p></li>
        <li><p>Switch between the Sea Surface Temperature, Moisture, and Wind maps to see the data for each circle.</p></li>
        <li><p>Which circles create the strongest hurricanes? Why?</p></li>
      </ul></p>
      
      <exercise xml:id="inv-c-a" label="IC.1">
        <title>Explain Hurricane Formation</title>
        <statement>
          <p>In your own words, explain how sea surface temperature, moisture, and wind interact to create strong hurricanes - or weaken them.</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="inv-c-b" label="IC.2">
        <title>Evaluate Model Accuracy</title>
        <statement>
          <p>Explain how you could evaluate the accuracy of this model of hurricane strength. What would you do next if you decided the model was not appropriate?</p>
        </statement>
        <response/>
      </exercise>
      
      <p>In this course, you will encounter two main types of models: <term>statistical models</term> and <term>probability/simulation models</term>. For example, the Random Babies simulation in Investigation B, allowed you to simulate hypothetical data to estimate probabilities of different events. As long as the model valid, we can predict that all four mothers receiving the correct babies would not happen very often in the long run. Most models rely on simplifying assumptions, like babies being returned <q>completely at random.</q></p>
      
      <p>The graphs below show histograms of the hurricane data with different probability models (red curves).</p>
      
      <figure xml:id="fig-hurricane-histograms">
        <sidebyside widths="45% 45%" margins="5%">
          <image source="hurhist1.png">
            <description>Histogram of hurricane data with probability model overlay (red curve)</description>
          </image>
          <image source="hurrhis2.png">
            <description>Histogram of hurricane data with alternative probability model overlay (red curve)</description>
          </image>
        </sidebyside>
      </figure>
      
      <exercise xml:id="inv-c-c" label="IC.3">
        <title>Compare Graphical Displays</title>
        <statement>
          <p>Describe the difference between a histogram and a dotplot. When might histograms be more useful?</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="inv-c-d" label="IC.4">
        <title>Select Best Model</title>
        <statement>
          <p>Which model (red curve) do you consider a better match to the observed data?</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="inv-c-e" label="IC.5">
        <title>Define Statistical Model</title>
        <statement>
          <p>What does the term <q>model</q> mean in this situation? Why would such a model be useful? What assumptions would you need to make? [Hint: Which do you consider more likely, a year with 13 hurricanes or with 14?]</p>
        </statement>
        <response/>
      </exercise>
      
      <p>To get an idea of a statistical model, you will collect some data:</p>
      
      <p><ul>
        <li><p>Using a measurement tool provided by your instructor, measure the circumference of a tennis ball.</p></li>
      </ul></p>
      
      <exercise xml:id="inv-c-measurement" label="IC.measurement">
        <title>Record Your Measurement</title>
        <statement>
          <p>Record your measurement here (to the nearest hundredths place): <var width="10"/> cm</p>
        </statement>
      </exercise>
      
      <exercise xml:id="inv-c-f" label="IC.6">
        <title>Examine Measurement Variation</title>
        <statement>
          <p>Did everyone in class find the same value? What are some possible explanations for different measurements?</p>
        </statement>
        <response/>
      </exercise>
      
      <p>We can think of these measurements as observations from a random process, which we can summarize with a statistical model. If we consider 28.5cm the <q>true value,</q> then we can write our statistical model as</p>
      
      <p>Measurement recorded = 28.5 + random error</p>
      
      <exercise xml:id="inv-c-g" label="IC.7">
        <title>Estimate Measurement Error</title>
        <statement>
          <p>How could we estimate the likely amount of random error in your class's measurement process?</p>
        </statement>
        <response/>
      </exercise>
      
      <p>Much of what scientists do is try to measure, explain, and minimize the amount of random variation.</p>
      
      <exercise xml:id="inv-c-h" label="IC.8">
        <title>Reduce Measurement Error</title>
        <statement>
          <p>Suggest a way to reduce the measurement error in your class's process.</p>
        </statement>
        <response/>
      </exercise>
      
      <exercise xml:id="inv-c-i" label="IC.9">
        <title>Understand Measurement Model</title>
        <statement>
          <p>What does the term <q>model</q> mean here? Why would such a model be useful? What assumptions need to be made?</p>
        </statement>
        <response/>
      </exercise>
      
      <subsection xml:id="practiceCA">
        <title>Practice Problem C.A</title>
        
        <p>Researchers often compare data generated from a model to observed data to help validate the model. If the model's data reasonably matches the observed data, that helps confirm that they (the model builders) understand the underlying data generating process.</p>
        
        <p>Open this app to model the tennis ball measurement random process: <url href="https://iambethchance.shinyapps.io/Modeling8/">https://iambethchance.shinyapps.io/Modeling8/</url></p>
        
        <exercise xml:id="practice-ca-a" label="PPC.A.1">
          <statement>
            <p>Suggest and label four possible sources of variation in the tennis ball measurements. Enter them as the four pie charts and conjecture sizes and probabilities for those sources (e.g., right now, Spinner 1 assumes a perfect measurement with 0.50 probability, a -.1 cm error with 0.25 probability and a +.1 cm error with 0.25 probability). Include a screen capture of your random process.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-ca-b" label="PPC.A.2">
          <statement>
            <p>Simulate one measurement by pressing the Simulate data button. What did you find for the total random error across your four sources? Will this be the same every time?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-ca-c" label="PPC.A.3">
          <statement>
            <p>Generate the same number of measurements as we took in class. Compare the simulated data to the actual data from class (e.g., shape, center, spread). What looks similar and what looks different?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-ca-d" label="PPC.A.4">
          <statement>
            <p>Suggest a way to adjust the model that you think will lead to simulated data that better matches the observed data. Briefly justify your choice.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practiceCB">
        <title>Practice Problem C.B</title>
        
        <p>Suppose human body temperatures can be modelled with a normal distribution with mean 98.6<degree/>F. Suppose you take repeated measures of your temperature over several days.</p>
        
        <exercise xml:id="practice-cb-a" label="PPC.B.1">
          <statement>
            <p>Which distribution below do you think is more believable? Briefly justify your choice.</p>
            <image source="PPC.B.png" width="80%">
              <description>Four histograms labeled A, B, C, and D showing different distributions of body temperature measurements centered around 98.6 degrees Fahrenheit</description>
            </image>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-cb-b" label="PPC.B.2">
          <statement>
            <p>Explain why you might be suspicious if someone told you Distribution D was their results.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-cb-c" label="PPC.B.3">
          <statement>
            <p>Suggest four possible sources of variation in your body temperature measurements.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-cb-d" label="PPC.B.4">
          <statement>
            <p>Distributions A-C have the same mean (98.6) but different spread or variability. Which of the graphs above has the largest standard deviation? Approximate the value of each standard deviation by interpreting the standard deviation as a <q>typical</q> deviation from the mean.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-cb-e" label="PPC.B.5">
          <statement>
            <p>The 4 distributions are all <q>bell-shaped and symmetric.</q> Do you think actual repeated body measurements on the same individual will behave this way? Briefly explain your reasoning.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-cb-f" label="PPC.B.6">
          <statement>
            <p>Suppose I randomly select one of the temperatures from Distribution C. Approximate the probability that the temperature is larger than 99<degree/>F. Interpret your probability in context.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
  </section>
  
  <section xml:id="chapter1">
    <title>Chapter 1: Analyzing One Categorical variable</title>
    ANALYZING ONE CATEGORICAL VARIABLE

<p>In this chapter, you will begin to analyze results from statistical studies
 and focus on the process of statistical inference. In particular, you will 
 learn how to assess evidence against a particular claim about a random process.</p>
    <subsection xml:id="investigation1-1">
      <title>Investigation 1.1: Friend or Foe?</title>
      
      <introduction>
        <p>In a study reported in the November 2007 issue of <em>Nature</em>, researchers investigated whether infants take into account an individual's actions towards others in evaluating that individual as appealing or aversive, perhaps laying the foundation for social interaction (<url href="https://pubmed.ncbi.nlm.nih.gov/18033298/">Hamlin, Wynn, and Bloom, 2007</url>). In other words, do children who aren't even yet talking still form impressions as to someone's friendliness based on their actions?</p>
        
            <p>In one component of the study, sixteen 10-month-old infants were shown a <q>climber</q> character (a piece of wood with <q>googly</q> eyes glued onto it) that could not make it up a hill in two tries.</p>
            
            <aside>
              <title>Video Demonstrations</title>
              <p><url href="https://www.youtube.com/watch?v=WqEV9Otdp58">Video 1: Helper behavior</url></p>
              <p><url href="https://www.youtube.com/watch?v=YX6PTixcS5I">Video 2: Hinder behavior</url></p>
              <p><url href="https://www.youtube.com/watch?v=dijiqWrUOx0">Video 3: Infant choice</url></p>
              <p>More videos: <url href="http://campuspress.yale.edu/infantlab/media/">Yale Infant Lab</url></p>
            </aside>
            
            <p>Then the infants were shown two scenarios for the climber's next try, one where the climber was pushed to the top of the hill by another character (the <q>helper</q> toy) and one where the climber was pushed back down the hill by another character (the <q>hinderer</q> toy). The infant was alternately shown these two scenarios several times.</p>
            
       <sidebyside widths="58% 38%" margins="0% 4%" valign="top">
          <stack>
  
            <p>Then the child was presented with both pieces of wood (the helper and the hinderer characters) and asked to pick one to play with.</p>
          </stack>
          <image source="images/infant.GIF" width="100%">
            <description>Infant choosing between helper and hinderer toys</description>
          </image>
        </sidebyside>
      </introduction>
      
      <paragraphs>
        <title>Collecting the Data</title>
        
        <assemblage xml:id="def-sample">
          <title>Definitions: Sample and Sample Size</title>
          <p>A <term>sample</term> is a collection of observed outcomes generated by repeated realizations a random process. The set of observations should reflect the typical behavior, and the variability inherent in that process. A study's <term>sample size</term> is the number of outcomes observed.</p>
        </assemblage>
        
        <exercise xml:id="inv1-1-a" label="I1.1.1">
          <title>Identify the Sample</title>
          <statement>
            <p>Identify the sample in this study.</p>
          </statement>
          <hint>
            <p>The sample consists of the observational units from which data were collected.</p>
          </hint>
          <answer>
            <p>The sample is the observations from the 16 infants.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-b" label="I1.1.2">
          <title>Assess Independence Assumption</title>
          <statement>
            <p>Do you think it is reasonable to model these observations as independent realizations of the random process under <q>identical conditions</q>? Explain.</p>
          </statement>
          <hint>
            <p>Consider whether the infants can be viewed as interchangeable and whether each infant's choice was measured separately.</p>
          </hint>
          <answer>
            <p>Opinions will vary, but if we consider the infants as interchangeable (no differences between them) and the infants' choices were all measured separately, that this modeling assumption seems appropriate. In particular, we need to be willing to model each infant as having the same probability of picking the helper toy.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-c" label="I1.1.3">
          <title>Explain Experimental Controls</title>
          <statement>
            <p>Why is it important that the researchers varied the colors and shapes of the wooden characters and even on which side the toys were presented to the infants?</p>
          </statement>
          <hint>
            <p>Think about other factors besides the helping/hindering behavior that might influence an infant's choice.</p>
          </hint>
          <answer>
            <p>This is to control for (or at least balance out) any other factors that could be influencing the infants' choices.</p>
          </answer>
          <response/>
        </exercise>
        
        <assemblage xml:id="def-variable-types">
          <title>Definition: Variables</title>
          <p>The measurements we are taking define the <term>variable</term>. We classify the type of variable as <term>categorical</term> (assigning each observational unit to a category) or <term>quantitative</term> (assigning each observational unit a numerical measurement). A special type of categorical variable is a <term>binary variable</term>, which has just two possible outcomes (often labeled <q>success</q> and <q>failure</q>).</p>
        </assemblage>
        
        <exercise xml:id="inv1-1-d" label="I1.1.4">
          <title>Identify the Variable</title>
          <statement>
            <p>What is the variable we are measuring about each observation?</p>
          </statement>
          <hint>
            <p>Think about what information is recorded for each infant.</p>
          </hint>
          <answer>
            <p>Variable = which toy does the infant choose to play with.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-d2" label="I1.1.4b">
          <title>Classify Variable Type</title>
          <statement>
            <p>Is this variable quantitative or categorical?</p>
          </statement>
          <choices randomize="no">
            <choice correct="yes">
              <statement>
                <p>Categorical</p>
              </statement>
              <feedback>
                <p>Correct! The variable records which category (Helper or Hinderer) each infant chose, making it a categorical variable.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>Quantitative</p>
              </statement>
              <feedback>
                <p>Not quite. A quantitative variable would be a numerical measurement. Here we're recording which toy was chosen, which is a category.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>Think about whether the data is a number or a category.</p>
          </hint>
        </exercise>
        
        <assemblage xml:id="def-research-question">
          <title>Definition: Research Question</title>
          <p>A <term>research question</term> often looks for patterns in a variable or compares a variable across different groups or looks for a relationship between variables.</p>
        </assemblage>
        
        <exercise xml:id="inv1-1-e" label="I1.1.5">
          <title>State Research Question</title>
          <statement>
            <p>What research question is of interest here?</p>
          </statement>
          <hint>
            <p>What question are the researchers trying to answer about infant behavior?</p>
          </hint>
          <answer>
            <p>The research question is whether infants in general (assuming identical infants from a random process) are more likely to pick the helper toy than the hinderer toy in the long run.</p>
          </answer>
          <response/>
        </exercise>
      </paragraphs>
      
      <paragraphs>
        <title>Summarizing the Observed Data</title>
        
        <p>To summarize the distribution of a categorical variable, we can simply count how many are in each category and make a <term>bar graph</term><idx><h>bar graph</h><h>graphical display of categorical data with bars for each category</h></idx> to display the results, one bar for each outcome, with heights representing the number of observations in each category, separating the bars to indicate distinct categories.</p>
        
        <exercise xml:id="inv1-1-f" label="I1.1.6">
          <title>Create Bar Graph</title>
          <statement>
            <p>The <q>raw data</q> can be found on the course webpage as a txt file (<url href="https://www.rossmanchance.com/iscam3/data/InfantData.txt">InfantData.txt</url>). How many do you see of each possible outcome? Sketch the bar graph. Give your graph an <q>active title,</q> a concise sentence stating the main message/key takeaways from the graph.</p>
          </statement>
          <hint>
            <p>Count how many infants chose each toy. A bar graph should have bars for each category (Helper and Hinderer) with heights representing the counts.</p>
          </hint>
          <answer>
            <p>14/16 = 0.875</p>
            <p>Active title: A majority of infants preferred the helper toy.</p>
            <image source="tech_images/ch1solsbargraph.jpg" width="70%">
              <description>Bar graph showing 14 infants chose Helper toy and 2 chose Hinderer toy</description>
            </image>
          </answer>
          <response/>
        </exercise>
        
        <paragraphs xml:id="tech-detour-loading">
          <title>Technology Detour - Loading in a Data File</title>
          
          <exercise xml:id="tech-detour-r-loading-rstudio" label="Loading Data - RStudio">
            <title>Loading Data - RStudio</title>
            <statement>
              <p>In RStudio, choose <c>Import Dataset > From Text (readr)</c> and enter the URL, then press <c>Import</c>.</p>
              <ul>
                <li><p>Example URL: <url href="https://www.rossmanchance.com/iscam3/data/InfantData.txt">https://www.rossmanchance.com/iscam3/data/InfantData.txt</url></p></li>
                <li><p>Keep <c>First Row as Names</c> checked</p></li>
                <li><p>For ISCAM files, change the <c>Delimiter</c> to <c>Tab</c></p></li>
                <li><p>Press <c>Update</c> to preview the data</p></li>
                <li><p>You can set the dataset name</p></li>
              </ul>
              
              <note>
                <title>RStudio Reminder</title>
                <p>With other data files, you may need to consider how <q>missing values</q> are coded. The Import Dataset dialog gives you a preview so you can check that the data looks correct before importing.</p>
              </note>
            </statement>
            <solution>
              <p>After importing, you should see the data appear in your Environment pane (upper right) and a data viewer window will open showing the contents of the file. The data table should show one column named <c>choice</c> with 16 rows containing either "Helper" or "Hinderer".</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-r-loading" label="Loading Data - R">
            <title>Loading Data - R</title>
            <statement>
              <p><alert>Files from the Web</alert></p>
              <p>Open the InfantData.txt (raw data) link from the data files page, select all, copy, and then in R use the following command. Keep in mind that R is case sensitive:</p>
              
              <p><em>PC:</em></p>
              <program language="r" interactive="sage">
                <input>
InfantData = read.table("clipboard", header=TRUE)
                </input>
              </program>
              
              <p><em>Mac:</em></p>
              <program language="r" interactive="sage">
                <input>
InfantData = read.table(pipe("pbpaste"), header=TRUE)
                </input>
              </program>
              
              <p>You can also use a URL (in quotes). The <c>header</c> command indicates the variables have names.</p>
              
              <p><alert>Text Files on Your Computer</alert></p>
              <program language="r" interactive="sage">
                <input>
InfantData = read.table(file.choose(), header=T)
                </input>
              </program>
              
              <p>To see the data, type:</p>
              <program language="r" interactive="sage">
                <input>
View(InfantData)
# or
head(InfantData)
                </input>
              </program>
              
              <p>Next you can <q>attach</q> the file to be able to use variable names directly:</p>
              <program language="r" interactive="sage">
                <input>
attach(InfantData)    # Now R knows what the "choice" variable is
                </input>
              </program>
              
              <p>Or you need to clarify to R which datafile you are using (e.g., <c>InfantData$choice</c>).</p>
              
              <p><alert>Other Input Options</alert></p>
              <p>Depending on how the data you are pasting is formatted, you may need additional arguments:</p>
              <ul>
                <li><p><c>sep="\t"</c> - separated by tabs</p></li>
                <li><p><c>na.strings="*"</c> - how to code missing values</p></li>
                <li><p><c>strip.white=TRUE</c> - strip extra white space</p></li>
              </ul>
              
              <note>
                <title>R Reminder</title>
                <p>R is case sensitive! <c>InfantData</c> and <c>infantdata</c> are different objects. Always check your data after loading with <c>View()</c> or <c>head()</c> to make sure it loaded correctly. Using <c>attach()</c> lets you reference column names directly, but be careful - if you have multiple datasets loaded, this can cause confusion.</p>
              </note>
            </statement>
            <solution>
              <p>After running <c>head(InfantData)</c>, you should see output similar to:</p>
              <pre>
     choice
1    Helper
2    Helper
3    Helper
4    Helper
5    Helper
6  Hinderer
              </pre>
              <p>This shows the first 6 observations of the data. The full dataset contains 16 observations total.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-jmp-loading" label="Loading Data - JMP">
            <title>Loading Data - JMP</title>
            <statement>
              <p><alert>Method 1: Copy and Paste</alert></p>
              <p>Choose <c>File > New > Data table</c>. Open the <url href="https://www.rossmanchance.com/iscam2/data/InfantData.txt" target="_blank">InfantData.txt</url> (raw data) link from the <url href="https://www.rossmanchance.com/iscam4/files.html" target="_blank">data files page</url> and select all the observations and the variable name and copy the data into the clipboard. Return to the data table in JMP and select <c>Edit > Paste with Column Names</c>.</p>
              
              <p><alert>Method 2: Open File</alert></p>
              <p>If the .txt file is saved on your computer, you can choose <c>File > Open</c> and use the pull-down menu to change the file type.</p>
              
              <note>
                <title>JMP Reminder</title>
                <p>When using <c>Paste with Column Names</c>, make sure you include the header row (variable names) in your selection. JMP will automatically detect the data types for each column. Always check the data table after importing to ensure everything looks correct.</p>
              </note>
            </statement>
            <solution>
              <p>After pasting or opening the file, you should see a data table with one column labeled <c>choice</c> containing 16 rows. The column should be recognized as a Character data type. The values should alternate between "Helper" and "Hinderer" entries.</p>
              <image source="tech_images/JMPdatatable.png" width="70%">
                <description>JMP data table showing the choice column with 16 rows of Helper and Hinderer values</description>
              </image>
            </solution>
          </exercise>
        </paragraphs>
        
        <paragraphs xml:id="tech-detour-tallying">
          <title>Technology Detour - Tallying the Outcomes</title>
          
          <exercise xml:id="tech-detour-r" label="R">
            <title>Tallying the Outcomes - R</title>
            <statement>
              <p>To count the number of correct and incorrect responses, type:</p>
              <program language="r" interactive="sage">
                <input>
table(InfantData)
                </input>
              </program>
              
              <note>
                <title>R Reminder</title>
                <p>The <c>table()</c> function automatically counts the frequency of each unique value in your data. Make sure your data is loaded before running this command.</p>
              </note>
            </statement>
            <solution>
              <p>The output should show:</p>
              <pre>
choice
  Helper Hinderer 
      14        2
              </pre>
              <p>This indicates that 14 infants chose the Helper toy and 2 chose the Hinderer toy.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-jmp" label="JMP">
            <title>Tallying the Outcomes - JMP</title>
            <statement>
              <p>Choose <c>Analyze > Tabulate</c>. In the new window, drag the <c>choice</c> column to either the Drop Zone for columns or for rows. Press <c>Done</c>.</p>
              
              <image source="tech_images/JMPtabulate.png" width="70%">
                <description>JMP Tabulate window showing counts: Helper 14, Hinderer 2</description>
              </image>
              
              <note>
                <title>JMP Reminder</title>
                <p>Look for the red triangle (<q>hot spot</q>) menus in JMP windows - they provide additional options and actions. Dragging variables to different zones (rows vs. columns) changes how your table is organized.</p>
              </note>
            </statement>
            <solution>
              <p>The Tabulate output should display a table showing the counts for each category:</p>
              <ul>
                <li><p>Helper: 14</p></li>
                <li><p>Hinderer: 2</p></li>
                <li><p>Total (N): 16</p></li>
              </ul>
              <p>The exact layout depends on whether you placed the variable in rows or columns, but the counts will be the same.</p>
              <image source="tech_images/JMPtable.png" width="50%">
                <description>JMP frequency table showing choice categories and their counts</description>
              </image>
            </solution>
          </exercise>
        </paragraphs>
        
        <paragraphs xml:id="tech-detour-bargraphs">
          <title>Technology Detour - Bar Graphs</title>
          
          <exercise xml:id="tech-detour-r-bargraph-raw" label="Bar Graphs - R (raw data)">
            <title>Bar Graphs - R (raw data)</title>
            <statement>
              <p>You need to pass the tabled data into the barplot function:</p>
              <program language="r" interactive="sage">
                <input>
barplot(table(InfantData), xlab="Choice", ylab="Frequency")
                </input>
              </program>
              <p>You may need to toggle to the R Graphics Window to see the graph window. Now you can use R to export the graph to a file or you can Copy and Paste or use a screen capture.</p>
              
              <note>
                <title>R Reminder</title>
                <p>The <c>xlab</c> and <c>ylab</c> arguments add labels to your axes. Always label your graphs to make them interpretable! You can nest the <c>table()</c> function inside <c>barplot()</c> to go directly from raw data to a graph.</p>
              </note>
            </statement>
            <solution>
              <p>You should see a bar graph with two bars:</p>
              <ul>
                <li><p>A bar for "Helper" with height 14</p></li>
                <li><p>A bar for "Hinderer" with height 2</p></li>
              </ul>
              <p>The x-axis should be labeled "Choice" and the y-axis should be labeled "Frequency". The bars should have gaps between them to indicate these are categorical data.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-r-bargraph-summary" label="Bar Graphs - R (summary data)">
            <title>Bar Graphs - R (summary data)</title>
            <statement>
              <p>If you already (or only) have the summarized data (the number of successes and failures), you can type:</p>
              <program language="r" interactive="sage">
                <input>
barplot(c(14, 2), names.arg=c("Helper", "Hinderer"))
                </input>
              </program>
              
              <note>
                <title>R Reminder</title>
                <p>The <c>c()</c> function creates a vector (list) of values. The <c>names.arg</c> parameter assigns category labels to each bar. The order matters - the first count gets the first label!</p>
              </note>
            </statement>
            <solution>
              <p>You should see a bar graph identical to the one created from raw data:</p>
              <ul>
                <li><p>A bar labeled "Helper" with height 14</p></li>
                <li><p>A bar labeled "Hinderer" with height 2</p></li>
              </ul>
              <p>This method is useful when you only have summary statistics rather than the full dataset.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-jmp-bargraph-summary" label="Bar Graphs - JMP (summary data)">
            <title>Bar Graphs - JMP (summary data)</title>
            <statement>
              <p><alert>Method 1: From Tabulate Window</alert></p>
              <p>In the Tabulate window (from above), use the red down arrow in the upper left corner (<q>hot spot</q>) and select <c>Show Chart</c>. Best when using the Drop zone for rows.</p>
              
              <image source="tech_images/bargraphJMP1.png" width="50%">
                <description>JMP Tabulate window with Show Chart option</description>
              </image>
              
              <p><alert>Method 2: Graph Builder</alert></p>
              <p>If you have the categories and counts in a data window, choose <c>Graph > Graph Builder</c>. Drag the variable names to the x-axis and the counts to the y-axis. Press the 7th icon to convert the chart to a bar graph.</p>
              
              <image source="tech_images/bargraphJMP2.png" width="50%">
                <description>JMP Graph Builder interface for creating bar graphs from summary data</description>
              </image>
              
              <note>
                <title>JMP Reminder</title>
                <p>Graph Builder is JMP's most flexible graphing tool. The icons at the top let you switch between different graph types. Drag and drop variables to different zones to change what the graph displays.</p>
              </note>
            </statement>
            <solution>
              <p>You should see a bar graph showing two bars with the frequency counts clearly labeled. The Helper bar should be noticeably taller (14) than the Hinderer bar (2). The graph should automatically include axis labels and a legend if needed.</p>
              <image source="tech_images/JMPbargraph2.png" width="70%">
                <description>JMP bar graph created from summary data showing Helper and Hinderer counts</description>
              </image>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-jmp-bargraph-raw" label="Bar Graphs - JMP (raw data)">
            <title>Bar Graphs - JMP (raw data)</title>
            <statement>
              <p><alert>Method 1: Graph Builder</alert></p>
              <p>From the Data Table window, select <c>Graph > Graph Builder</c>. Drag the Choice variable to the X-axis. Hover until the X-region shows the group labels and then let go. Press the 7th (<q>Bar</q>) icon to convert the chart to a bar graph.</p>
              
              <image source="tech_images/bargraphJMP3.png" width="50%">
                <description>JMP Graph Builder showing dragging variable to X-axis</description>
              </image>
              
              <image source="tech_images/bargraphJMP4.png" width="50%">
                <description>JMP Graph Builder with Bar chart icon selected</description>
              </image>
              
              <p><alert>Method 2: Distribution Platform</alert></p>
              <p>Choose <c>Analyze > Distribution</c>. With the choice column highlighted, press the <c>Y, Columns</c> button (or drag to the white box). Press <c>OK</c>.</p>
              
              <image source="tech_images/bargraphJMP6.png" width="50%">
                <description>JMP Distribution output with frequency chart</description>
              </image>
              
              <p>You have lots of options here (using the hot spots), like turning the graph horizontal, adding an axis (putting it on the left), adding labels, separating bars, etc.</p>
              
              <image source="tech_images/bargraphJMP7.png" width="50%">
                <description>JMP Distribution hot spot menu options</description>
              </image>
              
              <note>
                <title>JMP Reminder</title>
                <p>The Distribution platform is great for exploring categorical data. Use the red triangle hot spots to customize your graph - you can make bars horizontal, add counts/percentages, change colors, and more. Experiment with the options to make your graph publication-ready!</p>
              </note>
            </statement>
            <solution>
              <p>Either method should produce a bar graph showing the distribution of choices. You should see:</p>
              <ul>
                <li><p>Two distinct bars for Helper and Hinderer</p></li>
                <li><p>The Helper bar should be approximately 7 times taller than the Hinderer bar (14 vs 2)</p></li>
                <li><p>Frequency counts labeled on or near the bars</p></li>
                <li><p>Clear axis labels and category names</p></li>
              </ul>
              <p>Using the Distribution platform gives you more statistical output beyond just the graph, including percentages and other summary statistics.</p>
              <image source="tech_images/JMPbargraph1.png" width="50%">
                <description>JMP bar graph showing Helper and Hinderer distribution</description>
              </image>
            </solution>
          </exercise>
        </paragraphs>
      </paragraphs>
      
      <paragraphs>
        <title>Drawing Conclusions Beyond the Sample</title>
        
        <p>Clearly a majority/more than half of the infants chose the helper toy in this sample of 16 infants. But does that convince us that infants in general are more likely to pick the helper toy in the long run? In other words, what is the probability that an infant will choose the helper toy?</p>
        
        <p><em>Model assumption:</em> Note we are assuming each infant has the same probability of picking the helper toy, we just don't know the value of that probability.</p>
        
        <exercise xml:id="inv1-1-g" label="I1.1.7">
          <title>Researchers' Hypothesis</title>
          <statement>
            <p>What do the researchers think is true about the value of this probability (e.g., do they think it is larger or smaller than 0.50)?</p>
          </statement>
          <choices randomize="no">
            <choice correct="yes">
              <statement>
                <p>Larger than 0.50</p>
              </statement>
              <feedback>
                <p>Correct! The researchers hypothesize that infants prefer the helper toy, which would mean the probability of choosing the helper is greater than 0.50.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>Smaller than 0.50</p>
              </statement>
              <feedback>
                <p>Not quite. If infants preferred the hinderer toy, the probability would be less than 0.50, but that's not what the researchers think.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>Equal to 0.50</p>
              </statement>
              <feedback>
                <p>Not quite. A probability of 0.50 would mean infants choose equally between the two toys, which is not the researchers' hypothesis.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>Consider what the research hypothesis is about infant preferences for the helper toy.</p>
          </hint>
        </exercise>
        
        <exercise xml:id="inv1-1-h" label="I1.1.8">
          <title>Consider Chance Explanation</title>
          <statement>
            <p>Is it possible that in the long run infants just choose equally between the two toys (e.g., the probability an infant will choose the helper toy is 0.5) and we just happened to see more than half choose the helper toy in our sample?</p>
          </statement>
          <choices randomize="no">
            <choice correct="yes">
              <statement>
                <p>Yes</p>
              </statement>
              <feedback>
                <p>Correct! It's possible that the true probability is 0.50 and we just observed an unusual sample by chance.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>No</p>
              </statement>
              <feedback>
                <p>Actually, it is possible. Random samples can vary, and we might see more than half choose the helper toy even if the true probability is 0.50.</p>
              </feedback>
            </choice>
          </choices>
        </exercise>
        
        <exercise xml:id="inv1-1-i" label="I1.1.9">
          <title>Rule Out Color Preference</title>
          <statement>
            <p>Is it plausible that the observed majority occurred because infants just prefer the color blue?</p>
          </statement>
          <choices randomize="no">
            <choice>
              <statement>
                <p>Yes</p>
              </statement>
              <feedback>
                <p>Not quite. The researchers varied the colors, shapes, and positions of the toys to balance out these factors, so color preference is not a plausible explanation.</p>
              </feedback>
            </choice>
            <choice correct="yes">
              <statement>
                <p>No</p>
              </statement>
              <feedback>
                <p>Correct! We are not considering color, shape, or position as the explanation because these factors were balanced in the design of the study.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>Recall why the researchers varied colors, shapes, and positions.</p>
          </hint>
        </exercise>
        
        <p>So that leaves us with two explanations for the majority we observed:</p>
        <p><ol>
          <li><p>There is something to the theory that infants are genuinely more likely to pick the helper toy (for some reason).</p></li>
          <li><p>Infants choose equally between the two toys in the long run and we happened to get <q>lucky</q> and had an unusual sample where most of the infants in our sample picking the helper toy.</p></li>
        </ol></p>
        
        <exercise xml:id="inv1-1-j" label="I1.1.10">
          <title>Choose Between Explanations</title>
          <statement>
            <p>So for the two possibilities we are still considering, how might you choose between them? In particular, how might you convince someone whether or not option (2) is plausible based on this study?</p>
          </statement>
          <hint>
            <p>Think about what makes an outcome unusual or typical when choices are made randomly.</p>
          </hint>
          <answer>
            <p>We would need to convince someone that if these results were just happening "randomly," it would be unusual to get 14 infants picking the helper toy.</p>
          </answer>
          <response/>
        </exercise>
        
        <p>Our analysis approach is going to be to assume the second explanation is true (similar to how in a legal trial we assume a defendant is innocent), and then see whether our data are consistent or inconsistent with that assumption. To do this, we need to investigate the values we expect to see for the number choosing the helper toy when 16 infants are equally choosing between the two toys. As you saw with the Random Babies (Investigation B), we can simulate the outcomes of a random process to help us determine which outcomes are more or less likely to occur.</p>
        
        <exercise xml:id="inv1-1-k" label="I1.1.11">
          <title>Design a Simulation</title>
          <statement>
            <p>Suggest a method for carrying out a simulation of 16 infants picking equally between the two toys.</p>
          </statement>
          <hint>
            <p>Think about a simple physical randomization device that gives two equally likely outcomes.</p>
          </hint>
          <answer>
            <p>We could toss a coin for each infant, letting heads represent choosing the helper toy and tails represent choosing the hinderer toy. This makes the two choices equally likely on each toss. Then use 16 coins or toss one coin 16 times to represent the 16 infants. (We are assuming these are equivalent, that the observational units are identical.) These results will help us assess the variability in the outcomes of 16 infants "just by chance." This will help us decide whether 14 is a typical outcome or an unusual outcome when we know for a fact that the "infants" choose equally (in the long run) between the two toys.</p>
          </answer>
          <response/>
        </exercise>
      </paragraphs>
      
      <paragraphs>
        <title>Simulation</title>
        
        <p>For a 50-50 simulation model, we can flip a fair coin. We can arbitrarily define <q>heads</q> to be choosing the helper toy and <q>tails</q> to be choosing the hinderer toy. We will repeat the random process 16 times to represent the 16 infants, and we will count how many times we flip heads, representing an infant choosing the helper toy. The chart below shows this mapping of the real world, which we saw one instance of, and the simulation model, which we can easily repeat many times. Keep in mind that in the simulation model, we know the probability of heads is 0.50.</p>
        
        <table xml:id="table-simulation-model">
          <title>Mapping real world to simulation model</title>
          <tabular halign="left" top="medium" bottom="medium" left="medium" right="medium">
            <row header="yes" bottom="medium" left="medium" right="medium">
              <cell right="medium"></cell>
              <cell right="medium">Real world</cell>
              <cell>Simulation model</cell>
            </row>
            <row bottom="minor" left="medium" right="medium">
              <cell right="medium">One observation</cell>
              <cell right="medium">Infant choice</cell>
              <cell>Coin toss</cell>
            </row>
            <row bottom="minor" left="medium" right="medium">
              <cell right="medium">Sample</cell>
              <cell right="medium">16 infants</cell>
              <cell>16 coin tosses</cell>
            </row>
            <row bottom="minor" left="medium" right="medium">
              <cell right="medium">Success</cell>
              <cell right="medium">Picks helper toy</cell>
              <cell>Lands heads</cell>
            </row>
            <row left="medium" right="medium">
              <cell right="medium">Probability of <q>success</q></cell>
              <cell right="medium">Unknown</cell>
              <cell>0.50</cell>
            </row>
          </tabular>
        </table>
        
        <exercise xml:id="inv1-1-l" label="I1.1.12">
          <title>Conduct Coin Toss Simulation</title>
          <statement>
            <p>Flip a coin 16 times, representing the 16 infants in the study (one repetition of this random process). Tally the results below and count how many of the 16 chose the helper toy:</p>
            <p><em><q>Could have been</q> outcomes</em></p>
            <p>Heads (helper toy): <var width="5"/></p>
            <p>Tails (hinderer toy): <var width="5"/></p>
            <p>Total number of heads in 16 tosses: <var width="5"/></p>
          </statement>
          <hint>
            <p>Flip a coin 16 times and count the number of heads and tails. The totals should add to 16.</p>
          </hint>
          <answer>
            <p>Results will vary by class. Below is one possible set of results:</p>
            <image source="tech_images/ch1solsdotplot.jpg" width="70%">
              <description>Dotplot showing distribution of class simulation results for number of heads in 16 coin tosses</description>
            </image>
          </answer>
        </exercise>
        
        <exercise xml:id="inv1-1-m" label="I1.1.13">
          <title>Combine Class Results</title>
          <statement>
            <p>Combine your simulation results for each repetition with your classmates' on the scale below. Create a dotplot by placing a dot above the numerical result found by each person's set of 16 tosses.</p>
          </statement>
          <hint>
            <p>Each person in class should contribute one dot to the class dotplot, placed above their number of heads out of 16.</p>
          </hint>
          <answer>
            <p>Results will vary by class. See image in the previous exercise for an example dotplot.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-n" label="I1.1.14">
          <title>Describe Simulation Variability</title>
          <statement>
            <p>Did everyone get the same number of heads every time? What is an average or typical number of heads in a set of 16 tosses? Is this what you expected? Explain.</p>
          </statement>
          <hint>
            <p>Look at the center of the dotplot. What value appears most frequently or is in the middle of the distribution?</p>
          </hint>
          <answer>
            <p>No, there will be variability across the sets of 16 tosses, but 8 heads is an average or typical number of heads.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-o" label="I1.1.15">
          <title>Assess Unusualness</title>
          <statement>
            <p>Does 14 heads appear to be an unusual outcome for 16 observations from a process where heads should appear 50% of the time in the long run?</p>
          </statement>
          <hint>
            <p>Look at your class dotplot. How often did values as extreme as 14 (or more) occur? Is 14 in the "tail" or center of the distribution?</p>
          </hint>
          <answer>
            <p>Answers will vary, but 14 does appear to be somewhat unusual, not occurring very often, in the "tail" of the distribution.</p>
          </answer>
          <response/>
        </exercise>
        
        <p>We really need to simulate this hypothetical random selection process hundreds, preferably thousands of times. This would be very tedious and time-consuming with coins, so let's turn to technology.</p>
        
        <exercise xml:id="inv1-1-p" label="I1.1.16">
          <statement>
            <p>Use the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url> to simulate these 16 infants making this helper/hinderer choice, still assuming that infants have no real preference and so are equally likely to choose either toy.</p>
            <p><ul>
              <li><p>Keep the Probability of heads set to 0.5.</p></li>
              <li><p>Set the Number of Tosses to 16.</p></li>
              <li><p>Keep the Number of repetitions at 1 for now.</p></li>
              <li><p>Press Draw Samples.</p></li>
            </ul></p>
            <p>Report the number of heads (i.e., the number of infants who choose the helper toy) for this <q>could have been</q> (under the assumption of no preference) outcome.</p>
            <p>Number of heads: <var width="5"/></p>
          </statement>
          <hint>
            <p>The applet will simulate flipping 16 coins and count the number of heads for you automatically.</p>
          </hint>
          <answer>
            <p>Results will vary.</p>
          </answer>
        </exercise>
        
        <exercise xml:id="inv1-1-q" label="I1.1.17">
          <title>Repeat Simulation Multiple Times</title>
          <statement>
            <p>Uncheck the Show animation box and press Draw Samples four more times, each time recording the number of the 16 infants who choose the helper toy. Did you get the same number of heads all five times?</p>
          </statement>
          <choices randomize="no">
            <choice>
              <statement>
                <p>Yes</p>
              </statement>
              <feedback>
                <p>Actually, random processes typically produce different results each time. You should see variation in the number of heads across the five repetitions.</p>
              </feedback>
            </choice>
            <choice correct="yes">
              <statement>
                <p>No</p>
              </statement>
              <feedback>
                <p>Correct! There should be variation in the results across the repetitions. This variability is a natural characteristic of random processes.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>Each repetition simulates a new set of 16 coin flips. Think about whether random processes produce identical results every time.</p>
          </hint>
        </exercise>
        
        <exercise xml:id="inv1-1-r" label="I1.1.18">
          <title>Generate Null Distribution</title>
          <statement>
            <p>Now change the Number of repetitions to 1995 and press Draw Samples, to produce a total of 2,000 repetitions of this random process of tossing a coin 16 times. For the dotplot you have created, what does each dot represent (i.e., what would you need to do to add another dot to the graph)?</p>
          </statement>
          <hint>
            <p>Think about what you did to create one dot in the physical coin-flipping activity.</p>
          </hint>
          <answer>
            <p>Each dot in the dotplot represents the number of heads in 16 coin tosses (representing the choices of a set of 16 infants).</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-r2" label="I1.1.18b">
          <title>Classify Graph Variable</title>
          <statement>
            <p>Is the graph variable (number of heads) quantitative or categorical?</p>
          </statement>
          <choices randomize="no">
            <choice correct="yes">
              <statement>
                <p>Quantitative</p>
              </statement>
              <feedback>
                <p>Correct! The variable "number of heads" is quantitative because it represents a numerical count that can be measured and has meaningful numerical values.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>Categorical</p>
              </statement>
              <feedback>
                <p>Not quite. The number of heads is a count (0, 1, 2, ..., 16), which makes it quantitative rather than categorical. Categorical variables assign observations to categories, not numerical values.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>What does the horizontal axis represent? Is it counting something or assigning categories?</p>
          </hint>
        </exercise>
        
        <exercise xml:id="inv1-1-s" label="I1.1.19">
          <title>Draw Conclusion</title>
          <statement>
            <p>Now that we have a better picture of the long-run behavior of this process, discuss whether you would consider option 2 before (j): <q>Infants choose equally between the two toys in the long run and we happened to get 'lucky' and find most of the infants in our sample picking the helper toy</q> to be a plausible conclusion for this study. Explain your reasoning as if to a skeptic.</p>
          </statement>
          <hint>
            <p>Look at how often 14 or more heads occurred in your 2,000 simulated repetitions. Is this common or rare? What does this tell you about the plausibility of the "no preference" assumption?</p>
          </hint>
          <answer>
            <p>Because it is very unlikely for us to have seen results at least as extreme as what we observed (14 successes) under the assumption of 50-50 chance, we have evidence against this claim and instead in favor of the claim that there is something other than random chance at play in this sample.</p>
          </answer>
          <response/>
        </exercise>
      </paragraphs>
      
      <paragraphs>
        <title>Discussion</title>
        
        <p>Returning to our legal trial analogy, if you decide that the observed <q>data</q> is unlikely to occur by chance alone, you are going to <q>reject</q> the assumption of <q>innocence</q> (and say we have evidence the defendant is guilty). If you decide the data/evidence is not unusual by chance alone, then you <q>fail to reject</q> that assumption (and we say we don't have evidence the defendant is guilty <mdash/> we aren't proving the defendant innocent, just that the evidence is not inconsistent with that assumption, <q>not guilty</q>).</p>
        
        <p>So based on these simulation results, we would say the data (14 helper choices out of 16 trials) is unusual under the assumption that infants genuinely have no preference and are choosing blindly when presenting the toys. This evidence convinces us that <q>There is something to the theory that infants are genuinely more likely to pick the helper toy (for some reason)</q> is the more believable explanation for why so many of the infants in this study picked the helper toy over the hinderer toy. We haven't proven this is true, but based on the strong majority these researchers saw, even for this small sample size of 16, we would consider the evidence convincing (<q>beyond a reasonable doubt</q>) that, in the long run, the probability of choosing the helper toy in this random process is greater than 0.5. Because the researchers controlled for other possible explanations for the observed preference results like color and handedness, we will conclude that there is convincing evidence that infants really do have a genuine preference for the helper toy over the hindering toy.</p>
      </paragraphs>
      
      <assemblage xml:id="study-conclusions-1-1">
        <title>Study Conclusions</title>
        
        <p>In a study of <q>social evaluation,</q> researchers explored whether pre-verbal infants have a preference for a <q>helping</q> toy over a <q>hindering</q> toy. Treating the 16 infants as identical observations from a random process with equal probability of success/failure, we find that getting 14 infants choosing the helper toy is not consistent with the types of values we expect to see when we have <q>infants</q> choosing equally between the two toys. This means that the researchers' data provide strong statistical evidence to reject this <q>no preference</q> model and conclude that the infants' choices are actually governed by a process where there is a genuine preference for the helper toy (or at least that it's more complicated than each infant flipping a coin to decide). Of course, this conclusion depends on the assumption of <q>identical infants</q> and that these 16 infants' choices are representative of the larger process of viewing the videos and selecting a toy. Also keep in mind that not all infants had a clear preference for either object.</p>
      </assemblage>
      
      <subsection xml:id="practice1-1A">
        <title>Practice Problem 1.1A</title>
        
        <p>In a second experiment, the same events were repeated but the object climbing the hill no longer had the googly eyes attached. The researchers wanted to see whether the preference was made based on a social evaluation more than a perceptual preference. Suppose 8 of 12 (different) infants chose the push-up toy.</p>
        
        <exercise xml:id="practice-1-1a-a" label="PP1.1A.1">
          <statement>
            <p>If you were to use a coin to carry out a simulation analysis to evaluate these results: how many times would you flip the coin for one repetition <mdash/> 6, 8, 10, 12, 16, or 1000?</p>
          </statement>
          <choices randomize="no">
            <choice>
              <statement>
                <p>6</p>
              </statement>
              <feedback>
                <p>Not quite. Think about how many infants were in this experiment.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>8</p>
              </statement>
              <feedback>
                <p>Close, but this is the number who chose the push-up toy, not the total number of infants.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>10</p>
              </statement>
              <feedback>
                <p>Not quite. Check the problem statement for the total number of infants in the experiment.</p>
              </feedback>
            </choice>
            <choice correct="yes">
              <statement>
                <p>12</p>
              </statement>
              <feedback>
                <p>Correct! You need to flip the coin 12 times to represent the 12 different infants in this experiment, just like we flipped 16 times to represent the 16 infants in the original study.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>16</p>
              </statement>
              <feedback>
                <p>Not quite. That was the sample size in the original study, but this experiment has a different number of infants.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>1000</p>
              </statement>
              <feedback>
                <p>Not quite. 1000 would be the number of repetitions we might do, not the number of coin flips per repetition.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>How many infants participated in this second experiment? Each coin flip represents one infant's choice.</p>
          </hint>
        </exercise>
        
        <exercise xml:id="practice-1-1a-b" label="PP1.1A.2">
          <statement>
            <p>Use the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url> to decide whether it is plausible that when the googly eyes are removed infants do not have a genuine preference between the two toys. What do you conclude?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-1B">
        <title>Practice Problem 1.1B</title>
        
        <p>In 2019, the home team won 54 of the first 88 games of the Premier Soccer League season. Consider these games as a sample from a random process (all games that could have occurred in first 3 months).</p>
        
        <exercise xml:id="practice-1-1b-a" label="PP1.1B.1">
          <statement>
            <p>Could we use a coin tossing simulation to model this random process? What would each coin toss represent? What are we assuming about the process? How many times would we toss the coin for one repetition? Define what is meant by <q>probability of success</q> in this context.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-1b-b" label="PP1.1B.2">
          <statement>
            <p>Use the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url> to decide whether these data provide convincing statistical evidence that the home team is more likely than the visiting team to win in the long run. Justify your conclusion.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-1b-c" label="PP1.1B.3">
          <statement>
            <p>At the beginning of the 2020 season, fans were not allowed at the games due to the Coronavirus pandemic. For the first three months of this season, the home team won 40 of 87 matches. Decide whether these data provide convincing statistical evidence that the home team is more likely than the visiting team to win when no fans are present. Justify your conclusion.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
    
    <subsection xml:id="investigation1-2">
      <title>Investigation 1.2: Can Wolves Understand Human Cues?</title>
      
      <sidebyside widths="58% 38%">
        <stack>
          <p>Previous research has demonstrated that domesticated dogs can be trained to understand human cues, such as looking or pointing at an object. But it was not clear how the animals would perform with "behavioral cues" showing intent such as reaching for, but not obtaining, or trying to open an object.</p>
          
        </stack>
        <image source="images/wolf.jpg" width="100%"/>
      </sidebyside>
          <p><url href="https://www.nature.com/articles/s41598-017-12055-6#MOESM1">Lampe et al. (2017)</url> gave captive wolves, pack dogs living in identical conditions to the wolves, and pet dogs living with families a series of "object-choice tasks." A table was placed outside a fenced compartment, and a container was placed at each end of the table, one containing food and one empty. The experimenter would give the cue as to which container had the food and then the animal would touch one of the two targets next to the containers. A 6-year-old female timber wolf, Yukon, chose the intended container in 6 of the 8 trials with behavioral cues.</p>
      
      <exercise xml:id="inv1-2-a" label="I1.2.1">
        <title>Identify Sample and Process</title>
        <statement>
          <p>Identify the sample/random process for this study.</p>
        </statement>
        <response/>
        <hint>
          <p>What is the sample size?</p>
        </hint>
        <solution>
          <p>The random process is the repeated trials given to Yukon (<m>n = 8</m>).</p>
        </solution>
      </exercise>
      

      <exercise xml:id="inv1-2-b" label="I1.2.2">
        <title>Identify the Variable</title>
        <statement>
          <p>Identify the variable of interest for this process.</p>
        </statement>
        <response/>
        <hint>
          <p>The variable is the measurements recorded for each observation.</p>
        </hint>
        <solution>
          <p>The variable is whether or not Yukon picks the cued container.</p>
        </solution>
      </exercise>

      <exercise xml:id="inv1-2-b2" label="I1.2.2b">
        <title>Classify Variable Type</title>
        <statement>
          <p>Is this variable quantitative or categorical?</p>
        </statement>
        <choices randomize="no">
          <choice correct="yes">
            <statement>
              <p>Categorical</p>
            </statement>
            <feedback>
              <p>Correct! The variable records which category (cued or not cued) Yukon chose, making it a categorical variable.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>Quantitative</p>
            </statement>
            <feedback>
              <p>Not quite. A quantitative variable would be a numerical measurement. Here we're recording which container was chosen, which is a category.</p>
            </feedback>
          </choice>
        </choices>
        <hint>
          <p>Think about whether the data is a number or a category.</p>
        </hint>
        <solution>
          <p>The variable is categorical.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="inv1-2-c" label="I1.2.3">
        <title>Expected Success Rate</title>
        <statement>
          <p>If Yukon was purely guessing, how often would you expect her to identify the correct container?</p>
        </statement>
        <choices randomize="no">
          <choice correct="yes">
            <statement>
              <p>about 50% of the time</p>
            </statement>
            <feedback>
              <p>Correct! With two equally likely options, we would expect Yukon to choose correctly about half the time by chance.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>about 33% of the time</p>
            </statement>
            <feedback>
              <p>This would be the probability if there were three equally likely options.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>about 75% of the time</p>
            </statement>
            <feedback>
              <p>This would mean Yukon has some understanding of the cues, not just guessing.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>about 25% of the time</p>
            </statement>
            <feedback>
              <p>This would be the probability if there were four equally likely options.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>never</p>
            </statement>
            <feedback>
              <p>Even when guessing, there's a chance of being correct.</p>
            </feedback>
          </choice>
        </choices>
        <solution>
          <p>About 50% of the time.</p>
        </solution>
      </exercise>
      
      <p>We will think of the sample of 8 attempts as identical observations from a random process, and we are choosing between two possibilities:</p>
      <p><ol>
        <li><p>Yukon can understand behavioral cues,</p></li>
        <li><p>Yukon does not consistently understand behavioral cues and is guessing randomly.</p></li>
      </ol></p>
      
      <assemblage xml:id="def-hypotheses">
        <title>Definition: Hypotheses</title>
        <p>In drawing conclusions beyond our sample data to the underlying random process, we will often be choosing between two competing claims about the underlying process:</p>
        <p><ul>
          <li><p>The <term>null hypothesis</term><idx><h>null hypothesis</h><h>the "by chance alone" explanation</h></idx>, which is the "by chance alone" explanation;</p></li>
          <li><p>The <term>alternative hypothesis</term><idx><h>alternative hypothesis</h><h>what researchers hope to show</h></idx>, which is usually what the researchers are hoping to show.</p></li>
        </ul></p>
        
        <p>In Investigation 1.1, the null hypothesis was that infants (in general) choose equally among the two toys in the long run. The alternative hypothesis was that infants have a genuine preference for the helper toy.</p>
      </assemblage>
      
        <aside>
          <title>How to use matching questions</title>
          <p>Drag the descriptions from the left to match them with the correct answer on the right.</p>
        </aside>
      <exercise xml:id="inv1-2-d" label="I1.2.4">
        <title>State Hypotheses</title>
        <statement>
          <p>Identify the above possibilities as the null and alternative hypotheses.</p>
        </statement>
        <matches>
          <match order="1">
            <premise>Yukon does not consistently understand behavioral cues and is guessing randomly</premise>
            <response>Null Hypothesis</response>
          </match>
          <match order="2">
            <premise>Yukon can understand behavioral cues</premise>
            <response>Alternative Hypothesis</response>
          </match>
        </matches>
        <solution>
          <p><b>Null:</b> Yukon does not consistently understand behavioral cues and is guessing randomly between the 2 containers.</p>
          <p><b>Alternative:</b> Yukon can understand behavioral cues.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="inv1-2-e" label="I1.2.5">
        <title>Plan the Simulation</title>
        <statement>
          <p>So our simulation model is going to assume the null hypothesis is true and we will see how unusual it is to find 6 successes and 2 failures in 8 attempts. Can we use "coin tossing" again? How many times will we toss the coin?</p>
        </statement>
        <response/>
        <solution>
          <p>Yes, we can use coin tosses again with heads = top side down and tails = top side up. We want to use 8 tosses for each repetition and count how many heads we have.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="inv1-2-f" label="I1.2.6">
        <statement>
          <p>Use the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url> to carry out 1,000 repetitions of the simulation. Check the Summary Statistics box and report the mean and standard deviation of your simulated distribution of "could have been" outcomes.</p>
          <p>Mean: <var width="5"/> <br/>
          Standard deviation: <var width="5"/></p>
        </statement>
        <response/>
        <solution>
          <p>Example results:</p>
          <ul>
            <li>Histogram</li>
            <li>Description automatically generated with low confidence</li>
          </ul>
          <p>The mean number of heads is about 4 (half of 8) and the standard deviation of the number of heads is about 1.5.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="inv1-2-g" label="I1.2.7">
        <title>Evaluate Surprise Level</title>
        <statement>
          <p>Based on your simulation results, which assumes Yukon is guessing, should we be very surprised to see 6 correct guesses? Explain/support your reasoning.</p>
        </statement>
        <response/>
        <solution>
          <p>An outcome of 6 heads does not appear to be in the tail of the distribution.</p>
        </solution>
      </exercise>
      
      <paragraphs>
        <title>Measuring "Rareness"</title>
        
        <p>In Investigation 1.1, the observed result (14) was pretty far in the tail of the distribution and you probably agreed that we could consider it unusual. This result (6 out of 8) is not as inconsistent with the null hypothesis; so where do we "draw the line"? First, we need agree on a measure of "rareness." We could just calculate the theoretical probability of 6 heads in 8 tosses (0.1094), but keep in mind that if we have a larger sample size (e.g., 100 tosses), then any individual outcome (e.g., 62 heads) will have a small probability. So we want to judge how extreme our observation is relative to the other observations in the simulated distribution. One way to do this is to count how many outcomes are as or even more extreme (even further from the expected value) than the observed outcome. For example, if we tell you that only 1% of rattlesnakes are longer than 2.5 meters, then you know to be very surprised to see a 3-meter rattlesnake and you may even begin to think that what you are looking at is not a rattlesnake at all!</p>
        
        <exercise xml:id="inv1-2-h" label="I1.2.8">
          <title>Calculate P-value</title>
          <statement>
            <p>In the applet, enter 6 in the Count samples box and keep the "as extreme as" button to greater than or equal to, <m>\geq</m>. Report the proportion of the repetitions with 6 or more heads (correct choices).</p>
            <p>In 1,000 repetitions, assuming the probability of choosing correctly is 0.50, we found <var width="5"/> % of repetitions of 8 attempts to result in 6 or more successes.</p>
          </statement>
          <response/>
          <solution>
            <p>Results will vary but should be around 0.15, or 15% of repetitions resulting in 6 or more heads.</p>
          </solution>
        </exercise>
        
        <p>Notice that we consider the direction of the alternative hypothesis to help us determine which outcomes we consider "more extreme" than our observed outcome. This tail probability you found in (h) is referred to as the p-value.</p>
        
        <assemblage xml:id="def-pvalue-null-distribution">
          <title>Definition: Null Distribution and P-value</title>
          <p>Because the simulation assumes the null hypothesis to be true, we can refer to the distribution you simulated as the <term>null distribution</term><idx><h>null distribution</h><h>distribution assuming null hypothesis is true</h></idx>. When you determine the proportion of the results in the null distribution that are at least as extreme as the observed result, you are estimating a probability. We will refer to this probability as the <term>p-value</term><idx><h>p-value</h><h>probability of results as extreme as observed, assuming null hypothesis</h></idx>. We use the p-value to evaluate the strength of evidence against the null hypothesis.</p>
          
          <p>The smaller the p-value, the stronger the evidence against the null hypothesis. There are no hard-and-fast cut-off values for gauging the smallness of a p-value, but generally speaking:</p>
          <p><ul>
            <li><p>A p-value above 0.10 constitutes little or no evidence against the null hypothesis.</p></li>
            <li><p>A p-value below 0.10 but above 0.05 constitutes moderate evidence against the null hypothesis.</p></li>
            <li><p>A p-value below 0.05 but above 0.01 constitutes strong evidence against the null hypothesis.</p></li>
            <li><p>A p-value below 0.01 constitutes very strong evidence against the null hypothesis.</p></li>
          </ul></p>
        </assemblage>
        
        <exercise xml:id="inv1-2-i" label="I1.2.9">
          <title>Compare P-values</title>
          <statement>
            <p>Did everyone in your class obtain the same p-value? <em>(If not, are you surprised?)</em></p>
          </statement>
          <choices randomize="no">
            <choice>
              <statement>
                <p>Yes</p>
              </statement>
              <feedback>
                <p>Actually, because we're using simulation, each person's results will vary slightly.</p>
              </feedback>
            </choice>
            <choice correct="yes">
              <statement>
                <p>No</p>
              </statement>
              <feedback>
                <p>Correct! The p-value will vary slightly across simulations because of the random nature of the process.</p>
              </feedback>
            </choice>
          </choices>
          <solution>
            <p>No, the p-value will vary slightly across the simulations.</p>
          </solution>
        </exercise>
        
        <p>Because we are assuming a random process, we can use probability rules to calculate an "exact" value for the p-value. In fact, we have been assuming a very special random process, a binomial process.</p>
      </paragraphs>
      
      <paragraphs>
        <title>Probability Detour â€“ Binomial Random Variables</title>
        
        <assemblage xml:id="def-binomial-random-variable">
          <title>Definition: Binomial Random Variable</title>
          <p>A <term>Binomial random variable</term><idx><h>binomial random variable</h><h>counts successes in independent trials</h></idx> counts the number of successes in a random process with the following properties:</p>
          <p><ul>
            <li><p>Each trial results in either "success" or "failure" (we have a binary categorical variable).</p></li>
            <li><p>The trials are independent: The outcome of one trial does not change the probability of success on the next trial.</p></li>
            <li><p>The probability of success, <m>\pi</m>, is constant across the trials.</p></li>
            <li><p>There are a fixed number of trials, <m>n</m>.</p></li>
          </ul></p>
          
          <p>If the number of successes, <m>X</m>, is a binomial random variable, then we can say <m>X \sim \text{Binomial}(n, \pi)</m>.</p>
        </assemblage>
        
        <p>Because we are assuming the null hypothesis to be true, we are treating each attempt as an identical repetition of a random process with a probability of success of 0.50 for each attempt (always two containers to choose from), and one attempt outcome does not impact the probability of success on the next attempt (e.g., a screen was lowered between attempts and the location of the food randomized each time) so the attempts are independent. We are counting <m>X</m>, the observed number of correct choices in the <m>n = 8</m> trials. So <m>X \sim</m> (is distributed as) <m>\text{Binomial}(8, 0.50)</m> and we want to determine the probability of observing 6 or more successes in 8 attempts by chance alone, <m>P(X \geq 6)</m>. We will illustrate this calculation next, and then turn to technology to find binomial probabilities.</p>
        
        <paragraphs>
          <title>Calculating Binomial Probabilities</title>
          
          <exercise xml:id="inv1-2-j" label="I1.2.10">
            <title>Calculate Single Outcome Probability</title>
            <statement>
              <p>Let S represent Success and F represent Failure. Consider one particular outcome for the 8 trials with 6 successes: SSFSSSFS. Because we are assuming the trials are independent, we can find the probability of this event by multiplying together the probabilities of the individual outcomes in the event.</p>
              <p><md>
                <mrow>P(\text{SSFSSSFS}) \amp = P(S) \times P(S) \times P(F) \times P(S)</mrow>
                <mrow>\amp \quad \times P(S) \times P(S) \times P(F) \times P(S)</mrow>
              </md></p>
              <p>What is the calculated product? <var width="5"/></p>
            </statement>
            <response/>
            <solution>
              <p>0.58</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-k" label="I1.2.11">
            <title>Count Arrangements</title>
            <statement>
              <p>But there are other possible outcomes that would also result in 6 successes and 2 failures (for example, SFSSSSSF). How many ways are there to arrange the 6 successes among the 8 slots?</p>
              <p>This is where the binomial coefficient comes in handy. This <term>binomial coefficient</term><idx><h>binomial coefficient</h><h>counts ways to select k items from n</h></idx>, denoted by <m>C(n, k)</m> or <m>\binom{n}{k} = \frac{n!}{k!(n-k)!}</m>, counts the number of ways there are to select <m>k</m> items from a set of <m>n</m> items. In this case, we want to find the number of ways to select 6 spots from the 8 trials for the successes:</p>
              <p><me>C(8, 6) = \frac{8!}{6!2!}</me></p>
              <p>What is the calculated result? <var width="5"/></p>
            </statement>
            <response/>
            <solution>
              <p>28</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-l" label="I1.2.12">
            <title>Calculate Probability for 6 Successes</title>
            <statement>
              <p>Because the 28 outcomes corresponding to 6 successes are mutually exclusive (can't occur simultaneously), we can find the probability of at least one of them happening by adding all of the probabilities together:</p>
              <p><me>P(\text{SSFSSSFS}) + P(\text{SFSSSSSF}) + \ldots = 28 \times (0.5^8)</me></p>
              <p>What is the calculated product? <var width="5"/></p>
              <p>In general, the binomial probability of obtaining <m>k</m> successes in a sequence of <m>n</m> independent trials with success probability <m>\pi</m> on each trial is:</p>
              <p><me>P(X = k) = \binom{n}{k} \pi^k (1-\pi)^{n-k}</me></p>
              <p>where <m>\binom{n}{k} = \frac{n!}{k!(n-k)!}</m></p>
            </statement>
            <response/>
            <solution>
              <p>0.1094</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-m" label="I1.2.13">
            <title>Calculate Complete P-value</title>
            <statement>
              <p>Is the number you found in (l) our p-value for this study? If not, how would we find the p-value?</p>
            </statement>
            <response/>
            <solution>
              <p>No, so far we have found P(X = 6), but the p-value is defined as P(X &gt; 6).</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-n" label="I1.2.14">
            <statement>
              <p>In the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url>, check the Exact Binomial box. (Optional: See Technology Detour below.) How does the binomial distribution match up to your earlier simulation results? How does the binomial (or "exact") p-value compare to what you simulated earlier? Did everyone in class obtain the same "exact" p-value?</p>
            </statement>
            <response/>
            <solution>
              <p>0.1445. This should be similar to the simulation results and everyone would obtain the same calculated value.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-o" label="I1.2.15">
            <title>Interpret P-value</title>
            <statement>
              <p>Write a one-sentence interpretation of this p-value in this context. Key components to include: what random process is being repeated, what is the null hypothesis that we are assuming to be true, what is the observed result we are considering, which outcomes are we considering to be more extreme?</p>
            </statement>
            <response/>
            <solution>
              <p>If we were to repeatedly examine samples of 8 attempts from wolves who do not understand the communication cues, we would expect 6 or more wolves to pick the correct container for about 14% of those samples by chance alone.</p>
            </solution>
          </exercise>
        </paragraphs>
      </paragraphs>
      
      <paragraphs>
        <title>Conclusions</title>
        
        <exercise xml:id="inv1-2-p" label="I1.2.16">
          <title>State Conclusion</title>
          <statement>
            <p>Based on this analysis, do these data provide convincing evidence that wolves can understand behavioral cues?</p>
          </statement>
          <response/>
          <solution>
            <p>No, a p-value of 0.14 is not strong evidence against the null hypothesis. It is plausible that Yukon would do as well in 8 trials even if she didn't understand the cue and was simply guessing.</p>
          </solution>
        </exercise>
      </paragraphs>
      
      <assemblage xml:id="study-conclusions-1-2">
        <title>Study Conclusions</title>
        <p>If we assume Yukon is guessing between the two containers, regardless of the cue, then finding 6 or more successes in 8 trials is actually not very surprising (binomial p-value = 0.1445); about 14% of samples from a 50/50 process would show 6 or more successes in 8 trials. This does not provide convincing evidence that Yukon can perform "above chance," but there is not information about whether other wolves or other cues would show better performance.</p>
      </assemblage>
      
      <subsection xml:id="practice1-2A">
        <title>Practice Problem 1.2A</title>
        
        <p>When Yukon was given "communicative cues" (looking at the container, pointing to the container) instead of behavioral cues, she was correct in 7 out of 8 attempts. Does this outcome provide convincing evidence that wolves understand communicative cues?</p>
        
        <exercise xml:id="practice-1-2a-a" label="PP1.2A.1">
          <statement>
            <p>State the null and alternative hypotheses for this study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2a-b" label="PP1.2A.2">
          <statement>
            <p>Report both a simulation-based and the exact p-value. Include a one-sentence interpretation of the p-value in this context.</p>
            <p>Simulation-based p-value: <var width="5"/></p>
            <p>Exact p-value: <var width="5"/></p>
            <p>Interpretation: The probability of <var width="30"/> assuming <var width="30"/>.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2a-c" label="PP1.2A.3">
          <statement>
            <p>Summarize your analysis and the conclusions you would draw from this study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2a-d" label="PP1.2A.4">
          <statement>
            <p>Across the 12 wolves in the study, in the 64 trials with communicative cues, the wolves understood the cue 41 times. What is the new p-value for these results? Explain why this would not be an appropriate analysis.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-2B">
        <title>Practice Problem 1.2B</title>
        
        <p>A study in Psychonomic Bulletin and Review (<url href="https://psycnet.apa.org/record/2007-18366-015" target="_blank">Lea, Thomas, Lamkin, <ampersand/> Bell, 2007</url>) presented evidence that "people use facial prototypes when they encounter different names." Similar to one of the experiments they conducted, you will be asked to match photos of two faces to the names Tim and Bob. The researchers wrote that their participants "overwhelmingly agreed" on which face belonged to Tim. You will conduct a similar study in class to see whether your class also agrees with which face is Tim's more than you would expect from random chance (here "random chance" = there is no facial prototyping and people pick a name for the face on the left at random).</p>
        
        <exercise xml:id="practice-1-2b-a" label="PP1.2B.1">
          <statement>
            <p>What is the sample/random process and variable in this study? What assumptions are we making about this process?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2b-b" label="PP1.2B.2">
          <statement>
            <p>State the null and alternative hypotheses for this study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2b-c" label="PP1.2B.3">
          <statement>
            <p>Report the count, proportion, and percentage "correctly" identifying Tim's face in your class.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2b-d" label="PP1.2B.4">
          <statement>
            <p>Use the applet or the technology instructions below to obtain a binomial p-value. What do you conclude about the null hypothesis?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2b-e" label="PP1.2B.5">
          <statement>
            <p>Do you think the properties of the binomial random variable are met here? What assumptions need to be made?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <paragraphs xml:id="tech-detour-binomial">
        <title>Technology Detour â€“ Calculating Binomial Probabilities</title>
        
        <exercise xml:id="tech-detour-r-binomial" label="Binomial Probabilities - R">
          <title>Calculating Binomial Probabilities in R</title>
          <statement>
            <p>Make sure you have the ISCAM Workspace loaded.</p>
            <p>The <c>iscambinomprob</c> function takes the following inputs:</p>
            <p><ul>
              <li><p><c>k</c> = the observed value you want to calculate the probability about</p></li>
              <li><p><c>n</c> = the sample size of the binomial distribution</p></li>
              <li><p><c>prob</c> = the probability of success in the binomial distribution</p></li>
              <li><p><c>lower.tail</c> = TRUE if you want the probability less than or equal to the observed value, FALSE if want the probability greater than or equal to the observed value</p></li>
            </ul></p>
            
            <p>For the Friend or Foe study, in the Console at the prompt, type:</p>
            <program language="r" interactive="sage">
              <input>
iscambinomprob(k=14, n=16, prob=.5, lower.tail=FALSE)
              </input>
            </program>
            <p>or</p>
            <program language="r" interactive="sage">
              <input>
iscambinomprob(14, 16, .5, FALSE)
              </input>
            </program>
            <p>(Yes, "false" needs to be capitalized)</p>
            
            <p>You should see both the probability appear in the Console window and a shaded graph open in a separate Graphics window. (You may have to toggle windows to see this Graphics window.)</p>
            
            <note>
              <title>R Reminder</title>
              <p>The <c>iscambinomprob</c> function is part of the ISCAM package. Make sure to load the package first with <c>library(iscam)</c>. The <c>lower.tail</c> parameter controls the direction: FALSE gives you <m>P(X \geq k)</m>, TRUE gives you <m>P(X \leq k)</m>.</p>
            </note>
          </statement>
          <solution>
            <p>For the Friend or Foe study with 14 successes out of 16 trials, the binomial p-value should be very small (approximately 0.0021), indicating strong evidence against the null hypothesis that infants are choosing randomly between the two toys.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="tech-detour-jmp-binomial" label="Binomial Probabilities - JMP">
          <title>Calculating Binomial Probabilities in JMP</title>
          <statement>
            <p>Using the Distribution Calculator in the <url href="http://www.rossmanchance.com/iscam4/data/ISCAM_Journal.jrn" download="ISCAM_Journal.jrn" target="_blank">ISCAM Journal File</url> (Download this file to your computer and then open the .jrn file to launch JMP.)</p>
            <p><ol>
              <li><p>Select Binomial from the Distribution pull down menu.</p></li>
              <li><p>Specify the values of the probability of success (<m>\pi</m>) and n (the sample size).</p></li>
              <li><p>Leave the Type of Calculation as is.</p></li>
              <li><p>Select Probability Option <m>X \geq Q_a</m> but specify <m>Q_a</m> to equal <m>k-1</m> (e.g., 13).</p></li>
              <li><p>Press Enter.</p></li>
            </ol></p>
            
            <note>
              <title>JMP Reminder</title>
              <p>In JMP's Distribution Calculator, you need to subtract 1 from your observed value when using the <m>\geq</m> option because JMP calculates <m>P(X > Q_a)</m> as <m>P(X \geq Q_a + 1)</m>. So to get <m>P(X \geq 14)</m>, you enter 13 as <m>Q_a</m>.</p>
            </note>
          </statement>
          <solution>
            <p>The JMP Distribution Calculator will display both the probability value and a visual representation of the binomial distribution with the tail area shaded. For finding <m>P(X \geq 14)</m> when <m>n=16</m> and <m>\pi=0.5</m>, enter 13 for <m>Q_a</m> to get the correct p-value of approximately 0.0021.</p>
          </solution>
        </exercise>
      </paragraphs>
    </subsection>
    
    <subsection xml:id="investigation-1-3">
      <title>Investigation 1.3: Are You Clairvoyant?</title>
      
      <introduction>
        <p>A standard test for extra-sensory perception (ESP) asks subjects to identify which of five symbols (e.g., circle, plus, square, diamond, waves) is on the front of a card, viewed by the experimenter but not the subject. The experimenter concentrates on the symbol and a <q>hit</q> is when the subject correctly identifies the symbol being viewed by the experimenter. The subject is given several trials, with the viewed symbol randomly determined for each of the trials, with no discernible pattern.</p>
        
        <figure xml:id="fig-esp-cards">
          <caption>ESP Test Symbols</caption>
          <image source="esp.png" width="60%">
            <description>Five ESP test symbols: circle, plus sign, square, diamond, and wavy lines</description>
          </image>
        </figure>
      </introduction>
      
      <p>Online tests are available as well. Go to <url href="http://www.psychicscience.org/esp3.aspx" target="_blank">www.psychicscience.org/esp3.aspx</url> to test your clairvoyance (predicting what's about to happen rather than reading what someone else is thinking). Scroll down to Advanced ESP Test and review the 5 possible symbols, then press Start. Click on the card that you believe is about to be shown. Repeat for 10 rounds, keeping tracking of the number of hits in your first 10 attempts.</p>
      
      <exercise xml:id="I1-3-1" label="I1.3.1">
        <title>Conduct the ESP Test</title>
        <statement>
          <p>How many hits did you get? <var width="10" /></p>
        </statement>
      </exercise>
      
      <exercise xml:id="I1-3-2" label="I1.3.2">
        <title>Identify Sample and Variable</title>
        <statement>
          <p>Identify the sample and variable for this random process.</p>
        </statement>
        <response/>
        <hint>
          <p>What is the sample size? What was measured about each observation?</p>
        </hint>
        <solution>
          <p>The random process is the repeated attempts to identify the symbol correctly. The sample size is the 10 trials. Variable = correct/incorrect identification (categorical). The sample size is 10.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-3" label="I1.3.3">
        <title>Binomial Random Process</title>
        <statement>
          <p>Do you consider it reasonable to model your observations as coming from a binomial random process? Explain your reasoning.</p>
        </statement>
        <response/>
        <hint>
          <p>Consider the four conditions for a binomial process: two outcomes, independence, fixed number of trials, and constant probability.</p>
        </hint>
        <solution>
          <p>If the target symbols are randomly selected (equally likely), the student uses the same method each time, and the student is not more likely to correctly identify some symbols more than others (e.g., guessing each time) then a binomial process does seem reasonable.</p>
        </solution>
      </exercise>
      
      <assemblage xml:id="terminology-statistic-parameter">
        <title>Terminology Detour: Statistic vs. Parameter</title>
        
        <p>In analyzing data, it is important to differentiate between a <term>statistic</term> and the <term>parameter</term>. The observed statistic is a (known) numerical value that summarizes the observed results, whereas the parameter is the same numerical summary but applied to the underlying random process that generated the data. The value of the statistic is what we observe in the study, whereas the value of the parameter is rarely known.</p>
        
        <p>In Investigation 1.1, the statistic could be either the number (14) or the proportion (0.875) of infants who chose the helper toy. The parameter would then be the long-run probability of an infant picking the helper toy. In the case of a binomial random variable, we will use the symbol <m>\pi</m> (lower case Greek letter for <q>p</q>) to represent this unknown process probability.</p>
      </assemblage>
      
      <exercise xml:id="I1-3-4" label="I1.3.4">
        <title>Identify the Parameter</title>
        <statement>
          <p>Identify (in words) the parameter of interest for this study.</p>
        </statement>
        <response/>
        <hint>
          <p>A parameter describes a long-run probability or proportion for the entire process, not just your sample result.</p>
        </hint>
        <solution>
          <p>The parameter is your probability of correct identification (the long-run probability of correctly identifying the symbol).</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-4b" label="I1.3.4b">
        <title>Parameter Symbol</title>
        <statement>
          <p>What symbol will we use to represent this parameter?</p>
        </statement>
        <hint>
          <p>Look for the Greek letter used for a process probability in a binomial distribution.</p>
        </hint>
        <choices randomize="no">
          <choice>
            <statement><p><m>\hat{p}</m></p></statement>
            <feedback><p>This is the symbol for the sample proportion (statistic), not the population parameter.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p><m>\pi</m></p></statement>
            <feedback><p>Correct! We use <m>\pi</m> to represent the probability of success in a binomial process.</p></feedback>
          </choice>
          <choice>
            <statement><p><m>\mu</m></p></statement>
            <feedback><p>This is the symbol for a population mean, not a probability.</p></feedback>
          </choice>
          <choice>
            <statement><p><em>p</em></p></statement>
            <feedback><p>While <em>p</em> is sometimes used for probability, we use the Greek letter <m>\pi</m> for the process probability parameter.</p></feedback>
          </choice>
        </choices>
        <solution>
          <p>We use <m>\pi</m> to represent your probability of correct identification.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-5" label="I1.3.5">
        <title>State the Null Hypothesis</title>
        <statement>
          <p>The null hypothesis is that you aren't clairvoyant and are guessing every time. State this as a null hypothesis using symbols and words.</p>
          <p><em>Tip: Type "pi" for the Greek letter. Format as: H_0: pi = value</em></p>
        </statement>
        <response/>
        <hint>
          <p>If guessing randomly among 5 symbols, what is the probability of guessing correctly?</p>
        </hint>
        <solution>
          <p><m>H_0: \pi = 0.20</m> (you have a 1 in 5 chance of guessing correctly)</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-6" label="I1.3.6">
        <title>State the Alternative Hypothesis</title>
        <statement>
          <p>State the alternative hypothesis using symbols and words.</p>
          <p><em>Tip: Type "pi" for the Greek letter. Use greater than, less than, or not equal to. Format as: H_a: pi &gt; value</em></p>
          <aside>
            <p>Notice that the hypothesized values for <m>\pi</m> in the null and alternative can't <q>overlap;</q> they are competing statements about <m>\pi</m>.</p>
          </aside>
        </statement>
        <response/>
        <hint>
          <p>If you are clairvoyant, would your probability of correct identification be higher or lower than random guessing?</p>
        </hint>
        <solution>
          <p><m>H_a: \pi > 0.20</m> (you have a higher probability of predicting correctly)</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-7" label="I1.3.7">
          <title>Simulation Method</title>
          <statement>
            <p>Assume the null hypothesis is true and let the random variable <m>C</m> denote the number of correct identifications (hits) in 10 attempts. If we were to simulate this random process, could we toss coins? If not, suggest another way we could generate simulated results assuming the null hypothesis to be true. (e.g., what would you want an applet to do?)</p>
          </statement>
          <response/>
          <hint>
            <p>Coin tosses give 50/50 probability. Does your null hypothesis assume 50% chance of success?</p>
          </hint>
          <solution>
            <p>We can model <m>C</m> with the binomial distribution:</p>
            <p><ul>
              <li><p>Each trial has two outcomes: correct match or not</p></li>
              <li><p>The trials are independent (the cards are shuffled in between attempts and the symbols are placed at random with no patterns from trial to trial)</p></li>
              <li><p>There are a fixed number of attempts (<m>n = 10</m>)</p></li>
              <li><p>The probability of success (if someone is guessing) is the same for each trial (<m>= 0.20</m> if using 5 cards each trial). We aren't changing the number of cards or anything else from trial-to-trial.</p></li>
            </ul></p>
            <p>We can't toss a coin because we are not assuming 50/50 for success/failure. To model 0.20 we could use spinners.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-3-8" label="Null distribution predictions">
          <title>Null Distribution Predictions</title>
          <statement>
            <p>Where do you think your null distribution will be centered? What are the largest and smallest possible values for the number of correct identifications in 10 attempts? What are the largest and smallest values you think you will see in the simulation?</p>
          </statement>
          <response/>
          <hint>
            <p>Use the probability from the null hypothesis times the number of attempts to find the expected value.</p>
          </hint>
          <solution>
            <p>On average, if someone is guessing, we would <q>expect</q> to see <m>\frac{1}{5}(10) = 2</m> correct answers (in the long run). <m>E(C) = 10(0.20) = 2</m> if assuming 5 cards.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-3-9" label="Applet simulation">
          <title>Carry Out the Simulation</title>
          <statement>
            <p>In the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url>, specify the values for <m>\pi</m> and <m>n</m>. Carry out one repetition of the simulation. Explain the simulation process in your own words.</p>
          </statement>
          <response/>
          <hint>
            <p>Set pi to your null hypothesis value and n to the number of attempts you made.</p>
          </hint>
          <solution>
            <p>Results will vary. The applet should generate 10 spinners (each a 0.20 probability of success = landing in the blue region) and then record the number of successes in those 10 spins.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-3-10" label="Theoretical mean SD">
          <title>Theoretical Mean and Standard Deviation</title>
          <statement>
            <p>Then check the Exact Binomial box to see the null distribution after infinitely many repetitions. Press the Reset button to remove the one simulated result and check the Summary Statistics box. What are the theoretical values for the mean and standard deviation of the null distribution?</p>
            
            <p>Mean = <var width="5" /></p>
            <p>Std Dev = <var width="5" /></p>
          </statement>
          <response/>
          <hint>
            <p>Look for the values displayed in the Summary Statistics section of the applet after pressing Reset.</p>
          </hint>
          <solution>
            <p>After pressing Reset to remove the one simulated trial, you should find Mean = 2.000, SD = 1.265.</p>
          </solution>
        </exercise>
        
        <assemblage xml:id="binomial-formulas">
          <title>Binomial Distribution Formulas</title>
          <p>It can be shown that when <m>X</m> is Binomial(<m>n</m>, <m>\pi</m>), the expected value is <m>E(X) = n \times \pi</m> and the variance is <m>V(X) = n\pi(1 - \pi)</m>. (See Exploration B for more discussion of expected value and variance of a random variable.)</p>
        </assemblage>
        
        <exercise xml:id="I1-3-11" label="Verify calculations">
          <title>Verify the Calculations</title>
          <statement>
            <p>Verify these calculations match the applet output and remember that the standard deviation is the square root of the variance.</p>
          </statement>
          <response/>
          <hint>
            <p>Use the formulas provided in the previous question with n=10 and pi=0.20.</p>
          </hint>
          <solution>
            <p><m>E(C) = 10(0.2) = 2.00</m> and <m>SD(C) = \sqrt{10 \times 0.2 \times 0.8} = 1.265</m>.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-3-12" label="Result in tail">
          <title>Result in the Tail?</title>
          <statement>
            <p>Was your statistic from Checkpoint 3.77 (your number of hits) in the direction specified by the alternative hypothesis? If it was, is it in one of the tails (outer edges) of the null distribution from Checkpoint 3.86?</p>
          </statement>
          <response/>
          <hint>
            <p>Compare your number of hits to the mean of the distribution. Is it larger (right tail) or smaller (left tail)?</p>
          </hint>
          <solution>
            <p>Results will vary, but quite possible your results were below the expected value.</p>
          </solution>
        </exercise>
      
      <p>If your observed number of successes was below the mean, then you can conclude that your data do not provide evidence in favor of the alternative hypothesis and you should not start your own psychic hotline! But if your result was above the mean, then we would like to measure the strength of evidence against the null hypothesis. You have already seen how to do that using a p-value.</p>
      
      <exercise xml:id="I1-3-13" label="I1.3.13">
        <title>Explore p-value Threshold</title>
        <statement>
          <p>Use the applet to explore how many hits a subject would need in 10 attempts for the p-value to be below 0.05.</p>
        </statement>
        <response/>
        <hint>
          <p>Use your mouse to drag the red line.</p>
        </hint>
        <solution>
          <p>A subject would need at least 5 hits in 10 attempts for the p-value to be below 0.05 (specifically, P(X â‰¥ 5) = 0.0328).</p>
        </solution>
      </exercise>
      
      <paragraphs xml:id="alternative-measure-rareness">
        <title>An Alternative Measure of Rareness</title>
        
        <p>As an alternative to the p-value, another measure of where an observation falls in a distribution is <q>how many standard deviations</q> it is from the mean of the distribution.</p>
        
        <figure xml:id="fig-ruler">
          <caption>A number line showing distances from the null hypothesis mean</caption>
          <image source="images/ruler2.png" width="50%">
            <description>A ruler or number line showing the distance scale for evaluating deviations from the hypothesized mean.</description>
          </image>
        </figure>
        
        <p><me>\frac{\text{observed number of hits} - \text{expected value}}{\text{standard deviation}} </me></p>
        
        <exercise xml:id="I1-3-14" label="I1.3.14">
          <title>Standardize Your Result</title>
          <statement>
            <p>How many standard deviations was your observed result from the expected value for the binomial distribution?</p>
          </statement>
          <response/>
          <hint>
            <p>Use the formula: (observed - expected) / standard deviation. Substitute your number of hits for observed, and use the mean and SD from Checkpoint 3.86.</p>
          </hint>
          <solution>
            <p>The standardized statistic expresses the distance in <q>standard deviations away</q> from the hypothesized value of <m>\pi</m>. A negative value means the distance is below the mean; a positive value means the distance is above the mean.</p>
          </solution>
        </exercise>
        
        <p>This calculation is often referred to as <term>standardizing the statistic</term>.</p>
        
        <p>Again, there are no hard and fast rules for what constitutes a large value here, but generally, when we have a fairly symmetric distribution, values more than 2 standard deviations above or below the expected value (mean) are considered extreme.</p>
      </paragraphs>
        
        <exercise xml:id="I1-3-15" label="I1.3.15">
            <title>Standardizing 5 Hits</title>
            <statement>
              <p>How many standard deviations from the mean (expected value) would 5 hits be?</p>
            </statement>
            <response/>
            <hint>
              <p>Use the same formula as the previous question: (5 - 2) / 1.265. What does this value tell you?</p>
            </hint>
            <solution>
              <p>A standardized statistic of 1 means that the sample result is one standard deviation above the mean of 2. Because the SD is 1.265, 1 SD above the mean is at <m>2 + 1.265 = 3.265</m>. Rounding to the nearest whole number, that would correspond to 3 correct identifications. (Or you could solve: <m>(x - 2)/1.265 = 1</m> to find <m>x = 3.265</m>.)</p>
            </solution>
          </exercise>
          
          <exercise xml:id="I1-3-16" label="I1.3.16">
            <title>Distribution for 25 Attempts</title>
            <statement>
              <p>Suppose you don't know whether or not someone is clairvoyant and you plan to give the person 25 attempts. What are the theoretical expected number and standard deviation for the random variable <m>C</m>, the number of hits when <m>n = 25</m> assuming they are just guessing each time? How do they compare to the values you found in (j)?</p>
            </statement>
            <response/>
            <hint>
              <p>Use the binomial formulas with n = 25 and pi = 0.20. Expected value = n Ã— pi, and SD = square root of n Ã— pi Ã— (1 - pi).</p>
            </hint>
            <solution>
              <p>Expected value = <m>5</m>, SD = <m>2</m></p>
              <p>Note: You can check these in the applet. Because the value of <m>n</m> has changed, both have increased. The larger the sample size, the more variability in the distribution.</p>
            </solution>
          </exercise>
          
          <p>How many hits would someone need to get correct in 25 attempts to convince you they aren't simply guessing? Let's consider two ways to decide.</p>
          
          <exercise xml:id="I1-3-17" label="I1.3.17">
            <title>Approach 1: P-value Threshold</title>
            <statement>
              <p><alert>Approach 1:</alert> What value for <m>c</m> would give you a probability below 0.05 of obtaining that many or more hits? In other words, what is the smallest value of <m>c</m> so <m>P(C \geq c) &lt; 0.05</m>?</p>
            </statement>
            <response/>
            <hint>
              <p>Use the applet to find probabilities for different values of c.</p>
            </hint>
            <solution>
              <p>We need to find <m>c</m> such that <m>P(C \geq c) &lt; 0.05</m>. Using the applet:
                <ul>
                  <li><p><m>P(C \geq 8) = 0.109</m> (too large)</p></li>
                  <li><p><m>P(C \geq 9) = 0.048</m> (this will work!)</p></li>
                </ul>
              So if someone had 9 or more correct, we might choose to consider that statistically significant.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="I1-3-17b" label="I1.3.17b">
            <title>Approach 2: Standard Deviations</title>
            <statement>
              <p><alert>Approach 2:</alert> What is the smallest value of <m>c</m> that is at least 2 standard deviations from the expected value?</p>
            </statement>
            <response/>
            <hint>
              <p>Use the expected value and standard deviation from Checkpoint 3.93.</p>
            </hint>
            <solution>
              <p>The observed value would need to be more than <m>5 + 2(2) = 9</m>.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="I1-3-18" label="Compare approaches">
            <title>Compare the Two Approaches</title>
            <statement>
              <p>How do your answers for these two approaches compare?</p>
            </statement>
            <response/>
            <hint>
              <p>Look at the values of c you found in both approaches. Are they the same or very close? What does this suggest about the relationship between p-values and standard deviations?</p>
            </hint>
            <solution>
              <p>It is not a coincidence that the value of 9 appears in both and is close to the expected value + 2 SD. It turns out that with a <q>large enough</q> sample size, if a standardized statistic is about 2 SD from the mean, the p-value will be close to 0.05. We will develop this idea much more carefully when we turn to the normal approximation to the binomial.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="I1-3-19" label="Four symbols">
            <title>Test with Four Symbols</title>
            <statement>
              <p>Suppose you changed the test to use only 4 symbols. Does this change the expected number or standard deviation for the number of hits when a subject is guessing? How many would someone need to identify correctly to convince you they could perform better than guessing in the long-run?</p>
            </statement>
            <response/>
            <hint>
              <p>With 4 symbols, the probability of guessing correctly changes to 1/4 = 0.25. Recalculate the expected value and SD using this new probability, then find how many hits would be 2 SD above the mean.</p>
            </hint>
            <solution>
              <p>This would increase the probability of a correct guess to 0.25, and so the probability model would need to change as well. If there are only 4 cards, the probability of a correct guess increases to 0.25. So, with 25 attempts, the expected value would be <m>25(0.25) = 6.25</m> with an SD of <m>\sqrt{25(0.25)(0.75)} = 2.17</m>. So <m>6.25 + 2(2.17) = 10.59 \approx 11</m>. Notice that this <q>cutoff</q> value went up (10 or 11 vs. 9). This is because guessing is more likely to do well so we need more evidence that someone is not guessing. Also, using the applet, <m>P(C \geq 10) = 0.097</m> and <m>P(C \geq 11) = 0.044</m>.</p>
            </solution>
          </exercise>
      
      <paragraphs xml:id="investigation-1-3-summary">
        <title>Summary</title>
        
        <p>The number of correct answers in 25 attempts, for someone who is guessing, can be modeled with a binomial distribution (assuming the probability of a correct answer is 0.20 each time and there is no pattern from attempt to attempt). In this case, the hypothesized value for the probability of <q>success</q> will be 0.20 rather than 0.5 due to the five cards to choose from, which we could model with spinners rather than coin tosses. If someone is simply guessing, in the long run they will guess correctly by chance alone 20% of the time. This means that if we give someone 25 attempts, we expect them to answer correctly <m>0.20 \times 25 = 5</m> times (on average, in the long run), with a standard deviation of <m>\sqrt{25(0.20)(0.80)} = 2</m> hits in 25 attempts. Keep in mind that the <q>statistical significance</q> of an outcome will depend on both the mean and the standard deviation of the null distribution. In this case, someone would need 9 or more hits to be more than 2 standard deviations above the mean, which corresponds to a p-value of 0.048. (It is not a coincidence that the 0.05 cut-off gives very similar results to the 2SD cut-off.)</p>
      </paragraphs>
      
      <subsection xml:id="practice1-3A">
        <title>Practice Problem 1.3A</title>
        
        <exercise xml:id="PP1-3A-1" label="PP1.3A.1">
          <title>Six Symbols: Distribution Changes</title>
          <statement>
            <p>Suppose the test had consisted of 6 symbols instead of 5 (with <m>n = 25</m> still). How will that change the binomial distribution? [You should comment on both the mean and the standard deviation.]</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3A-2" label="PP1.3A.2">
          <title>Six Symbols: Surprising Outcome</title>
          <statement>
            <p>Would an outcome of 9 correct guesses be more or less surprising in this case (vs. 5 symbols)?</p>
            <p><ul>
              <li><p>Will the probability of 9 or more correct identifications be larger or smaller than with 5 symbols?</p></li>
              <li><p>Will the outcome of 9 be more or fewer standard deviations from the mean than with 5 symbols?</p></li>
            </ul></p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3A-3" label="PP1.3A.3">
          <title>Ten Symbols</title>
          <statement>
            <p>What about 10 symbols? What are the mean and standard deviation of the binomial distribution? Would an outcome of 9 or more correct identifications be more or less surprising than with 5 symbols?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3A-4" label="PP1.3A.4">
          <title>Shape of Distribution</title>
          <statement>
            <p>How does the shape of the binomial distribution change as you lower <m>\pi</m>? Explain why.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-3B">
        <title>Practice Problem 1.3B</title>
        
        <p>Return to the wolf (Yukon). In another study, Yukon correctly understood a communicative cue in 7 of 8 attempts.</p>
        
        <exercise xml:id="PP1-3B-1" label="PP1.3B.1">
          <title>Parameter and Statistic</title>
          <statement>
            <p>Identify (in words) the parameter and statistic in that study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3B-2" label="PP1.3B.2">
          <title>Standardized Result</title>
          <statement>
            <p>How many standard deviations did the observed statistic fall above the expected value assuming Yukon picks equally between the two containers regardless of the cue in the long run?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3B-3" label="PP1.3B.3">
          <title>Surprising Outcome?</title>
          <statement>
            <p>Would her performance be considered a surprising outcome when the null hypothesis is true? Explain.</p>
          </statement>
          <response/>
        </exercise>
        
        <p>Return to the infants choosing a helper toy over a hinderer toy 14 times out of 16 choices.</p>
        
        <exercise xml:id="PP1-3B-4" label="PP1.3B.4">
          <title>Infant Study: Parameter and Statistic</title>
          <statement>
            <p>Identify (in words) the parameter and statistic in that study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3B-5" label="PP1.3B.5">
          <title>Infant Study: Standardized Result</title>
          <statement>
            <p>How many standard deviations did the observed statistic fall above the expected value assuming infants choose equally between the two types of toys?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3B-6" label="PP1.3B.6">
          <title>Infant Study: Time Variable</title>
          <statement>
            <p>In the infant study, researchers also looked at the amount of time the infants spent watching the two videos (to see whether one captured their attention more than the other). Identify a possible parameter of interest for this new variable.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-3C">
        <title>Practice Problem 1.3C</title>
        
        <p>Suppose you select 100 students at your school to estimate the proportion who prefer Coke to Pepsi.</p>
        
        <exercise xml:id="PP1-3C-1" label="PP1.3C.1">
          <title>Random Process</title>
          <statement>
            <p>Identify the <em>random process</em> of interest.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3C-2" label="PP1.3C.2">
          <title>The Sample</title>
          <statement>
            <p>Identify the <em>sample</em> in the study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3C-3" label="PP1.3C.3">
          <title>Parameter of Interest</title>
          <statement>
            <p>Define the <em>parameter of interest</em> in the study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3C-4" label="PP1.3C.4">
          <title>The Statistic</title>
          <statement>
            <p>Define the <em>statistic</em> in the study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3C-5" label="PP1.3C.5">
          <title>Average Number of States</title>
          <statement>
            <p>Suppose you want to estimate the average number of states visited by students at your school. Define the parameter of interest.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
    
    <subsection xml:id="investigation-1-4">
      <title>Investigation 1.4: Heart Transplant Mortality</title>
      
      <p>Poloneicki, Sismanidis, Bland, and Jones (<url href="https://pubmed.ncbi.nlm.nih.gov/14751918/">2004</url>) reported that in September 2000 heart transplantation at St. George's Hospital in London was suspended because of concern that more patients were dying than previously. Newspapers reported that the 80% mortality rate in the last 10 cases was of particular concern because it was over five times the national average. The variable measured was whether or not the patient died within 30 days of the transplant. Although there was not an officially reported national mortality rate (probability of death within 30 days for patients undergoing this procedure), the researchers determined that 15% was a reasonable benchmark for comparison.</p>
      
      <exercise xml:id="I1-4-1" label="I1.4.1">
        <title>Define Sample and Variable</title>
        <statement>
          <p>Define the sample random process and variable for this study. Is the variable quantitative or categorical?</p>
          <p>Sample/Random process: <var width="50" /></p>
          <p>Variable: <var width="50" /></p>
          <p>Type: <var width="20" /></p>
        </statement>
        <response/>
        <hint>
          <p>Think about what is being observed repeatedly and what outcome is being measured for each observation.</p>
        </hint>
        <solution>
          <p>Sample/Random process: The 10 most recent heart transplantation surgeries at St. George's Hospital (or more generally, heart transplantation surgeries at this hospital, across all the patients)</p>
          <p>Variable: Whether or not the patient died within 30 days of the transplant</p>
          <p>Type: Categorical (binary)</p>
          <p>Note: We define "success" as death within 30 days (could be either death or survival, but this matches the 15% parameter), and "failure" as survival.</p>
        </solution>
      </exercise>
      
      <p>We need to consider which outcome we will consider "success" and which we will consider "failure." The choice is often arbitrary, though sometimes we may want to focus on the more unusual outcome as success. In fact, in many epidemiology studies, "death" is typically the outcome of interest or "success."</p>
      
      <exercise xml:id="I1-4-2" label="I1.4.2">
        <title>Define Parameter</title>
        <statement>
          <p>Considering death within 30 days as a success, define the parameter of interest in this study (in words).</p>
          <p>Parameter: <var width="50" /></p>
        </statement>
        <response/>
        <hint>
          <p>What long-run proportion or probability are we interested in?</p>
        </hint>
        <solution>
          <p>Parameter: The underlying probability of death within 30 days of transplant at this hospital.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-2b" label="I1.4.2b">
        <title>Parameter Symbol</title>
        <statement>
          <p>What symbol should we use to represent this parameter?</p>
        </statement>
        <hint>
          <p>Look for the Greek letter used for a process probability in a binomial distribution.</p>
        </hint>
        <choices randomize="no">
          <choice>
            <statement><p><m>\hat{p}</m></p></statement>
            <feedback><p>This is the symbol for the sample proportion (statistic), not the population parameter.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p><m>\pi</m></p></statement>
            <feedback><p>Correct! We use <m>\pi</m> to represent the probability of success in a binomial process.</p></feedback>
          </choice>
          <choice>
            <statement><p><m>\mu</m></p></statement>
            <feedback><p>This is the symbol for a population mean, not a probability.</p></feedback>
          </choice>
          <choice>
            <statement><p><m>p</m></p></statement>
            <feedback><p>While <em>p</em> is sometimes used for probability, we use the Greek letter <m>\pi</m> for the process probability parameter.</p></feedback>
          </choice>
        </choices>
        <solution>
          <p>We use <m>\pi</m> to represent the probability of death within 30 days.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-2c" label="I1.4.2c">
        <title>Check Binomial Process</title>
        <statement>
          <p>Is it reasonable to model this heart transplantation process as a binomial process?</p>
        </statement>
        <response/>
        <hint>
          <p>Check the four conditions for a binomial process: two outcomes, fixed number of trials, independence, and constant probability.</p>
        </hint>
        <solution>
          <p>Yes, this is a binomial process if we assume the transplants are independent and the probability of death is the same for each transplant patient.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-3" label="I1.4.3">
        <title>Nothing Unusual Implication</title>
        <statement>
          <p>If there is nothing unusual about the mortality rate for heart transplantations at this hospital (compared to other U.K. hospitals), what does this imply about the value of the probability of "success"?</p>
          <p><m>\pi</m> <var width="5" /> <var width="10" /></p>
        </statement>
        <setup>
          <var>
            <condition string="^\s*=\s*$">
              <feedback>
                <p>Correct! If nothing is unusual, Ï€ equals the benchmark.</p>
              </feedback>
            </condition>
            <condition string="^\s*&lt;\s*$">
              <feedback>
                <p>Not quite. If nothing is unusual, the rate should match the benchmark, not be less than it.</p>
              </feedback>
            </condition>
            <condition string="^\s*>\s*$">
              <feedback>
                <p>Not quite. If nothing is unusual, the rate should match the benchmark, not be greater than it.</p>
              </feedback>
            </condition>
          </var>
          <var>
            <condition number="0.15">
              <feedback>
                <p>Correct! The benchmark is 0.15 (15%).</p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>What was stated as the reasonable benchmark for comparison?</p>
              </feedback>
            </condition>
          </var>
        </setup>
        <hint>
          <p>What was stated as the reasonable benchmark for comparison?</p>
        </hint>
        <solution>
          <p><m>\pi = 0.15</m></p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-4" label="I1.4.4">
        <title>Higher Rate Implication</title>
        <statement>
          <p>If the patients at this hospital are indeed dying at a higher rate than the benchmark rate, what does this imply about the value of the probability of "success"?</p>
          <p><m>\pi</m> <var width="5" /> <var width="10" /></p>
        </statement>
        <setup>
          <var>
            <condition string="^\s*>\s*$">
              <feedback>
                <p>Correct! A higher rate means Ï€ is greater than the benchmark.</p>
              </feedback>
            </condition>
            <condition string="^\s*=\s*$">
              <feedback>
                <p>Not quite. If the rate is higher, Ï€ should be greater than the benchmark, not equal to it.</p>
              </feedback>
            </condition>
            <condition string="^\s*&lt;\s*$">
              <feedback>
                <p>Not quite. If the rate is higher, Ï€ should be greater than the benchmark, not less than it.</p>
              </feedback>
            </condition>
          </var>
          <var>
            <condition number="0.15">
              <feedback>
                <p>Correct! The benchmark is 0.15 (15%).</p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>What is the benchmark rate?</p>
              </feedback>
            </condition>
          </var>
        </setup>
        <hint>
          <p>If the rate is higher than 15%, what inequality would describe <m>\pi</m>?</p>
        </hint>
        <solution>
          <p><m>\pi > 0.15</m></p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-5" label="I1.4.5">
        <title>State Hypotheses</title>
        <statement>
          <p>Translate your answers to the previous questions to null and alternative hypothesis statements. Keep in mind, the null hypothesis claims the observed result is "just by chance," whereas the alternative hypothesis translates the research conjecture.</p>
          <p>Match each hypothesis type with the correct statement:</p>
        </statement>
        <matches>
          <match order="1">
            <premise>Alternative Hypothesis (<m>H_a</m>)</premise>
            <response><m>\pi > 0.15</m> (the death rate at St. George's is larger than the national average)</response>
          </match>
          <match order="2">
            <premise>Null Hypothesis (<m>H_0</m>)</premise>
            <response><m>\pi = 0.15</m> (the death rate at St. George's is the same as the national average)</response>
          </match>
        </matches>
        <hint>
          <p>The null hypothesis typically states equality, while the alternative states the direction of the research suspicion.</p>
        </hint>
      </exercise>
      
      <exercise xml:id="I1-4-6" label="I1.4.6">
        <title>Direction of Sample Result</title>
        <statement>
          <p>Of the hospital's ten most recent transplantations at the time of the study, there had been eight deaths within the first 30 days following surgery. Is this sample result in the direction suspected by the researchers? Explain.</p>
        </statement>
        <response/>
        <hint>
          <p>Compare 8/10 = 0.80 to the benchmark of 0.15.</p>
        </hint>
        <solution>
          <p><m>\hat{p} = 8/10 = 0.8</m></p>
          <p>Since 0.8 > 0.15, yes, the result is in the conjectured direction.</p>
        </solution>
      </exercise>
      
      <p>You could use the One Proportion Inference applet to use simulation or the binomial distribution to find the p-value. Many statistical software packages will carry out a "Binomial test" directly.</p>
      
      <paragraphs xml:id="tech-detour-binomial-test">
        <title>Technology Detour â€“ Binomial Test of Significance</title>
        
        <exercise xml:id="tech-detour-r-binomtest" label="Binomial Test - R">
          <title>Conducting a Binomial Test in R (Summarized Data)</title>
          <statement>
            <p>The <c>iscambinomtest</c> function from the ISCAM package takes the following inputs:</p>
            <p><ul>
              <li><p><c>observed</c> = Observed number of successes or proportion of successes</p>
                <p>With a data vector, can first determine number of successes, e.g., <c>table(NamesData)</c></p>
                <p>If you enter a value less than one, it will assume you entered the proportion</p></li>
              <li><p><c>n</c> = Number of trials (sample size)</p></li>
              <li><p><c>hypothesized</c> = Hypothesized probability</p></li>
              <li><p><c>alternative</c> = Direction of alternative (e.g., "greater" or "less" or "two.sided")</p></li>
            </ul></p>
            
            <p>For the Friend or Foe study, using the command (with or without input labels):</p>
            <program language="r" interactive="sage">
              <input>
iscambinomtest(observed=14, n=16, hyp=.5, alt="greater")
              </input>
            </program>
            
            <p>should show output in the Console window as well as a graph of the binomial distribution with the p-value shaded in the Graphics window.</p>
            
            <note>
              <title>R Reminder</title>
              <p>Make sure to load the ISCAM package first with <c>library(iscam)</c>.</p>
            </note>
          </statement>
          <solution>
            <p>The output will show:</p>
            <ul>
              <li><p>The observed number of successes (8) and sample size (10)</p></li>
              <li><p>The hypothesized probability (0.15)</p></li>
              <li><p>The p-value: P(X â‰¥ 8) = 0.00000866 (or 8.665 Ã— 10<m>^{-6}</m>)</p></li>
              <li><p>A graph showing the binomial distribution with the upper tail shaded</p></li>
            </ul>
          </solution>
        </exercise>
        
        <exercise xml:id="tech-detour-jmp-binomtest" label="Binomial Test - JMP">
          <title>Conducting a Binomial Test in JMP</title>
          <statement>
            <p>Using the Distribution Calculator in the <url href="http://www.rossmanchance.com/iscam4/data/ISCAM_Journal.jrn" download="ISCAM_Journal.jrn" target="_blank">ISCAM Journal File</url> (Download this file to your computer and then open the .jrn file to launch JMP.)</p>
            
            <p><ul>
              <li><p>Choose Analyze > Distribution</p>
                <p><ul>
                  <li><p><em>With raw data</em>, drag the variable to the Y, Columns slot. Press OK.</p></li>
                  <li><p><em>With summarized data</em>, move the column with the category names to the Y, columns slot and move the column with the counts to the Freq slot. Press OK.</p></li>
                </ul></p>
              </li>
              <li><p>From the variable's hot spot, select <term>Test Probabilities</term>.</p></li>
              <li><p>Specify the hypothesized probability of success for the category you want to define as success (only).</p></li>
              <li><p>Then pick a one-sided alternative hypothesis (greater than or less than).</p></li>
            </ul></p>
            
            <sidebyside widths="45% 50%" margins="0%">
              <stack>
                <p>JMP assumes "success" to be the first category alphabetically unless you specify otherwise with <term>Cols > Column Info > Column Properties > Value Ordering</term>.</p>
                <p><em>Note</em>: "not equal to" alternatives will be discussed in Investigation 1.5.</p>
              </stack>
              <image source="images/JMPTestp.png">
                <description>JMP Test Probabilities dialog showing setup for binomial test</description>
              </image>
            </sidebyside>
            
            <p>Press Done.</p>
            
            <figure xml:id="fig-jmp-test-results">
              <image source="images/JMPTestp2.png" width="70%">
                <description>JMP output showing binomial test results with p-value</description>
              </image>
            </figure>
          </statement>
          <solution>
            <p>The output table will show:</p>
            <ul>
              <li><p><term>Level</term>: The categories (e.g., death, survival)</p></li>
              <li><p><term>Estim Prob</term>: The observed proportion (0.80 for deaths)</p></li>
              <li><p><term>Hypoth Prob</term>: The hypothesized probability (0.15)</p></li>
              <li><p><term>Prob > z</term>: The one-sided p-value â‰ˆ 0.0000087</p></li>
            </ul>
          </solution>
        </exercise>
      </paragraphs>
      
      <exercise xml:id="I1-4-7" label="I1.4.7">
        <title>Report the P-value</title>
        <statement>
          <p>Find and report the p-value from your technology (including appropriate notation for the event of interest).</p>
        </statement>
        <response/>
        <hint>
          <p>Use technology to find P(X â‰¥ 8) when X ~ Binomial(10, 0.15).</p>
        </hint>
        <solution>
          <p>Example results:</p>
          <figure>
            <image source="images/inv14sols1.png" width="60%">
              <description>Simulation showing probability of 8 or more successes out of 10 trials with pi=0.15</description>
            </image>
          </figure>
          <p>We see that we never get 8 or more successes so the p-value is approximately zero.</p>
          <p>R tells us the p-value equals <m>8.665 \times 10^{-6}</m></p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-8" label="I1.4.8">
        <title>Interpret the P-value</title>
        <statement>
          <p>Provide a detailed interpretation of your p-value:</p>
          <p>The p-value is the probability of obtaining <var width="10" /> or <var width="10" /> successes in <var width="10" /> trials from a random process, assuming <var width="50" />.</p>
        </statement>
        <response/>
        <hint>
          <p>Fill in the blanks with the specific numbers and assumption from this context.</p>
        </hint>
        <solution>
          <p>This is the probability of getting 8 or more "successes" out of 10 observations from a random process where the long-run probability of success equals 0.15.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-9" label="I1.4.9">
        <title>Draw Conclusions</title>
        <statement>
          <p>Evaluate your p-value: what conclusions would you draw about the probability of death within 30 days of a heart transplant at this hospital?</p>
        </statement>
        <response/>
        <hint>
          <p>Consider how small the p-value is and what that suggests about the null hypothesis.</p>
        </hint>
        <solution>
          <p>We have very strong evidence in favor of <m>\pi > 0.15</m> (<m>H_a</m>). We don't think the higher mortality rate observed in these 10 cases happened just by chance.</p>
        </solution>
      </exercise>
      
      <paragraphs>
        <title>Does it matter which outcome I choose to be success?</title>
        
        <exercise xml:id="I1-4-10" label="I1.4.10">
          <title>Alternative Success Definition</title>
          <statement>
            <p>Suppose that we had focused on survival for 30 days rather than death within 30 days as a "success" in this study. Describe how the hypotheses would change and how the calculation of the binomial p-value would change. Then go ahead and calculate and interpret the exact binomial p-value with this set-up. How does its value compare to your answer in the previous question? How (if at all) does your conclusion change?</p>
            
            <p><m>\pi</m> represents: <var width="50" /></p>
            <p>Hâ‚€: <var width="20" /></p>
            <p>Hâ‚: <var width="20" /></p>
            <p>p-value = P(X <var width="20" />)</p>
            
            <p>Interpretation: The p-value is the probability of obtaining <var width="10" /> or <var width="10" /> successes in <var width="10" /> observations from a random process, assuming <var width="50" />.</p>
          </statement>
          <response/>
          <hint>
            <p>If survival is success, then the benchmark becomes 0.85. How many survived out of 10?</p>
          </hint>
          <solution>
            <p>The null hypothesis would be <m>H_0: \pi = 0.85</m> and the alternative hypothesis would be <m>H_a: \pi &lt; 0.85</m>.</p>
            <figure>
              <image source="images/inv1.4intro.png" width="60%">
                <description>Binomial distribution showing survival as success with pi=0.85</description>
              </image>
            </figure>
            <p>This turns out to be an equivalent analysis.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-4-10b" label="I1.4.10b">
          <title>Compare P-value and Conclusion</title>
          <statement>
            <p>Compared to the analysis with death as success, the p-value has:</p>
          </statement>
          <choices randomize="yes">
            <choice>
              <statement><p>Increased</p></statement>
            </choice>
            <choice correct="yes">
              <statement><p>Stayed the same</p></statement>
            </choice>
            <choice>
              <statement><p>Decreased</p></statement>
            </choice>
          </choices>
          <hint>
            <p>Compare the p-value from the death analysis to the survival analysis.</p>
          </hint>
        </exercise>
        
        <exercise xml:id="I1-4-10c" label="I1.4.10c">
          <title>Impact on Conclusion</title>
          <statement>
            <p>Compared to the analysis with death as success, does the conclusion change when we use survival as success?</p>
          </statement>
          <choices randomize="yes">
            <choice correct="yes">
              <statement><p>No change - the conclusion remains the same</p></statement>
            </choice>
            <choice>
              <statement><p>Yes - it is no longer significant</p></statement>
            </choice>
            <choice>
              <statement><p>Yes - it is now significant</p></statement>
            </choice>
          </choices>
          <hint>
            <p>Does changing the definition of success affect the strength of evidence?</p>
          </hint>
        </exercise>
      </paragraphs>
      
      <paragraphs>
        <title>Does the sample size matter?</title>
        
        <p>Following up on the suspicion that the sample of size 10 aroused, these researchers proceeded to gather data on the previous 361 patients who received a heart transplant at this hospital dating back to 1986. They found 71 deaths within 30 days among heart transplantations.</p>
        
        <exercise xml:id="I1-4-11" label="I1.4.11">
          <title>Calculate Sample Proportion</title>
          <statement>
            <p>Calculate the sample proportion of deaths for these data: <var width="10" /></p>
          </statement>
          <response/>
          <hint>
            <p>Sample proportion = 71/361.</p>
          </hint>
          <solution>
            <p><m>\hat{p} = 71/361 = 0.197</m></p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-4-11b" label="I1.4.11b">
          <title>Predict Strength of Evidence</title>
          <statement>
            <p>Predict whether this is more or less convincing evidence that this hospital's death rate exceeds 0.15. Explain your reasoning.</p>
          </statement>
          <response/>
          <hint>
            <p>Compare the sample proportion (0.197) to 0.15. Also consider that with a larger sample size, we have more information.</p>
          </hint>
          <solution>
            <p>This sample proportion is much closer to 0.15 but also based on a much larger sample size. Predictions will vary by student.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-4-11c" label="I1.4.11c">
          <title>Calculate P-value with Technology</title>
          <statement>
            <p>Use technology to determine the binomial probability of finding at least 71 deaths in a sample of 361 if <m>\pi = 0.15</m>.</p>
          </statement>
          <response/>
          <hint>
            <p>Use the One Proportion Inference applet or R with n=361, observed=71, and Ï€=0.15.</p>
          </hint>
          <solution>
            <figure>
              <image source="images/inv1.4largen.png" width="60%">
                <description>Binomial distribution for n=361 with pi=0.15 showing p-value</description>
              </image>
            </figure>
            <p>p-value â‰ˆ 0.01</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-4-12" label="I1.4.12">
          <title>Evaluate Larger Sample Evidence</title>
          <statement>
            <p>Is the probability you found convincing evidence to consider the sample result surprising if the mortality rate at this hospital matched the national rate? Explain.</p>
          </statement>
          <response/>
          <hint>
            <p>Consider how small the p-value is - what threshold are you using?</p>
          </hint>
          <solution>
            <p>Yes, small p-value. Reject <m>H_0</m> that <m>\pi = 0.15</m>, convinced that <m>\pi > 0.15</m>.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-4-13" label="I1.4.13">
          <title>Compare Strength of Evidence</title>
          <statement>
            <p>Is the evidence against the null hypothesis stronger or weaker than the earlier analysis based on 10 deaths? Explain how you are deciding and why the strength of evidence has changed in this manner.</p>
          </statement>
          <response/>
          <hint>
            <p>Compare the two p-values. Which is smaller?</p>
          </hint>
          <solution>
            <p>The evidence is a bit weaker (though still quite strong) demonstrated by the larger p-value.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-4-14" label="I1.4.14">
          <title>Expected Number of Deaths</title>
          <statement>
            <p>Calculate the expected number of deaths, E(X), for each sample size.</p>
            <p>n = 10: E(X) = <var width="10" /></p>
            <p>n = 361: E(X) = <var width="10" /></p>
          </statement>
          <response/>
          <hint>
            <p>Use the formula E(X) = n Ã— Ï€ where Ï€ = 0.15.</p>
          </hint>
          <solution>
            <p>E(X) = 10(0.15) = 1.5 or 361(0.15) = 54.15</p>
          </solution>
        </exercise>
      </paragraphs>
      
      <p>The following graphs display the two theoretical probability distributions (for sample sizes n = 10 and n = 361), both assuming the null hypothesis (<m>\pi = 0.15</m>) is true. These graphs show just how far the observed values (8 and 71) are from the expected value of the number of deaths (0.15 Ã— 10 = 1.5 and 0.15 Ã— 361 = 54.15) in each case. You should also note that the shape, center, and variability of the probability distribution for number of successes are all affected by the sample size n.</p>
      
      <figure xml:id="fig-heart-transplant-n10">
        <caption>Binomial distribution for n=10, Ï€=0.15</caption>
        <image source="images/inv1.4smalln.png" width="45%">
          <description>Binomial distribution showing n=10, pi=0.15, with observed value of 8 marked</description>
        </image>
      </figure>
      
      <figure xml:id="fig-heart-transplant-n361">
        <caption>Binomial distribution for n=361, Ï€=0.15</caption>
        <image source="images/inv1.4largen.png" width="45%">
          <description>Binomial distribution showing n=361, pi=0.15, with observed value of 71 marked</description>
        </image>
      </figure>
      
      <p>Keep in mind that of interest to us is the observed statistic's relative location in the null distribution. Thus, we are most interested in how variable the possible outcomes are from the "expected" outcome. The center of the distribution isn't all that interesting to us in answering the research question because we determine what the center of the distribution will be by how we specify the null hypothesis. Even the shape isn't all that interesting on its own in answering our research question.</p>
      
      <exercise xml:id="I1-4-15" label="I1.4.15">
        <title>Distribution Feature Differences</title>
        <statement>
          <p>Identify another feature (beside center, shape, and variability) of the above distributions that differs between them.</p>
        </statement>
        <response/>
        <hint>
          <p>Think about practical aspects like the scale or range of values displayed.</p>
        </hint>
        <solution>
          <p>The most obvious difference is how close together the spikes are.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-16" label="I1.4.16">
        <title>Standardize Second Dataset</title>
        <statement>
          <p>How many standard deviations is the observed sample proportion above the hypothesized probability for the second dataset?</p>
          
          <p>Expected value when n = 361 and <m>\pi = 0.15</m>: <var width="10" /></p>
          <p>SD when n = 361 and <m>\pi = 0.15</m>: <var width="10" /></p>
          <p>Number of standard deviations 71 is above the expected value: <var width="10" /></p>
        </statement>
        <response/>
        <hint>
          <p>Use E(X) = n Ã— Ï€ and SD(X) = âˆš(n Ã— Ï€ Ã— (1-Ï€)). Then calculate (71 - E(X))/SD(X).</p>
        </hint>
        <solution>
          <p>SD(X) = sqrt(361 Ã— 0.15 Ã— 0.85) = 6.78</p>
          <p>Observed 71</p>
          <p>(71 - 54.15)/6.78 â‰ˆ 2.49. This is larger than 2.</p>
          <p>For first data set: (8 - 1.5)/sqrt(10 Ã— 0.15 Ã— 0.85) = 6.5/1.13 = 5.75 (this shows us that the evidence is a fair bit stronger with the first data set)</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-16b" label="I1.4.16b">
        <title>Evaluate Standardized Evidence</title>
        <statement>
          <p>Does this calculation also provide strong evidence against the null hypothesis? How are you deciding?</p>
        </statement>
        <response/>
        <hint>
          <p>Consider whether being 2.49 standard deviations from the expected value is unusual.</p>
        </hint>
        <solution>
          <p>Yes, this provides strong evidence against the null hypothesis. A result more than 2 standard deviations from the expected value is generally considered unusual, and 2.49 SD is quite far from the mean.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-17" label="I1.4.17">
        <title>Which Dataset is More Valid?</title>
        <statement>
          <p>In your opinion, which data set do you think is more valid to use â€“ the larger sample size or the more recent data? Explain how you are deciding.</p>
        </statement>
        <response/>
        <hint>
          <p>Consider the trade-offs: more data vs. more current/relevant data. Also think about "data snooping."</p>
        </hint>
        <solution>
          <p>Opinions will vary. The larger sample size is more likely to give us more precise results but some based on very old data which may no longer be representative of the current process.</p>
        </solution>
      </exercise>
      
      <assemblage xml:id="study-conclusions-1-4">
        <title>Study Conclusions</title>
        <p>A sample mortality rate of 80% is indeed quite surprising, even with a sample size as small as 10, if the actual probability of death were 0.15. The (exact) p-value is 0.0000087, and the observed statistic is 5.76 standard deviations above the expected value, providing extremely strong evidence that the actual probability of death at this hospital is higher than the national benchmark of 0.15 (fewer than 1 in 100,000 sets of 10 operations would "randomly" have 8 or more deaths if <m>\pi = 0.15</m>). However, we must be cautious about doing this type of "data snooping," where we allowed a seemingly unusual observation to motivate our suspicion and then use the same data to support our suspicion. Once the initial suspicion has formed, we should collect new data on which to test the suspicion. The actual investigation examined all previous heart transplantations at this hospital over the previous 14 years. In this broader study, the p-value is 0.0097 and the observed number of successes is 2.48 standard deviations above the expected number, still providing very strong evidence against the null hypothesis. That is, there is strong evidence that this hospital's probability of mortality was higher than the 15% national benchmark. We must, however, be cautious because our study has not identified what factors could be leading to the higher rate. Perhaps this hospital tends to see sicker patients to begin with. The researchers actually performed a more sophisticated analysis that incorporated information about the risk factors of all the operations at this hospital and reached similar conclusions.</p>
      </assemblage>
      
      <subsection xml:id="practice1-4A">
        <title>Practice Problem 1.4A</title>
        
        <p>In April 2014, the city of Flint Michigan switched its water supply to the Flint River in an effort to save money. The U.S. Environmental Protection Agency (EPA)'s Lead and Copper Rule states that if lead concentrations exceed an action level of 15 parts per billion (ppb) in more than 10% of homes sampled, then actions must be undertaken to control corrosion, and the public must be informed. In the initial sample of 71 homes, 8 tested above 15 ppb.</p>
        
        <exercise xml:id="PP1-4A-1" label="PP1.4A.1">
          <title>Binomial Process Justification</title>
          <statement>
            <p>Suppose our variable is "was the lead concentration level above 15 ppb?". Is it reasonable to model this as a binomial process? Justify your response for each condition. Be sure to explain how you are defining success and any assumptions you are making about the process.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4A-2" label="PP1.4A.2">
          <title>Define Parameter</title>
          <statement>
            <p>Define (in words) the parameter of interest.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4A-3" label="PP1.4A.3">
          <title>State Hypotheses</title>
          <statement>
            <p>State null and alternative hypotheses for testing whether the probability of a house testing above 15 ppb is more than 0.10.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4A-4" label="PP1.4A.4">
          <title>Calculate P-value</title>
          <statement>
            <p>Report the binomial p-value for your hypotheses.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4A-5" label="PP1.4A.5">
          <title>Modified Dataset P-value</title>
          <statement>
            <p>After dropping two "suspicious" observations, 6 of the 69 remaining observations were above 15 ppb. Report the binomial p-value for your hypotheses. Is the second p-value larger or smaller than the first?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-4B">
        <title>Practice Problem 1.4B</title>
        
        <p>Reconsider the wolf (Yukon) who correctly understood a communicative cue in 7 of 8 attempts. Let <m>\pi</m> represent the probability of Yukon identifying the correct container with a communicative cue.</p>
        
        <exercise xml:id="PP1-4B-1" label="PP1.4B.1">
          <title>Greater Than Alternative</title>
          <statement>
            <p>If the alternative hypothesis is <m>H_a: \pi > 0.50</m>, what is the p-value? Based on this p-value, state an appropriate conclusion in terms of the alternative hypothesis.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4B-2" label="PP1.4B.2">
          <title>Less Than Alternative</title>
          <statement>
            <p>If the alternative hypothesis is <m>H_a: \pi &lt; 0.50</m>, what is the p-value? Based on this p-value, state an appropriate conclusion in terms of the alternative hypothesis.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4B-3" label="PP1.4B.3">
          <title>When P-value Exceeds 0.50</title>
          <statement>
            <p>Under what circumstances will a p-value calculation like these be larger than 0.50?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-4C">
        <title>Practice Problem 1.4C</title>
        
        <p>One of the first times the U.S. Supreme Court considered statistical significance in an employment discrimination case was in Hazelwood School District vs. United States (1977). The U.S. government sued the City of Hazelwood, a suburb of St. Louis, MO, on the grounds that it discriminated against African Americans in its hiring of school teachers. The evidence introduced noted that of the 405 teachers hired in 1972 and 1973 (the years following the passage of the Civil Rights Act), only 15 had been African-American. By comparison, according to 1970 census figures, of the almost 20,000 elementary and secondary teachers employed in the St. Louis area, 15.4% were African American. We want to decide whether the data on these 405 teachers is convincing evidence that the Hazelwood hiring process had a probability of a new hire being African American that was less than 0.154.</p>
        
        <exercise xml:id="PP1-4C-1" label="PP1.4C.1">
          <title>Expected Number of Hires</title>
          <statement>
            <p>What is the expected number of African-American hires in a sample of 405 teachers if the probability of a new hire being African American equals 0.154?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4C-2" label="PP1.4C.2">
          <title>Standardize and Conclude</title>
          <statement>
            <p>Using the binomial distribution, how many standard deviations is 15 from the expected number of new hires that are African American when the null hypothesis is true? What conclusion would you draw?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4C-3" label="PP1.4C.3">
          <title>Excluding St. Louis City</title>
          <statement>
            <p>The St. Louis City School District had recently followed a policy attempting to maintain a 50% African-American teaching staff. If you exclude the St. Louis City School District, then proportion of eligible teachers in the St. Louis area that were African-American was 0.057. What is the new expected number of hires? What conclusions would you draw?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4C-4" label="PP1.4C.4">
          <title>Importance of Labor Market Definition</title>
          <statement>
            <p>Discuss briefly how this case illustrates "the importance of the choice of the relevant labor market area" in cases of discrimination.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
    
    <subsection xml:id="investigation-1-5">
      <title>Investigation 1.5: Buttered Toast</title>
      
      <p>The folks at MythBusters, a popular television program on the Discovery Channel, wanted to investigate whether a piece of toast that has been buttered on one side is more likely to land butter/messy side down or butter-side up. First, they wanted to design a toast-dropping rig that would have no built-in bias for unbuttered toast to land on either side when dropped. For this pilot study, they labeled the sides "top" and "bottom" for ten unbuttered pieces of toast and counted how many landed "top-down."</p>
      
      <exercise xml:id="I1-5-1" label="I1.5.1">
        <title>Define Process and Variable</title>
        <statement>
          <p>Identify the sample/random process and variable of interest in this study. Which outcome will you consider "success"? Do we have a binomial process?</p>
          <p>Random process: <var width="50" /></p>
          <p>Variable: <var width="50" /></p>
          <p>Success: <var width="30" /></p>
          <p>Binomial process? <var width="20" /></p>
        </statement>
        <response/>
        <hint>
          <p>Consider what is being repeated and what outcome is measured each time.</p>
        </hint>
        <solution>
          <p>Random process: Repeated dropping pieces of toast, assuming identical conditions.</p>
          <p>Variable: Whether the piece of toast lands top side down or top side up</p>
          <p>Success: Top side down</p>
          <p>Binomial process: Yes, assuming each drop is independent with the same probability.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-2" label="I1.5.2">
        <title>Define Parameter</title>
        <statement>
          <p>Identify the parameter of interest in this study (in words).</p>
        </statement>
        <response/>
        <hint>
          <p>What long-run proportion are we interested in?</p>
        </hint>
        <solution>
          <p>The probability of a piece of toast landing top side down.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-2b" label="I1.5.2b">
        <title>Parameter Symbol</title>
        <statement>
          <p>What symbol should we use to represent this parameter?</p>
        </statement>
        <hint>
          <p>Look for the Greek letter used for a process probability in a binomial distribution.</p>
        </hint>
        <choices randomize="no">
          <choice>
            <statement><p><m>\hat{p}</m></p></statement>
            <feedback><p>This is the symbol for the sample proportion (statistic), not the population parameter.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p><m>\pi</m></p></statement>
            <feedback><p>Correct! We use <m>\pi</m> to represent the probability of success in a binomial process.</p></feedback>
          </choice>
          <choice>
            <statement><p><m>\mu</m></p></statement>
            <feedback><p>This is the symbol for a population mean, not a probability.</p></feedback>
          </choice>
          <choice>
            <statement><p><m>p</m></p></statement>
            <feedback><p>While <em>p</em> is sometimes used for probability, we use the Greek letter <m>\pi</m> for the process probability parameter.</p></feedback>
          </choice>
        </choices>
        <solution>
          <p>We use <m>\pi</m> to represent the probability of a piece of toast landing top side down.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-3" label="I1.5.3">
        <title>State Null Hypothesis</title>
        <statement>
          <p>State the null hypothesis using symbols and words.</p>
          <p><m>H_0</m>: <var width="50" /></p>
        </statement>
        <response/>
        <hint>
          <p>If there's no bias, what should the probability be?</p>
        </hint>
        <solution>
          <p><m>H_0: \pi = 0.5</m> (equally likely to land top down or top up)</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-4" label="I1.5.4">
        <title>Two-Sided Alternative</title>
        <statement>
          <p>With 10 pieces of toast, what outcomes for the number of successes would convince you that there was a problem with the rig? Suggest a way of stating the alternative hypothesis that reflects this interest/prior suspicion.</p>
          <p><m>H_a</m>: <var width="50" /></p>
        </statement>
        <response/>
        <hint>
          <p>Would you be concerned if the result was extreme in either direction (too many or too few successes)?</p>
        </hint>
        <solution>
          <p><m>H_a: \pi \neq 0.50</m> (one side is more likely)</p>
          <p>This is a two-sided alternative hypothesis.</p>
        </solution>
      </exercise>
      
      <p>You have now stated a two-sided alternative hypothesis (rather than a "one-sided" alternative of strictly less than or strictly greater than). So now we need to decide which values we will consider "or more extreme" in calculating the p-value.</p>
      
      <exercise xml:id="I1-5-5" label="I1.5.5">
        <title>Calculate One-Sided Probability</title>
        <statement>
          <p>In this pilot study, the toast landed top-down 3 times and top-up 7 times. Use the One Proportion Inference applet to calculate the binomial probability of 3 or fewer successes in 10 attempts, assuming the null hypothesis is true (i.e., P(X â‰¤ 3) where X is the number landing top-down).</p>
        </statement>
        <response/>
        <hint>
          <p>Use technology with n=10, Ï€=0.5, and find P(X â‰¤ 3).</p>
        </hint>
        <solution>
          <p>P(X â‰¤ 3) = 0.1719</p>
          <figure>
            <image source="images/inv1.5pilot1.png" width="60%">
              <description>Binomial distribution for n=10, pi=0.5 showing P(X less than or equal to 3)</description>
            </image>
          </figure>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-6" label="I1.5.6">
        <title>Identify More Extreme Outcomes</title>
        <statement>
          <p>Conjecture: What other outcomes would you consider "as or more surprising" as 3 or fewer successes?</p>
        </statement>
        <response/>
        <hint>
          <p>Think about the symmetry of the distribution when Ï€ = 0.5.</p>
        </hint>
        <solution>
          <p>Reasonable conjectures include X â‰¥ 7</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-7" label="I1.5.7">
        <title>Calculate Two-Sided P-value</title>
        <statement>
          <p>If we calculate the two-sided p-value as P(X â‰¤ 3) + P(X â‰¥ 7), what would you report for the p-value? Would you find this p-value to be convincing evidence in favor of the two-sided alternative hypothesis?</p>
        </statement>
        <response/>
        <hint>
          <p>When the distribution is symmetric, P(X â‰¥ 7) = P(X â‰¤ 3).</p>
        </hint>
        <solution>
          <p>The applet tells us P(X â‰¥ 7) also equals 0.1719, so the two-sided p-value = 2(0.1719) = 0.3438</p>
          <p>This p-value is quite large, so we would not have convincing evidence against the null hypothesis.</p>
        </solution>
      </exercise>
      
      <paragraphs>
        <title>What if our original hypotheses had been <m>H_0: \pi = 0.55</m> vs. <m>H_a: \pi \neq 0.55</m>?</title>
        
        <exercise xml:id="I1-5-8" label="I1.5.8">
          <title>Alternative Null Hypothesis</title>
          <statement>
            <p>Restate the alternative hypothesis in words. How will the null distribution change?</p>
          </statement>
          <response/>
          <hint>
            <p>How does changing Ï€ from 0.5 to 0.55 affect the center of the distribution?</p>
          </hint>
          <solution>
            <p>Now we think the long-run proportion of toast drops landing top side down is not 0.55. This will shift the null distribution to center at 5.5 rather than at 5 successes.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-5-9" label="I1.5.9">
          <title>Left Tail Probability</title>
          <statement>
            <p>Make this change in the applet and find the binomial probability of 3 or fewer successes.</p>
          </statement>
          <response/>
          <hint>
            <p>Use n=10, Ï€=0.55, and find P(X â‰¤ 3).</p>
          </hint>
          <solution>
            <p>P(X â‰¤ 3 when Ï€ = 0.55) = 0.1020</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-5-10" label="I1.5.10">
          <title>Right Tail Comparison</title>
          <statement>
            <p>Now find P(X â‰¥ 7) when Ï€ = 0.55. How does it compare to P(X â‰¤ 3)? Why does this make sense?</p>
          </statement>
          <response/>
          <hint>
            <p>Is 7 further from the expected value than 3 is?</p>
          </hint>
          <solution>
            <p>P(X â‰¥ 7) increases to 0.2660 because now an outcome of 7 is closer to the expected value of the null distribution.</p>
          </solution>
        </exercise>
      </paragraphs>
      
      <p>In this text, we will consider outcomes "more extreme" than the observed outcome if the "tail probability" is less than or equal to the tail probability of the observed outcome. So for this null hypothesis (Ï€ = 0.55), because P(X â‰¥ 7) > P(X â‰¤ 3), we would not consider x = 7 to be "more extreme" than x = 3. Therefore, we would not include x = 7 in the p-value calculation. Notice, this distinction arose once our binomial distribution was not symmetric (Ï€ â‰  0.50).</p>
      
      <exercise xml:id="I1-5-11" label="I1.5.11">
        <title>Find More Extreme Value</title>
        <statement>
          <p>Find P(X â‰¥ 8). Is x = 8 considered more extreme than x = 3?</p>
        </statement>
        <response/>
        <hint>
          <p>Compare P(X â‰¥ 8) to P(X â‰¤ 3) = 0.1020.</p>
        </hint>
        <solution>
          <p>P(X â‰¥ 8) = 0.0996 which is now smaller than P(X â‰¤ 3) so we could consider x = 8 a more extreme observation compared to x = 3.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-12" label="I1.5.12">
        <title>Two-Sided P-value for Ï€=0.55</title>
        <statement>
          <p>Calculate the two-sided p-value as P(X â‰¤ 3) + P(X â‰¥ 8)</p>
        </statement>
        <response/>
        <hint>
          <p>Add the two tail probabilities you found.</p>
        </hint>
        <solution>
          <p>0.1020 + 0.0996 = 0.2016</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-13" label="I1.5.13">
        <title>Verify with Applet</title>
        <statement>
          <p>Verify your result by checking the Two-sided box in the applet. [Hint: Make sure you are starting with X â‰¤ 3.]</p>
        </statement>
        <response/>
        <hint>
          <p>Use the "Tails" option in the pull-down menu.</p>
        </hint>
        <solution>
          <p>Results match if you start with P(X â‰¤ 3) and use the pull-down menu to select "Tails" for the two-sided p-value.</p>
          <figure>
            <image source="images/inv1.5pilot2.png" width="60%">
              <description>Two-sided binomial test for n=10, pi=0.55 showing two-sided p-value</description>
            </image>
          </figure>
        </solution>
      </exercise>
      
      <p>There are other ways to define "more extreme" as well, and results will vary across different software packages (see Practice Problem 1.5). But the results will be more similar the more symmetric the null distribution is, and when the null distribution is skewed, adjusting for the asymmetry is generally preferred to going "the same distance" on each side or doubling the one-sided p-value.</p>
      
      <assemblage xml:id="def-two-sided-pvalue">
        <title>Definition: Two-sided p-values</title>
        <p>Two-sided p-values are used with two-sided alternative hypotheses (â‰ , not equal to). A two-sided p-value considers outcomes in both tails that are at least as rare as the observed result, where <em>at least as rare</em> could be defined as having a smaller tail probability of occurring as the observed statistic. If the null distribution is symmetric, the approaches are equivalent and the two-sided p-value will be double the one-sided p-value.</p>
      </assemblage>
      
      <exercise xml:id="I1-5-14" label="I1.5.14">
        <title>Evaluate Pilot Study Conclusion</title>
        <statement>
          <p>The MythBusters decided a 3/7 split was "way outside a random sample" and so they needed to build a different toast-dropping rig. Do you agree with their conclusion from the pilot study? Write a short paragraph to the MythBusters justifying your answer. Include appropriate numerical evidence to support your argument.</p>
        </statement>
        <response/>
        <hint>
          <p>Consider both p-values you calculated (for Ï€=0.50 and Ï€=0.55).</p>
        </hint>
        <solution>
          <p>Based on the two-sided p-values, both 0.50 and 0.55 are plausible values for the probability of a piece of toast landing top side down. Because 0.50 is plausible (p-value = 0.3438), these data do not provide convincing evidence that there is a built-in bias with the mechanism and they could have continued to use it.</p>
        </solution>
      </exercise>
      
      <p>After building a new rig (that they were more confident had no bias), they used the rig to drop buttered toast from the roof of a building. The Mythbusters weren't sure whether the toast would land butter-side down (as in the myth) or whether, like a curved leaf falling from a tree, the toast might try to "right itself" and land with the indented side (from being buttered) down. So again, they wanted to use a two-sided alternative hypothesis, allowing for either possibility to be of interest.</p>
      
      <p>They dropped 48 pieces of toast, with 19 landing butter-side-down.</p>
      
      <exercise xml:id="I1-5-15" label="I1.5.15">
        <title>Buttered Toast Two-Sided Test</title>
        <statement>
          <p>Use the applet to find the two-sided p-value for testing <m>H_0: \pi = 0.5</m> vs. <m>H_a: \pi \neq 0.50</m>. Do you have strong enough evidence to reject the null hypothesis and conclude Ï€ differs from 0.5? Why are you making this decision?</p>
        </statement>
        <response/>
        <hint>
          <p>Use n=48, observed=19, Ï€=0.5, and check the two-sided box.</p>
        </hint>
        <solution>
          <figure>
            <image source="images/inv1.5buttered.png" width="60%">
              <description>Two-sided binomial test for n=48, pi=0.5, observed=19</description>
            </image>
          </figure>
          <p>The p-value is not small (p-value = 0.1934, which is larger than 0.05), so we fail to reject the null hypothesis that Ï€ = 0.50. We conclude it is plausible that buttered toast is equally likely to land up or down when dropped from the top of a building.</p>
        </solution>
      </exercise>
      
      <assemblage xml:id="study-conclusions-1-5">
        <title>Study Conclusions</title>
        <p>These data (19 out of 48) do not provide convincing evidence against the null hypothesis that toast buttered on one side is equally likely to land butter side up or down (two-sided p-value = 0.1934). In other words, it is plausible that this is a 50/50 process. However, this analysis cannot be used as proof that Ï€ = 0.50, as other values could be plausible as well. The sample data allow for many (technically, infinitely many) plausible values of this probability, as you will explore in the next investigation.</p>
        
        <p><alert>Discussion:</alert> Recall that the process we are using to testing our hypotheses is to first assume the null hypothesis is true. For this reason, we can never use this process as evidence <em>for</em> the null hypothesis, only lack of evidence <em>against</em> it. Keep in mind the saying "Absence of evidence is not evidence of absence." Also, note that our evidence depends on the form of the alternative hypothesis. A more complete statement is that we do not have evidence in favor of the alternative that we specified, and that our strength of evidence could differ if we started with a different alternative hypothesis.</p>
      </assemblage>
      
      <paragraphs xml:id="tech-detour-two-sided">
        <title>Technology Detour â€“ Two-sided p-values</title>
        
        <exercise xml:id="tech-detour-two-sided-applet" label="Two-sided - Applet">
          <title>Two-sided p-values in One Proportion Inference applet</title>
          <statement>
            <p><ul>
              <li><p>Check the two-sided box</p></li>
              <li><p>For the "smallest tail probability" approach, set the pull-down menu to "Tails" (finds tail value on other side that is first below the one-sided p-value)</p></li>
              <li><p>For the "smallest p-value" approach, set the pull-down menu to "Individual" (sums all probabilities smaller than the observed)</p></li>
              <li><p>(These will match when the distribution is symmetric.)</p></li>
            </ul></p>
          </statement>
        </exercise>
        
        <exercise xml:id="tech-detour-two-sided-r" label="Two-sided - R">
          <title>Two-sided p-values in R</title>
          <statement>
            <p>Using the <c>iscambinomtest</c> function, specify <c>alternative = "two.sided"</c></p>
            <p>(Smallest p-value method)</p>
            <program language="r" interactive="sage">
              <input>
iscambinomtest(observed=19, n=48, hyp=0.5, alt="two.sided")
              </input>
            </program>
          </statement>
        </exercise>
        
        <exercise xml:id="tech-detour-two-sided-jmp" label="Two-sided - JMP">
          <title>Two-sided p-values in JMP</title>
          <statement>
            <p><alert>Note:</alert> The default two-sided test under Analyze > Distribution is not an "exact" binomial test.</p>
          </statement>
        </exercise>
      </paragraphs>
      
      <subsection xml:id="practice1-5">
        <title>Practice Problem 1.5</title>
        
        <p>There are other approaches for calculating the two-sided p-value. For example, we could consider an outcome k more extreme than the observed, if P(X = k) &lt; P(X = observed).</p>
        
        <exercise xml:id="PP1-5-1" label="PP1.5.1">
          <title>Explain Alternative Approach</title>
          <statement>
            <p>Explain the distinction in this approach and the one used above.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-5-2" label="PP1.5.2">
          <title>Apply Alternative Method</title>
          <statement>
            <p>Return to the pilot study with 3 successes out of n = 10 drops. Based on this new approach, which values above 5 would you consider more extreme than 3 when Ï€ = 0.55? Document your justification. What is the resulting two-sided p-value? [Hints: Use <em>As extreme as =</em> in the applet. Confirm your results by changing the pull-down menu from "tails" to "individual."]</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-5-3" label="PP1.5.3">
          <title>Strange Behavior with Extreme Observations</title>
          <statement>
            <p>Suppose n = 20 and you observed 0 successes. Find the two-sided p-values using the approach suggested in (b) for Ï€ = 0.13, Ï€ = 0.145, and Ï€ = 0.15. According to the two-sided p-values, which of these values are plausible for Ï€ at the 10% level of significance? What strange behavior do you observe?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-5-4" label="PP1.5.4">
          <title>Why Not Other Methods?</title>
          <statement>
            <p>Or we could choose to use x values that are the same number (or more) of standard deviations above the mean or double the one-sided p-value. Why do you think these methods are not recommended in general?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-5-5" label="PP1.5.5">
          <title>When to Use One-Sided Tests</title>
          <statement>
            <p>It's interesting that the one-sided p-value for the pilot study is also not statistically significant. If it had been, would it be reasonable for the Mythbusters to use the one-sided p-value instead to support their conclusion? Explain.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
    
    <subsection xml:id="investigation-1-6">
      <title>Investigation 1.6: Kissing the Right Way</title>
      
      <p>In the previous investigation, you learned how to decide whether a hypothesized value of the parameter is plausible based on a two-sided p-value. The two-sided p-value is used when you do not have a prior suspicion or interest in whether the hypothesized value is too large or too small. In fact, in many studies we may not even really have a hypothesized value, but are more interested in using the sample data to estimate the value of the parameter. What are all the plausible values for the parameter?</p>
      
      <p>Most people are right-handed and even the right eye is dominant for most people. Researchers have long believed that late-stage human embryos tend to turn their heads to the right. German bio-psychologist Onur GÃ¼ntÃ¼rkÃ¼n (Nature, 2003) conjectured that this tendency to turn to the right manifests itself in other ways as well, so he studied kissing couples to see whether both people tend to lean their heads to the right more often than to their left (and if so, how strong the tendency is). He and his researchers observed couples from age 13 to 70 in public places such as airports, train stations, beaches, and parks in the United States, Germany, and Turkey. The observers were careful not to include couples who were holding objects such as luggage that might have affected which direction they turned. We will model the overall decision-making process when kissing as a binomial random process.</p>
      
      <exercise xml:id="I1-6-1" label="I1.6.1">
        <title>Identify Sample, Variable, and Parameter</title>
        <statement>
          <p>Identify the sample and variable in this study, as well as the parameter of interest.</p>
          <p>Sample: <var width="50" /></p>
          <p>Variable: <var width="50" /></p>
          <p>Parameter: <var width="50" /></p>
        </statement>
        <response/>
        <hint>
          <p>What group was observed, what was measured, and what long-run proportion are we interested in?</p>
        </hint>
        <solution>
          <p>Sample: 124 observed kissing couples in public places</p>
          <p>Variable: Whether the couple leaned right or left</p>
          <p>Parameter: <m>\pi</m> = the long-run probability (proportion) that a kissing couple leans right</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-6-2" label="I1.6.2">
        <title>One-Sided or Two-Sided?</title>
        <statement>
          <p>If Dr. GÃ¼ntÃ¼rkÃ¼n wants to investigate whether a majority of kissing couples lean right in the long run, is this a one-sided or a two-sided test?</p>
        </statement>
        <response/>
        <hint>
          <p>Does "majority" suggest a specific direction?</p>
        </hint>
        <solution>
          <p>One-sided test (specifically <m>\pi > 0.5</m>)</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-6-3" label="I1.6.3">
        <title>Hypotheses for 2/3 Conjecture</title>
        <statement>
          <p>Dr. GÃ¼ntÃ¼rkÃ¼n actually conjectured that 2/3 of kissing couples would lean right in the long run. State appropriate null and alternative hypotheses for his conjecture.</p>
        </statement>
        <response/>
        <hint>
          <p>The conjecture becomes the alternative hypothesis.</p>
        </hint>
        <solution>
          <p><m>H_0: \pi = 2/3</m> (or <m>\pi = 0.667</m>)</p>
          <p><m>H_a: \pi \neq 2/3</m> (two-sided, since we want to see if the data support this specific value)</p>
          <p>Or if testing whether it's at least 2/3: <m>H_a: \pi > 2/3</m></p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-6-4" label="I1.6.4">
        <title>Hypotheses for Tic-Tac Claim</title>
        <statement>
          <p>A Tic-Tac ad once claimed 74% of kissing couples lean right. State appropriate null and alternative hypotheses for investigating this ad's claim.</p>
        </statement>
        <response/>
        <hint>
          <p>We want to test if the claim is accurate.</p>
        </hint>
        <solution>
          <p><m>H_0: \pi = 0.74</m></p>
          <p><m>H_a: \pi \neq 0.74</m> (two-sided)</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-6-5" label="I1.6.5">
        <title>Calculate Sample Proportion</title>
        <statement>
          <p>Dr. GÃ¼ntÃ¼rkÃ¼n found 80 out of 124 couples leaned right. Calculate the observed sample proportion. Note: We can use the symbol <m>\hat{p}</m> to refer to a sample proportion.</p>
        </statement>
        <response/>
        <hint>
          <p>Sample proportion = (number of successes)/(sample size)</p>
        </hint>
        <solution>
          <p><m>\hat{p} = 80/124 = 0.645</m> (about 64.5%)</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-6-6" label="I1.6.6">
        <title>Predict Plausible Values</title>
        <statement>
          <p>Based on Dr. GÃ¼ntÃ¼rkÃ¼n's result, what is your best guess for <m>\pi</m>, the long-run probability a kissing couple leans right? Do you think 0.50 will be a plausible value for <m>\pi</m>? 2/3? 0.74? Explain your reasoning.</p>
        </statement>
        <response/>
        <hint>
          <p>The sample proportion provides a point estimate. Consider how far each hypothesized value is from the observed proportion.</p>
        </hint>
        <solution>
          <p>Best guess: <m>\pi \approx 0.645</m> (the sample proportion)</p>
          <p>0.50 seems too low - likely not plausible</p>
          <p>2/3 (0.667) is quite close - likely plausible</p>
          <p>0.74 is somewhat higher - might be plausible, but less certain</p>
        </solution>
      </exercise>
      
      <p>We could employ a "trial-and-error" type of approach to determine which values of <m>\pi</m> appear plausible based on what we observed in the sample. This involves testing different values of <m>\pi</m> and seeing whether the corresponding two-sided p-value is larger than some pre-specified cut-off, typically 0.05. (This cut-off is often called the level of significance.) That is, we will consider <m>\pi_0</m> a plausible value for <m>\pi</m> if assuming <m>\pi = \pi_0</m> does not make our sample statistic look surprising (yielding a small p-value).</p>
      
      <exercise xml:id="I1-6-7" label="I1.6.7">
        <title>Find 95% Confidence Interval</title>
        <statement>
          <p>Use the One Proportion Inference applet to determine the values of <m>\pi_0</m> such that observing 80 of 124 successes or a result more extreme occurs in at least 5% of samples. [Hints: Use values of <m>\pi</m> that are multiples of 0.01 until you can find the boundaries where the exact two-sided p-values (using the tails of the binomial distribution) change from below 0.05 to above 0.05. Then feel free to "zoom in" to three decimal places of accuracy if you'd like.] On a number line, indicate which values are rejected (not plausible) and which values are not rejected and therefore considered plausible.</p>
        </statement>
        <response/>
        <hint>
          <p>Test values systematically: start with values like 0.50, 0.55, 0.60, etc., and find where the p-value crosses 0.05.</p>
        </hint>
        <solution>
          <p>The 95% confidence interval using the "smallest tail probability" (Blaker) approach is approximately <m>0.557</m> to <m>0.727</m>.</p>
          <p>Values below 0.557 and above 0.727 would have two-sided p-values less than 0.05 and would be rejected.</p>
          <p>Values between 0.557 and 0.727 would have two-sided p-values greater than 0.05 and are considered plausible.</p>
        </solution>
      </exercise>
      
      <assemblage xml:id="def-confidence-interval">
        <title>Definition: Confidence Interval</title>
        <p>A <term>confidence interval (CI)</term> specifies the plausible values of the parameter based on the sample result.</p>
      </assemblage>
      
      <p>What you found in the previous exercise will be called a "95% confidence interval" as it was derived using the <m>1 - 0.95 = 0.05</m> cut-off value/significance level.</p>
      
      <exercise xml:id="I1-6-8" label="I1.6.8">
        <title>Interpret 95% CI</title>
        <statement>
          <p>Interpret the confidence interval from the previous exercise. What are you 95% confident of?</p>
        </statement>
        <response/>
        <hint>
          <p>A confidence interval gives a range of plausible values for the parameter.</p>
        </hint>
        <solution>
          <p>We are 95% confident that the true probability that a kissing couple leans right is between 0.557 and 0.727 (or approximately 56% to 73%).</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-6-9" label="I1.6.9">
        <title>Find 99% Confidence Interval</title>
        <statement>
          <p>Repeat the process but using 0.01 rather than 0.05 as the criterion for rejection/plausibility (level of significance). [Hints: You can check the Show sliders box in the applet and use the slider or edit the orange number to change the value of <m>\pi_0</m>. Keep in mind that you are changing the conjectured value of <m>\pi</m>, not the observed number of successes, which should stay at 80.] Does this "99% confidence interval" include more or fewer values than the 95% confidence interval? Explain why this makes intuitive sense.</p>
        </statement>
        <response/>
        <hint>
          <p>A higher confidence level means we want to be more certain, so we need a wider interval.</p>
        </hint>
        <solution>
          <p>The 99% confidence interval is approximately <m>0.529</m> to <m>0.749</m>.</p>
          <p>This interval includes <em>more</em> values than the 95% confidence interval (it's wider).</p>
          <p>Explanation: To be more confident (99% vs. 95%) that we've captured the true parameter value, we need to include more values, making the interval wider.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-6-10" label="I1.6.10">
        <title>Compare Intervals</title>
        <statement>
          <p>Identify a value that is captured in the 99% confidence interval but not the 95% confidence interval. Interpret the meaning of this observation. Explain what your analysis reveals about this value as a plausible value of <m>\pi</m>.</p>
        </statement>
        <response/>
        <hint>
          <p>Look at values near the endpoints of the 95% interval.</p>
        </hint>
        <solution>
          <p>For example, <m>\pi = 0.54</m> is in the 99% CI (0.529 to 0.749) but not in the 95% CI (0.557 to 0.727).</p>
          <p>This means that if we tested <m>H_0: \pi = 0.54</m> vs. <m>H_a: \pi \neq 0.54</m>:</p>
          <p><ul>
            <li><p>The two-sided p-value would be between 0.01 and 0.05</p></li>
            <li><p>We would reject <m>H_0</m> at the 0.05 significance level</p></li>
            <li><p>We would fail to reject <m>H_0</m> at the 0.01 significance level</p></li>
          </ul></p>
          <p>So 0.54 is "somewhat" plausible but not highly plausible.</p>
        </solution>
      </exercise>
      
      <assemblage xml:id="study-conclusions-1-6">
        <title>Study Conclusions</title>
        <p>The researchers are assuming they have a representative sample from a binomial random process and want to estimate <m>\pi</m>, the underlying probability that a randomly selected kissing couple leans to the right. Based on this sample of 124 observations, we estimate <m>\pi</m> to be close to <m>\hat{p} = 80/124 = 0.645</m>. However, we know there is some sampling variability, so we want to find an interval of values that appear to be plausible values of <m>\pi</m>. We do this by finding the values of <m>\pi_0</m> for which the two-sided p-value (<m>H_0: \pi = \pi_0</m> vs. <m>H_a: \pi \neq \pi_0</m>) is greater than 0.05. These are all the values of the parameter such that our sample result is not overly surprising. You should have found this "95% confidence interval," using the "smallest tail probability" approach, to be approximately 0.557 to 0.727 (results from using different software or the applet will differ slightly). Thus, based on these sample results, we are "confident" that the actual value of <m>\pi</m>, the probability a random kissing couple leans right, is between 0.56 and 0.73.</p>
        
        <p>A 99% confidence interval for <m>\pi</m> extends from 0.529 to 0.749 (a smaller lower endpoint and a larger upper endpoint, but a similar midpoint) and therefore includes additional plausible values of the parameter compared to the 95% interval. The 99% confidence interval is wider than the 95% interval because a higher level of confidence requires more "room for error." You will learn other methods for calculating confidence intervals for a binomial process in the next section.</p>
        
        <p><alert>Discussion:</alert> In this investigation you have learned a second type of "statistical inference": providing an interval of plausible values for the parameter based on an observed sample statistic. Confidence intervals provide a nice companion to tests of significance and are also very useful by themselves. Whereas a test of significance allows you to test the plausibility of a specific hypothesized value, if you reject the null hypothesis, the test of significance provides no information as to how different the actual parameter is from the hypothesized value. If you fail to reject the null hypothesis, you only know that the tested value is one of many plausible values. A confidence interval provides an estimate (with bounds) of the actual value of the parameter. You will learn some additional methods for finding confidence intervals later in this text, but do be aware that some software packages use different methods for finding the "exact" binomial two-sided p-values.</p>
      </assemblage>
      
      <exercise xml:id="I1-6-11" label="I1.6.11">
        <title>Alternative CI Method</title>
        <statement>
          <p>Alternatively, another way to define a binomial confidence interval is to find all the values of <m>\pi</m> such that P(X &lt; observed) &lt; (1 â€“ confidence level)/2 and P(X > observed) &lt; (1 â€“ confidence level)/2. Use the applet to find the 95% confidence interval using this approach. [Hints: Remember to use the one-sided p-value and change the direction of the tail probability between &lt; and >, but not =.]</p>
          <p>How does the resulting 95% confidence interval compare to the previous one? Which interval is "better"? Explain.</p>
        </statement>
        <response/>
        <hint>
          <p>This is the Clopper-Pearson method. For 95% confidence, use 0.025 as the cutoff for each tail.</p>
        </hint>
        <solution>
          <p>The Clopper-Pearson 95% confidence interval will be slightly different (typically slightly wider) than the Blaker interval.</p>
          <p>Neither is definitively "better" - they use different definitions of "more extreme." The Blaker method tends to produce slightly shorter intervals and is increasingly preferred.</p>
        </solution>
      </exercise>
      
      <paragraphs xml:id="probability-detour-ci-methods">
        <title>Probability Detour â€“ Binomial Confidence Intervals</title>
        
        <p>Probably the most well-known binomial confidence interval method is the <term>Clopper-Pearson method</term> (Biometrika, 1934). Rather than using two-sided p-values, it will consider a value for <m>\pi</m> plausible as long as the one-sided tail probability is smaller than (1 â€“ confidence level)/2. One advantage of the Clopper-Pearson method is there is a simple computer algorithm for finding it, rather than needing to check all values as you have done here.</p>
        
        <p>The method we first showed you (keeping all values of <m>\pi</m> with a two-sided p-value larger than (1 â€“ confidence level) using the two-sided p-value based on the tail probabilities) is attributed to <term>Blaker</term> (The Canadian Journal of Statistics, 2000). We could refer to this as the "smallest tail probability" method.</p>
        
        <p>Another approach would be to use the "smallest p-value" approach for the two-sided p-value, switching to using P(X = x) to find values of x more extreme than observed in finding the two-sided p-value. This method, attributed to <term>Sterne</term> (Biometrika, 1954), has the disadvantage that the interval produced can have holes! For example, a value like 0.12 may be in the interval of plausible values, the value 0.13 may not, and the value 0.14 may be again.</p>
        
        <p>Many prefer the Blaker method to the holes of the Sterne method, and Blaker's method is now gaining favor over Clopper-Pearson because the intervals tend to be shorter. We will see some other methods later in this text as well. For now, keep in mind the likely duality between confidence intervals and tests of significance: The confidence interval is the set of values for which we would fail to reject the null hypothesis in favor of the two-sided alternative. So we can interpret the confidence interval as the set of plausible values for the parameter in that they are the values such that our observed sample result would not be surprising. Keep in mind that saying a value is <em>plausible</em> is not the same as saying a value is <em>probable</em>. We won't make probability statements about parameter values in this text.</p>
      </paragraphs>
      
      <exercise xml:id="I1-6-12" label="I1.6.12">
        <title>Probability Statement Error</title>
        <statement>
          <p>Explain why it is not appropriate to say "There is a 99% probability that between 52.6% and 75.2% of kissing couples lean right when they kiss."</p>
        </statement>
        <response/>
        <hint>
          <p>The parameter is fixed (not random), but the interval is random.</p>
        </hint>
        <solution>
          <p>The parameter <m>\pi</m> is a fixed value - it either is or isn't in the interval. The 99% refers to the confidence in our <em>method</em>: if we were to repeat this process many times, about 99% of the intervals we construct would contain the true parameter value. We cannot make a probability statement about this specific interval containing the parameter.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-6-13" label="I1.6.13">
        <title>Technology Comparison</title>
        <statement>
          <p>Use technology (see Technology Detour below) to determine the 95% and 99% Clopper-Pearson confidence intervals for the probability that a kissing couple leans to the right. Comment on how the 99% confidence interval compares to the 95% interval, examining both midpoints and widths. [Hint: Average the endpoints to find the midpoint; subtract the endpoints to find the width.]</p>
        </statement>
        <response/>
        <hint>
          <p>Use R's iscambinomtest function or JMP with the ISCAM Journal file.</p>
        </hint>
        <solution>
          <p>Using technology (e.g., R with <c>iscambinomtest(80, 124, conf.level=0.95)</c>):</p>
          <p>95% CI: approximately 0.556 to 0.725</p>
          <p>99% CI: approximately 0.528 to 0.751</p>
          <p>The 99% interval is wider (width â‰ˆ 0.223 vs. 0.169 for 95%) but has a similar midpoint (approximately 0.64).</p>
        </solution>
      </exercise>
      
      <paragraphs xml:id="tech-detour-exact-ci">
        <title>Technology Detour â€“ Exact Confidence Intervals</title>
        
        <p>Different software packages use different confidence interval methods, but you shouldn't see much distinction when the sample size is large.</p>
        
        <exercise xml:id="tech-detour-ci-r" label="CI - R">
          <title>Confidence Intervals in R</title>
          <statement>
            <p><alert>In R: Clopper-Pearson</alert> (tail probability &lt; (1-confidence)/2)</p>
            <program language="r" interactive="sage">
              <input>
iscambinomtest(observed, n, conf.level = )
              </input>
            </program>
            <p>Can enter either sample count or sample proportion for "observed."</p>
            <p>Be sure to label the confidence level. You can enter the proportion or the percentage value.</p>
            
            <p><alert>Output from R:</alert></p>
            <p>The <c>iscambinomtest</c> includes some interesting graphs.</p>
            <p><ul>
              <li><p>The bottom graph illustrates the 95% confidence interval. The interval is centered at the observed sample proportion <m>\hat{p}</m> and displays the two endpoints of the interval of plausible values for the process probability.</p></li>
              <li><p>The top graph shows the distribution assuming the lower value of the confidence interval as the process probability. This is as far left as we can shift that null distribution before the area to the right of the observed number of successes, 80, dips below 0.025.</p></li>
              <li><p>The middle graph shows how far we can move that distribution to the right (largest plausible value of <m>\pi</m>) before the probability below 80 dips below 0.025.</p></li>
            </ul></p>
          </statement>
        </exercise>
        
        <exercise xml:id="tech-detour-ci-jmp" label="CI - JMP">
          <title>Confidence Intervals in JMP</title>
          <statement>
            <p><alert>In JMP: Clopper-Pearson</alert> (tail probability &lt; (1-confidence)/2)</p>
            <p>Using the ISCAM Journal file, select <em>Confidence Interval for One Proportion (with Summary Stats)</em>.</p>
            <p>(The raw data option does not give an exact binomial confidence interval.)</p>
            <p>With summarized data, specify the count and sample size, and select the Binomial radio button.</p>
          </statement>
        </exercise>
      </paragraphs>
      
      <exercise xml:id="I1-6-14" label="I1.6.14">
        <title>Optional: Compare Methods</title>
        <statement>
          <p>Optional: Compare the Clopper-Pearson 99% interval to the Blaker 99% interval. Which is narrower?</p>
        </statement>
        <response/>
        <hint>
          <p>The Blaker method typically produces shorter intervals.</p>
        </hint>
        <solution>
          <p>The Blaker 99% interval is typically narrower than the Clopper-Pearson 99% interval, which is one reason it's gaining favor in practice.</p>
        </solution>
      </exercise>
      
      <subsection xml:id="practice1-6">
        <title>Practice Problem 1.6</title>
        
        <exercise xml:id="PP1-6-1" label="PP1.6.1">
          <title>St. George's Hospital CI</title>
          <statement>
            <p>Recall the 8 out of 10 statistic for St. George's Hospital (Investigation 1.4). Based on this result, what is an interval of plausible values for the underlying mortality rate at St. George's? [Hint: You can use a 95% confidence level if none is stated.] Describe how you found the interval and name the method used. Report the midpoint and width of this interval.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-6-2" label="PP1.6.2">
          <title>Larger Sample CI</title>
          <statement>
            <p>Use technology to calculate the 95% confidence interval based on the 71 deaths among 361 patients. Comment on how the width and midpoint of this interval differ from the interval in (a). Explain why these changes make sense.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-6-3" label="PP1.6.3">
          <title>CI and Hypothesis Test Duality</title>
          <statement>
            <p>Based on the interval in (b), if you were to test <m>H_0: \pi = 0.20</m> vs. <m>H_a: \pi \neq 0.20</m>, would you reject or fail to reject the null hypothesis? Explain how you know the conclusion based on the confidence interval without actually conducting the test.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <assemblage xml:id="summary-exact-binomial">
        <title>Summary of Exact Binomial Inference (Sampling from a Binomial Process)</title>
        
        <p>Let X represent the number of successes in the sample and <m>\pi</m> the probability of success for a binomial random process.</p>
        
        <p><alert>To test <m>H_0: \pi = \pi_0</m></alert></p>
        <p>We can calculate a p-value based on the binomial distribution with parameters n and <m>\pi_0</m>. The p-value can be one-sided or two-sided based on the statement of the research conjecture.</p>
        <p><ul>
          <li><p>If <m>H_a: \pi > \pi_0</m>: p-value = P(X â‰¥ observed)</p></li>
          <li><p>If <m>H_a: \pi &lt; \pi_0</m>: p-value = P(X â‰¤ observed)</p></li>
          <li><p>If <m>H_a: \pi \neq \pi_0</m>: p-value = sum of both tail probabilities using a method like "small p-values"</p></li>
        </ul></p>
        
        <p><alert>(100 Ã— C)% Confidence Interval for <m>\pi</m></alert></p>
        <p>The set of values such that the two-sided p-value based on the observed count is larger than the <m>(1 - C)</m> cut-off.</p>
        
        <p><alert>Technology</alert></p>
        <p><ul>
          <li><p>One Proportion Inference applet for approximate and exact binomial probability (p-value)</p></li>
          <li><p>R, ISCAM Workspace: <c>iscambinomtest(observed, n, hypothesized=Ï€_0, alternative="greater", "less," or "two.sided", conf.level)</c></p>
            <p>Can enter either sample count or sample proportion for "observed." If you don't specify a hypothesized value and alternative, be sure to label the confidence level.</p></li>
          <li><p>JMP:</p>
            <p>For a one-sided p-value: Analyze > Distribution (raw or tallied data using Freq)</p>
            <p>For a confidence interval: ISCAM Journal file > Confidence Interval for One Proportion using Summary Stats: specify the number of successes and the sample size</p></li>
        </ul></p>
        
        <p><alert>Handy Reminders</alert></p>
        <p><ul>
          <li><p>In R: If you don't remember the inputs for a function, just use ? before the function, e.g., <c>?iscambinomtest</c>. Use the up arrow to return to earlier commands.</p></li>
          <li><p>In JMP: Remember to look under "hot spots" and that options will change across menu items.</p></li>
        </ul></p>
      </assemblage>
    </subsection>
  </section>
  </article>
</pretext>
