<?xml version="1.0" encoding="UTF-8"?>
<section xml:id="inv-3-1">
  <title>Investigation 3.1: Teen Hearing Loss (cont.)</title>
<exercises><title>The Study</title>
  <introduction>
    <p>The Shargorodsky, Curhan, Curhan, and Eavey (<url href="https://jamanetwork.com/journals/jama/fullarticle/186427">2010</url>) study from <xref ref="inv-1-14" text="custom">Investigation 1.14</xref> actually focused on comparing the current hearing loss rate among teens (12-19 years) to previous years to see whether teen hearing loss is increasing, possibly due to heavier use of ear buds. In addition to the 1771 participants in the NHANES 2005-6 study (333 with some level of hearing loss), they also had hearing loss data on 2928 teens from NHANES III (1988-1994), with 480 showing some level of hearing loss. Our goal is to assess whether the difference between these two groups can be considered statistically significant.</p>
    
    <image source="images/Inv3.1intro.png" width="80%"/>
  </introduction>

  <exercise xml:id="inv3-1-a">
    <title>Study Design Difference</title>
    <statement>
      <p>What is the primary difference between this study and those examined in <em>ISCAM</em>Chapters 1 and 2?</p>
      <p><var width="60" height="3"/></p>
    </statement>
    <solution><p>different: compare 2 proportions to each other</p></solution>
    <response/>
  </exercise>

  <exercise xml:id="inv3-1-b">
    <title>Identify Populations and Variable</title>
    <statement>
      <p>Identify the two populations.</p>
      <p><var width="60" height="3"/></p>
      <p>Identify the variable.</p>
      <p><var width="60" height="3"/></p>
      <p>Identify the variable type.</p>
    </statement>
    <choices>
      <choice correct="yes"><statement>Categorical</statement></choice>
      <choice><statement>Quantitative</statement></choice>
    </choices>
    <solution>
      <p>populations: (1) 2005-6 teens; (2) 88-94 teens</p>
      <p>Variable: whether/not some hearing loss. Binary categorical</p>
    </solution>
    <response/>
  </exercise>

  <paragraphs>
    <title>Descriptive Statistics</title>
    
    <exercise xml:id="inv3-1-c">
      <title>Two-Way Table</title>
      <statement>
        <p>When we have two samples for a binary categorical variable, it is often useful to organize the data using a two-way table. Complete the following 2 × 2 table <em>of counts</em>.</p>
        <tabular halign="center" top="minor" bottom="minor" left="minor" right="minor">
          <row header="yes">
            <cell></cell>
            <cell>1988-1994</cell>
            <cell>2005-2006</cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell>Some hearing loss</cell>
            <cell><var width="10"/></cell>
            <cell><var width="10"/></cell>
            <cell><var width="10"/></cell>
          </row>
          <row>
            <cell>No hearing loss</cell>
            <cell><var width="10"/></cell>
            <cell><var width="10"/></cell>
            <cell><var width="10"/></cell>
          </row>
          <row>
            <cell>Total</cell>
            <cell>2928</cell>
            <cell>1771</cell>
            <cell><var width="10"/></cell>
          </row>
        </tabular>
      </statement>
      <solution>
        <tabular halign="center" top="minor" bottom="minor" left="minor" right="minor">
          <row header="yes">
            <cell></cell>
            <cell>1988-1994</cell>
            <cell>2005-2006</cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell>Some hearing loss</cell>
            <cell>480</cell>
            <cell>333</cell>
            <cell>813</cell>
          </row>
          <row>
            <cell>No hearing loss</cell>
            <cell>2448</cell>
            <cell>1438</cell>
            <cell>3886</cell>
          </row>
          <row>
            <cell>Total</cell>
            <cell>2928</cell>
            <cell>1771</cell>
            <cell>4699</cell>
          </row>
        </tabular>
      </solution>
      <response/>
    </exercise>

    <exercise xml:id="inv3-1-d">
      <title>Comparing Counts</title>
      <statement><p>Explain why it does not make sense to conclude that hearing loss was more prevalent in 1988-1994 than in 2005-2006 based only on the comparison that 480 > 333.</p></statement>
      <solution><p>Because the sample sizes for the two surveys are not the same</p></solution>
      <response/>
    </exercise>

    <exercise xml:id="inv3-1-e">
      <title>Comparing Proportions</title>
      <statement><p>Suggest a better way to compare the prevalence of hearing loss between the two studies. Calculate <em>one number</em> as the statistic for this study (what symbols are you using?). Does your statistic seem large enough to convince you that there has been an increase in hearing loss?</p></statement>
      <solution><p>88 - 05 = 480/2928 - 333/1771 = -0.024 (judgements of the impressiveness of this number will vary; it seems on the small side but the sample sizes are large)</p></solution>
      <response/>
    </exercise>

    <assemblage>
      <title>Definition: Conditional Proportions</title>
      <p>The simplest statistic for comparing a binary variable between two groups is the difference in the proportion of "successes" for each group. These proportions, calculated separately for each group rather than looking at the overall proportion, are called <term>conditional proportions</term><idx><h>conditional proportions</h></idx>.</p>
    </assemblage>

    <p>In this case, we compute the difference in the <em>proportion</em> of teens with some level of hearing loss between the two years (<m>\hat{p}_{94} - \hat{p}_{06} = 480/2928 - 333/1771</m>).</p>

    <p>The next step is to examine an effective graphical summary for comparing the two groups.</p>

    <paragraphs>
      <title>Technology Detour – Segmented Bar Graphs</title>
      
      <p>Use technology to create numerical and graphical summaries for these summarized data.</p>
      
      <hint>
        <title>R Instructions</title>
        <p>Create (and view) a matrix in R to store the counts from the two-way table:</p>
        <sage language="r">
          <input>
<![CDATA[
# Create matrix with counts from two-way table
hearing = matrix(c(480, 2448, 333, 1438), nrow=2,
                 dimnames = list(c("some loss", "no loss"), c("94", "06")))
hearing
]]>
          </input>
        </sage>
        <p>Convert to a matrix of conditional proportions (margin = 2 for column proportions):</p>
        <sage language="r">
          <input>
<![CDATA[
# Convert to proportions
hearingprop = prop.table(hearing, margin=2)
hearingprop
]]>
          </input>
        </sage>
        <p>Create a segmented bar graph:</p>
        <sage language="r">
          <input>
<![CDATA[
# Create segmented bar graph
barplot(hearingprop, legend=TRUE, ylab="proportion")
]]>
          </input>
        </sage>
      </hint>

      <hint>
        <title>JMP Instructions</title>
        <p>You can specify the counts from the two-way table, but you have to do so in "column format" (each row is a combination of the two variables and the counts are all in one column)</p>
        <p><ul>
          <li><p>Select <term index="no">Analyze > Fit Y by X</term> .</p></li>
          <li><p>Click Hearing Loss then click the <term index="no">Y, Response</term> button (or drag).</p></li>
          <li><p>Click Year then click the <term index="no">X, Factor</term> button (or drag). (With raw data, you would be done here.)</p></li>
          <li><p>Finally click <term index="no">Count</term> then the <term index="no">Freq</term> button. Click <term index="no">OK</term>.</p></li>
          <li><p>Right-click on one of the bars and select <term index="no">Cell Labelling > Show Percents</term>.</p></li>
        </ul></p>
        <p>JMP creates a "Mosaic Plot" (the column widths also reflect the relative sample sizes). An extended two-way table is shown below the Mosaic Plot although the rows and columns are reversed. Click the red Contingency Table arrow and uncheck Col% and Total% to see a less cluttered table.</p>
      </hint>
    </paragraphs>

    <exercise xml:id="inv3-1-f">
      <title>Descriptive Statistics</title>
      <statement>
        <p>Write a sentence or two comparing the distributions of hearing loss between these two studies. Be sure to report an appropriate statistic.</p>
      </statement>
      <solution>
        <p>A slightly higher proportion of teens (0.024) had some level of hearing loss in the 2005/6 data than in 1998-94.</p>
        <image source="images/Inv3.1solsf.jpg" width="60%"/>
      </solution>
      <response/>
    </exercise>

    <exercise xml:id="inv3-1-g">
      <title>Initial Conclusion</title>
      <statement><p>Do these data convince you that there is a difference in the population proportions? If not, what could be another explanation for the difference you see in these numerical and graphical summaries for these two samples?</p></statement>
      <solution><p>Judgements will vary, but we should still consider random sampling "error"</p></solution>
      <response/>
    </exercise>

  </paragraphs>

  <paragraphs>
    <title>Inferential Statistics</title>
    <p>As we've said before, it certainly is <em>possible</em> to obtain <em>sample</em> 
        proportions this far apart, just by random chance, even if the 
        <em>population</em> proportions (of teens with some hearing loss) 
        were the same. The question now is <em>how likely</em> such a difference 
        would be if the population proportions were the same.</p>
    <sidebyside widths="60% 35%" valign="top">
      <stack>
        <p> We can answer this question by modeling the sampling variability, arising from taking random samples from these populations, for the difference in two sample proportions. Investigating this sampling variability will help us to assess whether this particular difference in sample proportions is strong evidence that the population proportions actually differ.</p>
      </stack>
      <image source="images/Inv3.1animated.gif" width="100%">
        <description>Animated illustration of sampling variability in two proportions</description>
      </image>
    </sidebyside>

    <exercise xml:id="inv3-1-h">
      <title>Hypotheses</title>
      <statement>
        <p>Let <m>\pi_{94}</m> represent the proportion of all American teenagers in 1994 with at least some hearing loss, and similarly for <m>\pi_{06}</m>. Define the parameter of interest to be <m>\pi_{94} - \pi_{06}</m>, the difference in the population proportions between these two years. State appropriate null and alternative hypotheses about this parameter to reflect the researchers' conjecture that hearing loss by teens is becoming more prevalent.</p>
        <p><m>H_0: </m> <var width="5"/> <var width="5"/> <var width="5"/></p>
        <p><m>H_a: </m> <var width="5"/> <var width="5"/> <var width="5"/></p>
      </statement>
      <solution>
        <p><m>H_0: \pi_{94} = \pi_{06}</m> or <m>\pi_{94} - \pi_{06} = 0</m> (the population proportions are the same)</p>
        <p><m>H_a: \pi_{94} - \pi_{06} &lt; 0</m> or <m>\pi_{94} &lt; \pi_{06}</m> (a higher rate of hearing loss in 2006 than in 1994)</p>
        <p>Success = some hearing loss</p>
      </solution>
      <response/>
    </exercise>

  </paragraphs>

  <paragraphs>
    <title>Simulation</title>
    <p>Because the population sizes are very large compared to the sample sizes, we will model this by treating the populations as infinite and sampling from binomial processes.</p>
    
    <exercise xml:id="inv3-1-i">
      <title>Modeling Null Hypothesis</title>
      <statement><p>How do we model the null hypothesis being true?</p></statement>
      <solution><p>We sample from two random processes but we keep the process probability the same between them.</p></solution>
      <response/>
    </exercise>

    <exercise xml:id="inv3-1-j">
      <title>Pooled Estimate</title>
      <statement><p>So under the null hypothesis we really only have one value of <m>\pi</m> to estimate – the common population proportion with hearing loss for these two years. What is your best estimate for <m>\pi</m> from the sample data?</p>
    <var width = "10"/></statement>
      <hint>
        <p>Think about combining the two years together.</p>
      </hint>
      <solution><p>= 813/4699 = 0.173</p></solution>
      <response/>
    </exercise>

    <exercise xml:id="inv3-1-k">
      <title>Simulation Design</title>
      <statement><p>Describe how you could carry out a simulation analysis to investigate whether the observed difference in sample proportions provides strong evidence that the population proportions with hearing loss differed between these two time periods. How will you estimate the p-value?</p></statement>
      <solution><p>We could take random samples of 2928 and 1771 from two populations that have the same population proportion of successes. Then see how often 1 - 2 ≈ -0.024 when 94 - 06 = 0 by random sampling alone.</p></solution>
      <response/>
    </exercise>

    <p>We will begin our simulation analysis by assuming the population proportion is actually 
    this value (<m>\pi = (480 + 333)/(2928 + 1771) = 0.173</m>). We simulate the drawing of two different random samples from this population, one to represent the 1994 study and the other for the 2006 study. Then we examine the distribution of the difference in the conditional proportions with some hearing loss between these two years. Finally, we repeat this random sampling process for many trials. [Note: We can assume <m>\pi = 0.173</m> without loss of generality, but you might want to verify this with other values for <m>\pi</m> as well.]</p>
     <p>Use the <url href="https://www.rossmanchance.com/applets/2021/twopopprop/twopopprop.html">Comparing Two Population Proportions applet</url> to randomly sample one "could have been" difference in conditional proportions <em>assuming the null hypothesis is true</em>.</p>
        <p><ul>
          <li><p>Specify .173 as the process probability for both populations.</p></li>
          <li><p>Specify 2928 and 1771 as the two sample sizes.</p></li>
          <li><p>Leave the <alert>Number of samples</alert> set to 1.</p></li>
          <li><p>Press <alert>Draw Samples</alert>.</p></li>
        </ul></p>
   
  <interactive iframe="https://www.rossmanchance.com/applets/2021/twopopprop/twopopprop.html?hideExtras=1" width="160%" aspect="3:2"/>
    
    <exercise xml:id="inv3-1-l">
      <title>One Repetition</title>
      <statement>
        <p>Report the values you found for <m>\hat{p}_1</m>, <m>\hat{p}_2</m>, and <m>\hat{p}_1 - \hat{p}_2</m>.</p>
      <p><m>\hat{p}_1 = </m><var width="10"/> <m>\hat{p}_2 = </m><var width="10"/> <m>\hat{p}_1 - \hat{p}_2 = </m><var width="10"/></p>
      </statement>
      <hint>
        <p>See <xref ref="tech-detour-simulation-proportions" text="custom">Technology Detour</xref> below for carrying out these simulations in other software packages.</p>
      </hint>
      <solution>
        <p>Example results, =0.185 and  = 0.157 for a difference of 0.028.</p>
        <image source="images/Inv3.1solsl.jpg" width="60%"/>
      </solution>
      <response/>
    </exercise>

    <exercise xml:id="inv3-1-m">
      <title>Variability</title>
      <statement>
        <p>Will everyone in the class get the same answers to <xref ref="inv3-1-l" text="custom">question 12</xref>? Explain.</p>
        <p><var width="60" height="3"/></p>
      </statement>
      <solution><p>No, because of the randomness in the sampling process not everyone will get the same answers to checkpoint 16.</p></solution>
      <response/>
    </exercise>

    <p>To learn about the pattern of variation in our statistic, we want to generate many more outcomes assuming the null hypothesis to be true.</p>
<ul><li>Change the <alert>Number of samples</alert> from 1 to 999</li>
<li>Press <alert>Draw Samples</alert> for a total of 1,000 independent random samples. 
</li></ul>
    <exercise xml:id="inv3-1-n">
      <title>Many Repetitions</title>
      <statement><p>Describe the distribution of <m>\hat{p}_1</m> values, the distribution of <m>\hat{p}_2</m> values, and the distribution of <m>\hat{p}_1 - \hat{p}_2</m> values. Does the distribution of difference in proportions behave as you expected? In particular, does the mean of this distribution make sense? (How does it compare to the means of the individual <m>\hat{p}</m> distributions?) Explain.</p></statement>
      <solution>
        <p>Answers will vary but should expect the distributions of sample proportions (with large sample sizes) to each be approximately normal with means equal to the (same) population proportion and for the mean of the differences (assuming the null is true) to be close to zero.</p>
        <p>Example results:</p>
        <image source="images/Inv3.1solsn.jpg" width="60%"/>
        <p>The distributions of the  values should be approximately normal with means around 0.173. The standard deviations should be around 0.007 and 0.009. The distribution of the 1-2 values should be approximately normal with mean around 0 (0.173 - 0.173) and standard deviation around 0.011, which is larger than the individual  distribution SDs.</p>
      </solution>
      <response/>
    </exercise>
<ul><li>Now determine the empirical p-value by counting how often the simulated difference in conditional proportions is at least as extreme as the actual value observed in the study by entering the observed value in the <alert>Count Samples</alert> box and pressing the <alert>Count</alert> button. (Make sure the direction matches the alternative hypothesis.) 
</li></ul>
     ￼
     ￼
    <exercise xml:id="inv3-1-o">
      <title>Empirical p-value</title>
      <statement><p>Report your empirical p-value and indicate what conclusion you would draw from it.</p></statement>
      <solution>
        <p>Example results</p>
        <image source="images/Inv3.1solso.jpg" width="60%"/>
        <p>This is a small p-value and provides moderate evidence against the null hypothesis in favor of the alternative hypothesis that the population proportion with at least some level of hearing loss was greater in 2006 than in 1994.</p>
      </solution>
      <response/>
    </exercise>

  </paragraphs>

  <paragraphs>
    <title>Mathematical Model</title>
    <p>It turns out that there is no "exact" method for calculating the p-value here, because the difference in two binomial variables does not have a binomial, or any other known, probability distribution.</p>
    <exercise xml:id="inv3-1-p">
      <title>Distribution Shape</title>
      <statement>
        <p> However, did the histogram of <m>\hat{p}_1 - \hat{p}_2</m> values you examined remind you of any other probability distribution?</p>
        <p><var width="60" height="3"/></p>
      </statement>
      <solution><p>The normal distribution</p></solution>
      <response/>
    </exercise>
<ul><li>Check the <alert>Normal Approximation</alert> box to overlay a normal curve on your null distribution to evaluate whether the simulated differences appear to "line up" with observations from a standard normal distribution. </li></ul>
    <exercise xml:id="inv3-1-q">
      <title>Normal Approximation</title>
      <statement><p>Does the normal model appear to be a reasonable approximation to the null distribution?<var width="5"/></p></statement>
      <solution>
        <p>Yes, example results below</p>
        <image source="images/Inv3.1solsq.jpg" width="60%"/>
      </solution>
      <response/>
    </exercise>

    <assemblage>
      <title>Probability Detour</title>
      <p>There is a theoretical result that the <em>difference</em> in two normal distributions will also follow a normal distribution. When our sample sizes (<m>n_1</m> and <m>n_2</m>) are large, we know the individual binomial distributions are well approximated by normal distributions. Consequently, the difference of the sample proportions will be well approximated by a normal distribution as well. The mean of this distribution is simply the difference in the means of the individual normal distributions.</p>
    </assemblage>

    <exercise xml:id="inv3-1-r">
      <title>Variability Comparison</title>
      <statement>
        <p>How does the variability (SD) of the <em>difference</em> in <m>\hat{p}</m> values compare to the variability of the individual <m>\hat{p}</m> distributions?</p>
      </statement>
      <choices>
        <choice><statement>equal</statement></choice>
        <choice correct="yes"><statement>Larger</statement></choice>
        <choice><statement>Smaller</statement></choice>
      </choices>
      <statement>
        <p>Explain why this makes intuitive sense.</p>
        <p><var width="60" height="5"/></p>
      </statement>
      <solution><p>Larger. This makes sense because we now have two sources of variability and the overall amount of variation will grow. (For example, we could get two extreme results, in opposite directions, and end up with a large difference.)</p></solution>
      <response/>
    </exercise>

    <p>Two additional "rules for random variables" is, for two random variables <m>X</m> and <m>Y</m>,</p>
    <p><m>E(X \pm Y) = E(X) \pm E(Y)</m></p>
    <p><m>Var(X \pm Y) = Var(X) + Var(Y)</m>, as long as <m>X</m> and <m>Y</m> are independent</p>

    <exercise xml:id="inv3-1-s">
      <title>Expected Value and Variance</title>
      <statement><p>Use these rules to suggest a way to calculate (formula) <m>E(\hat{p}_1 - \hat{p}_2)</m> and <m>Var(\hat{p}_1 - \hat{p}_2)</m>.</p></statement>
      <solution>
        <p>E(<m>\hat{p}_1 - \hat{p}_2</m>) = E(<m>\hat{p}_1</m>) - E(<m>\hat{p}_2</m>) = <m>\pi_1 - \pi_2</m></p>
        <p>Var(<m>\hat{p}_1 - \hat{p}_2</m>) = Var(<m>\hat{p}_1</m>) + (-1)<m>^2</m>Var(<m>\hat{p}_2</m>) = <m>\pi_1(1-\pi_1)/n_1 + \pi_2(1-\pi_2)/n_2</m></p>
        <p>So SD(<m>\hat{p}_1 - \hat{p}_2</m>) = <m>\sqrt{\frac{\pi_1(1-\pi_1)}{n_1} + \frac{\pi_2(1-\pi_2)}{n_2}}</m></p>
      </solution>
      <response/>
    </exercise>

    <exercise xml:id="inv3-1-t">
      <title>Standard Error Formula</title>
      <statement><p>Suggest two different methods for calculating <m>SE(\hat{p}_1 - \hat{p}_2)</m> using the observed data.</p></statement>
      <solution><p>When the null hypothesis is true, we are assuming <m>\pi_1 = \pi_2</m>, so we can substitute in the same number for both values. Otherwise, we can substitute in <m>\hat{p}_1</m> and <m>\hat{p}_2</m>.</p></solution>
      <response/>
    </exercise>

    <assemblage>
      <title>Central Limit Theorem for the difference in two sample proportions</title>
      <p>When taking two independent samples (of sizes <m>n_1</m> and <m>n_2</m>) from large populations, the distribution of the difference in the sample proportions <m>(\hat{p}_1 - \hat{p}_2)</m> is approximately normal with mean equal to <m>\pi_1 - \pi_2</m> and standard deviation equal to <m>SD(\hat{p}_1 - \hat{p}_2) = \sqrt{\frac{\pi_1(1-\pi_1)}{n_1} + \frac{\pi_2(1-\pi_2)}{n_2}}</m>.</p>
      <p>Under the null hypothesis <m>H_0: \pi_1 - \pi_2 = 0</m>, the standard deviation simplifies to <m>\sqrt{\pi(1-\pi)(\frac{1}{n_1} + \frac{1}{n_2})}</m> where <m>\pi</m> is the common population proportion.</p>
      <p><term>Technical Conditions:</term> We will consider the normal model appropriate if the sample sizes are large, namely <m>n_1\pi_1 > 5</m>, <m>n_1(1 - \pi_1) > 5</m>, <m>n_2\pi_2 > 5</m>, <m>n_2(1 - \pi_2) > 5</m>, and the populations are large compared to the sample sizes.</p>
      <p>Note: The variability in the differences in sample proportions is larger than the variability of individual sample proportions. In fact, the <em>variances</em> (standard deviation squared) add, and then we take the square root of the sum of variances to find the standard deviation.</p>
    </assemblage>

    <p>However, to calculate these values we would need to know <m>\pi_1</m>, <m>\pi_2</m>, or <m>\pi</m>. So again we estimate the standard deviation of our statistic using the sample data.</p>
</paragraphs>
<paragraphs>
   <title>Case 1</title> 
    <p>When testing whether the null hypothesis is true, we are assuming the samples come from the same population, so we "pool" the two samples together to estimate the common population proportion of successes. That is, we estimate <m>\pi</m> by looking at the ratio of the total number of successes to the total sample size:</p>
    <p><m>\hat{p} = \frac{X_1+X_2}{n_1+n_2} = \frac{n_1\hat{p}_1+n_2\hat{p}_2}{n_1+n_2} = \frac{\text{total number of successes}}{\text{total sample size}}</m></p>

    <p>Then use we use this value to calculate the standard error of <m>\hat{p}_1 - \hat{p}_2</m> to be:</p>
    <p><m>SE(\hat{p}_1 - \hat{p}_2) = \sqrt{\hat{p}(1-\hat{p})(\frac{1}{n_1} + \frac{1}{n_2})}</m></p>

<p>Use these theoretical results to suggest the general <em>formula</em> for a standardized statistic and a method for calculating a p-value to test <m>H_0: \pi_1 - \pi_2 = 0</m> (also expressed as <m>H_0: \pi_1 = \pi_2</m>) versus the alternative <m>H_a: \pi_1 - \pi_2 &lt; 0</m> (or <m>H_a: \pi_1 &lt; \pi_2</m>). (This is referred to as the <term>two-sample z-test</term><idx><h>two-sample z-test</h></idx> or <term>two proportion z-test</term><idx><h>two proportion z-test</h></idx>.)</p>

    <exercise xml:id="inv3-1-u">
      <title>Standardized Statistic Formula</title>
      <statement>
        <p>standardized statistic = z = (observed-hypothesized)/(standard error) =</p>
      </statement>
      <solution><p>z = <m>\frac{\hat{p}_1 - \hat{p}_2 - 0}{\sqrt{\hat{p}(1-\hat{p})(\frac{1}{n_1} + \frac{1}{n_2})}}</m></p></solution>
      <response/>
    </exercise>

      
    <exercise xml:id="inv3-1-v">
      <title>Calculate <m>z</m>-statistic</title>
      <statement>
        <p>Calculate and interpret the value of the standardized statistic specified in the previous question as applied to the hearing loss study.</p>
        <p><m>\hat{p}_{94} - \hat{p}_{06} =</m> <var width="10"/></p>
        <p><m>\hat{p} =</m> <var width="10"/></p>
        <p><m>SE(\hat{p}_{94} - \hat{p}_{06}) =</m> <var width="10"/></p>
        <p>standardized statistic: <m>z =</m> <var width="10"/></p>
        <p>interpretation:</p>
        <p><var width="60" height="3"/></p>
      </statement>
      <solution>
        <p><m>\hat{p}_{94} - \hat{p}_{06}</m> = -0.024</p>
        <p><m>\hat{p}</m> = 0.173</p>
        <p>SE(<m>\hat{p}_{94} - \hat{p}_{06}</m>) = <m>\sqrt{.173(1-.173)(\frac{1}{2928} + \frac{1}{1771})}</m> = 0.0113</p>
        <p>standardized statistic: z = <m>\frac{-0.024-0}{0.0113}</m> = -2.12</p>
        <p>Interpretation: Our <m>\hat{p}_1 - \hat{p}_2</m> (-0.024) is 2.12 standard errors below the mean (<m>\pi_1 - \pi_2 = 0</m>)</p>
      </solution>
      <response/>
    </exercise>

    <exercise xml:id="inv3-1-w">
      <title>Compare SE</title>
      <statement>
        <p>Is the standard error close to the empirical standard deviation from your simulation results?</p>
        <p><var width="60" height="3"/></p>
      </statement>
      <solution><p>yes (.0113 vs. .011 for example)</p></solution>
      <response/>
    </exercise>

    <exercise xml:id="inv3-1-x">
      <title>Theoretical p-value</title>
      <aside>
        <title>Normal Probability Calculator applet</title>
        <p><url href="https://www.rossmanchance.com/applets/2021/normcalc/normcalc.htm" visual="rossmanchance.com/applets/2021/normcalc/normcalc.htm">Normal Probability Calculator applet</url></p>
      </aside>
      <statement><p>Use technology to compute the p-value for this standardized statistic using the standard normal distribution and compare it to your simulation results.</p>
      <var width = "10"/></statement>
      <solution><p>P(Z &lt; -2.12) ≈ 0.017, should be in the ballpark of your simulation results</p></solution>
      <response/>
    </exercise>

  </paragraphs>

  <paragraphs>
    <title>Case 2</title>
    <p> When calculating confidence intervals, we make no assumptions about the populations (for example, when we are not testing a particular null hypothesis but only estimating the parameter, we do not assume a common value for <m>\pi</m>). So we will use a different formula to approximate the standard deviation of <m>\hat{p}_1 - \hat{p}_2</m>:</p>
    <p><m>SE(\hat{p}_1 - \hat{p}_2) = \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}</m></p>

    <exercise xml:id="inv3-1-y">
      <title>CI Standard Error</title>
      <statement>
        <p>Calculate this version of the standard error. Is it much different from what you calculated in <xref ref="inv3-1-v" text="custom">question 22</xref>?</p>
        <p><var width="60" height="5"/></p>
      </statement>
      <solution>
        <p>SE(<m>\hat{p}_{94} - \hat{p}_{06}</m>) = <m>\sqrt{\frac{.164(1-.164)}{2928} + \frac{.188(1-.188)}{1771}}</m> = 0.0115</p>
        <p>This is  similar to the pooled SE of 0.0113.</p>
      </solution>
      <response/>
    </exercise>

    <exercise xml:id="inv3-1-z">
      <title>95% Confidence Interval</title>
      <statement><p>Calculate and interpret a 95% confidence interval to compare hearing loss of American teenagers in these two years. Is this confidence interval consistent with your test of significance? Why is it theoretically possible the interval would not be consistent with the test of significance?</p></statement>
      <solution>
        <p>estimate ± (critical value)(standard error)</p>
        <p><m>\hat{p}_1 - \hat{p}_2 \pm z^*\sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}</m></p>
        <p>-0.024 ± 1.96<m>\sqrt{\frac{.163(1-.163)}{2928} + \frac{.188(1-.188)}{1771}}</m> = (-0.047, -0.001)</p>
        <p>We are 95% confident that the population proportion with at least some hearing loss in 2006 is 0.001 to 0.047 larger than the population proportion with at least some hearing loss in 1994. This interval is consistent with our test because all of the values are negative (we rejected zero as a plausible value for the difference in population proportions in favor of the alternative that the probability of hearing loss was now larger). Technically we should adjust this comparison for the one-sided nature of the significance test. For example, the two-sided p-value would be 0.034, so we expect zero to not be included in the confidence interval for any confidence level of 96.6% or less.</p>
      </solution>
      <response/>
    </exercise>

    <insight><p>It is technically incorrect to say there has been a 0.15% to 4.67% increase in hearing loss from 1994 to 2006, because "percentage change" implies a multiplication of values, not an addition or subtraction as we are considering here. It would be acceptable to say that the increase is between 0.15 and 4.67 <em>percentage points</em>.</p></insight>

    <assemblage>
      <title>Technical Conditions</title>
      <p>The above Central Limit Theorem holds when the populations are much larger than the samples (e.g., more than 20 times the sample size) and when the sample size is large. We will consider the latter condition met when we have at least 5 successes and at least 5 failures in each sample (so there are four numbers to check).</p>
    </assemblage>

    <p><alert>Note:</alert> A "Wilson adjustment" can be used with this confidence interval similar to the Plus Four Method from Chapter 1, this time putting one additional success and one additional failure in each sample. This adjustment will be most useful when the sample proportions are close to 0 or 1 (that is when the sample size conditions above are not met).</p>

    <exercise xml:id="inv3-1-aa">
      <title>Conclusion</title>
      <statement><p>Summarize your conclusions from this study. Be sure to address statistical significance, statistical confidence, and the populations you are willing to generalize the results to. Also, are you willing to conclude that the change in the <em>prevalence</em> of hearing loss is due to the increased use of ear buds among teenagers between 1994 and 2006? Explain why or why not.</p></statement>
      <solution>
        <p>The change in the likelihood of some hearing loss in these two samples is statistically significant (p-value = 0.017 from z-test) and we are 95% confident that the population proportion is 0.001 to 0.047 higher "now" than before among all American teenagers (representative samples by NHANES).</p>
        <p>NOTE: The adjective "statistically significant" (didn't happen by chance alone) applies to the sample data, not the population data.</p>
      </solution>
      <response/>
    </exercise>

  </paragraphs>

    <assemblage>
      <title>Study Conclusions</title>
      <p>We have moderate evidence against the null hypothesis (p-value <m>\approx 0.02</m>, meaning we would get a difference in sample proportions <m>\hat{p}_1 - \hat{p}_2</m> as small as <m>-0.024</m> or smaller in about 1.7% of random samples from two populations with <m>\pi_1 = \pi_2</m>). We are 95% confident that the population proportion with some hearing loss is between 0.0015 and 0.047 higher "now" than ten years ago. We feel comfortable drawing these conclusions about the populations the NHANES samples were selected from as they were random samples from each population (and there was no overlap in the populations between these two time periods). However, there are many things that have changed during this time period, and it would not be reasonable to attribute this increase in hearing loss exclusively to the use of ear buds.</p>
    </assemblage>
    
    </exercises>

  <subsection xml:id="practice3-1A">
    <title>Practice Problem 3.1A</title>

    <p>In a follow-up study, <url href="https://jamanetwork.com/journals/jamapediatrics/fullarticle/2606596">Su &amp; Chan (2017)</url> examined hearing loss data for 1165 participants from the 2009-2010 National Health and Nutrition Examination Survey to see whether this trend has continued. They estimate the prevalence (after adjusting for a non-simple random sample and weighting the data to be representative of the population) of some hearing loss to be 0.152. If we treat this as a sample proportion, is this significantly different from the 2005-6 data?</p>

    <exercise xml:id="practice-3-1-a">
      <statement>
        <p>Analyze whether the 2009-2010 data is significantly different from the 2005-6 data.</p>
      </statement>
      <response/>
    </exercise>
  </subsection>

  <subsection xml:id="practice3-1B">
    <title>Practice Problem 3.1B</title>

    <p>In <xref ref="practice1-1B" text="custom">Practice Problem 1.1B</xref>, you considered data on the first 3 months of the Premier soccer league in 2019 (pre-Covid) and in 2020 (during Covid, when no fans were allowed). Consider these observations as random samples from independent processes. In 2019, the home team won 54 of the first 88 games and in 2020, the home team won 40 of 87 matches.</p>

    <exercise xml:id="practice-3-1-b-a">
      <title>Two-Way Table</title>
      <statement>
        <p>Create the two-way table for comparing these samples to each other. Calculate and interpret the difference in conditional proportions.</p>
      </statement>
      <response/>
    </exercise>

    <exercise xml:id="practice-3-1-b-b">
      <title>Hypotheses</title>
      <statement>
        <p>Specify appropriate null and alternative hypothesis, being clear how these hypotheses change from Chapter 1. Are you using a one-sided or two-sided alternative?</p>
      </statement>
      <response/>
    </exercise>

    <exercise xml:id="practice-3-1-b-c">
      <title>Simulation</title>
      <statement>
        <p>Use the <url href="https://www.rossmanchance.com/applets/2021/twopopprop/twopopprop.html?hideExtras=1">Comparing Two Population Proportions applet</url> to carry out a simulation. What are you using for the common probability of success? Which values do you count for the p-value? What do you conclude?</p>
      </statement>
      <response/>
    </exercise>

    <exercise xml:id="practice-3-1-b-d">
      <title>Technical Conditions</title>
      <statement>
        <p>Are the technical conditions met to calculate the two-sample <m>z</m>-interval for these data? Explain.</p>
      </statement>
      <response/>
    </exercise>

    <exercise xml:id="practice-3-1-b-e">
      <title>Confidence Interval</title>
      <statement>
        <p>Calculate and interpret a 95% confidence interval from these data.</p>
      </statement>
      <response/>
    </exercise>

    <p>Note: Data are "stacked" if each column represents a different variable (e.g., year surveyed and hearing condition) and they are "unstacked" if each column represents a different group (e.g., 1998 and 2002).</p>
  </subsection>

    <paragraphs>
      <title>Technology Detour – Two-sample z-procedures</title>
      
      <hint>
        <title>Theory-Based Inference applet</title>
        <p>In Theory-Based Inference applet</p>
        <p><ul>
          <li><p>Select Two proportions</p></li>
          <li><p>Check the box to paste in 2 columns of data (stacked or unstacked) and press Use data or specify the sample sizes and either the sample counts or the sample proportions and press Calculate.</p></li>
          <li><p>For the test, check the box for Test of Significance Keep the hypothesized difference at zero and set the direction of the alternative, press Calculate.</p></li>
          <li><p>For the confidence interval, check the box, specify the confidence level and press Calculate CI</p></li>
        </ul></p>
        <sidebyside widths="45% 45%">
          <image source="images/Inv3.1TBI1.png"/>
          <image source="images/Inv3.1TBI2.png"/>
        </sidebyside>
      </hint>
      <hint>
        <title>R Instructions</title>
        <p>The <c>iscamtwopropztest</c> function takes the following inputs:</p>
        <p><ul>
          <li><p><c>x1</c> = either the number of successes or sample proportion for first group</p></li>
          <li><p><c>n1</c> = sample size for first group</p></li>
          <li><p><c>x2</c> = count or proportion for second group</p></li>
          <li><p><c>n2</c> = sample size for second group</p></li>
          <li><p><c>hypothesized</c> = hypothesized difference (default is 0)</p></li>
          <li><p><c>alternative</c> = "less", "greater", or "two.sided" for the direction of the alternative hypothesis</p></li>
          <li><p><c>conf.level</c> = the confidence level (e.g., 0.95 for 95%)</p></li>
        </ul></p>
        
        <p>For the hearing loss study:</p>
        <sage language="r">
          <input>
<![CDATA[
# Load ISCAM functions from GitHub
source("https://raw.githubusercontent.com/iambethchance/iscam-runestone/master/ISCAM-functions.R");

# Two-sample z-test: 480 successes out of 2928 in 1994, 333 out of 1771 in 2006
# Testing if proportion in 1994 is less than proportion in 2006
iscamtwopropztest(x1=480, n1=2928, x2=333, n2=1771, 
                  hypothesized=0, alternative="less", conf.level=0.95)
]]>
          </input>
        </sage>
        <p>This finds the p-value for a one-sided alternative as well as a 95% confidence interval for <m>\pi_1-\pi_2</m>.</p>
      </hint>
      <hint>
        <title>JMP Instructions</title>
        <sidebyside widths="50% 45%" valign="top">
          <stack>
            <p><ul>
              <li><p><em>With raw data or after specifying the two-way table in column format</em>, select <term index="no">Analyze > Fit Y by X</term> and specify the categorical response variable (Y, Response) and the categorical explanatory variable (X, Factor)</p></li>
              <li><p><ul><li>Specify the counts if using a two-way table (and "year" is seen as a categorical variable)</li></ul></p></li>
              <li><p>Press OK.</p></li>
            </ul></p>
          </stack>
          <image source="images/Inv3.1JMP1.png"/>
        </sidebyside>
        
        <p><ul>
          <li>The p-value in the Pearson row matches a two-sided z-test.</li>
          <li>For a confidence interval, use the hot spot to select Two Sample Test for Proportions</li>
        </ul></p>
        <p><em>Note:</em> Here you can change which outcome is considered success. This also reports an "adjusted Wald" p-value</p>
        
        <sidebyside widths="50% 45%" valign="top">
          <stack>
            <p><ul>
              <li><p><em>With summary data</em> use the <url href="http://www.rossmanchance.com/iscam3/data/ISCAM_Journal.jrn">ISCAM Journal file</url>: Hypothesis Test for Two Proportions</p></li>
              <li><p>Specify the form of the alternative hypothesis</p></li>
              <li><p>Enter the number of successes and the sample sizes</p></li>
            </ul></p>
            <p>(This works for raw data too, but be careful how you specify the explanatory and response variables and use "pooled estimate of variance." This reports the <em>z</em>-score as well.)</p>
          </stack>
          <image source="images/Inv3.1JMP2.png"/>
        </sidebyside>
      </hint>
    </paragraphs>

    <paragraphs xml:id="tech-detour-simulation-proportions">
      <title>Technology Detour – Simulating Proportions from Independent Random Samples</title>
      
      <p>Simulation Steps:</p>
      <p><ol>
        <li><p>Generate a random sample of 2928 observations from a binomial process with <m>\pi = .173</m></p></li>
        <li><p>Generate a random sample of 1771 observations from a binomial process with <m>\pi = .173</m></p></li>
        <li><p>Convert the sample counts into sample proportions</p></li>
        <li><p>Calculate the difference in the sample proportions</p></li>
        <li><p>Repeat steps 1-4 a large number of times.</p></li>
      </ol></p>
      <p>You should explore the individual <m>\hat{p}</m> distributions but most focus on the distribution of <m>\hat{p}_1 - \hat{p}_2</m>, including the mean, standard deviation, and whether the distribution behaves like a normal distribution.</p>
      <hint>
        <title>R Instructions</title>
        <p>Generate a random sample for 1994:</p>
        <sage language="r">
          <input>
<![CDATA[
count1994 = rbinom(1, size = 2928, prob = .173)
count1994  # Displays the results
]]>
          </input>
        </sage>
        <p>Generate 1000 random samples from each year, calculate the proportions, find the differences:</p>
        <sage language="r">
          <input>
<![CDATA[
# Divides number of successes by n to get sample proportions (X/n)
phat94 = rbinom(1000, 2928, .173)/2928
phat06 = rbinom(1000, 1771, .173)/1771
phatdiffs = phat94 - phat06  # You now have 1000 differences
head(phatdiffs)  # Show first few differences
]]>
          </input>
        </sage>
        <p>Display the generated distributions:</p>
        <sage language="r">
          <input>
<![CDATA[
par(mfrow=c(3,1))  # Creates 3 rows in graph window
hist(phat94, main="Distribution of phat94", xlab="phat94")
hist(phat06, main="Distribution of phat06", xlab="phat06")
hist(phatdiffs, labels=T, main="Distribution of Differences", xlab="phat94 - phat06")
invisible()  # Suppress any remaining output
]]>
          </input>
        </sage>
        <sage language="r">
          <input>
<![CDATA[
cat("Mean phat94:", mean(phat94), "\n")
cat("Mean phat06:", mean(phat06), "\n")
cat("Mean phatdiffs:", mean(phatdiffs), "\n")
cat("SD phat94:", sd(phat94), "\n")
cat("SD phat06:", sd(phat06), "\n")
cat("SD phatdiffs:", sd(phatdiffs), "\n")
]]>
          </input>
        </sage>
        <p>Compare to a normal distribution:</p>
        <sage language="r">
          <input>
<![CDATA[
# Load ISCAM functions from GitHub
source("https://raw.githubusercontent.com/iambethchance/iscam-runestone/master/ISCAM-functions.R");

# Histogram with normal curve overlay
iscamaddnorm(phatdiffs, main="Distribution of Differences", xlab="phat1 - phat2")
]]>
          </input>
        </sage>
      </hint>
      <hint>
        <title>JMP Instructions</title>
        <p>Generate a random sample for 1994:</p>
        <p><ul>
          <li><p>In an empty Data window, select <term index="no">Cols > New Column<term>. 
          Name the column count1994, and specify 1 row. Create a formula and select <term index="no">Random > Random Binomial</term>. Specify <em>n</em> = 2928 and <em>p</em> = 0.173. Press <term index="no">OK</term></p></li>
        </ul></p>
        <p>Generate 1000 random samples from each year, calculate the proportions, find the differences:</p>
        <p><ul>
          <li><p>Create a new column but specify 1000 as the number of rows and repeat the above commands. (After creating the first column, you can double click on a second column to activate it, and then right click to open the formula editor.)</p></li>
          <li><p>Then create a new column/formula where you compute the difference in the proportions: count1994/2928 – count2006/1771. Call this column diff.</p></li>
        </ul></p>
        <p>Display the generated distributions:</p>
        <p><ul>
          <li><p>Choose <term index="no">Analyze > Distribution</term> and specify the differences column.</p></li>
          <li><p>Create a new column with a "conditional if" formula for diff <m>\leq</m> -0.024 ("true" or "false"). Then use <term index="no">Analyze > Distribution</term> to tally this column.</p></li>
        </ul></p>
        <p>Compare to a normal distribution:</p>
        <p><ul>
          <li><p>Use the diff hot spot to select <term index="no">Continuous Distribution > Normal</term> and to select <term index="no">Normal Quantile Plot</term>.</p></li>
        </ul></p>
      </hint>
    </paragraphs>
</section>
