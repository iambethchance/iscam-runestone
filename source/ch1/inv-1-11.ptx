<?xml version="1.0" encoding="UTF-8"?>
<section xml:id="investigation-1-11">
<title>Investigation 1.11: Ganzfeld Experiments</title>
<introduction>
<p><em>An important first step of designing a study is determining whether you have enough observations to be able to detect the effect of interest.</em></p>
</introduction>
<exercises xml:id="investigation1-11" hidden-label="yes">
    <title>The Study</title>
    
    <p>
      Statistician Jessica Utts has conducted extensive analysis of studies that have investigated psychic functioning. (Combining results across multiple studies, often to increase power, is called meta-analysis.) Utts (<url href="https://www.ics.uci.edu/~jutts/air.pdf" visual="ics.uci.edu/~jutts">1995</url>) cites research from Bem and Honorton (<url href="https://koestlerunit.wordpress.com/wp-content/uploads/2015/06/bem-honorton-1994.pdf">1994</url>) that analyzed studies that used a technique called ganzfeld.
    </p>
    
    <p>
      In a typical ganzfeld experiment, a "receiver" is placed in a room relaxing in a comfortable chair with halved ping-pong balls over the eyes, having a red light shone on them. The receiver also wears a set of headphones through which [static] noise is played. The receiver is in this state of mild sensory deprivation for half an hour. During this time, a "sender" observes a randomly chosen target and tries to mentally send this information to the receiver <ellipsis/> The receiver is taken out of the ganzfeld state and given a set of [four] possible targets, from which they must decide which one most resembled the images they witnessed. Most commonly there are three decoys along with a copy of the target itself. [<url href="http://en.wikipedia.org/wiki/Ganzfeld_experiment" visual="wikipedia.org">Wikipedia</url>]
    </p>
    
    <p>
      Utts has stated that she believes there is convincing evidence of ESP but that the effect is small. 
    </p>

    <exercise xml:id="I1-11-a" label="I1.11a">
      <title>State Hypotheses for ESP Study</title>
      <statement>
        <p>
          Suppose you want to test whether the subjects in these studies have ESP, with <m>\pi</m> equal to the actual probability that receivers identify the correct image among the four possible targets. State appropriate null and alternative hypotheses by specifying correct symbols and values.
        </p>
      <hint>
        <p>
          If there is no ESP, what would be the probability of correctly identifying the image by chance alone among four choices?
        </p>
      </hint>
      </statement>
      <setup>
        <!-- H0: Blank 1 - parameter symbol -->
        <var>
          <condition string="^\s*(\\pi|π|pi)\s*$">
            <feedback><p>Correct! Use <m>\pi</m> for the parameter.</p></feedback>
          </condition>
          <condition string="^\s*p\s*$">
            <feedback><p>Use the parameter <m>\pi</m>, not the statistic <m>p</m>.</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Use <m>\pi</m> for the parameter.</p></feedback>
          </condition>
        </var>
        
        <!-- H0: Blank 2 - equals sign -->
        <var>
          <condition string="^\s*=\s*$">
            <feedback><p>Correct! The null hypothesis uses equality.</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>The null hypothesis uses the equals sign (=).</p></feedback>
          </condition>
        </var>
        
        <!-- H0: Blank 3 - value -->
        <var>
          <condition string="^\s*0\.25\s*$">
            <feedback><p>Correct! If guessing randomly among 4 choices, the probability is 0.25.</p></feedback>
          </condition>
          <condition string="^\s*(1/4|\.25|25%)\s*$">
            <feedback><p>Correct idea! Express as a decimal: 0.25</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>What's the probability of guessing correctly among 4 choices?</p></feedback>
          </condition>
        </var>
        
        <!-- Ha: Blank 4 - parameter symbol -->
        <var>
          <condition string="^\s*(\\pi|π|pi)\s*$">
            <feedback><p>Correct! Use <m>\pi</m> for the parameter.</p></feedback>
          </condition>
          <condition string="^\s*p\s*$">
            <feedback><p>Use the parameter <m>\pi</m>, not the statistic <m>p</m>.</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Use <m>\pi</m> for the parameter.</p></feedback>
          </condition>
        </var>
        
        <!-- Ha: Blank 5 - greater than sign -->
        <var>
          <condition string="^\s*(>|&gt;)\s*$">
            <feedback><p>Correct! We're testing if ESP makes the probability greater than chance.</p></feedback>
          </condition>
          <condition string="^\s*=\s*$">
            <feedback><p>Are we testing for ESP (better than chance) or just random guessing?</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>We're testing if the probability is greater than (>) the chance value.</p></feedback>
          </condition>
        </var>
        
        <!-- Ha: Blank 6 - value -->
        <var>
          <condition string="^\s*0\.25\s*$">
            <feedback><p>Correct! We're testing against the same value as the null hypothesis.</p></feedback>
          </condition>
          <condition string="^\s*(1/4|\.25|25%)\s*$">
            <feedback><p>Correct idea! Express as a decimal: 0.25</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Use the same probability value as in the null hypothesis.</p></feedback>
          </condition>
        </var>
      </setup>
      <statement>
        <p>
          <m>H_0</m>: <var width="5"/> <var width="5"/> <var width="10"/>
        </p>
        <p>
          <m>H_a</m>: <var width="5"/> <var width="5"/> <var width="10"/>
        </p>
      </statement>
      <solution>
        <p>
          <m>H_0: \pi = 0.25</m> (The receivers are just guessing randomly among the four targets)
        </p>
        <p>
          <m>H_a: \pi > 0.25</m> (The receivers have some psychic ability to identify the correct target)
        </p>
      </solution>
    </exercise>

    <exercise xml:id="I1-11-b" label="I1.11b">
      <title>Check CLT and Describe Null Distribution</title>
      <statement>
        <p>
          The Bem and Honorton study reports on 329 sessions. Is this a large enough sample size to employ the Central Limit Theorem? Report the predicted mean and standard deviation of the null distribution of sample proportions.
        </p>
     <hint>
        <p>
          Check whether <m>n\pi \geq 10</m> and <m>n(1-\pi) \geq 10</m>.
        </p>
      </hint>
      </statement>
      <setup>
        <var>
          <condition string="^\s*[Yy]es\s*$">
            <feedback><p>Correct! The sample size is large enough for the CLT.</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Check whether both <m>n\pi \geq 10</m> and <m>n(1-\pi) \geq 10</m>.</p></feedback>
          </condition>
        </var>
        <var>
          <condition number="0.25">
            <feedback><p>Correct! The mean of the null distribution is <m>\pi = 0.25</m>.</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>The mean equals the hypothesized value of <m>\pi</m>.</p></feedback>
          </condition>
        </var>
        <var>
          <condition number="0.02387" tolerance="0.0001">
            <feedback><p>Correct! The standard deviation is <m>\sqrt{\frac{0.25(0.75)}{329}} \approx 0.02387</m>.</p></feedback>
          </condition>
          <condition number="0.0239" tolerance="0.0002">
            <feedback><p>Close! A more precise value is 0.02387.</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Use the formula <m>\sqrt{\frac{\pi(1-\pi)}{n}}</m>.</p></feedback>
          </condition>
        </var>
      </setup>
      <statement>
        <p>
          Large enough for CLT? <var width="10"/>
        </p>
        <p>
          Mean: <var width="10"/>
        </p>
        <p>
          Standard deviation: <var width="10"/>
        </p>
       </statement>
      <solution>
        <p>
          The sample size is large enough because <m>n\pi = 329(0.25) = 82.25 > 10</m> and <m>n(1-\pi) = 329(0.75) = 246.75 > 10</m>.
        </p>
        <p>
          We expect the distribution of sample proportions to be approximately normal with mean <m>\mu_{\hat{p}} = 0.25</m> and standard deviation <m>\text{SD}(\hat{p}) = \sqrt{\frac{0.25(0.75)}{329}} \approx 0.02387</m>.
        </p>
      </solution>
    </exercise>

    <p>
      In <xref ref="investigation-1-3" text="custom">Investigation 1.3</xref>, you determined that if someone was asked to choose among 5 symbols in 10 rounds, they would need to correctly identify 5 or more of the symbols to produce a p-value below 0.05 and be at least two standard deviations away from the expected 2 correct identifications. The result "5 or more correct" is often called the rejection region (the values of the statistic that lead us to reject the null hypothesis).
    </p>

    <assemblage xml:id="rejection-region-definition">
      <title>Definition</title>
      <p>
        The <term>rejection region</term> consists of the values we would need to observe for the statistic in the study in order to be willing to reject the null hypothesis.
      </p>
    </assemblage>
 <p>
          According to the distribution in <xref ref="I1-11-b" text="custom">Question 2</xref>, what proportion of the 329 sessions would need to be successful ("hits"), in order to reject the null hypothesis in <xref ref="I1-11-a" text="custom">Question 1</xref> in favor of the alternative hypothesis at the 5% level of significance?
        </p>
        <p>
          In the <url href="https://www.rossmanchance.com/applets/2021/power/power.html?hideExtras=1" visual="rossmanchance.com/applets/2021/power/power.html">Power Simulation applet</url>:
        </p>
  <p>
          <ul>
            <li><p>Specify the <alert>Hypothesized probability of success</alert>: 0.25</p></li>
            <li><p>Specify the <alert>Sample size</alert>: 329</p></li>
            <li><p>Specify the <alert>Number of repetitions</alert>: 1000</p></li>
            <li><p>Press <alert>Draw Samples</alert></p></li>
            <li><p>Choose <alert>Proportion of successes</alert> as the statistic</p></li>
            <li><p>Use the pull-down menu to set the <alert>Level of Significance</alert> to 0.05</p></li>
            <li><p>Press <alert>Count</alert></p></li>
            <li><p>Check the <alert>Normal Approximation</alert> and <alert>Summary Stats</alert> boxes to verify <xref ref="I1-11-b" text="custom">Question 2</xref></p></li>
          </ul>
        </p>
        <interactive iframe="https://www.rossmanchance.com/applets/2021/power/power.html?hideExtras=1" width="160%" aspect="3:2"/>
       
    <exercise xml:id="I1-11-c" label="I1.11c">
      <title>Find Rejection Region</title>
      <statement>
        <p>
          Report the rejection region found by the applet and include a one-sentence interpretation of this region.
        </p>
      </statement>
      <setup>
        <var>
          <condition string="^\s*(p\s*hat|p-hat|phat|\\hat\{p\}|\\hat\{?p\}?|p\^)\s*(>|>=|≥|&gt;=)\s*0?\.289\s*$">
            <feedback><p>Correct! The rejection region is <m>\hat{p} \geq 0.289</m>.</p></feedback>
          </condition>
          <condition string=".*(0?\.289|289|29%).*">
            <feedback><p>You have the right value. Make sure to include the inequality symbol and <m>\hat{p}</m>.</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Report the rejection region in the form <m>\hat{p} \geq</m> [value].</p></feedback>
          </condition>
        </var>
        <var>
          <condition string="^.+$" correct="yes">
            <feedback><p>Your answer has been saved.</p></feedback>
          </condition>
          <condition string="^\s*$" correct="no">
            <feedback><p>Please enter your interpretation.</p></feedback>
          </condition>
        </var>
      </setup>
      <statement>
        <p>
          Rejection region: <var width="50"/>
        </p>
        <p>
          Interpretation: <var width="60"/>
        </p>
      </statement>
      <solution>
        <p>
          Rejection region: <m>\hat{p} \geq 0.289</m>
        </p>
        <p>
          Interpretation: Someone would have to get at least 28.9% of the trials correct to be in the top 5% of the distribution.
        </p>
        <image source="images/Inv1.11-csol1.png" width="80%">
          <description>Power applet showing null distribution with rejection region shaded at the 5% significance level</description>
        </image>
      </solution>
    </exercise>

    <assemblage xml:id="type-i-error-definition">
      <title>Definition</title>
      <p>
        A <term>Type I error</term> in a test of significance occurs when the null hypothesis is true but we decide to reject the null hypothesis. This type of error is sometimes referred to as a false positive or a "false alarm."
      </p>
    </assemblage>

    <exercise xml:id="I1-11-d" label="I1.11d">
      <title>Probability of Type I Error</title>
      <statement>
        <p>
          According to the applet, what is the (normal approximation) probability of making a Type I error in this study? How could you have known this in advance? (Note that the normal approximation is not required to correspond to an integer value for the rejection region.)
        </p>
      <hint>
        <p>
          What is the relationship between the Type I error probability and the significance level?
        </p>
      </hint>
      </statement>
      <response/>
      <solution>
        <p>
          By setting the level of significance to 0.05, we ensure the probability of a Type I error is at most 0.05.
        </p>
      </solution>
    </exercise>

    <p>
      While a Type I error focuses on the null hypothesis being true, what if the null hypothesis is false – how likely are we to make the correct decision to reject the null hypothesis?
    </p>

    <assemblage xml:id="type-ii-error-power-definitions">
      <title>Definitions</title>
      <p>
        A <term>Type II error</term> occurs when we fail to reject the null hypothesis even though the null hypothesis is false. This type of error is sometimes referred to as a false negative or a "missed opportunity."
      </p>
      <p>
        The <term>power</term> of a test when <m>\pi = \pi_a</m> is defined as the probability of (correctly) rejecting the null hypothesis assuming this specific alternative value for the parameter. Thus, power reveals how likely our test is to detect a specific difference (or improvement or effect) that really is there.
      </p>
      <p>
        Note: Power = 1 – P(Type II error)
      </p>
    </assemblage>

    <exercise xml:id="I1-11-e" label="I1.11e">
      <title>Describe Alternative Distribution</title>
      <statement>
        <p>
          Suppose the probability of identifying the correct symbol is actually 0.30. Describe how the distribution of sample proportions will differ from <xref ref="I1-11-b" text="custom">Question 2</xref>.
        </p>
      <hint>
        <p>
          What will the mean and standard deviation be when <m>\pi = 0.30</m>?
        </p>
      </hint>
      </statement>
      <response/>
      <solution>
        <p>
          With <m>\pi = 0.30</m>, the mean changes to 0.30 and the standard deviation changes to <m>\sqrt{0.30(0.70)/329} \approx 0.0253</m>.
        </p>
      </solution>
    </exercise>

        <p>
          In the applet:
        </p>
        <p>
          <ul>
            <li><p>Change the <alert>Alternative probability of success</alert> value to 0.30</p></li>
            <li><p>Check the <alert>Show alternative</alert> box</p></li>
            <li><p>Press <alert>Draw Samples</alert></p></li>
            <li><p>Press <alert>Count</alert></p></li>
          </ul>
        </p>

    <exercise xml:id="I1-11-f" label="I1.11f">
      <title>Interpret Output </title>
      <statement>
        <p>
          Review the applet output and provide a one-sentence interpretation of the normal approximation value, 0.6645.
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          If we test <m>\pi = 0.25</m> but in reality <m>\pi = 0.30</m>, we will correctly reject the null hypothesis in favor of the one-sided alternative in about 66% of random samples of size n = 329. So the power of this test is approximately 0.66.
        </p>
        <image source="images/Inv1.11-fsol1.png" width="80%">
          <description>Power applet showing null and alternative distributions with power calculation for π = 0.30</description>
        </image>
        <image source="images/Inv1.11-fsol2.png" width="80%">
          <description>Additional power applet output showing detailed statistics for π = 0.30</description>
        </image>
      </solution>
    </exercise>

    <exercise xml:id="I1-11-f2" label="I1.11f2">
      <title>Identify Type of Probability</title>
      <statement>
        <p>
          Is the value 0.6645 the probability of a Type II error or the power of the test?
        </p>
      </statement>
      <choices randomize="yes">
        <choice>
          <statement><p>Probability of Type II error</p></statement>
        </choice>
        <choice correct="yes">
          <statement><p>Power of the test</p></statement>
        </choice>
        <choice>
          <statement><p>Neither</p></statement>
        </choice>
      </choices>
      <solution>
        <p>
          This value is the power of the test. Power = 1 - P(Type II error), so if power is 0.6645, then P(Type II error) = 1 - 0.6645 = 0.3355.
        </p>
      </solution>
    </exercise>

    <exercise xml:id="I1-11-g" label="I1.11g">
      <title>Calculate Power for π = 0.35</title>
      <statement>
        <p>
          Now use the applet to find the probability of rejecting the null hypothesis that <m>\pi = 0.25</m> when in reality <m>\pi = 0.35</m>? Explain your steps. How has the probability changed and why?
        </p>
      </statement>
      <setup>
        <var>
          <condition number="0.99" tolerance="0.01">
            <feedback><p>Correct! The power is approximately 0.99 when <m>\pi = 0.35</m>.</p></feedback>
          </condition>
          <condition number="0.99" tolerance="0.02">
            <feedback><p>Close! The power is approximately 0.99.</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Use the applet with alternative probability 0.35 and check the power value.</p></feedback>
          </condition>
        </var>
      </setup>
      <statement>
        <p>
          Power: <var width="10"/>
        </p>
        <p>
          Explanation: <var width="60"/>
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          Power when <m>\pi = 0.35</m>: approximately 0.99
        </p>
        <p>
          If the alternative value changes to 0.35, then the power increases to about 0.99. This makes sense because when the true parameter is farther from the null hypothesis value (0.35 vs 0.30), it becomes easier to detect the difference, so we have a higher probability of correctly rejecting the null hypothesis.
        </p>
        <image source="images/Inv1.11-gsol.png" width="80%">
          <description>Power applet showing null and alternative distributions with power calculation for π = 0.35</description>
        </image>
      </solution>
    </exercise>
<ul><li>Change the level of significance from 0.05 to 0.01 and press <alert>Count</alert>. </li></ul>
    <exercise xml:id="I1-11-h" label="I1.11h">
      <title>Effect of Changing Significance Level</title>
      <statement>
        <p>
          How does lowering the level of significance from 0.05 to 0.01 influence each of the following? 
        </p>
      </statement>
      <setup>
        <var>
          <condition string="^\s*[Ii]ncreases?\s*$">
            <feedback><p>Correct! The rejection region becomes more extreme (larger cutoff value).</p></feedback>
          </condition>
          <condition string="^\s*[Dd]ecreases?\s*$">
            <feedback><p>Think about it: with a lower significance level, we need more extreme values to reject. Does the cutoff move toward or away from the null value?</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Enter: increases, decreases, or no change</p></feedback>
          </condition>
        </var>
        <var>
          <condition string="^\s*[Dd]ecreases?\s*$">
            <feedback><p>Correct! Type I error probability equals the significance level, so it decreases to 0.01.</p></feedback>
          </condition>
          <condition string="^\s*[Ii]ncreases?\s*$">
            <feedback><p>Remember: P(Type I error) = significance level.</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Enter: increases, decreases, or no change</p></feedback>
          </condition>
        </var>
        <var>
          <condition string="^\s*[Ii]ncreases?\s*$">
            <feedback><p>Correct! With a stricter rejection criterion, we're less likely to reject H₀, even when it's false.</p></feedback>
          </condition>
          <condition string="^\s*[Dd]ecreases?\s*$">
            <feedback><p>Think about it: if we make it harder to reject H₀, what happens to our chance of failing to reject when H₀ is false?</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Enter: increases, decreases, or no change</p></feedback>
          </condition>
        </var>
        <var>
          <condition string="^\s*[Dd]ecreases?\s*$">
            <feedback><p>Correct! Power = 1 - P(Type II error), so power decreases when P(Type II error) increases.</p></feedback>
          </condition>
          <condition string="^\s*[Ii]ncreases?\s*$">
            <feedback><p>Remember: Power = 1 - P(Type II error). What happened to P(Type II error)?</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Enter: increases, decreases, or no change</p></feedback>
          </condition>
        </var>
      </setup>
      <statement>
        <p>
          Rejection region: <var width="7"/> (The cutoff value of the statistic becomes: larger, smaller, no change)
        </p>
        <p>
          Probability of Type I Error: <var width="7"/> (increases, decreases, no change)
        </p>
        <p>
          Probability of Type II Error: <var width="7"/> (increases, decreases, no change)
        </p>
        <p>
          Power (assuming <m>\pi_a = 0.35</m>): <var width="7"/> (increases, decreases, no change)
        </p>
      </statement>
      <solution>
        <p>
          Rejection region: increases (becomes more extreme/larger); approximately <m>\hat{p} \geq 0.3055</m>
        </p>
        <p>
          Probability of Type I Error: decreases to match 0.01
        </p>
        <p>
          Probability of Type II Error: increases slightly to about 0.05
        </p>
        <p>
          Power (assuming <m>\pi_a = 0.35</m>): decreases slightly from about 0.99 to about 0.95
        </p>
      </solution>
    </exercise>

<paragraphs>
<p>
Suppose the study had only involved 35 sessions. Because the sample size is small, use of the Central Limit Theorem is questionable. 
</p>
<p>
<ul><li>Uncheck the <alert>Normal Approximation</alert> box and check the <alert>Exact Binomial</alert> box.</li>
<li> Specify a hypothesized probability of 0.25, an alternative probability of 0.35, and a level of significance of 0.05. </li>
</ul>
</p>
</paragraphs>
    <exercise xml:id="I1-11-i" label="I1.11i">
      <title>Small Sample Size with Exact Binomial</title>
      <setup>
        <var>
          <condition string="^\s*(p\s*hat|p-hat|phat|\\hat\{p\}|\\hat\{?p\}?|p\^)\s*(>|&gt;|>=|&gt;=)\s*0?\.4(0)?\s*$">
            <feedback><p>Correct! The rejection region is <m>\hat{p} > 0.40</m>.</p></feedback>
          </condition>
          <condition string=".*(0?\.4|40%|14|15).*">
            <feedback><p>You're on the right track. Express as <m>\hat{p} > 0.40</m> or report the number of successes (15 or more).</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Check the applet output for the rejection region when <m>n</m> = 35.</p></feedback>
          </condition>
        </var>
        <var>
          <condition number="0.036" tolerance="0.002">
            <feedback><p>Correct! The Type I error probability is approximately 0.036.</p></feedback>
          </condition>
          <condition number="0.036" tolerance="0.005">
            <feedback><p>Close! A more precise value is 0.036.</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Check the applet output for the exact probability of Type I error.</p></feedback>
          </condition>
        </var>
        <var>
          <condition number="0.32" tolerance="0.02">
            <feedback><p>Correct! The power is approximately 0.32 when <m>\pi_a = 0.35</m>.</p></feedback>
          </condition>
          <condition number="0.32" tolerance="0.05">
            <feedback><p>Close! The power is approximately 0.32.</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Check the applet output for the power with alternative <m>\pi = 0.35</m>.</p></feedback>
          </condition>
        </var>
      </setup>
      <statement>
        <p>
          Rejection region: <var width="30"/>
        </p>
        <p>
          Probability of Type I Error: <var width="7"/>
        </p>
        <p>
          Power (assuming <m>\pi_a = 0.35</m>): <var width="7"/>
        </p>
      </statement>
      <solution>
        <p>
          Rejection region: <m>\hat{p} &gt; 0.40</m> (or 15 or more successes out of 35)
        </p>
        <p>
          Probability of Type I Error: approximately 0.036
        </p>
        <p>
          Power (assuming <m>\pi_a = 0.35</m>): approximately 0.32
        </p>
        <p>
          Note: The probability of a Type II error is approximately 0.68.
        </p>
        <image source="images/Inv1.11-isols.png" width="80%">
          <description>Power applet showing exact binomial calculation for small sample size with n=35</description>
        </image>
      </solution>
    </exercise>

    <exercise xml:id="I1-11-j" label="I1.11j">
      <title>Compare Power for Different Sample Sizes</title>
      <statement>
        <p>
          How does the power in <xref ref="I1-11-i" text="custom">Question 10</xref> compare to what you found for power earlier? [<em>Hint:</em> see <xref ref="I1-11-f" text="custom">Question 7</xref>] Explain why this relationship makes intuitive sense.
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          The power is much smaller with the smaller sample size (about 32% vs 99%). This makes sense as there will be more sample-to-sample variation by chance alone with the smaller sample size, making it more difficult to distinguish observations coming from the two different distributions. In other words, there is more overlap in the two distributions and the probability of finding a sample proportion to convince us to reject the null hypothesis is smaller.
        </p>
      </solution>
    </exercise>

    <p>
      Many software packages will calculate power for you, especially with the normal approximation to the binomial.
    </p>

    <paragraphs xml:id="tech-detour-power">
      <title>Technology Detour <mdash/> Calculating Power</title>
      
      <p>
        Keep in mind the results will differ a bit if you use the binomial distribution/only allow discrete values to find the rejection region.
      </p>

      <exercise xml:id="tech-detour-power-combined" label="Power - Combined">
        <title>Calculate Power with Technology</title>
        <statement>
          <p>
            Use technology (R or JMP) to calculate power for a one proportion test. Choose one set of instructions below by clicking on a hint.
          </p>
        <hint>
          <title>R Instructions</title>
          <p>
            The <c>iscambinompower</c> and <c>iscamnormpower</c> functions use the following inputs:
          </p>
          <p>
            <ul>
              <li><p><c>LOS</c> = the desired level of significance (<m>\alpha</m>)</p></li>
              <li><p><c>n</c> = the sample size (number of trials)</p></li>
              <li><p><c>prob1</c> = the process probability (<m>\pi</m>) under the null hypothesis</p></li>
              <li><p><c>alternative</c> = "less", "greater", or "two.sided"</p></li>
              <li><p><c>prob2</c> = the alternative probability of success</p></li>
            </ul>
          </p>
          <p>
            For example: <c>iscamnormpower(LOS=.05, n=20, prob1=.25, alternative="greater", prob2=0.333)</c>
          </p>
          <p>
            should reveal both distributions and report the rejection region to achieve the level of significance, the observed level of significance, and the power.
          </p>
          <image source="images/Inv1.11-kRsol.jpg" width="80%">
            <description>R output showing power calculation using iscamnormpower function</description>
          </image>
        </hint>
        <hint>
          <title>JMP Instructions</title>
          <p>
            In JMP:
          </p>
          <p>
            <ul>
              <li><p>Choose <alert>DOE > Sample Size Explorers > Power > Power for One Sample Proportion</alert></p></li>
              <li><p>Specify the form of the alternative, the level of significance (<m>\alpha</m>), an alternative probability of success, and set the Test Method to Normal Approximation.</p></li>
              <li><p>Specify the Sample Size, the null probability of success (Assumed Proportion), and alternative probability of success (Alternative Proportion).</p></li>
              <li><p>Press <alert>Enter</alert>.</p></li>
            </ul>
          </p>
          <image source="images/Inv1.11-kJMPsol.png" width="80%">
            <description>JMP Sample Size Explorer output showing power calculations</description>
          </image>
        </hint>
        </statement>
      </exercise>
    </paragraphs>

    <p>
      In fact, the most common application is to specify the desired power and solve for the necessary sample size before conducting the study to determine how many observations you should take.
    </p>

    <exercise xml:id="I1-11-k" label="I1.11k">
      <title>Sample Size for 80% Power at π = 0.30</title>
      <statement>
        <p>
          If your technology allows (or use trial and error), see how many sessions would be needed in the ganzfeld study to have at least an 80% chance of rejecting the null hypothesis if the actual probability of success is <m>\pi = 0.30</m>.
        </p>
      </statement>
      <setup>
        <var>
          <condition number="490" tolerance="10">
            <feedback><p>Correct! Approximately 490 sessions are needed to achieve 80% power when <m>\pi = 0.30</m>.</p></feedback>
          </condition>
          <condition number="490" tolerance="25">
            <feedback><p>Close! The more precise answer is around 490.</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Use technology or the applet to find the sample size that achieves 80% power.</p></feedback>
          </condition>
        </var>
      </setup>
      <statement>
        <p>
          Sample size needed: <var width="10"/>
        </p>
      </statement>
      <solution>
        <p>
          We would need a sample size close to 500 (approximately 490) to achieve 80% power when <m>\pi = 0.30</m>.
        </p>
        <image source="images/Inv1.11-kRsol.jpg" width="80%">
          <description>R output showing sample size calculation for 80% power using iscambinompower function</description>
        </image>
        <image source="images/Inv1.11-kJMPsol.png" width="80%">
          <description>JMP Sample Size Explorer showing power calculation for n=490</description>
        </image>
        <image source="images/Inv1.11-kAppletsol.jpg" width="80%">
          <description>Power applet showing sample size needed for 80% power when π = 0.30</description>
        </image>
      </solution>
    </exercise>

    <exercise xml:id="I1-11-l" label="I1.11l">
      <title>Sample Size for 80% Power at π = 0.35</title>
      <statement>
        <p>
          How will your answer to the previous question change if the actual probability of success is <m>\pi = 0.35</m>? Determine the number of sessions needed in this case.
        </p>
      </statement>
      <setup>
        <var>
          <condition number="175" tolerance="10">
            <feedback><p>Correct! Approximately 170-180 sessions are needed to achieve 80% power when <m>\pi = 0.35</m>.</p></feedback>
          </condition>
          <condition number="175" tolerance="20">
            <feedback><p>Close! The more precise answer is around 175.</p></feedback>
          </condition>
          <condition string=".*">
            <feedback><p>Use technology or the applet to find the sample size that achieves 80% power with <m>\pi = 0.35</m>.</p></feedback>
          </condition>
        </var>
      </setup>
      <statement>
        <p>
          Sample size needed: <var width="10"/>
        </p>
        <p>
          Explanation: <var width="60"/>
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          Approximately 170-180 sessions would be needed to achieve 80% power when <m>\pi = 0.35</m>.
        </p>
        <p>
          If the actual probability of success is even further away from the hypothesized value (0.35 vs 0.30), then we won't need as large a sample size to achieve the same power. The effect size is larger, making it easier to detect the difference with fewer observations.
        </p>
      </solution>
    </exercise>

    <assemblage xml:id="type-i-ii-errors-key-idea">
      <title>Key Ideas</title>
      <p>
        In any test of significance, we need to guard against two types of errors:
      </p>
      <p>
        <ul>
          <li><p><term>Type I error</term> = falsely rejecting a true null hypothesis ("false alarm")</p></li>
          <li><p><term>Type II error</term> = failing to reject a false null hypothesis ("missed opportunity")</p></li>
        </ul>
      </p>
      <p>
        We control the probability of a Type I error by stating a level of significance before we collect any data. We chiefly control the probability of a Type II error by determining what sample size is needed in a study to achieve a desired level of power. To do so, you need to establish in advance how false you think the null hypothesis is/what size of a difference you want to be able to detect. This is often done through subject-matter knowledge or prior study results.
      </p>
    </assemblage>

    <assemblage xml:id="study-conclusions">
      <title>Study Conclusions</title>
      
      <p>
        If the researchers believe there is a genuine but small effect (say 5 percentage points) of ESP, then with a sample size of 329, there is about a 65% chance that, when the probability of a correct identification equals 0.30, they will obtain a sample result that convinces them to reject the null hypothesis that <m>\pi = 0.250</m>. With a sample size of around 500, there is over 80% chance that the researchers will find evidence of ESP when <m>\pi = 0.30</m>. Keep in mind that with a large sample size, we can often find a statistically significant result that we may not consider practically significant.
      </p>

    </assemblage>

      <paragraphs>
        <p><title>Discussion:</title> When the sample size is small, the binomial distribution can be used for power calculations, but notice that the discreteness of the binomial probability distribution can complicate matters. This is another example where the normal distribution is simpler, but do keep in mind use of the normal approximation is not always valid.
      </p></paragraphs>

</exercises>

  <subsection xml:id="practice1-11A">
    <title>Practice Problem 1.11A</title>

    <p>
      For the research study on the mortality rate at St. George's hospital (<xref ref="investigation-1-4" text="custom">Investigation 1.4</xref>), the goal was to compare the mortality rate of that hospital to the national benchmark of 0.15.
    </p>

    <exercise xml:id="practice-1-11a-a" label="PP1.11A.1">
      <title>Identify Type of Error (Exceeding Benchmark)</title>
      <statement>
        <p>
          If you were to conclude that the hospital's death rate exceeds the national benchmark when it really does not, what type of error would you be committing?
        </p>
      </statement>
      <choices randomize="yes">
        <choice correct="yes">
          <statement><p>Type I</p></statement>
        </choice>
        <choice>
          <statement><p>Type II</p></statement>
        </choice>
        <choice>
          <statement><p>Both</p></statement>
        </choice>
        <choice>
          <statement><p>Neither</p></statement>
        </choice>
      </choices>
      <solution>
        <p>
          Type I error. This would be rejecting the null hypothesis (that <m>\pi = 0.15</m>) when it is actually true.
        </p>
      </solution>
    </exercise>

    <exercise xml:id="practice-1-11a-b" label="PP1.11A.2">
      <title>Identify Type of Error (Not Exceeding Benchmark)</title>
      <statement>
        <p>
          If you were to conclude that the hospital's death rate does not exceed the national benchmark when it really does, which type of error would you be committing?
        </p>
      </statement>
      <choices randomize="yes">
        <choice>
          <statement><p>Type I</p></statement>
        </choice>
        <choice correct="yes">
          <statement><p>Type II</p></statement>
        </choice>
        <choice>
          <statement><p>Both</p></statement>
        </choice>
        <choice>
          <statement><p>Neither</p></statement>
        </choice>
      </choices>
      <solution>
        <p>
          Type II error. This would be failing to reject the null hypothesis when it is actually false (the death rate really does exceed 0.15).
        </p>
      </solution>
    </exercise>

    <exercise xml:id="practice-1-11a-c" label="PP1.11A.3">
      <title>More Critical Error</title>
      <statement>
        <p>
          Which error, Type I or Type II, would you consider more critical here? Explain.
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          A Type II error might be considered more critical because failing to detect that the hospital has a higher death rate than the benchmark means patients may continue to receive substandard care. However, a Type I error could also be serious as it might unfairly damage the hospital's reputation. The answer may depend on the consequences of each type of error.
        </p>
      </solution>
    </exercise>

    <exercise xml:id="practice-1-11a-d" label="PP1.11A.4">
      <title>Compare Power for Different Alternatives</title>
      <statement>
        <p>
          Suppose you wanted to know the power of the test when the mortality rate at this hospital was 0.20 and when the mortality rate at this hospital was 0.25. For which alternative probability would you have a lower chance of committing a Type II error? Explain.
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          You would have a lower chance of committing a Type II error when <m>\pi = 0.25</m>. The power is higher when the true parameter value is further from the null hypothesis value (0.25 is further from 0.15 than 0.20 is), making it easier to detect the difference and reject the null hypothesis. Higher power means lower probability of Type II error.
        </p>
      </solution>
    </exercise>
  </subsection>

  <subsection xml:id="practice1-11B">
    <title>Practice Problem 1.11B</title>

    <exercise xml:id="practice-1-11b-a" label="PP1.11B.1">
      <title>Compare Type I Error Probabilities</title>
      <statement>
        <p>
          If Abe were to use a significance level of 0.05 and Bianca were to use a significance level of 0.01, who would have a smaller probability of Type I error? Explain briefly.
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          Bianca would have a smaller probability of Type I error. The probability of a Type I error equals the significance level, so Bianca's probability (0.01) is smaller than Abe's (0.05).
        </p>
      </solution>
    </exercise>

    <exercise xml:id="practice-1-11b-b" label="PP1.11B.2">
      <title>Compare Type II Error Probabilities</title>
      <statement>
        <p>
          If Abe were to use a significance level of 0.05 and Bianca were to use a significance level of 0.01, who would have a smaller probability of Type II error? Explain briefly.
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          Abe would have a smaller probability of Type II error. With a less stringent significance level (0.05 vs 0.01), it's easier to reject the null hypothesis, which means higher power and therefore lower probability of Type II error.
        </p>
      </solution>
    </exercise>

    <exercise xml:id="practice-1-11b-c" label="PP1.11B.3">
      <title>Compare Type I Error with Different Sample Sizes</title>
      <statement>
        <p>
          If Abe were to use a significance level of 0.05 with a sample size of <m>n = 50</m> and Bianca were to use a significance level of 0.01 with a sample size of <m>n = 100</m>, who would have a smaller probability of a Type I error?
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          Bianca would have a smaller probability of Type I error. The probability of Type I error is determined solely by the significance level (not by sample size), and Bianca's significance level (0.01) is smaller than Abe's (0.05).
        </p>
      </solution>
    </exercise>

    <exercise xml:id="practice-1-11b-d" label="PP1.11B.4">
      <title>Compare Power with Different Sample Sizes</title>
      <statement>
        <p>
          If Abe were to use a significance level of 0.05 with a sample size of <m>n = 50</m> and Bianca were to use a significance level of 0.01 with a sample size of <m>n = 100</m>, whose test would have more power?
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          This depends on the specific alternative being considered, but in general, Bianca's test might have more power despite the lower significance level, because her larger sample size (100 vs 50) substantially increases power. However, Abe's higher significance level also increases power. The net effect would depend on the specific parameter values.
        </p>
      </solution>
    </exercise>
  </subsection>

  <subsection xml:id="practice1-11C">
    <title>Practice Problem 1.11C</title>

    <p>
      For the research study on the mortality rate at St. George's hospital (<xref ref="investigation-1-4" text="custom">Investigation 1.4</xref>), the goal was to decide whether the mortality rate of that hospital exceeds the national benchmark of 0.15. Suppose you plan to monitor the next 20 operations, using a level of significance of 0.05. Also suppose the actual death rate at this hospital equals 0.20.
    </p>

    <exercise xml:id="practice-1-11c-a" label="PP1.11C.1">
      <title>Rejection Region and Power for π = 0.20</title>
      <statement>
        <p>
          Determine the rejection region and the power of this test.
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          Use technology with <m>n = 20</m>, <m>\pi_0 = 0.15</m>, <m>\pi_a = 0.20</m>, and <m>\alpha = 0.05</m> (one-sided greater).
        </p>
        <p>
          Rejection region: 7 or more deaths out of 20 operations.
        </p>
        <p>
          Power: approximately 0.13
        </p>
      </solution>
    </exercise>

    <exercise xml:id="practice-1-11c-b" label="PP1.11C.2">
      <title>Rejection Region and Power for π = 0.25</title>
      <statement>
        <p>
          Repeat assuming the actual death rate at this hospital equals 0.25. How does the power compare, and why does this make sense?
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          Rejection region: Still 7 or more deaths (this doesn't depend on the alternative).
        </p>
        <p>
          Power: approximately 0.27
        </p>
        <p>
          The power has increased because the true parameter value (0.25) is further from the null value (0.15), making it easier to detect the difference.
        </p>
      </solution>
    </exercise>
  </subsection>

  <subsection xml:id="practice1-11D">
    <title>Practice Problem 1.11D</title>

    <p>
      Suppose you want to test a person's ability to discriminate between two types of soda. You fill one cup with Soda A and two cups with Soda B. The subject tastes all 3 cups and is asked to identify the odd soda. You record the number of correct identifications in 10 attempts. Assume level of significance <m>\alpha = 0.05</m> and a one-sided alternative.
    </p>

    <exercise xml:id="practice-1-11d-a" label="PP1.11D.1">
      <title>Calculate Power</title>
      <statement>
        <p>
          If the subject's actual probability of a correct identification is 0.50, what is the power of this test for a level of significance of <m>\alpha = 0.05</m>?
        </p>
      <hint>
        <p>
          What is the null hypothesis?
        </p>
      </hint>
      </statement>
      <response/>
      <solution>
        <p>
          The null hypothesis is <m>\pi = 1/3</m> (guessing among 3 cups). Use technology with <m>n = 10</m>, <m>\pi_0 = 1/3</m>, <m>\pi_a = 0.50</m>, and <m>\alpha = 0.05</m>.
        </p>
        <p>
          Power: approximately 0.38
        </p>
      </solution>
    </exercise>

    <exercise xml:id="practice-1-11d-b" label="PP1.11D.2">
      <title>Interpret Power</title>
      <statement>
        <p>
          Write a one-sentence interpretation of the power you calculated in the <xref ref="practice-1-11d-a" text="custom">previous checkpoint</xref> in context.
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          If the subject can correctly identify the odd soda 50% of the time, there is approximately a 38% chance that we will correctly reject the null hypothesis (that they are just guessing) with 10 trials at the 0.05 significance level.
        </p>
      </solution>
    </exercise>

    <exercise xml:id="practice-1-11d-c" label="PP1.11D.3">
      <title>Power with 20 Attempts</title>
      <statement>
        <p>
          What is the power if you give the subject 20 attempts?
        </p>
        <p>
          Power: <var width="10"/>
        </p>
      </statement>
      <response/>
      <solution>
        <p>
          With <m>n = 20</m>, the power increases to approximately 0.63. The larger sample size makes it easier to detect the subject's ability if they truly can identify the odd soda 50% of the time.
        </p>
      </solution>
    </exercise>
  </subsection>

  <subsection xml:id="practice1-11E">
    <title>Practice Problem 1.11E</title>

    <p>
      Suppose that you want to re-conduct the kissing study in a large city with a sample of 100 kissing couples. You want to test the null hypothesis <m>H_0: \pi = 0.667</m> against a one-sided alternative <m>H_a: \pi &lt; 0.667</m> using a significance level of <m>\alpha = 0.05</m>, and you are concerned about the power of your test when <m>\pi = 0.5</m>.
    </p>

    <p>
      Consider the following graphs:
    </p>
    
    <image source="images/PP1.11E.png" width="80%">
      <description>Two normal distributions showing null hypothesis centered at 0.667 and alternative at 0.5, with regions labeled I, II, III, and IV</description>
    </image>

    <exercise xml:id="practice-1-11e-a" label="PP1.11E.1">
      <title>Type I Error Region</title>
      <statement>
        <p>
          Which region(s) represents the probability of making a Type I error?
        </p>
      </statement>
      <choices randomize="yes">
        <choice correct="yes">
          <statement><p>I</p></statement>
        </choice>
        <choice>
          <statement><p>II</p></statement>
        </choice>
        <choice>
          <statement><p>III</p></statement>
        </choice>
        <choice>
          <statement><p>IV</p></statement>
        </choice>
      </choices>
      <solution>
        <p>
          Region I represents the Type I error probability - the area in the left tail of the null distribution (centered at 0.667) that falls in the rejection region.
        </p>
      </solution>
    </exercise>

    <exercise xml:id="practice-1-11e-b" label="PP1.11E.2">
      <title>Type II Error Region</title>
      <statement>
        <p>
          Which region(s) represents the probability of making a Type II error?
        </p>
      </statement>
      <choices randomize="yes">
        <choice>
          <statement><p>I</p></statement>
        </choice>
        <choice correct="yes">
          <statement><p>II</p></statement>
        </choice>
        <choice>
          <statement><p>III</p></statement>
        </choice>
        <choice>
          <statement><p>IV</p></statement>
        </choice>
      </choices>
      <solution>
        <p>
          Region II represents the Type II error probability - the area under the alternative distribution (centered at 0.5) that does not fall in the rejection region.
        </p>
      </solution>
    </exercise>

    <exercise xml:id="practice-1-11e-c" label="PP1.11E.3">
      <title>Power Region</title>
      <statement>
        <p>
          Which region(s) represents the power of the test?
        </p>
      </statement>
      <choices randomize="yes">
        <choice>
          <statement><p>I</p></statement>
        </choice>
        <choice>
          <statement><p>II</p></statement>
        </choice>
        <choice correct="yes">
          <statement><p>III</p></statement>
        </choice>
        <choice>
          <statement><p>IV</p></statement>
        </choice>
      </choices>
      <solution>
        <p>
          Region III represents the power - the area under the alternative distribution (centered at 0.5) that falls in the rejection region.
        </p>
      </solution>
    </exercise>
  </subsection>

  <subsection xml:id="practice1-11F">
    <title>Practice Problem 1.11F</title>

    <exercise xml:id="practice-1-11f" label="PP1.11F.1">
      <title>Error Types Table</title>
      <statement>
        <p>
          The table below shows the possible states of the world and the possible decisions we can make. Indicate where the types of errors fall in this table and where the test makes the correct decision.
        </p>
          <tabular row-headers="yes">
            <row header="yes">
              <cell></cell>
              <cell colspan="2" halign="center">State of the world</cell>
            </row>
            <row header="yes">
              <cell>Test decision</cell>
              <cell><m>H_0</m> true</cell>
              <cell><m>H_0</m> false</cell>
            </row>
            <row>
              <cell>Reject <m>H_0</m></cell>
              <cell><var width="15"/></cell>
              <cell><var width="15"/></cell>
            </row>
            <row>
              <cell>Fail to reject <m>H_0</m></cell>
              <cell><var width="15"/></cell>
              <cell><var width="15"/></cell>
            </row>
          </tabular>
      </statement>
      <response/>
      <solution>
          <title>Test Decisions and Errors - Solution</title>
          <tabular row-headers="yes">
            <row header="yes" bottom="minor">
              <cell></cell>
              <cell colspan="2" halign="center">State of the world</cell>
            </row>
            <row header="yes" bottom="minor">
              <cell>Test decision</cell>
              <cell><m>H_0</m> true</cell>
              <cell><m>H_0</m> false</cell>
            </row>
            <row>
              <cell>Reject <m>H_0</m></cell>
              <cell>Type I error</cell>
              <cell>Correct decision (Power)</cell>
            </row>
            <row bottom="minor">
              <cell>Fail to reject <m>H_0</m></cell>
              <cell>Correct decision</cell>
              <cell>Type II error</cell>
            </row>
          </tabular>
      </solution>
    </exercise>
  </subsection>

</section>
