<?xml version="1.0" encoding="UTF-8"?>
<section xml:id="inv-2-2">
  <title>Investigation 2.2: Honking Reaction Times</title>

<exercises xml:id="investigation2-2" hidden-label="yes">
  <title>The Study</title>

  <introduction>
    <sidebyside widths="60% 35%" valign="top">
      <p>Diekmann, Krassnig, and Lorenz (<url href="https://pubmed.ncbi.nlm.nih.gov/9043205/">1996</url>) conducted a field study to explore whether driver characteristics are related to an aggressive response (Thanks to Jeff Sklar for pointing us to this article).</p>
      <image source="images/Inv2.2intro.png" width="100%">
        <description>Honking reaction times introduction image</description>
      </image>
    </sidebyside>
    
    <p>The study was conducted at a busy intersection in Munich, West Germany, on two afternoons (Sunday and Monday) in 1986.The experimenters sat in a Volkswagen Jetta (the "blocking car") and did not accelerate after the traffic light turned green, and timed how long before the driver of the blocked car reacted (either by honking or flashing headlights). The response time (in seconds) is our variable of interest. Some values were "censored" in that the researcher stopped timing before the driver actually honked. This can happen if there is a time limit to the observation period and "success" has not been observed within that time period.</p>
    
    <p>The data for the above study can be found in <url href="https://www.rossmanchance.com/iscam2/data/honking.txt" visual="rossmanchance.com/iscam4/data/honking.txt">honking.txt</url>.</p>
  </introduction>
  
  <exercise xml:id="inv2-2-a" label="I6.2.1">
    <title>Predict your reaction time</title>
    <statement>
      <p>How long do you think you would wait before you honked? (in seconds)</p>
      <p><var width="10"/></p>
    </statement>
  </exercise>
  
  <exercise xml:id="inv2-2-b" label="I6.2.2">
    <title>Explore honking reaction time data</title>
    <statement>
      <p><ul>
        <li><p>Use technology to create a histogram and describe the behavior of the data – shape, center, spread, outliers (suggest an explanation?).</p></li>
        <li><p>Then overlay a normal probability model. Do these data behave like a normal distribution? If not, how do they deviate from normality? Does the shape make sense in this context?</p></li>
        <li><p>Also examine a normal probability plot and discuss how deviations from the line correspond to the nonnormal shape you are observing.</p></li>
      </ul></p>
    </statement>
    <hint>
      <p>Were the observed response times/quantiles placed on the vertical or the horizontal axis?</p>
    </hint>
    <solution>
      <p>The distribution of response times are skewed to the right. Most people waited less than 5 seconds, but a couple waited more than 15 seconds. There is one outlier 17.15 seconds.</p>
      <p>Example output:</p>
      <image source="images/Inv2-2b-sols1.jpg" width="60%">
        <description>Histogram of honking response times</description>
      </image>
      <image source="images/Inv2-2b-sols2.jpg" width="60%">
        <description>Histogram with normal overlay for response times</description>
      </image>
      <p>The data do not behave like a normal distribution. The probability plot confirms that the largest response times are larger than we would expect from a normal distribution and the lowest response times are larger than we would expect.</p>
      <image source="images/Inv2-2b-sols3.jpg" width="60%">
        <description>Normal probability plot for response times</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-2-c" label="I6.2.3">
    <title>Compare mean and median</title>
    <statement>
      <p>Determine and compare the mean and median wait times.</p>
      <p>Mean: <var width="10"/> seconds</p>
      <p>Median: <var width="10"/> seconds</p>
      <p>Which is larger?</p>
    </statement>
    <choices randomize="no">
      <choice>
        <statement>
          <p>Mean</p>
        </statement>
      </choice>
      <choice>
        <statement>
          <p>Median</p>
        </statement>
      </choice>
    </choices>
    <hint>
      <p>Recall that the mean is the numerical average and the median has 50% of the observations on each side.</p>
    </hint>
    <solution>
      <p>The mean (4.249 s) is larger than the median (3.24 s) as it is pulled towards the larger values. Also note that the skewness statistic equals 2.52.</p>
    </solution>
    <response>
      <p>Why is it larger?</p>
    </response>
  </exercise>
  
  <assemblage xml:id="def-resistant-statistic">
    <title>Definition: Resistant Statistic</title>
    <p>A numerical summary (statistic) is said to be <term>resistant</term> when it is not strongly influenced by a change in one or two extreme data values.</p>
  </assemblage>
  
  <p>When data are skewed to the right/left, the mean will be pulled in the direction of the longer tail.</p>
  
  <p>When data are skewed, we might often prefer to report the median as a "typical" value in the data set, rather than the mean because the mean is pulled in the direction of the longer tail. In addition, you might not want to cite the standard deviation as a measure of spread in a skewed distribution.</p>
  
  <assemblage xml:id="def-iqr">
    <title>Definition: Interquartile Range (IQR)</title>
    <p><term>Interquartile range (IQR)</term> = upper quartile – lower quartile</p>
    <p>The lower quartile is a value such that roughly one-fourth of all the observations fall below it; the upper quartile is a value such that roughly one-fourth of all the observations fall above it. The IQR then measures the width of the interval containing the middle 50% of the observations.</p>
  </assemblage>
  
  <exercise xml:id="inv2-2-d" label="I6.2.4">
    <title>Compute interquartile range</title>
    <statement>
      <p>Use technology to compute the interquartile range.</p>
      <p>IQR: <var width="10"/> seconds</p>
    </statement>
    <hint>
      <p>Run the descriptive statistics command and report the lower and upper quartiles and then subtract.</p>
    </hint>
    <solution>
      <p>The interquartile range is 4.835 - 2.590 (Applet) gives 2.245 seconds. The width of the middle 50% of wait times is 2.245 seconds.</p>
    </solution>
    <response>
      <p>Write a one-sentence interpretation of this value:</p>
    </response>
  </exercise>
  
  <exercise xml:id="inv2-2-d2" label="I6.2.4b">
    <title>IQR as resistant measure</title>
    <statement>
      <p>Would you consider the IQR a resistant measure of spread?</p>
    </statement>
    <choices randomize="no">
      <choice correct="yes">
        <statement>
          <p>Yes</p>
        </statement>
      </choice>
      <choice>
        <statement>
          <p>No</p>
        </statement>
      </choice>
    </choices>
    <solution>
      <p>Like the median, the IQR should be resistant.</p>
    </solution>
    <response>
      <p>Explain:</p>
    </response>
  </exercise>
  
  <p>When the data are skewed, the median and interquartile range are often considered better numerical summaries of the center and variability of the distribution than the mean and standard deviation. When working with the median and interquartile range, we often report the five number summary which consists of the minimum, lower quartile, median, upper quartile, and maximum values.</p>
  
  <assemblage xml:id="def-boxplot">
    <title>Definition: Boxplot</title>
    <p>Another graph is based on the five-number summary, called a <term>boxplot</term> (invented by John Tukey in 1970). The box extends from the lower quartile to the upper quartile with a vertical line inside the box at the location of the median. Whiskers then typically extend to the min and max values.</p>
  </assemblage>
  
  <exercise xml:id="inv2-2-e" label="I6.2.5">
    <title>Create boxplot by hand</title>
    <statement>
      <p>Create by hand a boxplot for these data. Which display do you prefer, the boxplot or the histogram? Why?</p>
    </statement>
    <solution>
      <p>Example boxplot:</p>
      <image source="images/Inv2-2e-sols.jpg" width="60%">
        <description>Boxplot of response times</description>
      </image>
      <p>Preference will vary, but we do lose a fair bit of information in the boxplot.</p>
    </solution>
    <response/>
  </exercise>
  
  <p>Although boxplots are a nice visual of the five-number summary, they can sometimes miss interesting features in a data set. In particular, shape can be more difficult to judge in a boxplot, and they usually don't provide information about the size of a data set.</p>
  
  <p>Another application of the inter-quartile range is as a way to measure how far an observation is from the bulk of the distribution.</p>
  
  <assemblage xml:id="def-outlier-criterion">
    <title>Definition: Outlier Criterion and Modified Boxplot</title>
    <p>A value is an <term>outlier according to the 1.5IQR criterion</term> if the value is larger than the upper quartile + 1.5 × box length or smaller than the lower quartile – 1.5 × box length.</p>
    <p><alert>Note:</alert> The box length = upper quartile – lower quartile, is the interquartile range.</p>
    <p>A <term>modified boxplot</term> will display such outliers separately and then extend the whiskers to the most extreme non-outlier observation.</p>
  </assemblage>
  
  <exercise xml:id="tech-detour-modified-boxplots">
    <title>Technology Detour <mdash/> Modified Boxplots</title>
    <statement>
      <p>Create a "modified" boxplot for the honking response time data.</p>
    </statement>
    <hint>
      <title>Applet Instructions</title>
      <p>Use the <url href="https://www.rossmanchance.com/applets/2021/descstats/Dotplot.htm">Descriptive Statistics applet</url>:</p>
      <p><ul>
        <li><p>Paste in the data.</p></li>
        <li><p>Check the Add Boxplot box.</p></li>
        <li><p>Check the Show outliers box.</p></li>
      </ul></p>
      <p>Expected output:</p>
      <image source="images/Inv2-2f-Applet.jpg" width="60%">
        <description>Applet modified boxplot showing outliers</description>
      </image>
    </hint>
    <hint>
      <title>R Instructions</title>
      <p>Use the <c>boxplot</c> or <c>iscamboxplot</c> function:</p>
      <program language="r">
        <input>
boxplot(responsetime, ylab="time until reaction",    # Adds labels
        horizontal=TRUE)                              # Makes horizontal
# OR
iscamboxplot(responsetime, xlab="time until reaction")  # Uses quartiles
        </input>
      </program>
      <p>Expected output:</p>
      <image source="images/Inv2-2f-R.jpg" width="60%">
        <description>R modified boxplot showing outliers</description>
      </image>
      <p>Try it yourself:</p>
      <sage language="r">
        <input>
# Load ISCAM functions from GitHub
invisible(capture.output(source('https://raw.githubusercontent.com/iambethchance/iscam-runestone/master/ISCAM-functions.R?v=20251224')))

# Honking response time data (in seconds)
responsetime = c(1.86, 2.24, 2.28, 2.39, 2.50, 2.59, 2.67, 2.79, 2.81, 2.88, 
                 2.92, 3.06, 3.24, 3.30, 3.38, 3.43, 3.54, 3.56, 3.64, 3.76, 
                 3.79, 3.81, 3.82, 3.86, 3.94, 4.07, 4.12, 4.18, 4.20, 4.32, 
                 4.36, 4.44, 4.49, 4.55, 4.63, 4.64, 4.72, 4.81, 4.84, 4.90, 
                 4.91, 4.92, 5.03, 5.15, 5.34, 5.37, 5.61, 5.62, 5.64, 5.81, 
                 6.03, 6.20, 6.57, 6.67, 6.79, 9.78, 17.15)

# Create modified boxplot
iscamboxplot(responsetime, xlab="Time until reaction (seconds)")
        </input>
      </sage>
    </hint>
    <hint>
      <title>JMP Instructions</title>
      <p>In the Distributions window, use the red triangle (hot spot) next to the variable name and select Outlier Boxplot.</p>
      <p>Expected output:</p>
      <image source="images/Inv2-2f-JMP.jpg" width="60%">
        <description>JMP modified boxplot showing outliers</description>
      </image>
    </hint>
    <solution>
      <p>A modified boxplot displays the five-number summary with whiskers extending to the most extreme non-outlier observations. Points beyond 1.5 × IQR from the quartiles are marked as outliers.</p>
    </solution>
  </exercise>
  
  <exercise xml:id="inv2-2-f" label="I6.2.6">
    <title>Counting outliers</title>
    <statement>
      <p>Are there any outliers according to these criteria?</p>
    </statement>
    <solution>
      <p>Applet/R/JMP identify four ("high") outliers.</p>
    </solution>
    <response/>
  </exercise>
  
  <p>These data are not well modelled by a normal distribution. So can we still make predictions? There are a couple of strategies. One would be to consider whether a rescaling or transformation of the data might create a more normal-looking distribution, allowing us to use the methods from Investigation 2.1. In this case, we need a transformation that will downsize the large values more than the small values. Log transformations are often very helpful in this regard.</p>
  
  <assemblage xml:id="def-data-transformation">
    <title>Definition: Data Transformation</title>
    <p>A <term>data transformation</term> applies a mathematical function to each value to re-express the data on an alternative scale. Data transformations can also make the data more closely modeled with a normal distribution, which could then satisfy the conditions the Central Limit Theorem.</p>
  </assemblage>
  
  <exercise xml:id="inv2-2-g" label="I6.2.7">
    <title>Log transformation</title>
    <statement>
      <p>Create a new variable which is log(responsetime). (You can use either natural log or log base 10, but so we all do the same thing, let's use natural log here, which is the default in most software when you say "log.")</p>
      <p>Create a histogram of these data and a normal probability plot. Does log(responsetime) approximately follow a normal distribution? What are the mean and standard deviation of this distribution?</p>
    </statement>
    <hint>
      <title>In R</title>
      <p><c>lnresponsetime = log(responsetime)</c></p>
    </hint>
    <hint>
      <title>In JMP</title>
      <p>Create a new column and edit the formula. Type or use your mouse to select Transcendental > Log to create Log(responsetime). Press OK.</p>
    </hint>
    <solution>
      <p>This histogram of the ln response times is more symmetric and the normal probability plot is more linear. This is definitely more normal looking than before (but we might be able to do better). The mean is 1.292 and the SD = 0.5285. The skewness statistic is closer to zero (0.676).</p>
      <image source="images/Inv2-2g-sols1.jpg" width="60%">
        <description>Histogram of log-transformed response times</description>
      </image>
      <image source="images/Inv2-2g-sols2.jpg" width="60%">
        <description>Normal probability plot of log-transformed response times</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-2-h" label="I6.2.8">
    <title>Predict using normal distribution on log scale</title>
    <statement>
      <p>Use a normal distribution with mean 1.29 ln-sec and standard deviation 0.53 ln-seconds for the logged response times and predict how often someone will honk within the first 2 seconds.</p>
    </statement>
    <hint>
      <p>What are you going to use for the observation of interest?</p>
    </hint>
    <solution>
      <p>Using ln(2) ≈ 0.693 as the observed result, we find about 13% of the model distribution falls below.</p>
      <image source="images/Inv2-2h-sols.jpg" width="60%">
        <description>Normal distribution calculation for log scale</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-2-i" label="I6.2.9">
    <title>Compare prediction to observed data</title>
    <statement>
      <p>How does this prediction in <xref ref="inv2-2-h"/> compare to the observed percentage honking within the first 2 seconds in the data set?</p>
    </statement>
    <solution>
      <p>In the original distribution, 6 of the 57 observations are below 2 (10.5%).</p>
    </solution>
    <response/>
  </exercise>
  
  <paragraphs>
    <title>Alternative Probability Models</title>
    
    <p>Another approach is to fit a different mathematical model to the original data:</p>
  </paragraphs>
  
  <exercise xml:id="inv2-2-j" label="I6.2.10">
    <title>Exponential probability model</title>
    <statement>
      <p>Use technology to overlay an exponential probability model (often used to model wait times) to these data and/or create a probability plot using the exponential distribution as the reference distribution.</p>
      <p>Describe the behavior of the exponential distribution. Does it appear to be a reasonable fit for these data? Describe any deviations.</p>
    </statement>
    <hint>
      <title>In R</title>
      <p>For the qqplot we have to first get the quantiles:</p>
      <program language="r" interactive="sage">
        <input>
theoquant = qexp(ppoints(12))      # Generates 1/n quantiles for 12 observations
                                    # from exponential distribution
hist(theoquant)                     
qqplot(responsetime, theoquant)    # Your data vs. quantiles. Look for a line.
iscamaddexp(responsetime)          # overlay exponential model
        </input>
      </program>
    </hint>
    <hint>
      <title>In JMP</title>
      <p>In the Distribution window, use the hot spot to select Continuous Fit > Exponential.</p>
    </hint>
    <solution>
      <p>The exponential is skewed to the right with its peak at zero. This does not appear to be as good of a fit. We have more observations around 4-5 seconds than the exponential distribution would predict and fewer observations less than 1 second (we don't have any, the times could be rounded in the dataset?).</p>
      <image source="images/Inv2-2j-sols1.jpg" width="60%">
        <description>Histogram with exponential distribution overlay</description>
      </image>
      <image source="images/Inv2-2j-sols2.jpg" width="60%">
        <description>Exponential probability plot</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-2-k" label="I6.2.11">
    <title>Calculate probability using exponential distribution</title>
    <statement>
      <p>Use technology to calculate the probability of a wait time under 2 seconds using the exponential distribution with mean 4.25 sec</p>
      <p>How does it compare to your estimate in <xref ref="inv2-2-h"/> and the result in <xref ref="inv2-2-i"/>?</p>
    </statement>
    <hint>
      <title>In R</title>
      <p><c>pexp(2, rate = 1/4.25)</c> calculates P(X &lt; 2) when X ~ Exp(mean = 4.25)</p>
    </hint>
    <hint>
      <title>In JMP</title>
      <p>Using the Distribution Calculator and select the Exponential distribution. Specify a scale parameter of 1/4.25. Choose X &lt;= Qa and enter 2 for Qa (we don't need to worry about strict vs. non-strict inequalities here)</p>
    </hint>
    <solution>
      <p>This way overpredicts how often we will get a response time less than 2 seconds (0.3754).</p>
      <image source="images/Inv2-2k-sols.jpg" width="60%">
        <description>Exponential distribution probability calculation</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-2-l" label="I6.2.12">
    <title>Lognormal distribution</title>
    <statement>
      <p>Repeat <xref ref="inv2-2-j"/> and <xref ref="inv2-2-k"/> with a "lognormal" distribution.</p>
      <p><alert>Note:</alert> This is equivalent to fitting the normal distribution on the log-transformed data!</p>
    </statement>
    <hint>
      <title>In R</title>
      <program language="r" interactive="sage">
        <input>
qqplot(responsetime, qlnorm(ppoints(12)))
iscamaddlnorm(responsetime)
plnorm(2, meanlog = 1.292, sdlog = 0.5238)
        </input>
      </program>
    </hint>
    <hint>
      <title>In JMP</title>
      <p>Scroll down the Distribution list and choose the Lognormal distribution with location = 1.292 and scale = 0.5238.</p>
    </hint>
    <solution>
      <p>The log normal has the skewed right behavior but not as severely as the exponential and provides a better fit to our data. Now the prediction is 0.1326.</p>
      <image source="images/Inv2-2l-sols1.jpg" width="60%">
        <description>Histogram with lognormal distribution overlay</description>
      </image>
      <image source="images/Inv2-2l-sols2.jpg" width="60%">
        <description>Lognormal probability plot</description>
      </image>
      <image source="images/Inv2-2l-sols3.jpg" width="60%">
        <description>Lognormal distribution probability calculation</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <paragraphs>
    <title>Discussion</title>
    
    <p>There are of course, many other probability models we could look into. One limitation of the exponential distribution is that it assumes the same value for the mean and the standard deviation, clearly not the case for these data. There are other more flexible distributions (e.g., Gamma and Weibull) that use two parameters to characterize the distribution rather than only one.</p>
  </paragraphs>
  
  <exercise xml:id="inv2-2-m" label="I6.2.13">
    <title>Generalization of results</title>
    <statement>
      <p>To what population are you willing to generalize these results? Explain.</p>
    </statement>
    <hint>
      <p>Think about how the data were collected and what you learned about sampling methods in Chapter 1.</p>
    </hint>
    <solution>
      <p>We don't have a lot of information about how these participants were selected other than two afternoons in West Germany, so we should be cautious in generalizing these results too far beyond that time period and country. "Waiting time" can be very distinct across cultures.</p>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-2-n" label="I6.2.14">
    <title>Future research directions</title>
    <statement>
      <p>If you were to continue to explore this research area/data set, what would you be interested in investigating next?</p>
    </statement>
    <solution>
      <p>Answers will vary.</p>
    </solution>
    <response/>
  </exercise>
  
  <assemblage xml:id="study-conclusions-2-2">
    <title>Study Conclusions</title>
    
    <p>In this study, we found that the amount of time a blocked driver waits before responding follows a skewed right distribution with a mean of 4.25 seconds and a median of 3.24 seconds, with a few drivers waiting more than 10 seconds. Although the dataset is small, we might consider using these data to build a mathematical model for these skewed data, either using a transformation or a probability model other than the normal distribution, to help predict future results (e.g., a wait time of less than 2 seconds). These researchers were actually interested in whether the "social status" of the blocked car was related to how long it took before people honked. They found that "the mean and median response times decreased monotonically with the status of car, except when the blocked car was very small." Similar results had been found in an earlier study by Doob and Gross in the United States (1968) which varied the status of the blocking car. However, neither study was replicated by a Swiss study (Jann, Suhner, <ampersand/> Marioni, 1995), perhaps due to cultural differences.</p>
  </assemblage>
  
  </exercises>
  <subsection xml:id="practice2-2A">
    <title>Practice Problem 2.2A</title>
    
    <p>A group of Cal Poly students (Sasscer, Mease, Tanenbaum, and Hansen, 2009) conducted the following study: volunteers were to say "go," and then to say "stop" when they believed 30 seconds had passed. The researchers asked the participants to not count in their heads and recorded how much time had actually passed. The data are in <url href="https://www.rossmanchance.com/iscam4/data/30seconds.txt" visual="rossmanchance.com/iscam4/data/30seconds.txt">30seconds.txt</url>.</p>
    
    <exercise xml:id="practice-2-2a-a" label="PP2.2A.1">
      <title>Examine distribution of 30-second estimates</title>
      <statement>
        <p>Examine graphical and numerical summaries of these data. Describe the shape of the distribution. How do the mean and median compare? Is the skewness statistic positive or negative? What does this tell you about whether people tend to over or underestimate the length of 30 seconds?</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-2-2a-b" label="PP2.2A.2">
      <title>Assess normal model appropriateness</title>
      <statement>
        <p>Does a normal model seem appropriate here?</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-2-2a-c" label="PP2.2A.3">
      <title>Evaluate log transformation</title>
      <statement>
        <p>Does a log transformation succeed in creating a normal distribution? Explain how you might have predicted this answer based on the first graph you looked at in part (a).</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-2-2a-d" label="PP2.2A.4">
      <title>Generalization of results</title>
      <statement>
        <p>To what population would you be willing to generalize these data?</p>
      </statement>
      <response/>
    </exercise>
  </subsection>
  
  <subsection xml:id="practice2-2B">
    <title>Practice Problem 2.2B</title>
    
    <exercise xml:id="practice-2-2b" label="PP2.2B.1">
      <title>Compare Weibull and Gamma fits</title>
      <statement>
        <p>Below are distribution fits for the honking data with a Weibull distribution and a Gamma distribution.</p>
        <sidebyside widths="45% 45%">
          <stack>
            <p><em>Weibull</em></p>
            <image source="images/WeibullFit.jpg" width="100%">
              <description>Weibull distribution fit to honking data</description>
            </image>
          </stack>
          <stack>
            <p><em>Gamma</em></p>
            <image source="images/GammaFit.jpg" width="100%">
              <description>Gamma distribution fit to honking data</description>
            </image>
          </stack>
        </sidebyside>
        <p>Which do you think indicates a better fit for these data? Explain how you are deciding.</p>
      </statement>
      <response/>
    </exercise>
  </subsection>
  
</section>
