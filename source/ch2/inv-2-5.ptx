<?xml version="1.0" encoding="UTF-8"?>
<section xml:id="inv-2-5" numbered="no">
  <title>Investigation 2.5: What is a healthy body temperature? </title>
  <introduction>
    <p><em>In the previous investigation, we assumed random sampling from a finite population to predict the distribution of sample means and help us evaluate whether a particular value is an unlikely value for the sample mean by chance alone. However, this method is not realistic in practice as we had to make up a population to sample from and we had to make some assumptions about that population (e.g., shape). Luckily, the Central Limit Theorem also predicts how that distribution would behave for most population shapes. But the CLT does require us to know certain characteristics about the population.</em>  </p>
  </introduction>

  <exercises xml:id="investigation2-5" hidden-label="yes" numbered = "no">
  <title>The Claim</title>

  <introduction>
    <sidebyside widths="65% 30%" margins="0% 0%" valign="top">
 <p>German physician Carl Wunderlich analyzed a million temperatures from 25,000 patients and in 1869 published that the normal human-body temperature is 98.6°F. But several more recent studies have found that number to be too high, leading to speculation that Dr. Wunderlich was wrong, or that human body temperature has changed over time. </p>   <stack>
      <image source="images/Inv2.5Intro.png">
        <description>Introduction image for Healthy Body Temperatures investigation</description>
      </image>
      </stack>
    </sidebyside>
    <p>In a study published by Mackowiak, Wasserman, <ampersand/> Levine (<em>Journal of the American Medical Association</em>, <url href="https://jamanetwork.com/journals/jama/article-abstract/400116"> 1992)</url>, body temperatures (oral temperatures using a digital thermometer) were recorded for healthy men and women, aged 18-40 years, who were volunteers in Shigella vaccine trials at the University of Maryland Center for Vaccine Development, Baltimore. For these adults, the mean body temperature was found to be 98.249°F with a standard deviation of 0.733°F.</p>
  </introduction>
  
  <exercise xml:id="inv2-5-a" label="I7.2.1">
    <title>Define symbols in context</title>
    <statement>
      <p>Explain (in words, in context) what is meant by the following symbols as applied to this study: <m>n</m>, <m>\bar{x}</m>, <m>s</m>, <m>\mu</m>, <m>\sigma</m>. If you know a value, report it. Otherwise, define the symbol in words.</p>
      
      <p><m>n</m> = <var width="40"/></p>
      <p><m>\bar{x}</m> = <var width="40"/></p>
      <p><m>s</m> = <var width="40"/></p>
      <p><m>\mu</m> = <var width="40"/></p>
      <p><m>\sigma</m> = <var width="40"/></p>
    </statement>
    <setup>
      <var>
        <condition string=".*">
          <feedback><p>✓</p></feedback>
        </condition>
      </var>
      <var>
        <condition string=".*">
          <feedback><p>✓</p></feedback>
        </condition>
      </var>
      <var>
        <condition string=".*">
          <feedback><p>✓</p></feedback>
        </condition>
      </var>
      <var>
        <condition string=".*">
          <feedback><p>✓</p></feedback>
        </condition>
      </var>
      <var>
        <condition string=".*">
          <feedback><p>✓</p></feedback>
        </condition>
      </var>
    </setup>
    <solution>
      <p><m>n</m> represents the number of people in the study (hasn't been specified yet), <m>\bar{x}</m> = 98.249 = sample mean body temperature, <m>s</m> = 0.733 = sample standard deviation of the body temperatures, <m>\mu</m> = mean body temp in population (unknown), <m>\sigma</m> = standard deviation of body temperatures in entire population (unknown)</p>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-5-b" label="I7.2.2">
    <title>Write hypotheses</title>
    <statement>
      <p>Write a null hypothesis and an alternative hypothesis for testing Wunderlich's axiom using appropriate symbols.</p>
      
      <p><m>H_0</m>: <var width="30"/></p>
      <p><m>H_a</m>: <var width="30"/></p>
    </statement>
    <setup>
      <var case="insensitive">
        <condition string="(μ|mu|mean|m)\s*=\s*98\.6">
          <feedback><p>Correct!</p></feedback>
        </condition>
        <condition string=".*">
          <feedback><p>The null hypothesis should state that the population mean (μ) equals 98.6</p></feedback>
        </condition>
      </var>
      <var case="insensitive">
        <condition string="(μ|mu|mean|m)\s*(≠|!=|&lt;&gt;|not equal to|does not equal)\s*98\.6">
          <feedback><p>Correct!</p></feedback>
        </condition>
        <condition string=".*">
          <feedback><p>The alternative hypothesis should state that the population mean (μ) is not equal to 98.6</p></feedback>
        </condition>
      </var>
    </setup>
    <solution>
      <p>Let <m>\mu</m> represent the mean body temperature in the population of healthy adults.</p>
      <p><m>H_0: \mu = 98.6</m> (the body temperature of all healthy adults is 98.6)</p>
      <p><m>H_a: \mu \neq 98.6</m> (the body temperature of all healthy adults is no longer 98.6)</p>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-5-c" label="I7.2.3">
    <title>Apply Central Limit Theorem</title>
    <statement>
      <p>Suppose the axiom is correct and many different random samples of 13 adults are taken from a large normally distributed population with mean 98.6°F. What does the Central Limit Theorem tell you about the theoretical distribution of sample means? (Indicate any necessary information that is missing.)</p>
    </statement>
    <solution>
      <p>The distribution of sample means will be normally distributed (because the population is) with a mean equal to 98.6 (our assumption for the mean body temperature of the population), and standard deviation <m>\sigma/\sqrt{n}</m>.</p>
    </solution>
    <response/>
  </exercise>
  
  <p>If we assume the null hypothesis is true, then we have a value to use for the population mean. However, we don't have a value to use for the population standard deviation (sometimes called a "nuisance parameter" because we need its value to be able to use <m>SD(\bar{x})</m>, but it is not the parameter of interest).</p>
  
  <exercise xml:id="inv2-5-d" label="I7.2.4">
    <title>Estimate population standard deviation</title>
    <statement>
      <p>Suggest a method for estimating the population standard deviation from the sample data.</p>
    </statement>
    <solution>
      <p>We could use the sample standard deviation, <m>s</m>.</p>
    </solution>
    <response/>
  </exercise>
  
  <assemblage xml:id="definition-standard-error">
    <title>Definition: Standard Error of the Sample Mean</title>
    <p>The <term>standard error of the sample mean</term>, denoted by <m>SE(\bar{x})</m>, is an estimate of the standard deviation of <m>\bar{x}</m> (the sample to sample variability in sample means from repeated random samples) calculated by substituting the sample standard deviation <m>s</m> for the population standard deviation <m>\sigma</m>:</p>
    <p><me>SE(\bar{x}) = \frac{s}{\sqrt{n}}</me></p>
  </assemblage>
  
  <exercise xml:id="inv2-5-e" label="I7.2.5">
    <title>Calculate standard error</title>
    <statement>
      <p>Calculate the value of the standard error of the sample mean body temperature for this study when <m>n = 13</m>.</p>
      <p>SE(<m>\bar{x}</m>) = <var name="$se" width="8"/></p>
    </statement>
    <setup>
      <var>
        <condition number="0.203" tolerance="0.001">
          <feedback>
            <p>Correct! SE(<m>\bar{x}</m>) = <m>s/\sqrt{n} = 0.733/\sqrt{13} \approx 0.203</m></p>
          </feedback>
        </condition>
        <condition number="0.733">
          <feedback>
            <p>That's the value of <m>s</m>. You need to divide by <m>\sqrt{n}</m>.</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Incorrect. Use the formula SE(<m>\bar{x}</m>) = <m>s/\sqrt{n}</m>.</p>
          </feedback>
        </condition>
      </var>
    </setup>
    <solution>
      <p><m>s/\sqrt{n} = 0.733/\sqrt{13} \approx 0.203</m></p>
    </solution>
  </exercise>
  
  <exercise xml:id="inv2-5-f" label="I7.2.6">
    <title>Calculate standardized statistic</title>
    <statement>
      <p>Determine how many standard errors the sample mean (98.249) falls from the hypothesized value of 98.6 (the standardized statistic).</p>
      <p><var name="$tstat" width="8"/> standard errors</p>
    </statement>
    <setup>
      <var>
        <condition number="-1.73" tolerance="0.02">
          <feedback>
            <p>Correct! <m>t = (98.249 - 98.6)/0.203 \approx -1.73</m> standard errors</p>
          </feedback>
        </condition>
        <condition number="1.73" tolerance="0.02">
          <feedback>
            <p>Close, but pay attention to the sign. The sample mean is <em>below</em> the hypothesized value.</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Incorrect. Use the formula <m>t = (\bar{x} - \mu_0)/\text{SE}(\bar{x})</m>.</p>
          </feedback>
        </condition>
      </var>
    </setup>
    <solution>
      <p><m>(98.249 - 98.6)/0.203 \approx -1.73</m> standard errors</p>
    </solution>
  </exercise>
  
  <exercise xml:id="inv2-5-g" label="I7.2.7">
    <title>Evaluate standardized statistic</title>
    <statement>
      <p>Based on this calculation, would you consider the value of the sample mean (98.249) to be surprising, if the population mean were really equal to 98.6? Explain how you are deciding.</p>
    </statement>
    <solution>
      <p><m>|-1.73|</m> is less than 2 so doesn't seem all that unusual for the sample mean when <m>\mu = 98.6</m>.</p>
    </solution>
    <response/>
  </exercise>
  
  <p>Previously, we compared our standardized statistics (<m>z</m>-scores) to the normal distribution and said (absolute) values larger than two were considered rare. But we don't really have a <m>z</m>-score here because we had to estimate the standard deviation of the sample mean. This creates even more "uncertainty" in our standardized statistic and more random variation. Is that still true that two standard errors is unusual? Let's explore the method you just used to standardize the sample mean in more detail.</p>
  
  <paragraphs>
    <title>Explore with simulation</title>
  </paragraphs>
  
<p> We have created a population distribution of 20,000 body temperatures (<url href="https://www.rossmanchance.com/iscam4/data/BodyTempPop.txt">BodyTempPop.txt</url>).
Use the <url href="https://www.rossmanchance.com/applets/2021/sampling/OneSample.html?population=finitepop">Sampling from a Finite Population</url> applet and type the <c>BodyTempPop.txt</c> file name into the empty Population data window.</p>
    <interactive iframe="https://www.rossmanchance.com/applets/2021/sampling/OneSample.html?hideExtras=1" width="165%" aspect="3:2"/>
 
  <exercise xml:id="inv2-5-h" label="I7.2.8">
    <title>Examine population distribution</title>
    <statement>
      <p>Does this appear to be an approximately normally distributed population? <var width="5"/></p>
      
      <p>What is the population mean? <var name="$mean" width="8"/></p>
      
      <p>What is the population standard deviation? <var name="$sd" width="8"/></p>
    </statement>
    <setup>
      <var>
        <condition string="^\s*yes\s*$">
          <feedback>
            <p>Correct! The population distribution appears normally distributed.</p>
          </feedback>
        </condition>
        <condition string="^\s*no\s*$">
          <feedback>
            <p>Look at the shape more carefully. Does it appear symmetric and bell-shaped?</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Please enter yes or no</p>
          </feedback>
        </condition>
      </var>
      <var>
        <condition number="98.6" tolerance="0.01">
          <feedback>
            <p>Correct! The population mean is 98.6°F.</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Make sure you have finished loading in the body temperature data?</p>
          </feedback>
        </condition>
      </var>
      <var>
        <condition number="0.733" tolerance="0.001">
          <feedback>
            <p>Correct! The population standard deviation is 0.733°F.</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Check the population statistics displayed in the applet.</p>
          </feedback>
        </condition>
      </var>
    </setup>
    <solution>
      <p>Yes, the population distribution of body temperatures appears normally distributed with mean about 98.6 degrees and standard deviation 0.733 degrees.</p>
    </solution>
    <response/>
  </exercise>
  
  <ul><li>Use the applet to select 10,000 samples of 13 adults from this hypothetical population. </li></ul>
  <exercise xml:id="inv2-5-i" label="I7.2.9">
    <title>Verify Central Limit Theorem</title>
    <statement>
      <p>Does the behavior of the distribution of sample means agree with the Central Limit Theorem?</p>
    <hint>
      <p>Compare the CLT predictions (based on population shape, sample size) to the simulation results.</p>
    </hint>
    </statement>
    <choices randomize="no">
      <choice correct="yes"><statement><p>Yes</p></statement></choice>
      <choice><statement><p>No</p></statement></choice>
    </choices>
    <solution>
      <p>This is consistent with the central limit theorem as the shape is approximately normal, the mean is the same as the population mean, and the standard deviation is predicted by <m>0.733/\sqrt{13} = 0.203</m>.</p>
      <image source="images/Inv2.5isols.png" width="60%">
        <description>Sampling distribution showing consistency with Central Limit Theorem</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <p>But what about the statistic suggested in <xref ref="inv2-5-f" text="custom">Question 6</xref>; does this standardized statistic behave nicely and is this distribution again well modeled by a normal distribution?</p>
  <ul><li>
  In the applet, change the <term text="custom">Statistic</term> option (above the graph) to <m>t</m>-statistic, the name for the standardized sample mean using the standard error of the sample mean. 
  </li></ul>
  <exercise xml:id="inv2-5-j" label="I7.2.10">
    <title>Examine <m>t</m>-statistic distribution</title>
    <statement>
      <p>Describe the shape of the distribution of these <m>t</m>-statistics from your 10,000 random samples.</p>
    </statement>
    <solution>
      <p>The shape is symmetric and bell-shaped, with mean roughly zero and standard deviation a little larger than 1.</p>
      <image source="images/Inv2.5jsols.jpg" width="60%">
        <description>Distribution of t-statistics from 10,000 random samples</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <ul><li>
  Check the box to <alert>Overlay Normal Distribution</alert>; 
  </li></ul>
  <exercise xml:id="inv2-5-k" label="I7.2.11">
    <title>Compare to normal distribution</title>
    <statement>
      <p>Does this appear to be a reasonable fit? <var width="5"/> (yes or no)</p>
      
      <p>What p-value does this normal approximation produce?</p>
      <hint>
        <p>Enter your answer to <xref ref="inv2-5-f" text="custom">Question 6</xref> as the observed result for the <m>t</m>-statistic and count beyond.</p>
      </hint>
      <p>p-value = <var name="$pval" width="8"/></p>
    </statement>
    <setup>
      <var>
        <condition string="^\s*no\s*$">
          <feedback>
            <p>While both symmetric, the normal distribution is a bit taller in the middle and "lighter" in the tails.</p>
          </feedback>
        </condition>
        <condition string="^\s*yes\s*$">
          <feedback>
            <p>The fit is not very bad, but we do see some differences between the blue curve and the simulation results.</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Please enter yes or no</p>
          </feedback>
        </condition>
      </var>
      <var>
        <condition number="0.084" tolerance="0.002">
          <feedback>
            <p>Correct! For a two-sided test with <m>t = -1.73</m>, the normal approximation gives a p-value of approximately 0.084.</p>
          </feedback>
        </condition>
        <condition number="0.042" tolerance="0.002">
          <feedback>
            <p>This is the one-sided p-value. Remember to use a two-sided test (count beyond in both directions).</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Check your calculation. Use the t-statistic of -1.73 from Question 6 and find the area beyond ±1.73 using the normal distribution.</p>
          </feedback>
        </condition>
      </var>
    </setup>
    <solution>
      <p>The fit seems good, but not perfect. The normal distribution is perhaps a bit too "skinny" in the middle and doesn't go out far enough in the ends. This leads to an understimate
      of the probability of getting a <m>t</m> statistic = -1.73 or more extreme.</p>
      <sidebyside widths="45% 45%">
        <image source="images/Inv2.5ksols1.jpg">
          <description>t-distribution with normal overlay showing fit comparison</description>
        </image>
        <image source="images/Inv2.5ksols2.jpg">
          <description>p-value calculation using normal approximation</description>
        </image>
      </sidebyside>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-5-l" label="I7.2.12">
    <title>Evaluate normal approximation</title>
    <statement>
      <p>Does the theory-based p-value from the normal distribution accurately predict how often we would simulate a standardized statistic at least as extreme (in either direction) as the observed value of 1.73? Does it over predict or underpredict?</p>
    <hint>
      <p>How does the behavior of the distribution of the standardized statistics most differ from a normal model?</p>
    </hint>
    </statement>
    <solution>
      <p>The normal distribution underpredicts how often the sample mean falls 1.73 SEs from the population mean.</p>
    </solution>
    <response/>
  </exercise>
  
  <paragraphs>
    <title>Discussion</title>
    
    <p>If we zoom in on the tails of the distribution, we see that more of the simulated distribution lies in those tails than the normal distribution would predict.</p>    
    <image source="images/Inv2.5ttails.jpg" width="80%">
      <description>Combined view of distribution tail comparisons</description>
    </image>
    
    <p>To model the sampling distribution of the standardized statistic <m>\frac{\bar{x} - \mu}{s/\sqrt{n}}</m>, we need a density curve with <em>heavier tails</em> than the standard normal distribution. William S. Gosset, a chemist turned statistician, showed in 1908, while working for the Guinness Breweries in Dublin, that a "t probability curve" provides a better model for the sampling distribution of this standardized statistic when the population of observations follows a normal distribution.</p>
  </paragraphs>
  <ul><li><p>Check the <alert>Overlay <m>t</m> Distribution</alert> box. </p></li></ul>
  <exercise xml:id="inv2-5-m" label="I7.2.13">
    <title>Compare <m>t</m>-distribution to normal</title>
    <statement>      
      <p>What is the main visual difference in the  <m>t</m>-distribution model compared to the normal distribution model? Does this  <m>t</m>-distribution appear to be a better model for the simulated sampling distribution? Is the theory-based p-value using the <m>t</m>-distribution closer to the empirical p-value than the theory-based p-value using the normal distribution?</p>
    </statement>
    <solution>
      <p>The <m>t</m> distribution has heavier tails, more area out there, giving us a better prediction. The p-value from the  <m>t</m> distribution is much closer to the simulation results.</p>
    </solution>
    <response/>
  </exercise>
  <p>The actual body temperature study involved a sample of <m>n = 130</m> adults. </p>
  <ul><li>
  Use the applet to generate a sampling distribution of <m>t</m>-statistics for this sample size. </li>
  <li>Toggle between the normal and <m>t</m> probability distributions. 
  </li></ul>
  <exercise xml:id="inv2-5-n" label="I7.2.14">
    <title>Analyze with larger sample size</title>
    <statement>
      <p>Do you see much difference between them? What is the actual value of the observed <m>t</m>-statistic with this sample size? Where does it fall in this distribution? What do you conclude about the null hypothesis?</p>
    </statement>
    <solution>
      <p>With a sample size of 130, we don't see as much distinction between the normal and <m>t</m> distributions. With <m>n = 130</m>, <m>SE = 0.733/\sqrt{130} \approx 0.0643</m> and <m>t = (98.249 - 98.6)/0.0643 \approx -5.459</m>. The sample mean of 98.249 is 5.459 standard errors below the population mean of 98.6, which implies 98.249 would be very surprising to observe for the sample mean if the population mean were really 98.6. This is far out in the tail of the simulated sampling distribution and gives strong evidence against the null hypothesis that the population mean is equal to 98.6. (We would reject the null hypothesis.)</p>
      <image source="images/Inv2.5nsols.jpg" width="60%">
        <description>Sampling distribution of t-statistics for n=130 with observed value</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <paragraphs>
    <title>Discussion</title>
    
    <p>The consequence of this exploration is that when we are estimating both the population mean and the population standard deviation, we will compare our standardized statistic for the sample mean to the <m>t</m>-distribution instead of to the normal distribution to approximate p-values and confidence intervals. Although with larger sample sizes, the distinction will be quite minor.</p>
  </paragraphs>
  
  <assemblage xml:id="probability-detour-t-distribution">
    <title>Probability Detour – Student's <m>t</m>-distribution</title>
    
    <p>The <m>t</m> probability density curve is described by the following function:</p>
    <p><me>f(x) = \frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\sqrt{\nu\pi}\,\Gamma\left(\frac{\nu}{2}\right)}\left(1+\frac{x^2}{\nu}\right)^{-\frac{\nu+1}{2}}</me> where <m>-\infty &lt; x &lt; \infty</m></p>
    
    <p>An impressive function indeed! But you should notice that this function only depends on the parameter <m>\nu</m>, referred to as the <em>degrees of freedom</em>.</p>
    
    <p>This symmetric distribution has heavier tails than the standard normal distribution. We get a different <m>t</m>-distribution for each value of the degrees of freedom. As the degrees of freedom increase, the <m>t</m>-distribution approaches the standard normal distribution.</p>
    
    <sidebyside widths="47% 40%">
      <image source="images/Inv2.5t1.png">
        <description>t-distribution curves with different degrees of freedom</description>
      </image>
      <image source="images/Inv2.5t2.png">
        <description>t-distribution approaching normal distribution as degrees of freedom increase</description>
      </image>
    </sidebyside>
  </assemblage>
  
  <assemblage xml:id="one-sample-t-test">
    <title>One-sample <m>t</m>-test for <m>\mu</m></title>
    
    <p>To test a null hypothesis about a population mean <m>H_0: \mu = \mu_0</m>, when we don't know the population standard deviation (pretty much always), we will use the sample standard deviation to calculate the standard error <m>SE(\bar{x})</m> and compare the standardized statistic</p>
    
    <p><me>t = \frac{\bar{x} - \mu_0}{SE(\bar{x})} = \frac{\bar{x} - \mu_0}{s/\sqrt{n}}</me></p>
    
    <p>to a <m>t</m>-distribution with <m>n - 1</m> degrees of freedom. Theoretically, this approximation requires the population to follow a normal distribution. However, statisticians have found this approximation to also be reasonable for other population distributions whenever the sample size is large. How large the sample size needs to be depends on how skewed the population distribution is. Consequently, we will consider the <m>t</m> procedures valid when either the population distribution is symmetric or the sample size is large (e.g., larger than 30).</p>
  </assemblage>
  
  <assemblage xml:id="probability-detour-df">
    <title>Probability Detour – Degrees of Freedom</title>
    
    <p>Recall the formula for the sample standard deviation <m>s</m> (<xref ref="invA" text="custom">Investigation A</xref>), compares each observed data value <m>x_i</m> to the sample mean <m>\bar{x}</m>. But <m>\bar{x}</m> is calculated by averaging those same data values. So if I know <m>n - 1</m> of those data values and I know <m>\bar{x}</m>, then that last observation is forced to be a particular value. So we say the calculation has <m>n - 1</m> degrees of freedom, and that's why that formula divides by <m>n - 1</m>.</p>
  </assemblage>
  
  <paragraphs>
    <title>But what about confidence intervals?</title>
  </paragraphs>

      <p>Turn to the <url href="https://www.rossmanchance.com/applets/2021/confsim/ConfSim.html?hideExtras=1">Simulating Confidence Intervals applet</url>.</p>
      <ul>
        <li><p>Change the <alert>Statistic</alert> to Means, but keep the <alert>Distribution</alert> set to Normal and the <alert>Method</alert> as <m>z</m> with sigma.</p></li>
        <li><p>Set the population mean to 98.6, the population standard deviation to 0.733, and the sample size to 13.</p></li>
  <li>Generate 1000 random samples from this population and examine the running total for the percentage of 95% confidence intervals <m>(\bar{x} \pm 1.96\sigma/\sqrt{n})</m> that successfully capture the actual value of the population mean <m>\mu</m>.</li>
          </ul>
    <interactive iframe="https://www.rossmanchance.com/applets/2021/confsim/ConfSim.html?hideExtras=1" width="160%" aspect="3:2"/>
  <exercise xml:id="inv2-5-o" label="I7.2.15">
    <title>Examine <m>z</m> with sigma intervals</title>
    <statement>
      <p>Is this 95% confident "<m>z</m> with sigma" procedure behaving as it should? How are you deciding?
        [Press Sort. In what situations can an interval fail to capture <m>\mu</m>?]</p>
    
    </statement>
    <solution>
      <p>Results will vary, but should be close to 95%, indicating that the method does achieve the claimed confidence level. After sorting, we can see that intervals fail to capture <m>\mu</m> when the sample mean is unusually far from the population mean.</p>
      <image source="images/Inv2.5osols.png" width="60%">
        <description>Confidence interval simulation showing 95% coverage rate</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-5-p" label="I7.2.16">
    <title>Predict effect of using <m>s</m></title>
    <statement>
      <p>But more realistically, we don't know <m>\sigma</m> and will use <m>s</m> in calculating our confidence interval (e.g., <m>\bar{x} \pm 1.96s/\sqrt{n}</m>). Predict what will change about the resulting confidence intervals from different random samples if we use each sample standard deviation in place of <m>\sigma</m>.</p>
    <hint>
      <p>Think of two main properties of confidence intervals.</p>
    </hint>
    </statement>
    <solution>
      <p>Predictions will vary, but should think about how lengths of intervals will change from sample to sample. (The centers will be the same for both CI simulations.)</p>
    </solution>
    <response/>
  </exercise>
  <ul><li>Change the <alert>Method</alert> now to <m>z</m> with <m>s</m>. </li></ul>
  <exercise xml:id="inv2-5-q" label="I7.2.17">
    <title>Test <m>z</m> with <m>s</m> method</title>
    <statement>
      <p>What percentage of these 1000 confidence intervals succeed in capturing the population mean of 98.6? Is this close to 95%? If not, is it larger or smaller?</p>
    </statement>
    <solution>
      <p>Percentage drops to 91 or 92%.</p>
      <image source="images/Inv2.5qsols.png" width="60%">
        <description>Confidence interval simulation using z with s method showing reduced coverage</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-5-r" label="I7.2.18">
    <title>Repeat with smaller sample size</title>
    <statement>
      <p>Repeat the previous question with a sample size of <m>n = 5</m>.</p>
    </statement>
    <solution>
      <p>With a sample size of 5, the percentage will be closer to or even below 90% indicating that the method does not work as it should.</p>
      <image source="images/Inv2.5rsols.png" width="60%">
        <description>Confidence interval simulation with n=5 showing poor coverage rate</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <paragraphs>
    <title>Discussion</title>
    
    <p>This "<m>z</m> with <m>s</m>" procedure produces a coverage rate (for successfully capturing the value of the population mean) that is less than 95%, because again the normal distribution doesn't account for the additional uncertainty resulting from sample to sample when we need to use both <m>\bar{x}</m> and <m>s</m>. The fix will be to multiply the standard error by a critical value larger than 1.96 to compensate for the additional uncertainty introduced by estimating <m>\sigma</m> with <m>s</m>. The <m>t</m>-distribution will come to our rescue. Which <m>t</m>-distribution do we use? That will depend on our sample size; with smaller samples we need heavier tails and with larger samples we need a distribution more like the normal probability model. The heaviness of the tails will be determined by the "degrees of freedom" of the <m>t</m>-distribution.</p>
  </paragraphs>
  
  <ul>
  <li>Change the <term text="custom">Method</term> to <em>t</em>. </li>
  </ul>
  <exercise xml:id="inv2-5-s" label="I7.2.19">
    <title>Test <m>t</m>-interval method</title>
    <statement>
      <p>How do the intervals visibly change? Is the coverage rate indeed closer to 95%?</p>
    </statement>
    <solution>
      <p>The intervals become longer and now the overall percentage is closer to 95%.</p>
      <image source="images/Inv2.5ssols.png" width="60%">
        <description>Confidence interval simulation using t method showing improved coverage</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <p>This leads to a confidence interval formula with the same general form as in the previous chapter:  <m>sample\ statistic \pm  (critical\ value) \times (SE\ of\ statistic)</m>, where the critical value now comes from the <m>t_{n-1}</m> distribution (degrees of freedom = <m>n - 1</m>) instead of from the standard normal distribution.</p>
  
  <assemblage xml:id="one-sample-t-interval">
    <title>One-sample <m>t</m>-interval for <m>\mu</m></title>
    
    <p>When we have a symmetric sample or a large sample size, an approximate confidence interval for <m>\mu</m> is given by:</p>
    
    <p><me>\bar{x} \pm t_{n-1}^* \times \frac{s}{\sqrt{n}}</me></p>
    
    <p>Keep in mind that the critical value <m>t^*</m> tells us how many standard errors we need to extend from the sample mean (in each direction) based on how confident we want to be. Our goal is to develop a <m>100 \times C\%</m> confidence interval method that will capture the population parameter <m>(100 \times C)\%</m> of the time in the long run.</p>
  </assemblage>
  
  <paragraphs>
    <title>Technology Detour - Finding <m>t^*</m></title>
    <exercise xml:id="inv2-5-t-tech-combined" label="I7.2.20tech.combined">
      <title>Find Critical <m>t^*</m> Value with Technology</title>
      <statement>
        <p>Use technology (Applet, R, or JMP) to find the <m>t^*</m> value corresponding to a 95% confidence level and a sample size of <m>n = 5</m>. Choose one set of instructions below by clicking on a hint.</p>
        <p>Enter the <m>t^*</m> value you find: <var width="10"/></p>
      </statement>
      <hint>
        <title><url href="https://www.rossmanchance.com/applets/2021/tcalc/tCalc.htm?hideExtras=1" visual="rossmanchance.com/applets/2021/tcalc/tCalc.htm">t Probability Calculator applet</url></title>
        <p>Use the <url href="https://www.rossmanchance.com/applets/2021/tcalc/tCalc.htm?hideExtras=1" visual="rossmanchance.com/applets/2021/tcalc/tCalc.htm">t Probability Calculator applet</url> to find critical <m>t^*</m> values:</p>
        <p><ul>
          <li><p>Specify the degrees of freedom (df = <m>n - 1</m>)</p></li>
          <li><p>Check the box next to the less than symbol and then enter <m>(1-C)/2</m> (e.g., 0.025 for 95% confidence) in the probability box and press Return. The <m>t</m>-value box should fill in.</p></li>
        </ul></p>
        <p>For this problem, use df = 4 and probability = 0.025.</p>
        <interactive iframe="https://www.rossmanchance.com/applets/2021/tcalc/tCalc.htm?hideExtras=1" width="100%" aspect="5:3"/>
      </hint>
      <hint>
        <title>R/Sage Instructions</title>
        <p>Use R to find <m>t^*</m> with the <c>iscaminvt</c> function:</p>
        <p><ul>
          <li><p><c>prob</c> = the probability (e.g., 0.95 for 95%)</p></li>
          <li><p><c>df</c> = degrees of freedom (n - 1)</p></li>
          <li><p><c>direction</c> = "between" for confidence intervals, "above" or "below" for one-sided tests</p></li>
        </ul></p>
        <p>For 95% confidence with df = 4:</p>
        <sage language="r">
          <input># Load ISCAM functions from GitHub
source("https://raw.githubusercontent.com/iambethchance/iscam-runestone/master/ISCAM-functions.R")

iscaminvt(0.95, 4, "between")</input>
        </sage>
        <p>This should return <m>t^* = 2.776</m> </p>
      </hint>
      <hint>
        <title>JMP Instructions</title>
        <p>Use the <url href="https://www.jmp.com/en_us/learning-library/videos/distribution-calculator.html" visual="jmp.com/learning-library/videos/distribution-calculator.html">Distribution Calculator</url> in JMP:</p>
        <p><ul>
          <li><p>Use the Distribution menu to select <m>t</m></p></li>
          <li><p>Specify the degrees of freedom (n - 1)</p></li>
          <li><p>Choose Input probability and calculate quantiles</p></li>
          <li><p>Specify Central Probability and enter the confidence level (e.g., .95)</p></li>
        </ul></p>
        <p>For this problem, use df = 4 and confidence level = 0.95.</p>
      </hint>
      <setup>
        <var>
          <condition number="2.776" tolerance="0.001">
            <feedback>
              <p>Correct! For 95% confidence with df = 4, <m>t^* = 2.776</m>.</p>
            </feedback>
          </condition>
          <condition string=".*">
            <feedback>
              <p>Incorrect. Remember to use df = n - 1 = 4 for a sample size of 5.</p>
            </feedback>
          </condition>
        </var>
      </setup>
      <solution>
        <p><m>t_4^* = 2.776</m></p>
        <image source="images/Inv2.5tsols.png" width="60%">
          <description>t probability calculator showing t* value for df=4</description>
        </image>
      </solution>
    </exercise>
  </paragraphs>
  
  <exercise xml:id="inv2-5-t" label="I7.2.20">
    <title>Find <m>t_4^*</m> for <m>n\ =\ 5</m></title>
    <statement>
      <p>Using the technology detour above, find the <m>t_4^*</m> value corresponding to a 95% confidence level and a sample size of <m>n = 5</m>. How does this <m>t^*</m> critical value compare to the corresponding <m>z^*</m> value of 1.96 for 95% confidence?</p>
      
      <p><m>t_4^*</m> = <var name="$tstar" width="10"/></p>
      <p>Compared to <m>z^* = 1.96</m>, the <m>t_4^*</m> value is: <var width="20"/> (larger, smaller, essentially the same)</p>
    </statement>
    <setup>
      <var>
        <condition number="2.776" tolerance="0.001">
          <feedback>
            <p>Correct! For 95% confidence with df = 4, <m>t^* = 2.776</m>.</p>
          </feedback>
        </condition>
        <condition number="1.96" tolerance="0.01">
          <feedback>
            <p>That's the <m>z^*</m> value. You need to find the <m>t^*</m> value with df = 4.</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Incorrect. Use technology to find the <m>t^*</m> critical value for 95% confidence with df = n - 1 = 4.</p>
          </feedback>
        </condition>
      </var>
      <var case="insensitive">
        <condition string="^\s*larger\s*$">
          <feedback>
            <p>Correct! The <m>t^*</m> value of 2.776 is larger than the <m>z^*</m> value of 1.96 because the <em>t</em>-distribution has heavier tails.</p>
          </feedback>
        </condition>
        <condition string="^\s*smaller\s*$">
          <feedback>
            <p>Incorrect. Compare 2.776 to 1.96. The <m>t^*</m> value is always at least as large as <m>z^*</m>.</p>
          </feedback>
        </condition>
        <condition string="^\s*(essentially\s+the\s+same|about\s+the\s+same|the\s+same)\s*$">
          <feedback>
            <p>Incorrect. There is a substantial difference between 2.776 and 1.96 with such small degrees of freedom.</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Please enter one of: larger, smaller, or essentially the same</p>
          </feedback>
        </condition>
      </var>
    </setup>
    <solution>
      <p><m>t_4^* = 2.776</m></p>
      <p>The <m>t^*</m> critical value of 2.776 is larger than the corresponding <m>z^*</m> value of 1.96 for 95% confidence. This is because the t-distribution has heavier tails than the normal distribution, especially with small degrees of freedom (df = 4 in this case).</p>
      <image source="images/Inv2.5tsols.png" width="60%">
        <description>t probability calculator showing t* value for df=4</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-5-v" label="I7.2.22">
    <title>Find <m>t^*</m> for <m>n = 13</m></title>
    <statement>
      <p>Find the <m>t^*</m> value for the sample size of <m>n = 13</m>.</p>
      
      <p><m>t_{12}^*</m> = <var name="$tstar" width="10"/></p>
      
      <p>How do the <m>t</m>-critical values compare for these different sample sizes?</p>
      
      <p>Compared to the <m>t^*</m> value from <xref ref="inv2-5-t" text="custom">Question 20</xref> (for <m>n = 5</m>), the <m>t^*</m> value for <m>n = 13</m> is: <var width="15"/> (larger, smaller, essentially the same)</p>
      
      <p>Compared to the <m>z^*</m> value of 1.96, the <m>t^*</m> value for <m>n = 13</m> is: <var width="15"/>(larger, smaller, essentially the same)</p>
    </statement>
    <hint>
      <p>Is this what you expected? Explain: As the sample size increases, the <m>t^*</m> value decreases and approaches the <m>z^*</m> value.</p>
    </hint>
    <setup>
      <var>
        <condition number="2.179" tolerance="0.002">
          <feedback>
            <p>Correct! For <m>n = 13</m> (df = 12), the 95% critical value <m>t^* = 2.179</m>.</p>
          </feedback>
        </condition>
        <condition number="2.776" tolerance="0.01">
          <feedback>
            <p>That's the <m>t^*</m> value for df = 4 (n = 5). You need df = 12 for n = 13.</p>
          </feedback>
        </condition>
        <condition number="1.96" tolerance="0.01">
          <feedback>
            <p>That's the <m>z^*</m> value. You need to find the <m>t^*</m> value with df = 12.</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Use technology to find the <m>t^*</m> critical value for 95% confidence with df = n - 1 = 12.</p>
          </feedback>
        </condition>
      </var>
      <var>
        <condition string="^\s*smaller\s*$">
          <feedback>
            <p>Correct! The <m>t^*</m> value decreases as sample size increases. For <m>n = 13</m> (df = 12), <m>t^* = 2.179</m>, which is smaller than 2.776 from <m>n = 5</m> (df = 4).</p>
          </feedback>
        </condition>
        <condition string="^\s*larger\s*$">
          <feedback>
            <p>Incorrect. As sample size increases, the <m>t^*</m> value approaches the <m>z^*</m> value, so it gets smaller.</p>
          </feedback>
        </condition>
        <condition string="^\s*about\s+the\s+same\s*$">
          <feedback>
            <p>Incorrect. There is a noticeable difference. Check the <m>t^*</m> values for different degrees of freedom.</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Please enter one of: larger, smaller, or about the same</p>
          </feedback>
        </condition>
      </var>
      <var>
        <condition string="^\s*larger\s*$">
          <feedback>
            <p>Correct! For <m>n = 13</m> (df = 12), <m>t^* = 2.179</m>, which is larger than <m>z^* = 1.96</m> because the <m>t</m>-distribution has heavier tails.</p>
          </feedback>
        </condition>
        <condition string="^\s*smaller\s*$">
          <feedback>
            <p>Incorrect. The <m>t^*</m> value is always larger than the corresponding <m>z^*</m> value, though it approaches <m>z^*</m> as sample size increases.</p>
          </feedback>
        </condition>
        <condition string="^\s*about\s+the\s+same\s*$">
          <feedback>
            <p>Close! They are getting closer, but there is still a noticeable difference. For df = 12, <m>t^* = 2.179</m> vs <m>z^* = 1.96</m>.</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Please enter one of: larger, smaller, or about the same</p>
          </feedback>
        </condition>
      </var>
    </setup>
    <solution>
      <p>The <em>t</em> critical value of 2.179 is much closer to the <em>z</em> critical value of 1.96 with a larger sample size. Compared to the <m>t</m> critical value from <xref ref="inv2-5-t" text="custom">Question 20</xref>, the current critical value has decreased (is smaller) suggesting that the <em>t</em> critical value will approach the <m>z</m> critical value as the sample size increases. </p>
      <image source="images/Inv2.5vsols.png" width="60%">
        <description>t probability calculator showing t* value for df=12</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-5-w" label="I7.2.23">
    <title>Find <m>t^*</m> for <m>n = 130</m></title>
    <statement>
      <p>Find <m>t^*</m> for the sample size of <m>n = 130</m>.</p>
      
      <p><m>t_{129}^*</m> = <var name="$tstar" width="10"/></p>
      
      <p>Compared to the earlier <m>t^*</m> values (for <m>n = 5</m> and <m>n = 13</m>), the <m>t^*</m> value for <m>n = 130</m> is: <var width="20"/> (larger, smaller, essentially the same)</p>
      
      <p>Compared to the <m>z^*</m> value of 1.96, the <m>t^*</m> value for <m>n = 130</m> is: <var width="20"/> (larger, smaller, essentially the same)</p>
    </statement>
    <setup>
      <var>
        <condition number="1.979" tolerance="0.002">
          <feedback>
            <p>Correct! For <m>n = 130</m> (df = 129), the 95% critical value <m>t^* = 1.979</m>.</p>
          </feedback>
        </condition>
        <condition number="1.96" tolerance="0.01">
          <feedback>
            <p>That's the <m>z^*</m> value. You need to find the <m>t^*</m> value with df = 129, which will be slightly larger.</p>
          </feedback>
        </condition>
        <condition number="2.179" tolerance="0.01">
          <feedback>
            <p>That's the <m>t^*</m> value for df = 12 (n = 13). You need df = 129 for n = 130.</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Use technology to find the <m>t^*</m> critical value for 95% confidence with df = n - 1 = 129.</p>
          </feedback>
        </condition>
      </var>
      <var case="insensitive">
        <condition string="^\s*smaller\s*$">
          <feedback>
            <p>Correct! As sample size increases, the <m>t^*</m> value decreases (gets smaller) and approaches the <m>z^*</m> value.</p>
          </feedback>
        </condition>
        <condition string="^\s*larger\s*$">
          <feedback>
            <p>Incorrect. Compare the values: 2.776 (n=5), 2.179 (n=13), and 1.979 (n=130). As sample size increases, what happens to <m>t^*</m>?</p>
          </feedback>
        </condition>
        <condition string="^\s*(essentially\s+the\s+same|about\s+the\s+same|the\s+same)\s*$">
          <feedback>
            <p>There is a noticeable difference. Compare 2.776 and 2.179 to 1.979.</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Please enter one of: larger, smaller, or about the same</p>
          </feedback>
        </condition>
      </var>
      <var case="insensitive">
        <condition string="^\s*larger\s*$">
          <feedback>
            <p>Correct! The <m>t^*</m> value of 1.979 is still slightly larger than the <m>z^*</m> value of 1.96, though they are getting closer with this large sample size.</p>
          </feedback>
        </condition>
        <condition string="^\s*(essentially\s+the\s+same|about\s+the\s+same|the\s+same)\s*$">
          <feedback>
            <p>This is also reasonable! They are very close (1.979 vs 1.96), though <m>t^*</m> is still slightly larger.</p>
          </feedback>
        </condition>
        <condition string="^\s*smaller\s*$">
          <feedback>
            <p>Incorrect. The <m>t^*</m> value should be larger than the <m>z^*</m> value. Compare 1.979 to 1.96.</p>
          </feedback>
        </condition>
        <condition string=".*">
          <feedback>
            <p>Please enter one of: larger, smaller, or about the same</p>
          </feedback>
        </condition>
      </var>
    </setup>
    <solution>
      <p>For <m>n = 130</m> (df = 129), <m>t^* = 1.979</m>, getting pretty close to 1.96. As the sample size increases, the <m>t^*</m> value decreases and approaches the <m>z^*</m> value.</p>
      <image source="images/Inv2.5wsols.png" width="60%">
        <description>t probability calculator showing t* value for df=129</description>
      </image>
    </solution>
    <response/>
  </exercise>
  
  <exercise xml:id="inv2-5-x" label="I7.2.24">
    <title>Calculate confidence interval</title>
    <statement>
      <p>Use the critical value from the previous question to calculate a 95% confidence interval for the mean body temperature of a healthy adult based on our sample <m>(\bar{x} = 98.249</m>, <m>s = 0.733</m>, <m>n = 130)</m>. Is this interval consistent with your conclusion about the null hypothesis in <xref ref="inv2-5-n" text="custom">Question 14</xref>? Explain.</p>
    </statement>
    <solution>
      <p>95% confidence interval = <m>98.249 \pm 1.979 \times \frac{0.733}{\sqrt{130}} = 98.249 \pm 0.127 = (98.122, 98.376)</m>. This interval does not contain 98.6, which is consistent with our rejection of 98.6 as a plausible value for the population mean.</p>
    </solution>
    <response/>
  </exercise>
  
  <paragraphs>
    <title>Technology Detour - One Sample <m>t</m>-procedures</title>
    <exercise xml:id="inv2-5-y-tech-combined" label="I7.2.25tech.combined">
      <title>Conduct One Sample <m>t</m>-test with Technology</title>
      <statement>
        <p>Use technology (Applet, R, or JMP) to verify your by-hand calculations for the body temperature study (<m>\bar{x} = 98.249</m>, <m>s = 0.733</m>, <m>n = 130</m>, hypothesized <m>\mu = 98.6</m>, two-sided test, 95% confidence). Choose one set of instructions below by clicking on a hint.</p>
        <p>Enter the p-value you find: <var width="10"/></p>
      </statement>
      <hint>
        <title><url href="https://www.rossmanchance.com/applets/2021/tbia/TBIA.html?hideExtras=1" visual="rossmanchance.com/applets/2021/tbia/TBIA.html">Theory-Based Inference applet</url></title>
        <sidebyside widths="55% 40%" valign="top">
          <stack>
            <p>Use the <url href="https://www.rossmanchance.com/applets/2021/tbia/TBIA.html?hideExtras=1" visual="rossmanchance.com/applets/2021/tbia/TBIA.html">Theory-Based Inference applet</url> to conduct a one sample <m>t</m>-test:</p>
            <p><ul>
              <li><p>Select <term index="no">One mean</term> from the Scenario pull-down menu</p></li>
              <li><p>You can check Paste data to copy and paste in the raw data, or type in the sample size, mean, and standard deviation. Press <term index="no">Calculate</term>.</p></li>
              <li><p>Check the box for Test of significance and enter the hypothesized value of <m>\mu</m> and set the direction of the alternative. Press <term index="no">Calculate</term></p></li>
              <li><p>Check the box for Confidence interval, enter the confidence level and press <term index ="no">Calculate CI</term>.</p></li>
            </ul></p>
          </stack>
          <stack>
            <image source="images/Inv2.5TBIA1.png">
              <description>Step 1: Entering data in Theory-Based Inference applet</description>
            </image>
            <image source="images/Inv2.5TBIA2.png">
              <description>Step 2: Setting up hypothesis test</description>
            </image>
            <image source="images/Inv2.5TBIA3.png">
              <description>Step 3: Calculating confidence interval</description>
            </image>
          </stack>
        </sidebyside>
            <p>For the body temperature study, enter n = 130, mean = 98.249, SD = 0.733. Set the hypothesized value to 98.6 and select a two-sided alternative.</p>
      </hint>
      <hint>
        <title>R/Sage Instructions</title>
        <p>Use R to conduct a one sample <m>t</m>-test. You can use the <c>iscamonesamplet</c> function with summary statistics where:</p>
        <p><ul>
          <li><p><c>xbar</c> = sample mean</p></li>
          <li><p><c>sd</c> = sample standard deviation</p></li>
          <li><p><c>n</c> = sample size</p></li>
          <li><p><c>hypothesized</c> = hypothesized mean value</p></li>
          <li><p><c>alternative</c> = "two.sided", "greater", or "less"</p></li>
          <li><p><c>conf.level</c> = confidence level (e.g., 0.95 for 95%)</p></li>
        </ul></p>
        <sage language="r">
          <input># Load ISCAM functions from GitHub
source("https://raw.githubusercontent.com/iambethchance/iscam-runestone/master/ISCAM-functions.R")

# Use iscamonesamplet with summary statistics for the body temperature study
iscamonesamplet(xbar=98.249, sd=.733, n=130, hypothesized=98.6, 
                alternative="two.sided", conf.level=0.95)</input>
        </sage>
        <p><em>OR</em> use base R's <c>t.test</c> with a vector of raw data:</p>
        <program language="r">
          <input>
# Example with raw data (replace with your actual data)
body_temps &lt;- c(98.4, 98.6, 98.8, ...) 
t.test(body_temps, mu=98.6, alternative="two.sided", conf.level=0.95)
          </input>
        </program>
        <p>The function will display:</p>
        <p><ul>
          <li><p><m>t</m>-statistic: -5.46</p></li>
          <li><p>Two-sided p-value: &lt; 0.001</p></li>
          <li><p>95% confidence interval: (98.122, 98.376)</p></li>
        </ul></p>
      </hint>
      <hint>
        <title>JMP Instructions</title>
        <p>You can use raw data or summary data (see second option):</p>
        <p><ul>
          <li><p>In the Data window, choose <term text="custom">Analyze > Distribution</term></p></li>
          <li><p>Specify the variable in the <term text="custom">Y, Columns</term> box</p></li>
          <li><p>The 95% confidence interval will be shown in the Summary Statistics box. If you want to change the confidence level, use the variable hot spot and select <term text="custom">Confidence interval</term>.</p></li>
          <li><p>To perform the test of significance, use the variable hot spot, select <term text="custom">Test Mean</term>. Then enter the hypothesized value of <m>\mu</m> and press <term text="custom">OK</term>.</p></li>
        </ul></p>
        <p>OR</p>
        <p><ul>
          <li><p>Open the ISCAM Journal file > <term text="custom">Hypothesis Test</term> for One Mean</p></li>
          <li><p>Choose Raw Data (and pick the column) or Summary Statistics (and then specify the sample size, sample mean, and sample standard deviation)</p></li>
          <li><p>Be sure to choose the <m>t</m>-test Test Type and specify the alternative hypothesis</p></li>
          <li><p>In the ISCAM Journal file > <term text="custom">Confidence Interval for One Mean</term></p></li>
          <li><p>Choose the <m>t</m> interval type and specify confidence level</p></li>
          <li><p>You can also use the <url href="https://www.jmp.com/en_us/learning-library/videos/distribution-calculator.html" visual="jmp.com/learning-library/videos/distribution-calculator.html">Distribution Calculator</url> to find critical values</p></li>
        </ul></p>
      </hint>
      <setup>
        <var>
          <condition number="0.0001" tolerance="0.0002">
            <feedback>
              <p>Correct! For <m>t = -5.46</m> with df = 129, the two-sided p-value is less than 0.001.</p>
            </feedback>
          </condition>
          <condition string=".*">
            <feedback>
              <p>Check your calculation. The <m>t</m>-statistic should be approximately -5.46.</p>
            </feedback>
          </condition>
        </var>
      </setup>
      <solution>
        <p>Using technology:</p>
        <p><ul>
          <li><p><m>t</m>-statistic = -5.46</p></li>
          <li><p>Two-sided p-value &lt; 0.001</p></li>
          <li><p>95% confidence interval: (98.122, 98.376)</p></li>
        </ul></p>
        <image source="images/Inv2.5ysolsApplet.png" width="60%">
          <description>Theory-Based Inference applet output for one sample <m>t</m>-test and confidence interval</description>
        </image>
      </solution>
    </exercise>
  </paragraphs>
  
  <exercise xml:id="inv2-5-y" label="I7.2.25">
    <title>Use technology to verify calculations</title>
    <statement>
      <p>Use the technology detour above to verify your by-hand calculations and 
      summarize the conclusions you would draw from this study (both from the p-value and the confidence interval, including the population you are willing to generalize to). Also include interpretations, in context, of your p-value and your confidence level.</p>
    </statement>
    <response/>
  </exercise>
  
  <assemblage xml:id="study-conclusions-2-5">
    <title>Study Conclusions</title>
    
    <p>The sample data provide very strong evidence that the mean body temperature of healthy adults is not 98.6 degrees (<m>t = 5.46</m>, two-sided p-value <m>&lt; 0.001</m>). This indicates there is less than a 0.1% chance of obtaining a sample mean as far from 98.6 as 98.249 in a random sample of 130 healthy adults from a population with mean body temperature of 98.6 °F. A 95% confidence interval for the population mean body temperature is (98.122, 98.376), so we can be 95% confident that the population mean body temperature among healthy adults is between 98.122 and 98.376 °F. This interval is entirely less than 98.6, consistent with our having found very strong evidence to reject 98.6 as a plausible value for the population mean. We are 95% confident, meaning if we were to repeat this procedure on thousands of random samples, in the long-run roughly 95% of the resulting intervals would successfully capture the population mean. We believe these procedures are valid because the sample size of 130 should be large enough unless there is severe skewness in the population.</p>
  </assemblage>
  
  </exercises>
  <subsection xml:id="practice2-5A">
    <title>Practice Problem 2.5A</title>
    
    <introduction>
      <p>Explore the last statements in the above results box using <m>t</m> confidence intervals:</p>
    </introduction>
    
    <exercise xml:id="practice-2-5a-a" label="PP2.5A.1">
      <title>Coverage rate for skewed population</title>
      <statement>
        <p>Continue with the <url href="https://www.rossmanchance.com/applets/2021/confsim/ConfSim.html?hideExtras=1">Simulating Confidence Intervals applet</url>. Simulating Confidence Intervals applet. Explore the coverage rate of the <m>t</m>-procedure with random samples from an Exponential (skewed) population for <m>n = 5</m>, <m>n = 100</m>, and <m>n = 200</m>. Assess and summarize the performance of this <m>t</m>-procedure in each case.</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-2-5a-b" label="PP2.5A.2">
      <title>Coverage rate for uniform population</title>
      <statement>
        <p>Repeat the previous question for a Uniform population distribution with endpoints <m>a = 80</m> and <m>b = 85</m>.</p>
      </statement>
      <response/>
    </exercise>
  </subsection>
  
  <subsection xml:id="practice2-5B">
    <title>Practice Problem 2.5B</title>
    
    <introduction>
      <p>Stanford researchers (e.g., <url href="https://med.stanford.edu/news/all-news/2020/01/human-body-temperature-has-decreased-in-united-states.html">Protsiv et al., 2020</url>) claim that average normal human-body temperature is closer to 97.5 degrees Fahrenheit (<url href="https://www.wsj.com/articles/98-6-degrees-fahrenheit-isnt-the-average-any-more-11579257001">McGinty, Wall Street Journal, 2020</url>). Part of the Stanford study was to use digital oral instruments to take temperature readings from 150,280 individuals 2007-2017 (578,222 measurements). They found a mean of 98.04 °F and a standard deviation of 0.502 °F.</p>
    </introduction>
    
    <exercise xml:id="practice-2-5b-a" label="PP2.5B.1">
      <title>Interpret standard deviation</title>
      <statement>
        <p>Provide a one-sentence interpretation of the standard deviation.</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-2-5b-b" label="PP2.5B.2">
      <title>Sources of variation</title>
      <statement>
        <p>Identify some "sources of variation" in individual body temperatures. Which of these are "between individuals" and which are "within individuals"?</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-2-5b-c" label="PP2.5B.3">
      <title>Source not captured by SD</title>
      <statement>
        <p>Identify a source of variation in temperature measurements not captured by the standard deviation.</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-2-5b-d" label="PP2.5B.4">
      <title>Justify <m>t</m>-distribution</title>
      <statement>
        <p>Give two reasons why a <m>t</m>-distribution is likely to be an appropriate model for these data.</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-2-5b-e" label="PP2.5B.5">
      <title>Test temperature claim</title>
      <statement>
        <p>Using the mean and SD values provided, do these data provide convincing evidence that the average healthy body temperature is below 98.6 °F? Comment on both a p-value and a 95% confidence interval.</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-2-5b-f" label="PP2.5B.6">
      <title>Define high temperature</title>
      <statement>
        <p>Based on these data, what would you consider a statistically high body temperature for an individual?</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-2-5b-g" label="PP2.5B.7">
      <title>Evaluate Wunderlich's measurements</title>
      <statement>
        <p>From this analysis can we conclude that Wunderlich's measurements were flawed? What could be another explanation?</p>
      </statement>
      <response/>
    </exercise>
  </subsection>
  
  <subsection xml:id="practice2-5C">
    <title>Practice Problem 2.5C</title>
    
    <exercise xml:id="practice-2-5c-a" label="PP2.5C.1">
      <title>Evaluate observed mean</title>
      <statement>
        <p>As in <xref ref="inv2-5-i" text="custom">Question 9</xref>, use the <url href="https://www.rossmanchance.com/applets/2021/sampling/OneSample.html?">Sampling from Finite Population</url> applet to select 10,000 samples of 13 adults from the hypothetical population of 10,000 body temperatures. Based on the generated distribution of sample means, is the observed mean of 98.249 (or more extreme in either direction) a surprising outcome for this population?</p>
      </statement>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-2-5c-b" label="PP2.5C.2">
      <title>Find interval of plausible values</title>
      <statement>
        <p>Check the Fixed radio button and use the Shift center slider on the left-hand side to (slowly) raise the population mean. Stop when you find a value of the population mean that you first consider surprising. Now use the slider to lower the population mean. What is the smallest value for <m>\mu</m> that you consider plausible based on this sample mean? In other words, report your interval of plausible values.</p>
      </statement>
      <hint>
        <p>Click on the slider handle and use the arrow keys on your keyboard.</p>
      </hint>
      <response/>
    </exercise>
    
    <exercise xml:id="practice-2-5c-c" label="PP2.5C.3">
      <title>Repeat for <m>n = 130</m></title>
      <statement>
        <p>Repeat using the sample size of <m>n = 130</m>.</p>
      </statement>
      <response/>
    </exercise>
  </subsection>
  
</section>
