<?xml version="1.0" encoding="UTF-8"?>
<chapter xml:id="chapter1">
  <title>Chapter 1: Analyzing One Categorical Variable</title>

<p>In this chapter, you will begin to analyze results from statistical studies
 and focus on the process of statistical inference. In particular, you will 
 learn how to assess evidence against a particular claim about a random process.</p>
 
  <subsection xml:id="section-1-analyzing-process-probability">
    <title>Section 1: Analyzing a Process Probability</title>
    
    <p>In this section, you will learn to use exact binomial calculations, simulations, and confidence intervals to analyze categorical data from statistical studies. These fundamental methods will prepare you for understanding more advanced approximation techniques later in the chapter.</p>
    
    <subsection xml:id="investigation1-1">
      <title>Investigation 1.1: Friend or Foe?</title>
      
      <introduction>
        <p>In a study reported in the November 2007 issue of <em>Nature</em>, researchers investigated whether infants take into account an individual's actions towards others in evaluating that individual as appealing or aversive, perhaps laying the foundation for social interaction (<url href="https://pubmed.ncbi.nlm.nih.gov/18033298/">Hamlin, Wynn, and Bloom, 2007</url>). In other words, do children who aren't even yet talking still form impressions as to someone's friendliness based on their actions?</p>
        
            <p>In one component of the study, sixteen 10-month-old infants were shown a <q>climber</q> character (a piece of wood with <q>googly</q> eyes glued onto it) that could not make it up a hill in two tries.</p>
            
            <aside>
              <title>Video Demonstrations</title>
              <p><url href="https://www.youtube.com/watch?v=WqEV9Otdp58">Video 1: Helper behavior</url></p>
              <p><url href="https://www.youtube.com/watch?v=YX6PTixcS5I">Video 2: Hinder behavior</url></p>
              <p><url href="https://www.youtube.com/watch?v=dijiqWrUOx0">Video 3: Infant choice</url></p>
              <p>More videos: <url href="http://campuspress.yale.edu/infantlab/media/">Yale Infant Lab</url></p>
            </aside>
            
            <p>Then the infants were shown two scenarios for the climber's next try, one where the climber was pushed to the top of the hill by another character (the <q>helper</q> toy) and one where the climber was pushed back down the hill by another character (the <q>hinderer</q> toy). The infant was alternately shown these two scenarios several times.</p>
            
       <sidebyside widths="58% 38%" margins="0% 4%" valign="top">
          <stack>
  
            <p>Then the child was presented with both pieces of wood (the helper and the hinderer characters) and asked to pick one to play with.</p>
          </stack>
          <image source="images/infant.GIF" width="100%">
            <description>Infant choosing between helper and hinderer toys</description>
          </image>
        </sidebyside>
      </introduction>
      
      <paragraphs>
        <title>Collecting the Data</title>
        
        <assemblage xml:id="def-sample">
          <title>Definitions: Sample and Sample Size</title>
          <p>A <term>sample</term> is a collection of observed outcomes generated by repeated realizations a random process. The set of observations should reflect the typical behavior, and the variability inherent in that process. A study's <term>sample size</term> is the number of outcomes observed.</p>
        </assemblage>
        
        <exercise xml:id="inv1-1-a" label="I1.1.1">
          <title>Identify the Sample</title>
          <statement>
            <p>Identify the sample in this study.</p>
          </statement>
          <hint>
            <p>The sample consists of the observational units from which data were collected.</p>
          </hint>
          <answer>
            <p>The sample is the observations from the 16 infants.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-b" label="I1.1.2">
          <title>Assess Independence Assumption</title>
          <statement>
            <p>Do you think it is reasonable to model these observations as independent realizations of the random process under <q>identical conditions</q>? Explain.</p>
          </statement>
          <hint>
            <p>Consider whether the infants can be viewed as interchangeable and whether each infant's choice was measured separately.</p>
          </hint>
          <answer>
            <p>Opinions will vary, but if we consider the infants as interchangeable (no differences between them) and the infants' choices were all measured separately, that this modeling assumption seems appropriate. In particular, we need to be willing to model each infant as having the same probability of picking the helper toy.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-c" label="I1.1.3">
          <title>Explain Experimental Controls</title>
          <statement>
            <p>Why is it important that the researchers varied the colors and shapes of the wooden characters and even on which side the toys were presented to the infants?</p>
          </statement>
          <hint>
            <p>Think about other factors besides the helping/hindering behavior that might influence an infant's choice.</p>
          </hint>
          <answer>
            <p>This is to control for (or at least balance out) any other factors that could be influencing the infants' choices.</p>
          </answer>
          <response/>
        </exercise>
        
        <assemblage xml:id="def-variable-types">
          <title>Definition: Variables</title>
          <p>The measurements we are taking define the <term>variable</term>. We classify the type of variable as <term>categorical</term> (assigning each observational unit to a category) or <term>quantitative</term> (assigning each observational unit a numerical measurement). A special type of categorical variable is a <term>binary variable</term>, which has just two possible outcomes (often labeled <q>success</q> and <q>failure</q>).</p>
        </assemblage>
        
        <exercise xml:id="inv1-1-d" label="I1.1.4">
          <title>Identify the Variable</title>
          <statement>
            <p>What is the variable we are measuring about each observation?</p>
          </statement>
          <hint>
            <p>Think about what information is recorded for each infant.</p>
          </hint>
          <answer>
            <p>Variable = which toy does the infant choose to play with.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-d2" label="I1.1.4b">
          <title>Classify Variable Type</title>
          <statement>
            <p>Is this variable quantitative or categorical?</p>
          </statement>
          <choices randomize="no">
            <choice correct="yes">
              <statement>
                <p>Categorical</p>
              </statement>
              <feedback>
                <p>Correct! The variable records which category (Helper or Hinderer) each infant chose, making it a categorical variable.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>Quantitative</p>
              </statement>
              <feedback>
                <p>Not quite. A quantitative variable would be a numerical measurement. Here we're recording which toy was chosen, which is a category.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>Think about whether the data is a number or a category.</p>
          </hint>
        </exercise>
        
        <assemblage xml:id="def-research-question">
          <title>Definition: Research Question</title>
          <p>A <term>research question</term> often looks for patterns in a variable or compares a variable across different groups or looks for a relationship between variables.</p>
        </assemblage>
        
        <exercise xml:id="inv1-1-e" label="I1.1.5">
          <title>State Research Question</title>
          <statement>
            <p>What research question is of interest here?</p>
          </statement>
          <hint>
            <p>What question are the researchers trying to answer about infant behavior?</p>
          </hint>
          <answer>
            <p>The research question is whether infants in general (assuming identical infants from a random process) are more likely to pick the helper toy than the hinderer toy in the long run.</p>
          </answer>
          <response/>
        </exercise>
      </paragraphs>
      
      <paragraphs>
        <title>Summarizing the Observed Data</title>
        
        <p>To summarize the distribution of a categorical variable, we can simply count how many are in each category and make a <term>bar graph</term><idx><h>bar graph</h><h>graphical display of categorical data with bars for each category</h></idx> to display the results, one bar for each outcome, with heights representing the number of observations in each category, separating the bars to indicate distinct categories.</p>
        
        <exercise xml:id="inv1-1-f" label="I1.1.6">
          <title>Create Bar Graph</title>
          <statement>
            <p>The <q>raw data</q> can be found on the course webpage as a txt file (<url href="https://www.rossmanchance.com/iscam3/data/InfantData.txt">InfantData.txt</url>). How many do you see of each possible outcome? Sketch the bar graph. Give your graph an <q>active title,</q> a concise sentence stating the main message/key takeaways from the graph.</p>
          </statement>
          <hint>
            <p>Count how many infants chose each toy. A bar graph should have bars for each category (Helper and Hinderer) with heights representing the counts.</p>
          </hint>
          <answer>
            <p>14/16 = 0.875</p>
            <p>Active title: A majority of infants preferred the helper toy.</p>
            <image source="tech_images/ch1solsbargraph.jpg" width="70%">
              <description>Bar graph showing 14 infants chose Helper toy and 2 chose Hinderer toy</description>
            </image>
          </answer>
          <response/>
        </exercise>
        
        <paragraphs xml:id="tech-detour-loading">
          <title>Technology Detour - Loading in a Data File</title>
          
          <exercise xml:id="tech-detour-r-loading-rstudio" label="Loading Data - RStudio">
            <title>Loading Data - RStudio</title>
            <statement>
              <p>In RStudio, choose <c>Import Dataset > From Text (readr)</c> and enter the URL, then press <c>Import</c>.</p>
              <ul>
                <li><p>Example URL: <url href="https://www.rossmanchance.com/iscam3/data/InfantData.txt">https://www.rossmanchance.com/iscam3/data/InfantData.txt</url></p></li>
                <li><p>Keep <c>First Row as Names</c> checked</p></li>
                <li><p>For ISCAM files, change the <c>Delimiter</c> to <c>Tab</c></p></li>
                <li><p>Press <c>Update</c> to preview the data</p></li>
                <li><p>You can set the dataset name</p></li>
              </ul>
              
              <note>
                <title>RStudio Reminder</title>
                <p>With other data files, you may need to consider how <q>missing values</q> are coded. The Import Dataset dialog gives you a preview so you can check that the data looks correct before importing.</p>
              </note>
            </statement>
            <solution>
              <p>After importing, you should see the data appear in your Environment pane (upper right) and a data viewer window will open showing the contents of the file. The data table should show one column named <c>choice</c> with 16 rows containing either "Helper" or "Hinderer".</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-r-loading" label="Loading Data - R">
            <title>Loading Data - R</title>
            <statement>
              <p><alert>Files from the Web</alert></p>
              <p>Open the InfantData.txt (raw data) link from the data files page, select all, copy, and then in R use the following command. Keep in mind that R is case sensitive:</p>
              
              <p><em>PC:</em></p>
              <program language="r" interactive="sage">
                <input>
InfantData = read.table("clipboard", header=TRUE)
                </input>
              </program>
              
              <p><em>Mac:</em></p>
              <program language="r" interactive="sage">
                <input>
InfantData = read.table(pipe("pbpaste"), header=TRUE)
                </input>
              </program>
              
              <p>You can also use a URL (in quotes). The <c>header</c> command indicates the variables have names.</p>
              
              <p><alert>Text Files on Your Computer</alert></p>
              <program language="r" interactive="sage">
                <input>
InfantData = read.table(file.choose(), header=T)
                </input>
              </program>
              
              <p>To see the data, type:</p>
              <program language="r" interactive="sage">
                <input>
View(InfantData)
# or
head(InfantData)
                </input>
              </program>
              
              <p>Next you can <q>attach</q> the file to be able to use variable names directly:</p>
              <program language="r" interactive="sage">
                <input>
attach(InfantData)    # Now R knows what the "choice" variable is
                </input>
              </program>
              
              <p>Or you need to clarify to R which datafile you are using (e.g., <c>InfantData$choice</c>).</p>
              
              <p><alert>Other Input Options</alert></p>
              <p>Depending on how the data you are pasting is formatted, you may need additional arguments:</p>
              <ul>
                <li><p><c>sep="\t"</c> - separated by tabs</p></li>
                <li><p><c>na.strings="*"</c> - how to code missing values</p></li>
                <li><p><c>strip.white=TRUE</c> - strip extra white space</p></li>
              </ul>
              
              <note>
                <title>R Reminder</title>
                <p>R is case sensitive! <c>InfantData</c> and <c>infantdata</c> are different objects. Always check your data after loading with <c>View()</c> or <c>head()</c> to make sure it loaded correctly. Using <c>attach()</c> lets you reference column names directly, but be careful - if you have multiple datasets loaded, this can cause confusion.</p>
              </note>
            </statement>
            <solution>
              <p>After running <c>head(InfantData)</c>, you should see output similar to:</p>
              <pre>
     choice
1    Helper
2    Helper
3    Helper
4    Helper
5    Helper
6  Hinderer
              </pre>
              <p>This shows the first 6 observations of the data. The full dataset contains 16 observations total.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-jmp-loading" label="Loading Data - JMP">
            <title>Loading Data - JMP</title>
            <statement>
              <p><alert>Method 1: Copy and Paste</alert></p>
              <p>Choose <c>File > New > Data table</c>. Open the <url href="https://www.rossmanchance.com/iscam2/data/InfantData.txt" target="_blank">InfantData.txt</url> (raw data) link from the <url href="https://www.rossmanchance.com/iscam4/files.html" target="_blank">data files page</url> and select all the observations and the variable name and copy the data into the clipboard. Return to the data table in JMP and select <c>Edit > Paste with Column Names</c>.</p>
              
              <p><alert>Method 2: Open File</alert></p>
              <p>If the .txt file is saved on your computer, you can choose <c>File > Open</c> and use the pull-down menu to change the file type.</p>
              
              <note>
                <title>JMP Reminder</title>
                <p>When using <c>Paste with Column Names</c>, make sure you include the header row (variable names) in your selection. JMP will automatically detect the data types for each column. Always check the data table after importing to ensure everything looks correct.</p>
              </note>
            </statement>
            <solution>
              <p>After pasting or opening the file, you should see a data table with one column labeled <c>choice</c> containing 16 rows. The column should be recognized as a Character data type. The values should alternate between "Helper" and "Hinderer" entries.</p>
              <image source="tech_images/JMPdatatable.png" width="70%">
                <description>JMP data table showing the choice column with 16 rows of Helper and Hinderer values</description>
              </image>
            </solution>
          </exercise>
        </paragraphs>
        
        <paragraphs xml:id="tech-detour-tallying">
          <title>Technology Detour - Tallying the Outcomes</title>
          
          <exercise xml:id="tech-detour-r" label="R">
            <title>Tallying the Outcomes - R</title>
            <statement>
              <p>To count the number of correct and incorrect responses, type:</p>
              <program language="r" interactive="sage">
                <input>
table(InfantData)
                </input>
              </program>
              
              <note>
                <title>R Reminder</title>
                <p>The <c>table()</c> function automatically counts the frequency of each unique value in your data. Make sure your data is loaded before running this command.</p>
              </note>
            </statement>
            <solution>
              <p>The output should show:</p>
              <pre>
choice
  Helper Hinderer 
      14        2
              </pre>
              <p>This indicates that 14 infants chose the Helper toy and 2 chose the Hinderer toy.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-jmp" label="JMP">
            <title>Tallying the Outcomes - JMP</title>
            <statement>
              <p>Choose <c>Analyze > Tabulate</c>. In the new window, drag the <c>choice</c> column to either the Drop Zone for columns or for rows. Press <c>Done</c>.</p>
              
              <image source="tech_images/JMPtabulate.png" width="70%">
                <description>JMP Tabulate window showing counts: Helper 14, Hinderer 2</description>
              </image>
              
              <note>
                <title>JMP Reminder</title>
                <p>Look for the red triangle (<q>hot spot</q>) menus in JMP windows - they provide additional options and actions. Dragging variables to different zones (rows vs. columns) changes how your table is organized.</p>
              </note>
            </statement>
            <solution>
              <p>The Tabulate output should display a table showing the counts for each category:</p>
              <ul>
                <li><p>Helper: 14</p></li>
                <li><p>Hinderer: 2</p></li>
                <li><p>Total (N): 16</p></li>
              </ul>
              <p>The exact layout depends on whether you placed the variable in rows or columns, but the counts will be the same.</p>
              <image source="tech_images/JMPtable.png" width="50%">
                <description>JMP frequency table showing choice categories and their counts</description>
              </image>
            </solution>
          </exercise>
        </paragraphs>
        
        <paragraphs xml:id="tech-detour-bargraphs">
          <title>Technology Detour - Bar Graphs</title>
          
          <exercise xml:id="tech-detour-r-bargraph-raw" label="Bar Graphs - R (raw data)">
            <title>Bar Graphs - R (raw data)</title>
            <statement>
              <p>You need to pass the tabled data into the barplot function:</p>
              <program language="r" interactive="sage">
                <input>
barplot(table(InfantData), xlab="Choice", ylab="Frequency")
                </input>
              </program>
              <p>You may need to toggle to the R Graphics Window to see the graph window. Now you can use R to export the graph to a file or you can Copy and Paste or use a screen capture.</p>
              
              <note>
                <title>R Reminder</title>
                <p>The <c>xlab</c> and <c>ylab</c> arguments add labels to your axes. Always label your graphs to make them interpretable! You can nest the <c>table()</c> function inside <c>barplot()</c> to go directly from raw data to a graph.</p>
              </note>
            </statement>
            <solution>
              <p>You should see a bar graph with two bars:</p>
              <ul>
                <li><p>A bar for "Helper" with height 14</p></li>
                <li><p>A bar for "Hinderer" with height 2</p></li>
              </ul>
              <p>The x-axis should be labeled "Choice" and the y-axis should be labeled "Frequency". The bars should have gaps between them to indicate these are categorical data.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-r-bargraph-summary" label="Bar Graphs - R (summary data)">
            <title>Bar Graphs - R (summary data)</title>
            <statement>
              <p>If you already (or only) have the summarized data (the number of successes and failures), you can type:</p>
              <program language="r" interactive="sage">
                <input>
barplot(c(14, 2), names.arg=c("Helper", "Hinderer"))
                </input>
              </program>
              
              <note>
                <title>R Reminder</title>
                <p>The <c>c()</c> function creates a vector (list) of values. The <c>names.arg</c> parameter assigns category labels to each bar. The order matters - the first count gets the first label!</p>
              </note>
            </statement>
            <solution>
              <p>You should see a bar graph identical to the one created from raw data:</p>
              <ul>
                <li><p>A bar labeled "Helper" with height 14</p></li>
                <li><p>A bar labeled "Hinderer" with height 2</p></li>
              </ul>
              <p>This method is useful when you only have summary statistics rather than the full dataset.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-jmp-bargraph-summary" label="Bar Graphs - JMP (summary data)">
            <title>Bar Graphs - JMP (summary data)</title>
            <statement>
              <p><alert>Method 1: From Tabulate Window</alert></p>
              <p>In the Tabulate window (from above), use the red down arrow in the upper left corner (<q>hot spot</q>) and select <c>Show Chart</c>. Best when using the Drop zone for rows.</p>
              
              <image source="tech_images/bargraphJMP1.png" width="50%">
                <description>JMP Tabulate window with Show Chart option</description>
              </image>
              
              <p><alert>Method 2: Graph Builder</alert></p>
              <p>If you have the categories and counts in a data window, choose <c>Graph > Graph Builder</c>. Drag the variable names to the x-axis and the counts to the y-axis. Press the 7th icon to convert the chart to a bar graph.</p>
              
              <image source="tech_images/bargraphJMP2.png" width="50%">
                <description>JMP Graph Builder interface for creating bar graphs from summary data</description>
              </image>
              
              <note>
                <title>JMP Reminder</title>
                <p>Graph Builder is JMP's most flexible graphing tool. The icons at the top let you switch between different graph types. Drag and drop variables to different zones to change what the graph displays.</p>
              </note>
            </statement>
            <solution>
              <p>You should see a bar graph showing two bars with the frequency counts clearly labeled. The Helper bar should be noticeably taller (14) than the Hinderer bar (2). The graph should automatically include axis labels and a legend if needed.</p>
              <image source="tech_images/JMPbargraph2.png" width="70%">
                <description>JMP bar graph created from summary data showing Helper and Hinderer counts</description>
              </image>
            </solution>
          </exercise>
          
          <exercise xml:id="tech-detour-jmp-bargraph-raw" label="Bar Graphs - JMP (raw data)">
            <title>Bar Graphs - JMP (raw data)</title>
            <statement>
              <p><alert>Method 1: Graph Builder</alert></p>
              <p>From the Data Table window, select <c>Graph > Graph Builder</c>. Drag the Choice variable to the X-axis. Hover until the X-region shows the group labels and then let go. Press the 7th (<q>Bar</q>) icon to convert the chart to a bar graph.</p>
              
              <image source="tech_images/bargraphJMP3.png" width="50%">
                <description>JMP Graph Builder showing dragging variable to X-axis</description>
              </image>
              
              <image source="tech_images/bargraphJMP4.png" width="50%">
                <description>JMP Graph Builder with Bar chart icon selected</description>
              </image>
              
              <p><alert>Method 2: Distribution Platform</alert></p>
              <p>Choose <c>Analyze > Distribution</c>. With the choice column highlighted, press the <c>Y, Columns</c> button (or drag to the white box). Press <c>OK</c>.</p>
              
              <image source="tech_images/bargraphJMP6.png" width="50%">
                <description>JMP Distribution output with frequency chart</description>
              </image>
              
              <p>You have lots of options here (using the hot spots), like turning the graph horizontal, adding an axis (putting it on the left), adding labels, separating bars, etc.</p>
              
              <image source="tech_images/bargraphJMP7.png" width="50%">
                <description>JMP Distribution hot spot menu options</description>
              </image>
              
              <note>
                <title>JMP Reminder</title>
                <p>The Distribution platform is great for exploring categorical data. Use the red triangle hot spots to customize your graph - you can make bars horizontal, add counts/percentages, change colors, and more. Experiment with the options to make your graph publication-ready!</p>
              </note>
            </statement>
            <solution>
              <p>Either method should produce a bar graph showing the distribution of choices. You should see:</p>
              <ul>
                <li><p>Two distinct bars for Helper and Hinderer</p></li>
                <li><p>The Helper bar should be approximately 7 times taller than the Hinderer bar (14 vs 2)</p></li>
                <li><p>Frequency counts labeled on or near the bars</p></li>
                <li><p>Clear axis labels and category names</p></li>
              </ul>
              <p>Using the Distribution platform gives you more statistical output beyond just the graph, including percentages and other summary statistics.</p>
              <image source="tech_images/JMPbargraph1.png" width="50%">
                <description>JMP bar graph showing Helper and Hinderer distribution</description>
              </image>
            </solution>
          </exercise>
        </paragraphs>
      </paragraphs>
      
      <paragraphs>
        <title>Drawing Conclusions Beyond the Sample</title>
        
        <p>Clearly a majority/more than half of the infants chose the helper toy in this sample of 16 infants. But does that convince us that infants in general are more likely to pick the helper toy in the long run? In other words, what is the probability that an infant will choose the helper toy?</p>
        
        <p><em>Model assumption:</em> Note we are assuming each infant has the same probability of picking the helper toy, we just don't know the value of that probability.</p>
        
        <exercise xml:id="inv1-1-g" label="I1.1.7">
          <title>Researchers' Hypothesis</title>
          <statement>
            <p>What do the researchers think is true about the value of this probability (e.g., do they think it is larger or smaller than 0.50)?</p>
          </statement>
          <choices randomize="no">
            <choice correct="yes">
              <statement>
                <p>Larger than 0.50</p>
              </statement>
              <feedback>
                <p>Correct! The researchers hypothesize that infants prefer the helper toy, which would mean the probability of choosing the helper is greater than 0.50.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>Smaller than 0.50</p>
              </statement>
              <feedback>
                <p>Not quite. If infants preferred the hinderer toy, the probability would be less than 0.50, but that's not what the researchers think.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>Equal to 0.50</p>
              </statement>
              <feedback>
                <p>Not quite. A probability of 0.50 would mean infants choose equally between the two toys, which is not the researchers' hypothesis.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>Consider what the research hypothesis is about infant preferences for the helper toy.</p>
          </hint>
        </exercise>
        
        <exercise xml:id="inv1-1-h" label="I1.1.8">
          <title>Consider Chance Explanation</title>
          <statement>
            <p>Is it possible that in the long run infants just choose equally between the two toys (e.g., the probability an infant will choose the helper toy is 0.5) and we just happened to see more than half choose the helper toy in our sample?</p>
          </statement>
          <choices randomize="no">
            <choice correct="yes">
              <statement>
                <p>Yes</p>
              </statement>
              <feedback>
                <p>Correct! It's possible that the true probability is 0.50 and we just observed an unusual sample by chance.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>No</p>
              </statement>
              <feedback>
                <p>Actually, it is possible. Random samples can vary, and we might see more than half choose the helper toy even if the true probability is 0.50.</p>
              </feedback>
            </choice>
          </choices>
        </exercise>
        
        <exercise xml:id="inv1-1-i" label="I1.1.9">
          <title>Rule Out Color Preference</title>
          <statement>
            <p>Is it plausible that the observed majority occurred because infants just prefer the color blue?</p>
          </statement>
          <choices randomize="no">
            <choice>
              <statement>
                <p>Yes</p>
              </statement>
              <feedback>
                <p>Not quite. The researchers varied the colors, shapes, and positions of the toys to balance out these factors, so color preference is not a plausible explanation.</p>
              </feedback>
            </choice>
            <choice correct="yes">
              <statement>
                <p>No</p>
              </statement>
              <feedback>
                <p>Correct! We are not considering color, shape, or position as the explanation because these factors were balanced in the design of the study.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>Recall why the researchers varied colors, shapes, and positions.</p>
          </hint>
        </exercise>
        
        <p>So that leaves us with two explanations for the majority we observed:</p>
        <p><ol>
          <li><p>There is something to the theory that infants are genuinely more likely to pick the helper toy (for some reason).</p></li>
          <li><p>Infants choose equally between the two toys in the long run and we happened to get <q>lucky</q> and had an unusual sample where most of the infants in our sample picking the helper toy.</p></li>
        </ol></p>
        
        <exercise xml:id="inv1-1-j" label="I1.1.10">
          <title>Choose Between Explanations</title>
          <statement>
            <p>So for the two possibilities we are still considering, how might you choose between them? In particular, how might you convince someone whether or not option (2) is plausible based on this study?</p>
          </statement>
          <hint>
            <p>Think about what makes an outcome unusual or typical when choices are made randomly.</p>
          </hint>
          <answer>
            <p>We would need to convince someone that if these results were just happening "randomly," it would be unusual to get 14 infants picking the helper toy.</p>
          </answer>
          <response/>
        </exercise>
        
        <p>Our analysis approach is going to be to assume the second explanation is true (similar to how in a legal trial we assume a defendant is innocent), and then see whether our data are consistent or inconsistent with that assumption. To do this, we need to investigate the values we expect to see for the number choosing the helper toy when 16 infants are equally choosing between the two toys. As you saw with the Random Babies (Investigation B), we can simulate the outcomes of a random process to help us determine which outcomes are more or less likely to occur.</p>
        
        <exercise xml:id="inv1-1-k" label="I1.1.11">
          <title>Design a Simulation</title>
          <statement>
            <p>Suggest a method for carrying out a simulation of 16 infants picking equally between the two toys.</p>
          </statement>
          <hint>
            <p>Think about a simple physical randomization device that gives two equally likely outcomes.</p>
          </hint>
          <answer>
            <p>We could toss a coin for each infant, letting heads represent choosing the helper toy and tails represent choosing the hinderer toy. This makes the two choices equally likely on each toss. Then use 16 coins or toss one coin 16 times to represent the 16 infants. (We are assuming these are equivalent, that the observational units are identical.) These results will help us assess the variability in the outcomes of 16 infants "just by chance." This will help us decide whether 14 is a typical outcome or an unusual outcome when we know for a fact that the "infants" choose equally (in the long run) between the two toys.</p>
          </answer>
          <response/>
        </exercise>
      </paragraphs>
      
      <paragraphs>
        <title>Simulation</title>
        
        <p>For a 50-50 simulation model, we can flip a fair coin. We can arbitrarily define <q>heads</q> to be choosing the helper toy and <q>tails</q> to be choosing the hinderer toy. We will repeat the random process 16 times to represent the 16 infants, and we will count how many times we flip heads, representing an infant choosing the helper toy. The chart below shows this mapping of the real world, which we saw one instance of, and the simulation model, which we can easily repeat many times. Keep in mind that in the simulation model, we know the probability of heads is 0.50.</p>
        
        <table xml:id="table-simulation-model">
          <title>Mapping real world to simulation model</title>
          <tabular halign="left" top="medium" bottom="medium" left="medium" right="medium">
            <row header="yes" bottom="medium" left="medium" right="medium">
              <cell right="medium"></cell>
              <cell right="medium">Real world</cell>
              <cell>Simulation model</cell>
            </row>
            <row bottom="minor" left="medium" right="medium">
              <cell right="medium">One observation</cell>
              <cell right="medium">Infant choice</cell>
              <cell>Coin toss</cell>
            </row>
            <row bottom="minor" left="medium" right="medium">
              <cell right="medium">Sample</cell>
              <cell right="medium">16 infants</cell>
              <cell>16 coin tosses</cell>
            </row>
            <row bottom="minor" left="medium" right="medium">
              <cell right="medium">Success</cell>
              <cell right="medium">Picks helper toy</cell>
              <cell>Lands heads</cell>
            </row>
            <row left="medium" right="medium">
              <cell right="medium">Probability of <q>success</q></cell>
              <cell right="medium">Unknown</cell>
              <cell>0.50</cell>
            </row>
          </tabular>
        </table>
        
        <exercise xml:id="inv1-1-l" label="I1.1.12">
          <title>Conduct Coin Toss Simulation</title>
          <statement>
            <p>Flip a coin 16 times, representing the 16 infants in the study (one repetition of this random process). Tally the results below and count how many of the 16 chose the helper toy:</p>
            <p><em><q>Could have been</q> outcomes</em></p>
            <p>Heads (helper toy): <var width="5"/></p>
            <p>Tails (hinderer toy): <var width="5"/></p>
            <p>Total number of heads in 16 tosses: <var width="5"/></p>
          </statement>
          <hint>
            <p>Flip a coin 16 times and count the number of heads and tails. The totals should add to 16.</p>
          </hint>
          <answer>
            <p>Results will vary by class. Below is one possible set of results:</p>
            <image source="tech_images/ch1solsdotplot.jpg" width="70%">
              <description>Dotplot showing distribution of class simulation results for number of heads in 16 coin tosses</description>
            </image>
          </answer>
        </exercise>
        
        <exercise xml:id="inv1-1-m" label="I1.1.13">
          <title>Combine Class Results</title>
          <statement>
            <p>Combine your simulation results for each repetition with your classmates' on the scale below. Create a dotplot by placing a dot above the numerical result found by each person's set of 16 tosses.</p>
          </statement>
          <hint>
            <p>Each person in class should contribute one dot to the class dotplot, placed above their number of heads out of 16.</p>
          </hint>
          <answer>
            <p>Results will vary by class. See image in the previous exercise for an example dotplot.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-n" label="I1.1.14">
          <title>Describe Simulation Variability</title>
          <statement>
            <p>Did everyone get the same number of heads every time? What is an average or typical number of heads in a set of 16 tosses? Is this what you expected? Explain.</p>
          </statement>
          <hint>
            <p>Look at the center of the dotplot. What value appears most frequently or is in the middle of the distribution?</p>
          </hint>
          <answer>
            <p>No, there will be variability across the sets of 16 tosses, but 8 heads is an average or typical number of heads.</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-o" label="I1.1.15">
          <title>Assess Unusualness</title>
          <statement>
            <p>Does 14 heads appear to be an unusual outcome for 16 observations from a process where heads should appear 50% of the time in the long run?</p>
          </statement>
          <hint>
            <p>Look at your class dotplot. How often did values as extreme as 14 (or more) occur? Is 14 in the "tail" or center of the distribution?</p>
          </hint>
          <answer>
            <p>Answers will vary, but 14 does appear to be somewhat unusual, not occurring very often, in the "tail" of the distribution.</p>
          </answer>
          <response/>
        </exercise>
        
        <p>We really need to simulate this hypothetical random selection process hundreds, preferably thousands of times. This would be very tedious and time-consuming with coins, so let's turn to technology.</p>
        
        <exercise xml:id="inv1-1-p" label="I1.1.16">
          <title>Simulate Using Technology</title>
          <statement>
            <p>Use the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url> to simulate these 16 infants making this helper/hinderer choice, still assuming that infants have no real preference and so are equally likely to choose either toy.</p>
            <p><ul>
              <li><p>Keep the Probability of heads set to 0.5.</p></li>
              <li><p>Set the Number of Tosses to 16.</p></li>
              <li><p>Keep the Number of repetitions at 1 for now.</p></li>
              <li><p>Press Draw Samples.</p></li>
            </ul></p>
            <p>Report the number of heads (i.e., the number of infants who choose the helper toy) for this <q>could have been</q> (under the assumption of no preference) outcome.</p>
            <p>Number of heads: <var width="5"/></p>
          </statement>
          <hint>
            <p>The applet will simulate flipping 16 coins and count the number of heads for you automatically.</p>
          </hint>
          <answer>
            <p>Results will vary.</p>
          </answer>
        </exercise>
        
        <exercise xml:id="inv1-1-q" label="I1.1.17">
          <title>Repeat Simulation Multiple Times</title>
          <statement>
            <p>Uncheck the Show animation box and press Draw Samples four more times, each time recording the number of the 16 infants who choose the helper toy. Did you get the same number of heads all five times?</p>
          </statement>
          <choices randomize="no">
            <choice>
              <statement>
                <p>Yes</p>
              </statement>
              <feedback>
                <p>Actually, random processes typically produce different results each time. You should see variation in the number of heads across the five repetitions.</p>
              </feedback>
            </choice>
            <choice correct="yes">
              <statement>
                <p>No</p>
              </statement>
              <feedback>
                <p>Correct! There should be variation in the results across the repetitions. This variability is a natural characteristic of random processes.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>Each repetition simulates a new set of 16 coin flips. Think about whether random processes produce identical results every time.</p>
          </hint>
        </exercise>
        
        <exercise xml:id="inv1-1-r" label="I1.1.18">
          <title>Generate Null Distribution</title>
          <statement>
            <p>Now change the Number of repetitions to 1995 and press Draw Samples, to produce a total of 2,000 repetitions of this random process of tossing a coin 16 times. For the dotplot you have created, what does each dot represent (i.e., what would you need to do to add another dot to the graph)?</p>
          </statement>
          <hint>
            <p>Think about what you did to create one dot in the physical coin-flipping activity.</p>
          </hint>
          <answer>
            <p>Each dot in the dotplot represents the number of heads in 16 coin tosses (representing the choices of a set of 16 infants).</p>
          </answer>
          <response/>
        </exercise>
        
        <exercise xml:id="inv1-1-r2" label="I1.1.18b">
          <title>Classify Graph Variable</title>
          <statement>
            <p>Is the graph variable (number of heads) quantitative or categorical?</p>
          </statement>
          <choices randomize="no">
            <choice correct="yes">
              <statement>
                <p>Quantitative</p>
              </statement>
              <feedback>
                <p>Correct! The variable "number of heads" is quantitative because it represents a numerical count that can be measured and has meaningful numerical values.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>Categorical</p>
              </statement>
              <feedback>
                <p>Not quite. The number of heads is a count (0, 1, 2, ..., 16), which makes it quantitative rather than categorical. Categorical variables assign observations to categories, not numerical values.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>What does the horizontal axis represent? Is it counting something or assigning categories?</p>
          </hint>
        </exercise>
        
        <exercise xml:id="inv1-1-s" label="I1.1.19">
          <title>Draw Conclusion</title>
          <statement>
            <p>Now that we have a better picture of the long-run behavior of this process, discuss whether you would consider option 2 before (j): <q>Infants choose equally between the two toys in the long run and we happened to get 'lucky' and find most of the infants in our sample picking the helper toy</q> to be a plausible conclusion for this study. Explain your reasoning as if to a skeptic.</p>
          </statement>
          <hint>
            <p>Look at how often 14 or more heads occurred in your 2,000 simulated repetitions. Is this common or rare? What does this tell you about the plausibility of the "no preference" assumption?</p>
          </hint>
          <answer>
            <p>Because it is very unlikely for us to have seen results at least as extreme as what we observed (14 successes) under the assumption of 50-50 chance, we have evidence against this claim and instead in favor of the claim that there is something other than random chance at play in this sample.</p>
          </answer>
          <response/>
        </exercise>
      </paragraphs>
      
      <paragraphs>
        <title>Discussion</title>
        
        <p>Returning to our legal trial analogy, if you decide that the observed <q>data</q> is unlikely to occur by chance alone, you are going to <q>reject</q> the assumption of <q>innocence</q> (and say we have evidence the defendant is guilty). If you decide the data/evidence is not unusual by chance alone, then you <q>fail to reject</q> that assumption (and we say we don't have evidence the defendant is guilty <mdash/> we aren't proving the defendant innocent, just that the evidence is not inconsistent with that assumption, <q>not guilty</q>).</p>
        
        <p>So based on these simulation results, we would say the data (14 helper choices out of 16 trials) is unusual under the assumption that infants genuinely have no preference and are choosing blindly when presenting the toys. This evidence convinces us that <q>There is something to the theory that infants are genuinely more likely to pick the helper toy (for some reason)</q> is the more believable explanation for why so many of the infants in this study picked the helper toy over the hinderer toy. We haven't proven this is true, but based on the strong majority these researchers saw, even for this small sample size of 16, we would consider the evidence convincing (<q>beyond a reasonable doubt</q>) that, in the long run, the probability of choosing the helper toy in this random process is greater than 0.5. Because the researchers controlled for other possible explanations for the observed preference results like color and handedness, we will conclude that there is convincing evidence that infants really do have a genuine preference for the helper toy over the hindering toy.</p>
      </paragraphs>
      
      <assemblage xml:id="study-conclusions-1-1">
        <title>Study Conclusions</title>
        
        <p>In a study of <q>social evaluation,</q> researchers explored whether pre-verbal infants have a preference for a <q>helping</q> toy over a <q>hindering</q> toy. Treating the 16 infants as identical observations from a random process with equal probability of success/failure, we find that getting 14 infants choosing the helper toy is not consistent with the types of values we expect to see when we have <q>infants</q> choosing equally between the two toys. This means that the researchers' data provide strong statistical evidence to reject this <q>no preference</q> model and conclude that the infants' choices are actually governed by a process where there is a genuine preference for the helper toy (or at least that it's more complicated than each infant flipping a coin to decide). Of course, this conclusion depends on the assumption of <q>identical infants</q> and that these 16 infants' choices are representative of the larger process of viewing the videos and selecting a toy. Also keep in mind that not all infants had a clear preference for either object.</p>
      </assemblage>
      
      <subsection xml:id="practice1-1A">
        <title>Practice Problem 1.1A</title>
        
        <p>In a second experiment, the same events were repeated but the object climbing the hill no longer had the googly eyes attached. The researchers wanted to see whether the preference was made based on a social evaluation more than a perceptual preference. Suppose 8 of 12 (different) infants chose the push-up toy.</p>
        
        <exercise xml:id="practice-1-1a-a" label="PP1.1A.1">
          <title>Determine Sample Size for Simulation</title>
          <statement>
            <p>If you were to use a coin to carry out a simulation analysis to evaluate these results: how many times would you flip the coin for one repetition <mdash/> 6, 8, 10, 12, 16, or 1000?</p>
          </statement>
          <choices randomize="no">
            <choice>
              <statement>
                <p>6</p>
              </statement>
              <feedback>
                <p>Not quite. Think about how many infants were in this experiment.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>8</p>
              </statement>
              <feedback>
                <p>Close, but this is the number who chose the push-up toy, not the total number of infants.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>10</p>
              </statement>
              <feedback>
                <p>Not quite. Check the problem statement for the total number of infants in the experiment.</p>
              </feedback>
            </choice>
            <choice correct="yes">
              <statement>
                <p>12</p>
              </statement>
              <feedback>
                <p>Correct! You need to flip the coin 12 times to represent the 12 different infants in this experiment, just like we flipped 16 times to represent the 16 infants in the original study.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>16</p>
              </statement>
              <feedback>
                <p>Not quite. That was the sample size in the original study, but this experiment has a different number of infants.</p>
              </feedback>
            </choice>
            <choice>
              <statement>
                <p>1000</p>
              </statement>
              <feedback>
                <p>Not quite. 1000 would be the number of repetitions we might do, not the number of coin flips per repetition.</p>
              </feedback>
            </choice>
          </choices>
          <hint>
            <p>How many infants participated in this second experiment? Each coin flip represents one infant's choice.</p>
          </hint>
        </exercise>
        
        <exercise xml:id="practice-1-1a-b" label="PP1.1A.2">
          <title>Evaluate Evidence Without Eyes</title>
          <statement>
            <p>Use the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url> to decide whether it is plausible that when the googly eyes are removed infants do not have a genuine preference between the two toys. What do you conclude?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-1B">
        <title>Practice Problem 1.1B</title>
        
        <p>In 2019, the home team won 54 of the first 88 games of the Premier Soccer League season. Consider these games as a sample from a random process (all games that could have occurred in first 3 months).</p>
        
        <exercise xml:id="practice-1-1b-a" label="PP1.1B.1">
          <title>Model the Soccer Process</title>
          <statement>
            <p>Could we use a coin tossing simulation to model this random process? What would each coin toss represent? What are we assuming about the process? How many times would we toss the coin for one repetition? Define what is meant by <q>probability of success</q> in this context.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-1b-b" label="PP1.1B.2">
          <title>Test Home Field Advantage</title>
          <statement>
            <p>Use the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url> to decide whether these data provide convincing statistical evidence that the home team is more likely than the visiting team to win in the long run. Justify your conclusion.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-1b-c" label="PP1.1B.3">
          <title>Test Home Advantage Without Fans</title>
          <statement>
            <p>At the beginning of the 2020 season, fans were not allowed at the games due to the Coronavirus pandemic. For the first three months of this season, the home team won 40 of 87 matches. Decide whether these data provide convincing statistical evidence that the home team is more likely than the visiting team to win when no fans are present. Justify your conclusion.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
    
    <subsection xml:id="investigation1-2">
      <title>Investigation 1.2: Can Wolves Understand Human Cues?</title>
      
      <sidebyside widths="58% 38%">
        <stack>
          <p>Previous research has demonstrated that domesticated dogs can be trained to understand human cues, such as looking or pointing at an object. But it was not clear how the animals would perform with "behavioral cues" showing intent such as reaching for, but not obtaining, or trying to open an object.</p>
          
        </stack>
        <image source="images/wolf.jpg" width="100%"/>
      </sidebyside>
          <p><url href="https://www.nature.com/articles/s41598-017-12055-6#MOESM1">Lampe et al. (2017)</url> gave captive wolves, pack dogs living in identical conditions to the wolves, and pet dogs living with families a series of "object-choice tasks." A table was placed outside a fenced compartment, and a container was placed at each end of the table, one containing food and one empty. The experimenter would give the cue as to which container had the food and then the animal would touch one of the two targets next to the containers. A 6-year-old female timber wolf, Yukon, chose the intended container in 6 of the 8 trials with behavioral cues.</p>
      
      <exercise xml:id="inv1-2-a" label="I1.2.1">
        <title>Identify Sample and Process</title>
        <statement>
          <p>Identify the sample/random process for this study.</p>
        </statement>
        <response/>
        <hint>
          <p>What is the sample size?</p>
        </hint>
        <solution>
          <p>The random process is the repeated trials given to Yukon (<m>n = 8</m>).</p>
        </solution>
      </exercise>
      

      <exercise xml:id="inv1-2-b" label="I1.2.2">
        <title>Identify the Variable</title>
        <statement>
          <p>Identify the variable of interest for this process.</p>
        </statement>
        <response/>
        <hint>
          <p>The variable is the measurements recorded for each observation.</p>
        </hint>
        <solution>
          <p>The variable is whether or not Yukon picks the cued container.</p>
        </solution>
      </exercise>

      <exercise xml:id="inv1-2-b2" label="I1.2.2b">
        <title>Classify Variable Type</title>
        <statement>
          <p>Is this variable quantitative or categorical?</p>
        </statement>
        <choices randomize="no">
          <choice correct="yes">
            <statement>
              <p>Categorical</p>
            </statement>
            <feedback>
              <p>Correct! The variable records which category (cued or not cued) Yukon chose, making it a categorical variable.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>Quantitative</p>
            </statement>
            <feedback>
              <p>Not quite. A quantitative variable would be a numerical measurement. Here we're recording which container was chosen, which is a category.</p>
            </feedback>
          </choice>
        </choices>
        <hint>
          <p>Think about whether the data is a number or a category.</p>
        </hint>
        <solution>
          <p>The variable is categorical.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="inv1-2-c" label="I1.2.3">
        <title>Expected Success Rate</title>
        <statement>
          <p>If Yukon was purely guessing, how often would you expect her to identify the correct container?</p>
        </statement>
        <choices randomize="no">
          <choice correct="yes">
            <statement>
              <p>about 50% of the time</p>
            </statement>
            <feedback>
              <p>Correct! With two equally likely options, we would expect Yukon to choose correctly about half the time by chance.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>about 33% of the time</p>
            </statement>
            <feedback>
              <p>This would be the probability if there were three equally likely options.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>about 75% of the time</p>
            </statement>
            <feedback>
              <p>This would mean Yukon has some understanding of the cues, not just guessing.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>about 25% of the time</p>
            </statement>
            <feedback>
              <p>This would be the probability if there were four equally likely options.</p>
            </feedback>
          </choice>
          <choice>
            <statement>
              <p>never</p>
            </statement>
            <feedback>
              <p>Even when guessing, there's a chance of being correct.</p>
            </feedback>
          </choice>
        </choices>
        <solution>
          <p>About 50% of the time.</p>
        </solution>
      </exercise>
      
      <p>We will think of the sample of 8 attempts as identical observations from a random process, and we are choosing between two possibilities:</p>
      <p><ol>
        <li><p>Yukon can understand behavioral cues,</p></li>
        <li><p>Yukon does not consistently understand behavioral cues and is guessing randomly.</p></li>
      </ol></p>
      
      <assemblage xml:id="def-hypotheses">
        <title>Definition: Hypotheses</title>
        <p>In drawing conclusions beyond our sample data to the underlying random process, we will often be choosing between two competing claims about the underlying process:</p>
        <p><ul>
          <li><p>The <term>null hypothesis</term><idx><h>null hypothesis</h><h>the "by chance alone" explanation</h></idx>, which is the "by chance alone" explanation;</p></li>
          <li><p>The <term>alternative hypothesis</term><idx><h>alternative hypothesis</h><h>what researchers hope to show</h></idx>, which is usually what the researchers are hoping to show.</p></li>
        </ul></p>
        
        <p>In Investigation 1.1, the null hypothesis was that infants (in general) choose equally among the two toys in the long run. The alternative hypothesis was that infants have a genuine preference for the helper toy.</p>
      </assemblage>
      
        <aside>
          <title>How to use matching questions</title>
          <p>Drag the descriptions from the left to match them with the correct answer on the right.</p>
        </aside>
      <exercise xml:id="inv1-2-d" label="I1.2.4">
        <title>State Hypotheses</title>
        <statement>
          <p>Identify the above possibilities as the null and alternative hypotheses.</p>
        </statement>
        <matches>
          <match order="1">
            <premise>Yukon does not consistently understand behavioral cues and is guessing randomly</premise>
            <response>Null Hypothesis</response>
          </match>
          <match order="2">
            <premise>Yukon can understand behavioral cues</premise>
            <response>Alternative Hypothesis</response>
          </match>
        </matches>
        <solution>
          <p><b>Null:</b> Yukon does not consistently understand behavioral cues and is guessing randomly between the 2 containers.</p>
          <p><b>Alternative:</b> Yukon can understand behavioral cues.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="inv1-2-e" label="I1.2.5">
        <title>Plan the Simulation</title>
        <statement>
          <p>So our simulation model is going to assume the null hypothesis is true and we will see how unusual it is to find 6 successes and 2 failures in 8 attempts. Can we use "coin tossing" again? How many times will we toss the coin?</p>
        </statement>
        <response/>
        <solution>
          <p>Yes, we can use coin tosses again with heads = top side down and tails = top side up. We want to use 8 tosses for each repetition and count how many heads we have.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="inv1-2-f" label="I1.2.6">
        <statement>
          <p>Use the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url> to carry out 1,000 repetitions of the simulation. Check the Summary Statistics box and report the mean and standard deviation of your simulated distribution of "could have been" outcomes.</p>
          <p>Mean: <var width="5"/> <br/>
          Standard deviation: <var width="5"/></p>
        </statement>
        <response/>
        <solution>
          <p>Example results:</p>
          <ul>
            <li>Histogram</li>
            <li>Description automatically generated with low confidence</li>
          </ul>
          <p>The mean number of heads is about 4 (half of 8) and the standard deviation of the number of heads is about 1.5.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="inv1-2-g" label="I1.2.7">
        <title>Evaluate Surprise Level</title>
        <statement>
          <p>Based on your simulation results, which assumes Yukon is guessing, should we be very surprised to see 6 correct guesses? Explain/support your reasoning.</p>
        </statement>
        <response/>
        <solution>
          <p>An outcome of 6 heads does not appear to be in the tail of the distribution.</p>
        </solution>
      </exercise>
      
      <paragraphs>
        <title>Measuring "Rareness"</title>
        
        <p>In Investigation 1.1, the observed result (14) was pretty far in the tail of the distribution and you probably agreed that we could consider it unusual. This result (6 out of 8) is not as inconsistent with the null hypothesis; so where do we "draw the line"? First, we need agree on a measure of "rareness." We could just calculate the theoretical probability of 6 heads in 8 tosses (0.1094), but keep in mind that if we have a larger sample size (e.g., 100 tosses), then any individual outcome (e.g., 62 heads) will have a small probability. So we want to judge how extreme our observation is relative to the other observations in the simulated distribution. One way to do this is to count how many outcomes are as or even more extreme (even further from the expected value) than the observed outcome. For example, if we tell you that only 1% of rattlesnakes are longer than 2.5 meters, then you know to be very surprised to see a 3-meter rattlesnake and you may even begin to think that what you are looking at is not a rattlesnake at all!</p>
        
        <exercise xml:id="inv1-2-h" label="I1.2.8">
          <title>Calculate P-value</title>
          <statement>
            <p>In the applet, enter 6 in the Count samples box and keep the "as extreme as" button to greater than or equal to, <m>\geq</m>. Report the proportion of the repetitions with 6 or more heads (correct choices).</p>
            <p>In 1,000 repetitions, assuming the probability of choosing correctly is 0.50, we found <var width="5"/> % of repetitions of 8 attempts to result in 6 or more successes.</p>
          </statement>
          <response/>
          <solution>
            <p>Results will vary but should be around 0.15, or 15% of repetitions resulting in 6 or more heads.</p>
          </solution>
        </exercise>
        
        <p>Notice that we consider the direction of the alternative hypothesis to help us determine which outcomes we consider "more extreme" than our observed outcome. This tail probability you found in (h) is referred to as the p-value.</p>
        
        <assemblage xml:id="def-pvalue-null-distribution">
          <title>Definition: Null Distribution and P-value</title>
          <p>Because the simulation assumes the null hypothesis to be true, we can refer to the distribution you simulated as the <term>null distribution</term><idx><h>null distribution</h><h>distribution assuming null hypothesis is true</h></idx>. When you determine the proportion of the results in the null distribution that are at least as extreme as the observed result, you are estimating a probability. We will refer to this probability as the <term>p-value</term><idx><h>p-value</h><h>probability of results as extreme as observed, assuming null hypothesis</h></idx>. We use the p-value to evaluate the strength of evidence against the null hypothesis.</p>
          
          <p>The smaller the p-value, the stronger the evidence against the null hypothesis. There are no hard-and-fast cut-off values for gauging the smallness of a p-value, but generally speaking:</p>
          <p><ul>
            <li><p>A p-value above 0.10 constitutes little or no evidence against the null hypothesis.</p></li>
            <li><p>A p-value below 0.10 but above 0.05 constitutes moderate evidence against the null hypothesis.</p></li>
            <li><p>A p-value below 0.05 but above 0.01 constitutes strong evidence against the null hypothesis.</p></li>
            <li><p>A p-value below 0.01 constitutes very strong evidence against the null hypothesis.</p></li>
          </ul></p>
        </assemblage>
        
        <exercise xml:id="inv1-2-i" label="I1.2.9">
          <title>Compare P-values</title>
          <statement>
            <p>Did everyone in your class obtain the same p-value? <em>(If not, are you surprised?)</em></p>
          </statement>
          <choices randomize="no">
            <choice>
              <statement>
                <p>Yes</p>
              </statement>
              <feedback>
                <p>Actually, because we're using simulation, each person's results will vary slightly.</p>
              </feedback>
            </choice>
            <choice correct="yes">
              <statement>
                <p>No</p>
              </statement>
              <feedback>
                <p>Correct! The p-value will vary slightly across simulations because of the random nature of the process.</p>
              </feedback>
            </choice>
          </choices>
          <solution>
            <p>No, the p-value will vary slightly across the simulations.</p>
          </solution>
        </exercise>
        
        <p>Because we are assuming a random process, we can use probability rules to calculate an "exact" value for the p-value. In fact, we have been assuming a very special random process, a binomial process.</p>
      </paragraphs>
      
      <paragraphs>
        <title>Probability Detour â€“ Binomial Random Variables</title>
        
        <assemblage xml:id="def-binomial-random-variable">
          <title>Definition: Binomial Random Variable</title>
          <p>A <term>Binomial random variable</term><idx><h>binomial random variable</h><h>counts successes in independent trials</h></idx> counts the number of successes in a random process with the following properties:</p>
          <p><ul>
            <li><p>Each trial results in either "success" or "failure" (we have a binary categorical variable).</p></li>
            <li><p>The trials are independent: The outcome of one trial does not change the probability of success on the next trial.</p></li>
            <li><p>The probability of success, <m>\pi</m>, is constant across the trials.</p></li>
            <li><p>There are a fixed number of trials, <m>n</m>.</p></li>
          </ul></p>
          
          <p>If the number of successes, <m>X</m>, is a binomial random variable, then we can say <m>X \sim \text{Binomial}(n, \pi)</m>.</p>
        </assemblage>
        
        <p>Because we are assuming the null hypothesis to be true, we are treating each attempt as an identical repetition of a random process with a probability of success of 0.50 for each attempt (always two containers to choose from), and one attempt outcome does not impact the probability of success on the next attempt (e.g., a screen was lowered between attempts and the location of the food randomized each time) so the attempts are independent. We are counting <m>X</m>, the observed number of correct choices in the <m>n = 8</m> trials. So <m>X \sim</m> (is distributed as) <m>\text{Binomial}(8, 0.50)</m> and we want to determine the probability of observing 6 or more successes in 8 attempts by chance alone, <m>P(X \geq 6)</m>. We will illustrate this calculation next, and then turn to technology to find binomial probabilities.</p>
        
        <paragraphs>
          <title>Calculating Binomial Probabilities</title>
          
          <exercise xml:id="inv1-2-j" label="I1.2.10">
            <title>Calculate Single Outcome Probability</title>
            <statement>
              <p>Let S represent Success and F represent Failure. Consider one particular outcome for the 8 trials with 6 successes: SSFSSSFS. Because we are assuming the trials are independent, we can find the probability of this event by multiplying together the probabilities of the individual outcomes in the event.</p>
              <p><md>
                <mrow>P(\text{SSFSSSFS}) \amp = P(S) \times P(S) \times P(F) \times P(S)</mrow>
                <mrow>\amp \quad \times P(S) \times P(S) \times P(F) \times P(S)</mrow>
              </md></p>
              <p>What is the calculated product? <var width="5"/></p>
            </statement>
            <response/>
            <solution>
              <p>0.58</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-k" label="I1.2.11">
            <title>Count Arrangements</title>
            <statement>
              <p>But there are other possible outcomes that would also result in 6 successes and 2 failures (for example, SFSSSSSF). How many ways are there to arrange the 6 successes among the 8 slots?</p>
              <p>This is where the binomial coefficient comes in handy. This <term>binomial coefficient</term><idx><h>binomial coefficient</h><h>counts ways to select k items from n</h></idx>, denoted by <m>C(n, k)</m> or <m>\binom{n}{k} = \frac{n!}{k!(n-k)!}</m>, counts the number of ways there are to select <m>k</m> items from a set of <m>n</m> items. In this case, we want to find the number of ways to select 6 spots from the 8 trials for the successes:</p>
              <p><me>C(8, 6) = \frac{8!}{6!2!}</me></p>
              <p>What is the calculated result? <var width="5"/></p>
            </statement>
            <response/>
            <solution>
              <p>28</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-l" label="I1.2.12">
            <title>Calculate Probability for 6 Successes</title>
            <statement>
              <p>Because the 28 outcomes corresponding to 6 successes are mutually exclusive (can't occur simultaneously), we can find the probability of at least one of them happening by adding all of the probabilities together:</p>
              <p><me>P(\text{SSFSSSFS}) + P(\text{SFSSSSSF}) + \ldots = 28 \times (0.5^8)</me></p>
              <p>What is the calculated product? <var width="5"/></p>
              <p>In general, the binomial probability of obtaining <m>k</m> successes in a sequence of <m>n</m> independent trials with success probability <m>\pi</m> on each trial is:</p>
              <p><me>P(X = k) = \binom{n}{k} \pi^k (1-\pi)^{n-k}</me></p>
              <p>where <m>\binom{n}{k} = \frac{n!}{k!(n-k)!}</m></p>
            </statement>
            <response/>
            <solution>
              <p>0.1094</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-m" label="I1.2.13">
            <title>Calculate Complete P-value</title>
            <statement>
              <p>Is the number you found in (l) our p-value for this study? If not, how would we find the p-value?</p>
            </statement>
            <response/>
            <solution>
              <p>No, so far we have found P(X = 6), but the p-value is defined as P(X &gt; 6).</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-n" label="I1.2.14">
            <statement>
              <p>In the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url>, check the Exact Binomial box. (Optional: See Technology Detour below.) How does the binomial distribution match up to your earlier simulation results? How does the binomial (or "exact") p-value compare to what you simulated earlier? Did everyone in class obtain the same "exact" p-value?</p>
            </statement>
            <response/>
            <solution>
              <p>0.1445. This should be similar to the simulation results and everyone would obtain the same calculated value.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="inv1-2-o" label="I1.2.15">
            <title>Interpret P-value</title>
            <statement>
              <p>Write a one-sentence interpretation of this p-value in this context. Key components to include: what random process is being repeated, what is the null hypothesis that we are assuming to be true, what is the observed result we are considering, which outcomes are we considering to be more extreme?</p>
            </statement>
            <response/>
            <solution>
              <p>If we were to repeatedly examine samples of 8 attempts from wolves who do not understand the communication cues, we would expect 6 or more wolves to pick the correct container for about 14% of those samples by chance alone.</p>
            </solution>
          </exercise>
        </paragraphs>
      </paragraphs>
      
      <paragraphs>
        <title>Conclusions</title>
        
        <exercise xml:id="inv1-2-p" label="I1.2.16">
          <title>State Conclusion</title>
          <statement>
            <p>Based on this analysis, do these data provide convincing evidence that wolves can understand behavioral cues?</p>
          </statement>
          <response/>
          <solution>
            <p>No, a p-value of 0.14 is not strong evidence against the null hypothesis. It is plausible that Yukon would do as well in 8 trials even if she didn't understand the cue and was simply guessing.</p>
          </solution>
        </exercise>
      </paragraphs>
      
      <assemblage xml:id="study-conclusions-1-2">
        <title>Study Conclusions</title>
        <p>If we assume Yukon is guessing between the two containers, regardless of the cue, then finding 6 or more successes in 8 trials is actually not very surprising (binomial p-value = 0.1445); about 14% of samples from a 50/50 process would show 6 or more successes in 8 trials. This does not provide convincing evidence that Yukon can perform "above chance," but there is not information about whether other wolves or other cues would show better performance.</p>
      </assemblage>
      
      <subsection xml:id="practice1-2A">
        <title>Practice Problem 1.2A</title>
        
        <p>When Yukon was given "communicative cues" (looking at the container, pointing to the container) instead of behavioral cues, she was correct in 7 out of 8 attempts. Does this outcome provide convincing evidence that wolves understand communicative cues?</p>
        
        <exercise xml:id="practice-1-2a-a" label="PP1.2A.1">
          <title>State Hypotheses</title>
          <statement>
            <p>State the null and alternative hypotheses for this study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2a-b" label="PP1.2A.2">
          <title>Calculate and Interpret P-value</title>
          <statement>
            <p>Report both a simulation-based and the exact p-value. Include a one-sentence interpretation of the p-value in this context.</p>
            <p>Simulation-based p-value: <var width="5"/></p>
            <p>Exact p-value: <var width="5"/></p>
            <p>Interpretation: The probability of <var width="30"/> assuming <var width="30"/>.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2a-c" label="PP1.2A.3">
          <title>Summarize Analysis and Conclusions</title>
          <statement>
            <p>Summarize your analysis and the conclusions you would draw from this study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2a-d" label="PP1.2A.4">
          <title>Evaluate Pooled Data Analysis</title>
          <statement>
            <p>Across the 12 wolves in the study, in the 64 trials with communicative cues, the wolves understood the cue 41 times. What is the new p-value for these results? Explain why this would not be an appropriate analysis.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-2B">
        <title>Practice Problem 1.2B</title>
        
        <p>A study in Psychonomic Bulletin and Review (<url href="https://psycnet.apa.org/record/2007-18366-015" target="_blank">Lea, Thomas, Lamkin, <ampersand/> Bell, 2007</url>) presented evidence that "people use facial prototypes when they encounter different names." Similar to one of the experiments they conducted, you will be asked to match photos of two faces to the names Tim and Bob. The researchers wrote that their participants "overwhelmingly agreed" on which face belonged to Tim. You will conduct a similar study in class to see whether your class also agrees with which face is Tim's more than you would expect from random chance (here "random chance" = there is no facial prototyping and people pick a name for the face on the left at random).</p>
        
        <exercise xml:id="practice-1-2b-a" label="PP1.2B.1">
          <title>Identify Process and Variable</title>
          <statement>
            <p>What is the sample/random process and variable in this study? What assumptions are we making about this process?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2b-b" label="PP1.2B.2">
          <title>State Hypotheses</title>
          <statement>
            <p>State the null and alternative hypotheses for this study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2b-c" label="PP1.2B.3">
          <title>Report Class Results</title>
          <statement>
            <p>Report the count, proportion, and percentage "correctly" identifying Tim's face in your class.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2b-d" label="PP1.2B.4">
          <title>Calculate P-value and Conclude</title>
          <statement>
            <p>Use the applet or the technology instructions below to obtain a binomial p-value. What do you conclude about the null hypothesis?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="practice-1-2b-e" label="PP1.2B.5">
          <title>Verify Binomial Assumptions</title>
          <statement>
            <p>Do you think the properties of the binomial random variable are met here? What assumptions need to be made?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <paragraphs xml:id="tech-detour-binomial">
        <title>Technology Detour â€“ Calculating Binomial Probabilities</title>
        
        <exercise xml:id="tech-detour-r-binomial" label="Binomial Probabilities - R">
          <title>Calculating Binomial Probabilities in R</title>
          <statement>
            <p>Make sure you have the ISCAM Workspace loaded.</p>
            <p>The <c>iscambinomprob</c> function takes the following inputs:</p>
            <p><ul>
              <li><p><c>k</c> = the observed value you want to calculate the probability about</p></li>
              <li><p><c>n</c> = the sample size of the binomial distribution</p></li>
              <li><p><c>prob</c> = the probability of success in the binomial distribution</p></li>
              <li><p><c>lower.tail</c> = TRUE if you want the probability less than or equal to the observed value, FALSE if want the probability greater than or equal to the observed value</p></li>
            </ul></p>
            
            <p>For the Friend or Foe study, in the Console at the prompt, type:</p>
            <program language="r" interactive="sage">
              <input>
iscambinomprob(k=14, n=16, prob=.5, lower.tail=FALSE)
              </input>
            </program>
            <p>or</p>
            <program language="r" interactive="sage">
              <input>
iscambinomprob(14, 16, .5, FALSE)
              </input>
            </program>
            <p>(Yes, "false" needs to be capitalized)</p>
            
            <p>You should see both the probability appear in the Console window and a shaded graph open in a separate Graphics window. (You may have to toggle windows to see this Graphics window.)</p>
            
            <note>
              <title>R Reminder</title>
              <p>The <c>iscambinomprob</c> function is part of the ISCAM package. Make sure to load the package first with <c>library(iscam)</c>. The <c>lower.tail</c> parameter controls the direction: FALSE gives you <m>P(X \geq k)</m>, TRUE gives you <m>P(X \leq k)</m>.</p>
            </note>
          </statement>
          <solution>
            <p>For the Friend or Foe study with 14 successes out of 16 trials, the binomial p-value should be very small (approximately 0.0021), indicating strong evidence against the null hypothesis that infants are choosing randomly between the two toys.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="tech-detour-jmp-binomial" label="Binomial Probabilities - JMP">
          <title>Calculating Binomial Probabilities in JMP</title>
          <statement>
            <p>Using the Distribution Calculator in the <url href="http://www.rossmanchance.com/iscam4/data/ISCAM_Journal.jrn" download="ISCAM_Journal.jrn" target="_blank">ISCAM Journal File</url> (Download this file to your computer and then open the .jrn file to launch JMP.)</p>
            <p><ol>
              <li><p>Select Binomial from the Distribution pull down menu.</p></li>
              <li><p>Specify the values of the probability of success (<m>\pi</m>) and n (the sample size).</p></li>
              <li><p>Leave the Type of Calculation as is.</p></li>
              <li><p>Select Probability Option <m>X \geq Q_a</m> but specify <m>Q_a</m> to equal <m>k-1</m> (e.g., 13).</p></li>
              <li><p>Press Enter.</p></li>
            </ol></p>
            
            <note>
              <title>JMP Reminder</title>
              <p>In JMP's Distribution Calculator, you need to subtract 1 from your observed value when using the <m>\geq</m> option because JMP calculates <m>P(X > Q_a)</m> as <m>P(X \geq Q_a + 1)</m>. So to get <m>P(X \geq 14)</m>, you enter 13 as <m>Q_a</m>.</p>
            </note>
          </statement>
          <solution>
            <p>The JMP Distribution Calculator will display both the probability value and a visual representation of the binomial distribution with the tail area shaded. For finding <m>P(X \geq 14)</m> when <m>n=16</m> and <m>\pi=0.5</m>, enter 13 for <m>Q_a</m> to get the correct p-value of approximately 0.0021.</p>
          </solution>
        </exercise>
      </paragraphs>
    </subsection>
    
    <subsection xml:id="investigation-1-3">
      <title>Investigation 1.3: Are You Clairvoyant?</title>
      
      <introduction>
        <p>A standard test for extra-sensory perception (ESP) asks subjects to identify which of five symbols (e.g., circle, plus, square, diamond, waves) is on the front of a card, viewed by the experimenter but not the subject. The experimenter concentrates on the symbol and a <q>hit</q> is when the subject correctly identifies the symbol being viewed by the experimenter. The subject is given several trials, with the viewed symbol randomly determined for each of the trials, with no discernible pattern.</p>
        
        <figure xml:id="fig-esp-cards">
          <caption>ESP Test Symbols</caption>
          <image source="esp.png" width="60%">
            <description>Five ESP test symbols: circle, plus sign, square, diamond, and wavy lines</description>
          </image>
        </figure>
      </introduction>
      
      <p>Online tests are available as well. Go to <url href="http://www.psychicscience.org/esp3.aspx" target="_blank">www.psychicscience.org/esp3.aspx</url> to test your clairvoyance (predicting what's about to happen rather than reading what someone else is thinking). Scroll down to Advanced ESP Test and review the 5 possible symbols, then press Start. Click on the card that you believe is about to be shown. Repeat for 10 rounds, keeping tracking of the number of hits in your first 10 attempts.</p>
      
      <exercise xml:id="I1-3-1" label="I1.3.1">
        <title>Conduct the ESP Test</title>
        <statement>
          <p>How many hits did you get? <var width="10" /></p>
        </statement>
      </exercise>
      
      <exercise xml:id="I1-3-2" label="I1.3.2">
        <title>Identify Sample and Variable</title>
        <statement>
          <p>Identify the sample and variable for this random process.</p>
        </statement>
        <response/>
        <hint>
          <p>What is the sample size? What was measured about each observation?</p>
        </hint>
        <solution>
          <p>The random process is the repeated attempts to identify the symbol correctly. The sample size is the 10 trials. Variable = correct/incorrect identification (categorical). The sample size is 10.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-3" label="I1.3.3">
        <title>Binomial Random Process</title>
        <statement>
          <p>Do you consider it reasonable to model your observations as coming from a binomial random process? Explain your reasoning.</p>
        </statement>
        <response/>
        <hint>
          <p>Consider the four conditions for a binomial process: two outcomes, independence, fixed number of trials, and constant probability.</p>
        </hint>
        <solution>
          <p>If the target symbols are randomly selected (equally likely), the student uses the same method each time, and the student is not more likely to correctly identify some symbols more than others (e.g., guessing each time) then a binomial process does seem reasonable.</p>
        </solution>
      </exercise>
      
      <assemblage xml:id="terminology-statistic-parameter">
        <title>Terminology Detour: Statistic vs. Parameter</title>
        
        <p>In analyzing data, it is important to differentiate between a <term>statistic</term> and the <term>parameter</term>. The observed statistic is a (known) numerical value that summarizes the observed results, whereas the parameter is the same numerical summary but applied to the underlying random process that generated the data. The value of the statistic is what we observe in the study, whereas the value of the parameter is rarely known.</p>
        
        <p>In Investigation 1.1, the statistic could be either the number (14) or the proportion (0.875) of infants who chose the helper toy. The parameter would then be the long-run probability of an infant picking the helper toy. In the case of a binomial random variable, we will use the symbol <m>\pi</m> (lower case Greek letter for <q>p</q>) to represent this unknown process probability.</p>
      </assemblage>
      
      <exercise xml:id="I1-3-4" label="I1.3.4">
        <title>Identify the Parameter</title>
        <statement>
          <p>Identify (in words) the parameter of interest for this study.</p>
        </statement>
        <response/>
        <hint>
          <p>A parameter describes a long-run probability or proportion for the entire process, not just your sample result.</p>
        </hint>
        <solution>
          <p>The parameter is your probability of correct identification (the long-run probability of correctly identifying the symbol).</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-4b" label="I1.3.4b">
        <title>Parameter Symbol</title>
        <statement>
          <p>What symbol will we use to represent this parameter?</p>
        </statement>
        <hint>
          <p>Look for the Greek letter used for a process probability in a binomial distribution.</p>
        </hint>
        <choices randomize="no">
          <choice>
            <statement><p><m>\hat{p}</m></p></statement>
            <feedback><p>This is the symbol for the sample proportion (statistic), not the population parameter.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p><m>\pi</m></p></statement>
            <feedback><p>Correct! We use <m>\pi</m> to represent the probability of success in a binomial process.</p></feedback>
          </choice>
          <choice>
            <statement><p><m>\mu</m></p></statement>
            <feedback><p>This is the symbol for a population mean, not a probability.</p></feedback>
          </choice>
          <choice>
            <statement><p><em>p</em></p></statement>
            <feedback><p>While <em>p</em> is sometimes used for probability, we use the Greek letter <m>\pi</m> for the process probability parameter.</p></feedback>
          </choice>
        </choices>
        <solution>
          <p>We use <m>\pi</m> to represent your probability of correct identification.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-5" label="I1.3.5">
        <title>State the Null Hypothesis</title>
        <statement>
          <p>The null hypothesis is that you aren't clairvoyant and are guessing every time. State this as a null hypothesis using symbols and words.</p>
          <p><em>Tip: Type "pi" for the Greek letter. Format as: H_0: pi = value</em></p>
        </statement>
        <response/>
        <hint>
          <p>If guessing randomly among 5 symbols, what is the probability of guessing correctly?</p>
        </hint>
        <solution>
          <p><m>H_0: \pi = 0.20</m> (you have a 1 in 5 chance of guessing correctly)</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-6" label="I1.3.6">
        <title>State the Alternative Hypothesis</title>
        <statement>
          <p>State the alternative hypothesis using symbols and words.</p>
          <p><em>Tip: Type "pi" for the Greek letter. Use greater than, less than, or not equal to. Format as: H_a: pi &gt; value</em></p>
          <aside>
            <p>Notice that the hypothesized values for <m>\pi</m> in the null and alternative can't <q>overlap;</q> they are competing statements about <m>\pi</m>.</p>
          </aside>
        </statement>
        <response/>
        <hint>
          <p>If you are clairvoyant, would your probability of correct identification be higher or lower than random guessing?</p>
        </hint>
        <solution>
          <p><m>H_a: \pi > 0.20</m> (you have a higher probability of predicting correctly)</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-3-7" label="I1.3.7">
          <title>Simulation Method</title>
          <statement>
            <p>Assume the null hypothesis is true and let the random variable <m>C</m> denote the number of correct identifications (hits) in 10 attempts. If we were to simulate this random process, could we toss coins? If not, suggest another way we could generate simulated results assuming the null hypothesis to be true. (e.g., what would you want an applet to do?)</p>
          </statement>
          <response/>
          <hint>
            <p>Coin tosses give 50/50 probability. Does your null hypothesis assume 50% chance of success?</p>
          </hint>
          <solution>
            <p>We can model <m>C</m> with the binomial distribution:</p>
            <p><ul>
              <li><p>Each trial has two outcomes: correct match or not</p></li>
              <li><p>The trials are independent (the cards are shuffled in between attempts and the symbols are placed at random with no patterns from trial to trial)</p></li>
              <li><p>There are a fixed number of attempts (<m>n = 10</m>)</p></li>
              <li><p>The probability of success (if someone is guessing) is the same for each trial (<m>= 0.20</m> if using 5 cards each trial). We aren't changing the number of cards or anything else from trial-to-trial.</p></li>
            </ul></p>
            <p>We can't toss a coin because we are not assuming 50/50 for success/failure. To model 0.20 we could use spinners.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-3-8" label="Null distribution predictions">
          <title>Null Distribution Predictions</title>
          <statement>
            <p>Where do you think your null distribution will be centered? What are the largest and smallest possible values for the number of correct identifications in 10 attempts? What are the largest and smallest values you think you will see in the simulation?</p>
          </statement>
          <response/>
          <hint>
            <p>Use the probability from the null hypothesis times the number of attempts to find the expected value.</p>
          </hint>
          <solution>
            <p>On average, if someone is guessing, we would <q>expect</q> to see <m>\frac{1}{5}(10) = 2</m> correct answers (in the long run). <m>E(C) = 10(0.20) = 2</m> if assuming 5 cards.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-3-9" label="Applet simulation">
          <title>Carry Out the Simulation</title>
          <statement>
            <p>In the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?hideExtras=1" target="_blank">One Proportion Inference applet</url>, specify the values for <m>\pi</m> and <m>n</m>. Carry out one repetition of the simulation. Explain the simulation process in your own words.</p>
          </statement>
          <response/>
          <hint>
            <p>Set pi to your null hypothesis value and n to the number of attempts you made.</p>
          </hint>
          <solution>
            <p>Results will vary. The applet should generate 10 spinners (each a 0.20 probability of success = landing in the blue region) and then record the number of successes in those 10 spins.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-3-10" label="Theoretical mean SD">
          <title>Theoretical Mean and Standard Deviation</title>
          <statement>
            <p>Then check the Exact Binomial box to see the null distribution after infinitely many repetitions. Press the Reset button to remove the one simulated result and check the Summary Statistics box. What are the theoretical values for the mean and standard deviation of the null distribution?</p>
            
            <p>Mean = <var width="5" /></p>
            <p>Std Dev = <var width="5" /></p>
          </statement>
          <response/>
          <hint>
            <p>Look for the values displayed in the Summary Statistics section of the applet after pressing Reset.</p>
          </hint>
          <solution>
            <p>After pressing Reset to remove the one simulated trial, you should find Mean = 2.000, SD = 1.265.</p>
          </solution>
        </exercise>
        
        <assemblage xml:id="binomial-formulas">
          <title>Binomial Distribution Formulas</title>
          <p>It can be shown that when <m>X</m> is Binomial(<m>n</m>, <m>\pi</m>), the expected value is <m>E(X) = n \times \pi</m> and the variance is <m>V(X) = n\pi(1 - \pi)</m>. (See Exploration B for more discussion of expected value and variance of a random variable.)</p>
        </assemblage>
        
        <exercise xml:id="I1-3-11" label="Verify calculations">
          <title>Verify the Calculations</title>
          <statement>
            <p>Verify these calculations match the applet output and remember that the standard deviation is the square root of the variance.</p>
          </statement>
          <response/>
          <hint>
            <p>Use the formulas provided in the previous question with n=10 and pi=0.20.</p>
          </hint>
          <solution>
            <p><m>E(C) = 10(0.2) = 2.00</m> and <m>SD(C) = \sqrt{10 \times 0.2 \times 0.8} = 1.265</m>.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-3-12" label="Result in tail">
          <title>Result in the Tail?</title>
          <statement>
            <p>Was your statistic from Checkpoint 3.77 (your number of hits) in the direction specified by the alternative hypothesis? If it was, is it in one of the tails (outer edges) of the null distribution from Checkpoint 3.86?</p>
          </statement>
          <response/>
          <hint>
            <p>Compare your number of hits to the mean of the distribution. Is it larger (right tail) or smaller (left tail)?</p>
          </hint>
          <solution>
            <p>Results will vary, but quite possible your results were below the expected value.</p>
          </solution>
        </exercise>
      
      <p>If your observed number of successes was below the mean, then you can conclude that your data do not provide evidence in favor of the alternative hypothesis and you should not start your own psychic hotline! But if your result was above the mean, then we would like to measure the strength of evidence against the null hypothesis. You have already seen how to do that using a p-value.</p>
      
      <exercise xml:id="I1-3-13" label="I1.3.13">
        <title>Explore p-value Threshold</title>
        <statement>
          <p>Use the applet to explore how many hits a subject would need in 10 attempts for the p-value to be below 0.05.</p>
        </statement>
        <response/>
        <hint>
          <p>Use your mouse to drag the red line.</p>
        </hint>
        <solution>
          <p>A subject would need at least 5 hits in 10 attempts for the p-value to be below 0.05 (specifically, P(X â‰¥ 5) = 0.0328).</p>
        </solution>
      </exercise>
      
      <paragraphs xml:id="alternative-measure-rareness">
        <title>An Alternative Measure of Rareness</title>
        
        <p>As an alternative to the p-value, another measure of where an observation falls in a distribution is <q>how many standard deviations</q> it is from the mean of the distribution.</p>
        
        <figure xml:id="fig-ruler">
          <caption>A number line showing distances from the null hypothesis mean</caption>
          <image source="images/ruler2.png" width="50%">
            <description>A ruler or number line showing the distance scale for evaluating deviations from the hypothesized mean.</description>
          </image>
        </figure>
        
        <p><me>\frac{\text{observed number of hits} - \text{expected value}}{\text{standard deviation}} </me></p>
        
        <exercise xml:id="I1-3-14" label="I1.3.14">
          <title>Standardize Your Result</title>
          <statement>
            <p>How many standard deviations was your observed result from the expected value for the binomial distribution?</p>
          </statement>
          <response/>
          <hint>
            <p>Use the formula: (observed - expected) / standard deviation. Substitute your number of hits for observed, and use the mean and SD from Checkpoint 3.86.</p>
          </hint>
          <solution>
            <p>The standardized statistic expresses the distance in <q>standard deviations away</q> from the hypothesized value of <m>\pi</m>. A negative value means the distance is below the mean; a positive value means the distance is above the mean.</p>
          </solution>
        </exercise>
        
        <p>This calculation is often referred to as <term>standardizing the statistic</term>.</p>
        
        <p>Again, there are no hard and fast rules for what constitutes a large value here, but generally, when we have a fairly symmetric distribution, values more than 2 standard deviations above or below the expected value (mean) are considered extreme.</p>
      </paragraphs>
        
        <exercise xml:id="I1-3-15" label="I1.3.15">
            <title>Standardizing 5 Hits</title>
            <statement>
              <p>How many standard deviations from the mean (expected value) would 5 hits be?</p>
            </statement>
            <response/>
            <hint>
              <p>Use the same formula as the previous question: (5 - 2) / 1.265. What does this value tell you?</p>
            </hint>
            <solution>
              <p>A standardized statistic of 1 means that the sample result is one standard deviation above the mean of 2. Because the SD is 1.265, 1 SD above the mean is at <m>2 + 1.265 = 3.265</m>. Rounding to the nearest whole number, that would correspond to 3 correct identifications. (Or you could solve: <m>(x - 2)/1.265 = 1</m> to find <m>x = 3.265</m>.)</p>
            </solution>
          </exercise>
          
          <exercise xml:id="I1-3-16" label="I1.3.16">
            <title>Distribution for 25 Attempts</title>
            <statement>
              <p>Suppose you don't know whether or not someone is clairvoyant and you plan to give the person 25 attempts. What are the theoretical expected number and standard deviation for the random variable <m>C</m>, the number of hits when <m>n = 25</m> assuming they are just guessing each time? How do they compare to the values you found in (j)?</p>
            </statement>
            <response/>
            <hint>
              <p>Use the binomial formulas with n = 25 and pi = 0.20. Expected value = n Ã— pi, and SD = square root of n Ã— pi Ã— (1 - pi).</p>
            </hint>
            <solution>
              <p>Expected value = <m>5</m>, SD = <m>2</m></p>
              <p>Note: You can check these in the applet. Because the value of <m>n</m> has changed, both have increased. The larger the sample size, the more variability in the distribution.</p>
            </solution>
          </exercise>
          
          <p>How many hits would someone need to get correct in 25 attempts to convince you they aren't simply guessing? Let's consider two ways to decide.</p>
          
          <exercise xml:id="I1-3-17" label="I1.3.17">
            <title>Approach 1: P-value Threshold</title>
            <statement>
              <p><alert>Approach 1:</alert> What value for <m>c</m> would give you a probability below 0.05 of obtaining that many or more hits? In other words, what is the smallest value of <m>c</m> so <m>P(C \geq c) &lt; 0.05</m>?</p>
            </statement>
            <response/>
            <hint>
              <p>Use the applet to find probabilities for different values of c.</p>
            </hint>
            <solution>
              <p>We need to find <m>c</m> such that <m>P(C \geq c) &lt; 0.05</m>. Using the applet:
                <ul>
                  <li><p><m>P(C \geq 8) = 0.109</m> (too large)</p></li>
                  <li><p><m>P(C \geq 9) = 0.048</m> (this will work!)</p></li>
                </ul>
              So if someone had 9 or more correct, we might choose to consider that statistically significant.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="I1-3-17b" label="I1.3.17b">
            <title>Approach 2: Standard Deviations</title>
            <statement>
              <p><alert>Approach 2:</alert> What is the smallest value of <m>c</m> that is at least 2 standard deviations from the expected value?</p>
            </statement>
            <response/>
            <hint>
              <p>Use the expected value and standard deviation from Checkpoint 3.93.</p>
            </hint>
            <solution>
              <p>The observed value would need to be more than <m>5 + 2(2) = 9</m>.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="I1-3-18" label="Compare approaches">
            <title>Compare the Two Approaches</title>
            <statement>
              <p>How do your answers for these two approaches compare?</p>
            </statement>
            <response/>
            <hint>
              <p>Look at the values of c you found in both approaches. Are they the same or very close? What does this suggest about the relationship between p-values and standard deviations?</p>
            </hint>
            <solution>
              <p>It is not a coincidence that the value of 9 appears in both and is close to the expected value + 2 SD. It turns out that with a <q>large enough</q> sample size, if a standardized statistic is about 2 SD from the mean, the p-value will be close to 0.05. We will develop this idea much more carefully when we turn to the normal approximation to the binomial.</p>
            </solution>
          </exercise>
          
          <exercise xml:id="I1-3-19" label="Four symbols">
            <title>Test with Four Symbols</title>
            <statement>
              <p>Suppose you changed the test to use only 4 symbols. Does this change the expected number or standard deviation for the number of hits when a subject is guessing? How many would someone need to identify correctly to convince you they could perform better than guessing in the long-run?</p>
            </statement>
            <response/>
            <hint>
              <p>With 4 symbols, the probability of guessing correctly changes to 1/4 = 0.25. Recalculate the expected value and SD using this new probability, then find how many hits would be 2 SD above the mean.</p>
            </hint>
            <solution>
              <p>This would increase the probability of a correct guess to 0.25, and so the probability model would need to change as well. If there are only 4 cards, the probability of a correct guess increases to 0.25. So, with 25 attempts, the expected value would be <m>25(0.25) = 6.25</m> with an SD of <m>\sqrt{25(0.25)(0.75)} = 2.17</m>. So <m>6.25 + 2(2.17) = 10.59 \approx 11</m>. Notice that this <q>cutoff</q> value went up (10 or 11 vs. 9). This is because guessing is more likely to do well so we need more evidence that someone is not guessing. Also, using the applet, <m>P(C \geq 10) = 0.097</m> and <m>P(C \geq 11) = 0.044</m>.</p>
            </solution>
          </exercise>
      
      <paragraphs xml:id="investigation-1-3-summary">
        <title>Summary</title>
        
        <p>The number of correct answers in 25 attempts, for someone who is guessing, can be modeled with a binomial distribution (assuming the probability of a correct answer is 0.20 each time and there is no pattern from attempt to attempt). In this case, the hypothesized value for the probability of <q>success</q> will be 0.20 rather than 0.5 due to the five cards to choose from, which we could model with spinners rather than coin tosses. If someone is simply guessing, in the long run they will guess correctly by chance alone 20% of the time. This means that if we give someone 25 attempts, we expect them to answer correctly <m>0.20 \times 25 = 5</m> times (on average, in the long run), with a standard deviation of <m>\sqrt{25(0.20)(0.80)} = 2</m> hits in 25 attempts. Keep in mind that the <q>statistical significance</q> of an outcome will depend on both the mean and the standard deviation of the null distribution. In this case, someone would need 9 or more hits to be more than 2 standard deviations above the mean, which corresponds to a p-value of 0.048. (It is not a coincidence that the 0.05 cut-off gives very similar results to the 2SD cut-off.)</p>
      </paragraphs>
      
      <subsection xml:id="practice1-3A">
        <title>Practice Problem 1.3A</title>
        
        <exercise xml:id="PP1-3A-1" label="PP1.3A.1">
          <title>Six Symbols: Distribution Changes</title>
          <statement>
            <p>Suppose the test had consisted of 6 symbols instead of 5 (with <m>n = 25</m> still). How will that change the binomial distribution? [You should comment on both the mean and the standard deviation.]</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3A-2" label="PP1.3A.2">
          <title>Six Symbols: Surprising Outcome</title>
          <statement>
            <p>Would an outcome of 9 correct guesses be more or less surprising in this case (vs. 5 symbols)?</p>
            <p><ul>
              <li><p>Will the probability of 9 or more correct identifications be larger or smaller than with 5 symbols?</p></li>
              <li><p>Will the outcome of 9 be more or fewer standard deviations from the mean than with 5 symbols?</p></li>
            </ul></p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3A-3" label="PP1.3A.3">
          <title>Ten Symbols</title>
          <statement>
            <p>What about 10 symbols? What are the mean and standard deviation of the binomial distribution? Would an outcome of 9 or more correct identifications be more or less surprising than with 5 symbols?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3A-4" label="PP1.3A.4">
          <title>Shape of Distribution</title>
          <statement>
            <p>How does the shape of the binomial distribution change as you lower <m>\pi</m>? Explain why.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-3B">
        <title>Practice Problem 1.3B</title>
        
        <p>Return to the wolf (Yukon). In another study, Yukon correctly understood a communicative cue in 7 of 8 attempts.</p>
        
        <exercise xml:id="PP1-3B-1" label="PP1.3B.1">
          <title>Parameter and Statistic</title>
          <statement>
            <p>Identify (in words) the parameter and statistic in that study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3B-2" label="PP1.3B.2">
          <title>Standardized Result</title>
          <statement>
            <p>How many standard deviations did the observed statistic fall above the expected value assuming Yukon picks equally between the two containers regardless of the cue in the long run?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3B-3" label="PP1.3B.3">
          <title>Surprising Outcome?</title>
          <statement>
            <p>Would her performance be considered a surprising outcome when the null hypothesis is true? Explain.</p>
          </statement>
          <response/>
        </exercise>
        
        <p>Return to the infants choosing a helper toy over a hinderer toy 14 times out of 16 choices.</p>
        
        <exercise xml:id="PP1-3B-4" label="PP1.3B.4">
          <title>Infant Study: Parameter and Statistic</title>
          <statement>
            <p>Identify (in words) the parameter and statistic in that study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3B-5" label="PP1.3B.5">
          <title>Infant Study: Standardized Result</title>
          <statement>
            <p>How many standard deviations did the observed statistic fall above the expected value assuming infants choose equally between the two types of toys?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3B-6" label="PP1.3B.6">
          <title>Infant Study: Time Variable</title>
          <statement>
            <p>In the infant study, researchers also looked at the amount of time the infants spent watching the two videos (to see whether one captured their attention more than the other). Identify a possible parameter of interest for this new variable.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-3C">
        <title>Practice Problem 1.3C</title>
        
        <p>Suppose you select 100 students at your school to estimate the proportion who prefer Coke to Pepsi.</p>
        
        <exercise xml:id="PP1-3C-1" label="PP1.3C.1">
          <title>Random Process</title>
          <statement>
            <p>Identify the <em>random process</em> of interest.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3C-2" label="PP1.3C.2">
          <title>The Sample</title>
          <statement>
            <p>Identify the <em>sample</em> in the study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3C-3" label="PP1.3C.3">
          <title>Parameter of Interest</title>
          <statement>
            <p>Define the <em>parameter of interest</em> in the study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3C-4" label="PP1.3C.4">
          <title>The Statistic</title>
          <statement>
            <p>Define the <em>statistic</em> in the study.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-3C-5" label="PP1.3C.5">
          <title>Average Number of States</title>
          <statement>
            <p>Suppose you want to estimate the average number of states visited by students at your school. Define the parameter of interest.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
    
    <subsection xml:id="investigation-1-4">
      <title>Investigation 1.4: Heart Transplant Mortality</title>
      
      <p>Poloneicki, Sismanidis, Bland, and Jones (<url href="https://pubmed.ncbi.nlm.nih.gov/14751918/">2004</url>) reported that in September 2000 heart transplantation at St. George's Hospital in London was suspended because of concern that more patients were dying than previously. Newspapers reported that the 80% mortality rate in the last 10 cases was of particular concern because it was over five times the national average. The variable measured was whether or not the patient died within 30 days of the transplant. Although there was not an officially reported national mortality rate (probability of death within 30 days for patients undergoing this procedure), the researchers determined that 15% was a reasonable benchmark for comparison.</p>
      
      <exercise xml:id="I1-4-1" label="I1.4.1">
        <title>Define Sample and Variable</title>
        <statement>
          <p>Define the sample random process and variable for this study. Is the variable quantitative or categorical?</p>
          <p>Sample/Random process: <var width="50" /></p>
          <p>Variable: <var width="50" /></p>
          <p>Type: <var width="20" /></p>
        </statement>
        <response/>
        <hint>
          <p>Think about what is being observed repeatedly and what outcome is being measured for each observation.</p>
        </hint>
        <solution>
          <p>Sample/Random process: The 10 most recent heart transplantation surgeries at St. George's Hospital (or more generally, heart transplantation surgeries at this hospital, across all the patients)</p>
          <p>Variable: Whether or not the patient died within 30 days of the transplant</p>
          <p>Type: Categorical (binary)</p>
          <p>Note: We define "success" as death within 30 days (could be either death or survival, but this matches the 15% parameter), and "failure" as survival.</p>
        </solution>
      </exercise>
      
      <p>We need to consider which outcome we will consider "success" and which we will consider "failure." The choice is often arbitrary, though sometimes we may want to focus on the more unusual outcome as success. In fact, in many epidemiology studies, "death" is typically the outcome of interest or "success."</p>
      
      <exercise xml:id="I1-4-2" label="I1.4.2">
        <title>Define Parameter</title>
        <statement>
          <p>Considering death within 30 days as a success, define the parameter of interest in this study (in words).</p>
          <p>Parameter: <var width="50" /></p>
        </statement>
        <response/>
        <hint>
          <p>What long-run proportion or probability are we interested in?</p>
        </hint>
        <solution>
          <p>Parameter: The underlying probability of death within 30 days of transplant at this hospital.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-2b" label="I1.4.2b">
        <title>Parameter Symbol</title>
        <statement>
          <p>What symbol should we use to represent this parameter?</p>
        </statement>
        <hint>
          <p>Look for the Greek letter used for a process probability in a binomial distribution.</p>
        </hint>
        <choices randomize="no">
          <choice>
            <statement><p><m>\hat{p}</m></p></statement>
            <feedback><p>This is the symbol for the sample proportion (statistic), not the population parameter.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p><m>\pi</m></p></statement>
            <feedback><p>Correct! We use <m>\pi</m> to represent the probability of success in a binomial process.</p></feedback>
          </choice>
          <choice>
            <statement><p><m>\mu</m></p></statement>
            <feedback><p>This is the symbol for a population mean, not a probability.</p></feedback>
          </choice>
          <choice>
            <statement><p><m>p</m></p></statement>
            <feedback><p>While <em>p</em> is sometimes used for probability, we use the Greek letter <m>\pi</m> for the process probability parameter.</p></feedback>
          </choice>
        </choices>
        <solution>
          <p>We use <m>\pi</m> to represent the probability of death within 30 days.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-2c" label="I1.4.2c">
        <title>Check Binomial Process</title>
        <statement>
          <p>Is it reasonable to model this heart transplantation process as a binomial process?</p>
        </statement>
        <response/>
        <hint>
          <p>Check the four conditions for a binomial process: two outcomes, fixed number of trials, independence, and constant probability.</p>
        </hint>
        <solution>
          <p>Yes, this is a binomial process if we assume the transplants are independent and the probability of death is the same for each transplant patient.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-3" label="I1.4.3">
        <title>Nothing Unusual Implication</title>
        <statement>
          <p>If there is nothing unusual about the mortality rate for heart transplantations at this hospital (compared to other U.K. hospitals), what does this imply about the value of the probability of "success"?</p>
          <p><m>\pi</m> <var width="5" /> <var width="10" /></p>
        </statement>
        <setup>
          <var>
            <condition string="^\s*=\s*$">
              <feedback>
                <p>Correct! If nothing is unusual, Ï€ equals the benchmark.</p>
              </feedback>
            </condition>
            <condition string="^\s*&lt;\s*$">
              <feedback>
                <p>Not quite. If nothing is unusual, the rate should match the benchmark, not be less than it.</p>
              </feedback>
            </condition>
            <condition string="^\s*>\s*$">
              <feedback>
                <p>Not quite. If nothing is unusual, the rate should match the benchmark, not be greater than it.</p>
              </feedback>
            </condition>
          </var>
          <var>
            <condition number="0.15">
              <feedback>
                <p>Correct! The benchmark is 0.15 (15%).</p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>What was stated as the reasonable benchmark for comparison?</p>
              </feedback>
            </condition>
          </var>
        </setup>
        <hint>
          <p>What was stated as the reasonable benchmark for comparison?</p>
        </hint>
        <solution>
          <p><m>\pi = 0.15</m></p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-4" label="I1.4.4">
        <title>Higher Rate Implication</title>
        <statement>
          <p>If the patients at this hospital are indeed dying at a higher rate than the benchmark rate, what does this imply about the value of the probability of "success"?</p>
          <p><m>\pi</m> <var width="5" /> <var width="10" /></p>
        </statement>
        <setup>
          <var>
            <condition string="^\s*>\s*$">
              <feedback>
                <p>Correct! A higher rate means Ï€ is greater than the benchmark.</p>
              </feedback>
            </condition>
            <condition string="^\s*=\s*$">
              <feedback>
                <p>Not quite. If the rate is higher, Ï€ should be greater than the benchmark, not equal to it.</p>
              </feedback>
            </condition>
            <condition string="^\s*&lt;\s*$">
              <feedback>
                <p>Not quite. If the rate is higher, Ï€ should be greater than the benchmark, not less than it.</p>
              </feedback>
            </condition>
          </var>
          <var>
            <condition number="0.15">
              <feedback>
                <p>Correct! The benchmark is 0.15 (15%).</p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>What is the benchmark rate?</p>
              </feedback>
            </condition>
          </var>
        </setup>
        <hint>
          <p>If the rate is higher than 15%, what inequality would describe <m>\pi</m>?</p>
        </hint>
        <solution>
          <p><m>\pi > 0.15</m></p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-5" label="I1.4.5">
        <title>State Hypotheses</title>
        <statement>
          <p>Translate your answers to the previous questions to null and alternative hypothesis statements. Keep in mind, the null hypothesis claims the observed result is "just by chance," whereas the alternative hypothesis translates the research conjecture.</p>
          <p>Match each hypothesis type with the correct statement:</p>
        </statement>
        <matches>
          <match order="1">
            <premise>Alternative Hypothesis (<m>H_a</m>)</premise>
            <response><m>\pi > 0.15</m> (the death rate at St. George's is larger than the national average)</response>
          </match>
          <match order="2">
            <premise>Null Hypothesis (<m>H_0</m>)</premise>
            <response><m>\pi = 0.15</m> (the death rate at St. George's is the same as the national average)</response>
          </match>
        </matches>
        <hint>
          <p>The null hypothesis typically states equality, while the alternative states the direction of the research suspicion.</p>
        </hint>
      </exercise>
      
      <exercise xml:id="I1-4-6" label="I1.4.6">
        <title>Direction of Sample Result</title>
        <statement>
          <p>Of the hospital's ten most recent transplantations at the time of the study, there had been eight deaths within the first 30 days following surgery. Is this sample result in the direction suspected by the researchers? Explain.</p>
        </statement>
        <response/>
        <hint>
          <p>Compare 8/10 = 0.80 to the benchmark of 0.15.</p>
        </hint>
        <solution>
          <p><m>\hat{p} = 8/10 = 0.8</m></p>
          <p>Since 0.8 > 0.15, yes, the result is in the conjectured direction.</p>
        </solution>
      </exercise>
      
      <p>You could use the One Proportion Inference applet to use simulation or the binomial distribution to find the p-value. Many statistical software packages will carry out a "Binomial test" directly.</p>
      
      <paragraphs xml:id="tech-detour-binomial-test">
        <title>Technology Detour â€“ Binomial Test of Significance</title>
        
        <exercise xml:id="tech-detour-r-binomtest" label="Binomial Test - R">
          <title>Conducting a Binomial Test in R (Summarized Data)</title>
          <statement>
            <p>The <c>iscambinomtest</c> function from the ISCAM package takes the following inputs:</p>
            <p><ul>
              <li><p><c>observed</c> = Observed number of successes or proportion of successes</p>
                <p>With a data vector, can first determine number of successes, e.g., <c>table(NamesData)</c></p>
                <p>If you enter a value less than one, it will assume you entered the proportion</p></li>
              <li><p><c>n</c> = Number of trials (sample size)</p></li>
              <li><p><c>hypothesized</c> = Hypothesized probability</p></li>
              <li><p><c>alternative</c> = Direction of alternative (e.g., "greater" or "less" or "two.sided")</p></li>
            </ul></p>
            
            <p>For the Friend or Foe study, using the command (with or without input labels):</p>
            <program language="r" interactive="sage">
              <input>
iscambinomtest(observed=14, n=16, hyp=.5, alt="greater")
              </input>
            </program>
            
            <p>should show output in the Console window as well as a graph of the binomial distribution with the p-value shaded in the Graphics window.</p>
            
            <note>
              <title>R Reminder</title>
              <p>Make sure to load the ISCAM package first with <c>library(iscam)</c>.</p>
            </note>
          </statement>
          <solution>
            <p>The output will show:</p>
            <ul>
              <li><p>The observed number of successes (8) and sample size (10)</p></li>
              <li><p>The hypothesized probability (0.15)</p></li>
              <li><p>The p-value: P(X â‰¥ 8) = 0.00000866 (or 8.665 Ã— 10<m>^{-6}</m>)</p></li>
              <li><p>A graph showing the binomial distribution with the upper tail shaded</p></li>
            </ul>
          </solution>
        </exercise>
        
        <exercise xml:id="tech-detour-jmp-binomtest" label="Binomial Test - JMP">
          <title>Conducting a Binomial Test in JMP</title>
          <statement>
            <p>Using the Distribution Calculator in the <url href="http://www.rossmanchance.com/iscam4/data/ISCAM_Journal.jrn" download="ISCAM_Journal.jrn" target="_blank">ISCAM Journal File</url> (Download this file to your computer and then open the .jrn file to launch JMP.)</p>
            
            <sidebyside widths="48% 48%" margins="2%">
              <stack>
                <p><ul>
                  <li><p>Choose Analyze > Distribution</p>
                    <p><ul>
                      <li><p><em>With raw data</em>, drag the variable to the Y, Columns slot. Press OK.</p></li>
                      <li><p><em>With summarized data</em>, move the column with the category names to the Y, columns slot and move the column with the counts to the Freq slot. Press OK.</p></li>
                    </ul></p>
                  </li>
                </ul></p>
              </stack>
              <image source="images/JMPTestp.png">
                <description>JMP Test Probabilities dialog showing setup for binomial test</description>
              </image>
            </sidebyside>
            
            <sidebyside widths="48% 48%" margins="2%">
              <stack>
                <p><ul>
                  <li><p>From the variable's hot spot, select <term>Test Probabilities</term>.</p></li>
                  <li><p>Specify the hypothesized probability of success for the category you want to define as success (only).</p></li>
                  <li><p>Then pick a one-sided alternative hypothesis (greater than or less than).</p></li>
                  <li><p>Press Done.</p></li>
                </ul></p>
              </stack>
              <image source="images/JMPTestp2.png">
                <description>JMP output showing binomial test results with p-value</description>
              </image>
            </sidebyside>
            
            <p>JMP assumes "success" to be the first category alphabetically unless you specify otherwise with <term>Cols > Column Info > Column Properties > Value Ordering</term>.</p>
            
            <p><em>Note</em>: "not equal to" alternatives will be discussed in Investigation 1.5.</p>
          </statement>
          <solution>
            <p>The output table will show:</p>
            <ul>
              <li><p><term>Level</term>: The categories (e.g., death, survival)</p></li>
              <li><p><term>Estim Prob</term>: The observed proportion (0.80 for deaths)</p></li>
              <li><p><term>Hypoth Prob</term>: The hypothesized probability (0.15)</p></li>
              <li><p><term>Prob > z</term>: The one-sided p-value â‰ˆ 0.0000087</p></li>
            </ul>
          </solution>
        </exercise>
      </paragraphs>
      
      <exercise xml:id="I1-4-7" label="I1.4.7">
        <title>Report the P-value</title>
        <statement>
          <p>Find and report the p-value from your technology (including appropriate notation for the event of interest).</p>
        </statement>
        <response/>
        <hint>
          <p>Use technology to find P(X â‰¥ 8) when X ~ Binomial(10, 0.15).</p>
        </hint>
        <solution>
          <p>Example results:</p>
          <figure>
            <image source="images/inv14sols1.png" width="60%">
              <description>Simulation showing probability of 8 or more successes out of 10 trials with pi=0.15</description>
            </image>
          </figure>
          <p>We see that we never get 8 or more successes so the p-value is approximately zero.</p>
          <p>R tells us the p-value equals <m>8.665 \times 10^{-6}</m></p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-8" label="I1.4.8">
        <title>Interpret the P-value</title>
        <statement>
          <p>Provide a detailed interpretation of your p-value:</p>
          <p>The p-value is the probability of obtaining <var width="10" /> or <var width="10" /> successes in <var width="10" /> trials from a random process, assuming <var width="50" />.</p>
        </statement>
        <response/>
        <hint>
          <p>Fill in the blanks with the specific numbers and assumption from this context.</p>
        </hint>
        <solution>
          <p>This is the probability of getting 8 or more "successes" out of 10 observations from a random process where the long-run probability of success equals 0.15.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-9" label="I1.4.9">
        <title>Draw Conclusions</title>
        <statement>
          <p>Evaluate your p-value: what conclusions would you draw about the probability of death within 30 days of a heart transplant at this hospital?</p>
        </statement>
        <response/>
        <hint>
          <p>Consider how small the p-value is and what that suggests about the null hypothesis.</p>
        </hint>
        <solution>
          <p>We have very strong evidence in favor of <m>\pi > 0.15</m> (<m>H_a</m>). We don't think the higher mortality rate observed in these 10 cases happened just by chance.</p>
        </solution>
      </exercise>
      
      <paragraphs>
        <title>Does it matter which outcome I choose to be success?</title>
        
        <exercise xml:id="I1-4-10" label="I1.4.10">
          <title>Alternative Success Definition</title>
          <statement>
            <p>Suppose that we had focused on survival for 30 days rather than death within 30 days as a "success" in this study. Describe how the hypotheses would change and how the calculation of the binomial p-value would change. Then go ahead and calculate and interpret the exact binomial p-value with this set-up. How does its value compare to your answer in the previous question? How (if at all) does your conclusion change?</p>
            
            <p><m>\pi</m> represents: <var width="50" /></p>
            <p>Hâ‚€: <var width="20" /></p>
            <p>Hâ‚: <var width="20" /></p>
            <p>p-value = P(X <var width="20" />)</p>
            
            <p>Interpretation: The p-value is the probability of obtaining <var width="10" /> or <var width="10" /> successes in <var width="10" /> observations from a random process, assuming <var width="50" />.</p>
          </statement>
          <response/>
          <hint>
            <p>If survival is success, then the benchmark becomes 0.85. How many survived out of 10?</p>
          </hint>
          <solution>
            <p>The null hypothesis would be <m>H_0: \pi = 0.85</m> and the alternative hypothesis would be <m>H_a: \pi &lt; 0.85</m>.</p>
            <figure>
              <image source="images/inv1.4intro.png" width="60%">
                <description>Binomial distribution showing survival as success with pi=0.85</description>
              </image>
            </figure>
            <p>This turns out to be an equivalent analysis.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-4-10b" label="I1.4.10b">
          <title>Compare P-value and Conclusion</title>
          <statement>
            <p>Compared to the analysis with death as success, the p-value has:</p>
          </statement>
          <choices randomize="yes">
            <choice>
              <statement><p>Increased</p></statement>
            </choice>
            <choice correct="yes">
              <statement><p>Stayed the same</p></statement>
            </choice>
            <choice>
              <statement><p>Decreased</p></statement>
            </choice>
          </choices>
          <hint>
            <p>Compare the p-value from the death analysis to the survival analysis.</p>
          </hint>
        </exercise>
        
        <exercise xml:id="I1-4-10c" label="I1.4.10c">
          <title>Impact on Conclusion</title>
          <statement>
            <p>Compared to the analysis with death as success, does the conclusion change when we use survival as success?</p>
          </statement>
          <choices randomize="yes">
            <choice correct="yes">
              <statement><p>No change - the conclusion remains the same</p></statement>
            </choice>
            <choice>
              <statement><p>Yes - it is no longer significant</p></statement>
            </choice>
            <choice>
              <statement><p>Yes - it is now significant</p></statement>
            </choice>
          </choices>
          <hint>
            <p>Does changing the definition of success affect the strength of evidence?</p>
          </hint>
        </exercise>
      </paragraphs>
      
      <paragraphs>
        <title>Does the sample size matter?</title>
        
        <p>Following up on the suspicion that the sample of size 10 aroused, these researchers proceeded to gather data on the previous 361 patients who received a heart transplant at this hospital dating back to 1986. They found 71 deaths within 30 days among heart transplantations.</p>
        
        <exercise xml:id="I1-4-11" label="I1.4.11">
          <title>Calculate Sample Proportion</title>
          <statement>
            <p>Calculate the sample proportion of deaths for these data: <var width="10" /></p>
          </statement>
          <response/>
          <hint>
            <p>Sample proportion = 71/361.</p>
          </hint>
          <solution>
            <p><m>\hat{p} = 71/361 = 0.197</m></p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-4-11b" label="I1.4.11b">
          <title>Predict Strength of Evidence</title>
          <statement>
            <p>Predict whether this is more or less convincing evidence that this hospital's death rate exceeds 0.15. Explain your reasoning.</p>
          </statement>
          <response/>
          <hint>
            <p>Compare the sample proportion (0.197) to 0.15. Also consider that with a larger sample size, we have more information.</p>
          </hint>
          <solution>
            <p>This sample proportion is much closer to 0.15 but also based on a much larger sample size. Predictions will vary by student.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-4-11c" label="I1.4.11c">
          <title>Calculate P-value with Technology</title>
          <statement>
            <p>Use technology to determine the binomial probability of finding at least 71 deaths in a sample of 361 if <m>\pi = 0.15</m>.</p>
          </statement>
          <response/>
          <hint>
            <p>Use the One Proportion Inference applet or R with n=361, observed=71, and Ï€=0.15.</p>
          </hint>
          <solution>
            <figure>
              <image source="images/inv1.4largen.png" width="60%">
                <description>Binomial distribution for n=361 with pi=0.15 showing p-value</description>
              </image>
            </figure>
            <p>p-value â‰ˆ 0.01</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-4-12" label="I1.4.12">
          <title>Evaluate Larger Sample Evidence</title>
          <statement>
            <p>Is the probability you found convincing evidence to consider the sample result surprising if the mortality rate at this hospital matched the national rate? Explain.</p>
          </statement>
          <response/>
          <hint>
            <p>Consider how small the p-value is - what threshold are you using?</p>
          </hint>
          <solution>
            <p>Yes, small p-value. Reject <m>H_0</m> that <m>\pi = 0.15</m>, convinced that <m>\pi > 0.15</m>.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-4-13" label="I1.4.13">
          <title>Compare Strength of Evidence</title>
          <statement>
            <p>Is the evidence against the null hypothesis stronger or weaker than the earlier analysis based on 10 deaths? Explain how you are deciding and why the strength of evidence has changed in this manner.</p>
          </statement>
          <response/>
          <hint>
            <p>Compare the two p-values. Which is smaller?</p>
          </hint>
          <solution>
            <p>The evidence is a bit weaker (though still quite strong) demonstrated by the larger p-value.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-4-14" label="I1.4.14">
          <title>Expected Number of Deaths</title>
          <statement>
            <p>Calculate the expected number of deaths, E(X), for each sample size.</p>
            <p>n = 10: E(X) = <var width="10" /></p>
            <p>n = 361: E(X) = <var width="10" /></p>
          </statement>
          <response/>
          <hint>
            <p>Use the formula E(X) = n Ã— Ï€ where Ï€ = 0.15.</p>
          </hint>
          <solution>
            <p>E(X) = 10(0.15) = 1.5 or 361(0.15) = 54.15</p>
          </solution>
        </exercise>
      </paragraphs>
      
      <p>The following graphs display the two theoretical probability distributions (for sample sizes n = 10 and n = 361), both assuming the null hypothesis (<m>\pi = 0.15</m>) is true. These graphs show just how far the observed values (8 and 71) are from the expected value of the number of deaths (0.15 Ã— 10 = 1.5 and 0.15 Ã— 361 = 54.15) in each case. You should also note that the shape, center, and variability of the probability distribution for number of successes are all affected by the sample size n.</p>
      
      <figure xml:id="fig-heart-transplant-distributions">
        <caption>Binomial distributions for n=10 and n=361, both with Ï€=0.15</caption>
        <sidebyside widths="48% 48%" margins="2%">
          <image source="images/inv1.4smalln.png">
            <description>Binomial distribution showing n=10, pi=0.15, with observed value of 8 marked</description>
          </image>
          <image source="images/inv1.4largen.png">
            <description>Binomial distribution showing n=361, pi=0.15, with observed value of 71 marked</description>
          </image>
        </sidebyside>
      </figure>
      
      <p>Keep in mind that of interest to us is the observed statistic's relative location in the null distribution. Thus, we are most interested in how variable the possible outcomes are from the "expected" outcome. The center of the distribution isn't all that interesting to us in answering the research question because we determine what the center of the distribution will be by how we specify the null hypothesis. Even the shape isn't all that interesting on its own in answering our research question.</p>
      
      <exercise xml:id="I1-4-15" label="I1.4.15">
        <title>Distribution Feature Differences</title>
        <statement>
          <p>Identify another feature (beside center, shape, and variability) of the above distributions that differs between them.</p>
        </statement>
        <response/>
        <hint>
          <p>Think about practical aspects like the scale or range of values displayed.</p>
        </hint>
        <solution>
          <p>The most obvious difference is how close together the spikes are.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-16" label="I1.4.16">
        <title>Standardize Second Dataset</title>
        <statement>
          <p>How many standard deviations is the observed sample proportion above the hypothesized probability for the second dataset?</p>
          
          <p>Expected value when n = 361 and <m>\pi = 0.15</m>: <var width="10" /></p>
          <p>SD when n = 361 and <m>\pi = 0.15</m>: <var width="10" /></p>
          <p>Number of standard deviations 71 is above the expected value: <var width="10" /></p>
        </statement>
        <response/>
        <hint>
          <p>Use E(X) = n Ã— Ï€ and SD(X) = âˆš(n Ã— Ï€ Ã— (1-Ï€)). Then calculate (71 - E(X))/SD(X).</p>
        </hint>
        <solution>
          <p>SD(X) = sqrt(361 Ã— 0.15 Ã— 0.85) = 6.78</p>
          <p>Observed 71</p>
          <p>(71 - 54.15)/6.78 â‰ˆ 2.49. This is larger than 2.</p>
          <p>For first data set: (8 - 1.5)/sqrt(10 Ã— 0.15 Ã— 0.85) = 6.5/1.13 = 5.75 (this shows us that the evidence is a fair bit stronger with the first data set)</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-16b" label="I1.4.16b">
        <title>Evaluate Standardized Evidence</title>
        <statement>
          <p>Does this calculation also provide strong evidence against the null hypothesis? How are you deciding?</p>
        </statement>
        <response/>
        <hint>
          <p>Consider whether being 2.49 standard deviations from the expected value is unusual.</p>
        </hint>
        <solution>
          <p>Yes, this provides strong evidence against the null hypothesis. A result more than 2 standard deviations from the expected value is generally considered unusual, and 2.49 SD is quite far from the mean.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-4-17" label="I1.4.17">
        <title>Which Dataset is More Valid?</title>
        <statement>
          <p>In your opinion, which data set do you think is more valid to use â€“ the larger sample size or the more recent data? Explain how you are deciding.</p>
        </statement>
        <response/>
        <hint>
          <p>Consider the trade-offs: more data vs. more current/relevant data. Also think about "data snooping."</p>
        </hint>
        <solution>
          <p>Opinions will vary. The larger sample size is more likely to give us more precise results but some based on very old data which may no longer be representative of the current process.</p>
        </solution>
      </exercise>
      
      <assemblage xml:id="study-conclusions-1-4">
        <title>Study Conclusions</title>
        <p>A sample mortality rate of 80% is indeed quite surprising, even with a sample size as small as 10, if the actual probability of death were 0.15. The (exact) p-value is 0.0000087, and the observed statistic is 5.76 standard deviations above the expected value, providing extremely strong evidence that the actual probability of death at this hospital is higher than the national benchmark of 0.15 (fewer than 1 in 100,000 sets of 10 operations would "randomly" have 8 or more deaths if <m>\pi = 0.15</m>). However, we must be cautious about doing this type of "data snooping," where we allowed a seemingly unusual observation to motivate our suspicion and then use the same data to support our suspicion. Once the initial suspicion has formed, we should collect new data on which to test the suspicion. The actual investigation examined all previous heart transplantations at this hospital over the previous 14 years. In this broader study, the p-value is 0.0097 and the observed number of successes is 2.48 standard deviations above the expected number, still providing very strong evidence against the null hypothesis. That is, there is strong evidence that this hospital's probability of mortality was higher than the 15% national benchmark. We must, however, be cautious because our study has not identified what factors could be leading to the higher rate. Perhaps this hospital tends to see sicker patients to begin with. The researchers actually performed a more sophisticated analysis that incorporated information about the risk factors of all the operations at this hospital and reached similar conclusions.</p>
      </assemblage>
      
      <subsection xml:id="practice1-4A">
        <title>Practice Problem 1.4A</title>
        
        <p>In April 2014, the city of Flint Michigan switched its water supply to the Flint River in an effort to save money. The U.S. Environmental Protection Agency (EPA)'s Lead and Copper Rule states that if lead concentrations exceed an action level of 15 parts per billion (ppb) in more than 10% of homes sampled, then actions must be undertaken to control corrosion, and the public must be informed. In the initial sample of 71 homes, 8 tested above 15 ppb.</p>
        
        <exercise xml:id="PP1-4A-1" label="PP1.4A.1">
          <title>Binomial Process Justification</title>
          <statement>
            <p>Suppose our variable is "was the lead concentration level above 15 ppb?". Is it reasonable to model this as a binomial process? Justify your response for each condition. Be sure to explain how you are defining success and any assumptions you are making about the process.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4A-2" label="PP1.4A.2">
          <title>Define Parameter</title>
          <statement>
            <p>Define (in words) the parameter of interest.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4A-3" label="PP1.4A.3">
          <title>State Hypotheses</title>
          <statement>
            <p>State null and alternative hypotheses for testing whether the probability of a house testing above 15 ppb is more than 0.10.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4A-4" label="PP1.4A.4">
          <title>Calculate P-value</title>
          <statement>
            <p>Report the binomial p-value for your hypotheses.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4A-5" label="PP1.4A.5">
          <title>Modified Dataset P-value</title>
          <statement>
            <p>After dropping two "suspicious" observations, 6 of the 69 remaining observations were above 15 ppb. Report the binomial p-value for your hypotheses. Is the second p-value larger or smaller than the first?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-4B">
        <title>Practice Problem 1.4B</title>
        
        <p>Reconsider the wolf (Yukon) who correctly understood a communicative cue in 7 of 8 attempts. Let <m>\pi</m> represent the probability of Yukon identifying the correct container with a communicative cue.</p>
        
        <exercise xml:id="PP1-4B-1" label="PP1.4B.1">
          <title>Greater Than Alternative</title>
          <statement>
            <p>If the alternative hypothesis is <m>H_a: \pi > 0.50</m>, what is the p-value? Based on this p-value, state an appropriate conclusion in terms of the alternative hypothesis.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4B-2" label="PP1.4B.2">
          <title>Less Than Alternative</title>
          <statement>
            <p>If the alternative hypothesis is <m>H_a: \pi &lt; 0.50</m>, what is the p-value? Based on this p-value, state an appropriate conclusion in terms of the alternative hypothesis.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4B-3" label="PP1.4B.3">
          <title>When P-value Exceeds 0.50</title>
          <statement>
            <p>Under what circumstances will a p-value calculation like these be larger than 0.50?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-4C">
        <title>Practice Problem 1.4C</title>
        
        <p>One of the first times the U.S. Supreme Court considered statistical significance in an employment discrimination case was in Hazelwood School District vs. United States (1977). The U.S. government sued the City of Hazelwood, a suburb of St. Louis, MO, on the grounds that it discriminated against African Americans in its hiring of school teachers. The evidence introduced noted that of the 405 teachers hired in 1972 and 1973 (the years following the passage of the Civil Rights Act), only 15 had been African-American. By comparison, according to 1970 census figures, of the almost 20,000 elementary and secondary teachers employed in the St. Louis area, 15.4% were African American. We want to decide whether the data on these 405 teachers is convincing evidence that the Hazelwood hiring process had a probability of a new hire being African American that was less than 0.154.</p>
        
        <exercise xml:id="PP1-4C-1" label="PP1.4C.1">
          <title>Expected Number of Hires</title>
          <statement>
            <p>What is the expected number of African-American hires in a sample of 405 teachers if the probability of a new hire being African American equals 0.154?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4C-2" label="PP1.4C.2">
          <title>Standardize and Conclude</title>
          <statement>
            <p>Using the binomial distribution, how many standard deviations is 15 from the expected number of new hires that are African American when the null hypothesis is true? What conclusion would you draw?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4C-3" label="PP1.4C.3">
          <title>Excluding St. Louis City</title>
          <statement>
            <p>The St. Louis City School District had recently followed a policy attempting to maintain a 50% African-American teaching staff. If you exclude the St. Louis City School District, then proportion of eligible teachers in the St. Louis area that were African-American was 0.057. What is the new expected number of hires? What conclusions would you draw?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-4C-4" label="PP1.4C.4">
          <title>Importance of Labor Market Definition</title>
          <statement>
            <p>Discuss briefly how this case illustrates "the importance of the choice of the relevant labor market area" in cases of discrimination.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
    
    <subsection xml:id="investigation-1-5">
      <title>Investigation 1.5: Buttered Toast</title>
      
      <sidebyside widths="58% 38%">
        <stack>
          <p>The folks at MythBusters, a popular television program on the Discovery 
          Channel, wanted to investigate whether a piece of toast that has been 
          buttered on one side is more likely to land butter/messy side down or 
          butter-side up. First, they wanted to design a toast-dropping rig that 
          would have no built-in bias for unbuttered toast to land on either side 
          when dropped. For this pilot study, they labeled the sides "top" and "bottom" for ten 
          unbuttered pieces of toast and counted how many landed "top-down."</p>
        </stack>
        <image source="images/1.5intro.png" width="100%" decorative="yes">
          <description>MythBusters buttered toast investigation introduction</description>
        </image>
      </sidebyside>
      
      <exercise xml:id="I1-5-1" label="I1.5.1">
        <title>Define Process and Variable</title>
        <statement>
          <p>Identify the sample/random process and variable of interest in this study. Which outcome will you consider "success"? Do we have a binomial process?</p>
          <p>Random process: <var width="50" /></p>
          <p>Variable: <var width="50" /></p>
          <p>Success: <var width="30" /></p>
          <p>Binomial process? <var width="20" /></p>
        </statement>
        <response/>
        <hint>
          <p>Consider what is being repeated and what outcome is measured each time.</p>
        </hint>
        <solution>
          <p>Random process: Repeated dropping pieces of toast, assuming identical conditions.</p>
          <p>Variable: Whether the piece of toast lands top side down or top side up</p>
          <p>Success: Top side down</p>
          <p>Binomial process: Yes, assuming each drop is independent with the same probability.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-2" label="I1.5.2">
        <title>Define Parameter</title>
        <statement>
          <p>Identify the parameter of interest in this study (in words).</p>
        </statement>
        <response/>
        <hint>
          <p>What long-run proportion are we interested in?</p>
        </hint>
        <solution>
          <p>The probability of a piece of toast landing top side down.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-2b" label="I1.5.2b">
        <title>Parameter Symbol</title>
        <statement>
          <p>What symbol should we use to represent this parameter?</p>
        </statement>
        <hint>
          <p>Look for the Greek letter used for a process probability in a binomial distribution.</p>
        </hint>
        <choices randomize="no">
          <choice>
            <statement><p><m>\hat{p}</m></p></statement>
            <feedback><p>This is the symbol for the sample proportion (statistic), not the population parameter.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p><m>\pi</m></p></statement>
            <feedback><p>Correct! We use <m>\pi</m> to represent the probability of success in a binomial process.</p></feedback>
          </choice>
          <choice>
            <statement><p><m>\mu</m></p></statement>
            <feedback><p>This is the symbol for a population mean, not a probability.</p></feedback>
          </choice>
          <choice>
            <statement><p><m>p</m></p></statement>
            <feedback><p>While <em>p</em> is sometimes used for probability, we use the Greek letter <m>\pi</m> for the process probability parameter.</p></feedback>
          </choice>
        </choices>
        <solution>
          <p>We use <m>\pi</m> to represent the probability of a piece of toast landing top side down.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-3" label="I1.5.3">
        <title>State Null Hypothesis</title>
        <statement>
          <p>State the null hypothesis using symbols and words.</p>
          <p><m>H_0</m>: <var width="50" /></p>
        </statement>
        <response/>
        <hint>
          <p>If there's no bias, what should the probability be?</p>
        </hint>
        <solution>
          <p><m>H_0: \pi = 0.5</m> (equally likely to land top down or top up)</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-4" label="I1.5.4">
        <title>Two-Sided Alternative</title>
        <statement>
          <p>With 10 pieces of toast, what outcomes for the number of successes would convince you that there was a problem with the rig? Suggest a way of stating the alternative hypothesis that reflects this interest/prior suspicion.</p>
          <p><m>H_a</m>: <var width="50" /></p>
        </statement>
        <response/>
        <hint>
          <p>Would you be concerned if the result was extreme in either direction (too many or too few successes)?</p>
        </hint>
        <solution>
          <p><m>H_a: \pi \neq 0.50</m> (one side is more likely)</p>
          <p>This is a two-sided alternative hypothesis.</p>
        </solution>
      </exercise>
      
      <p>You have now stated a two-sided alternative hypothesis (rather than a "one-sided" alternative of strictly less than or strictly greater than). So now we need to decide which values we will consider "or more extreme" in calculating the p-value.</p>
      
      <interactive platform="html" xml:id="oneprop-applet-1-5">
        <slate surface="html">
          <![CDATA[
          <iframe src="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm" 
                  style="width: 100%; min-width: 900px; height: 750px; border: 1px solid #ccc;" 
                  title="One Proportion Inference Applet">
          </iframe>
          ]]>
        </slate>
      </interactive>
      
      <exercise xml:id="I1-5-5" label="I1.5.5">
        <title>Calculate One-Sided Probability</title>
        <statement>
          <p>In this pilot study, the toast landed top-down 3 times and top-up 7 times. Use the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm" target="_blank">One Proportion Inference applet</url> to calculate the binomial probability of 3 or fewer successes in 10 attempts, assuming the null hypothesis is true (i.e., P(X â‰¤ 3) where X is the number landing top-down).</p>
        </statement>
        <response/>
        <hint>
          <p>Use technology with n=10, Ï€=0.5, and find P(X â‰¤ 3).</p>
        </hint>
        <solution>
          <p>P(X â‰¤ 3) = 0.1719</p>
          <figure>
            <image source="images/inv1.5After.png" width="60%">
              <description>Binomial distribution for n=10, pi=0.5 showing P(X less than or equal to 3)</description>
            </image>
          </figure>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-6" label="I1.5.6">
        <title>Identify More Extreme Outcomes</title>
        <statement>
          <p>Conjecture: What other outcomes would you consider "as or more surprising" as 3 or fewer successes?</p>
        </statement>
        <response/>
        <hint>
          <p>Think about the symmetry of the distribution when Ï€ = 0.5.</p>
        </hint>
        <solution>
          <p>Reasonable conjectures include X â‰¥ 7</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-7" label="I1.5.7">
        <title>Calculate Two-Sided P-value</title>
        <statement>
          <p>If we calculate the two-sided p-value as P(X â‰¤ 3) + P(X â‰¥ 7), what would you report for the p-value? Would you find this p-value to be convincing evidence in favor of the two-sided alternative hypothesis?</p>
        </statement>
        <response/>
        <hint>
          <p>When the distribution is symmetric, P(X â‰¥ 7) = P(X â‰¤ 3).</p>
        </hint>
        <solution>
          <p>The applet tells us P(X â‰¥ 7) also equals 0.1719, so the two-sided p-value = 2(0.1719) = 0.3438</p>
          <p>This p-value is quite large, so we would not have convincing evidence against the null hypothesis.</p>
        </solution>
      </exercise>
      
      <paragraphs>
        <title>What if our original hypotheses had been <m>H_0: \pi = 0.55</m> vs. <m>H_a: \pi \neq 0.55</m>?</title>
        
        <exercise xml:id="I1-5-8" label="I1.5.8">
          <title>Alternative Null Hypothesis</title>
          <statement>
            <p>Restate the alternative hypothesis in words. How will the null distribution change?</p>
          </statement>
          <response/>
          <hint>
            <p>How does changing Ï€ from 0.5 to 0.55 affect the center of the distribution?</p>
          </hint>
          <solution>
            <p>Now we think the long-run proportion of toast drops landing top side down is not 0.55. This will shift the null distribution to center at 5.5 rather than at 5 successes.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-5-9" label="I1.5.9">
          <title>Left Tail Probability</title>
          <statement>
            <p>Make this change in the applet and find the binomial probability of 3 or fewer successes.</p>
          </statement>
          <response/>
          <hint>
            <p>Use n=10, Ï€=0.55, and find P(X â‰¤ 3).</p>
          </hint>
          <solution>
            <p>P(X â‰¤ 3 when Ï€ = 0.55) = 0.1020</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-5-10" label="I1.5.10">
          <title>Right Tail Comparison</title>
          <statement>
            <p>Now find P(X â‰¥ 7) when Ï€ = 0.55. How does it compare to P(X â‰¤ 3)? Why does this make sense?</p>
          </statement>
          <response/>
          <hint>
            <p>Is 7 further from the expected value than 3 is?</p>
          </hint>
          <solution>
            <p>P(X â‰¥ 7) increases to 0.2660 because now an outcome of 7 is closer to the expected value of the null distribution.</p>
          </solution>
        </exercise>
      </paragraphs>
      
      <p>In this text, we will consider outcomes "more extreme" than the observed outcome if the "tail probability" is less than or equal to the tail probability of the observed outcome. So for this null hypothesis (Ï€ = 0.55), because P(X â‰¥ 7) > P(X â‰¤ 3), we would not consider x = 7 to be "more extreme" than x = 3. Therefore, we would not include x = 7 in the p-value calculation. Notice, this distinction arose once our binomial distribution was not symmetric (Ï€ â‰  0.50).</p>
      
      <exercise xml:id="I1-5-11" label="I1.5.11">
        <title>Find More Extreme Value</title>
        <statement>
          <p>Find P(X â‰¥ 8). Is x = 8 considered more extreme than x = 3?</p>
        </statement>
        <response/>
        <hint>
          <p>Compare P(X â‰¥ 8) to P(X â‰¤ 3) = 0.1020.</p>
        </hint>
        <solution>
          <p>P(X â‰¥ 8) = 0.0996 which is now smaller than P(X â‰¤ 3) so we could consider x = 8 a more extreme observation compared to x = 3.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-12" label="I1.5.12">
        <title>Two-Sided P-value for Ï€=0.55</title>
        <statement>
          <p>Calculate the two-sided p-value as P(X â‰¤ 3) + P(X â‰¥ 8)</p>
        </statement>
        <response/>
        <hint>
          <p>Add the two tail probabilities you found.</p>
        </hint>
        <solution>
          <p>0.1020 + 0.0996 = 0.2016</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-5-13" label="I1.5.13">
        <title>Verify with Applet</title>
        <statement>
          <p>Verify your result in the applet: Start with 3 and use the "Tails" option, then check the <strong>Two-sided</strong> box.</p>
        </statement>
        <response/>
        <hint>
          <p>Use the "Tails" option in the pull-down menu.</p>
        </hint>
        <solution>
          <p>Results match if you start with P(X â‰¤ 3) and use the pull-down menu to select "Tails" for the two-sided p-value.</p>
          <figure>
            <image source="images/inv1.5pilot2.png" width="60%">
              <description>Two-sided binomial test for n=10, pi=0.55 showing two-sided p-value</description>
            </image>
          </figure>
        </solution>
      </exercise>
      
      <p>There are other ways to define "more extreme" as well, and results will vary across different software packages (see Practice Problem 1.5). But the results will be more similar the more symmetric the null distribution is, and when the null distribution is skewed, adjusting for the asymmetry is generally preferred to going "the same distance" on each side or doubling the one-sided p-value.</p>
      
      <assemblage xml:id="def-two-sided-pvalue">
        <title>Definition: Two-sided p-values</title>
        <p>Two-sided p-values are used with two-sided alternative hypotheses (â‰ , not equal to). A two-sided p-value considers outcomes in both tails that are at least as rare as the observed result, where <em>at least as rare</em> could be defined as having a smaller tail probability of occurring as the observed statistic. If the null distribution is symmetric, the approaches are equivalent and the two-sided p-value will be double the one-sided p-value.</p>
      </assemblage>
      
      <exercise xml:id="I1-5-14" label="I1.5.14">
        <title>Evaluate Pilot Study Conclusion</title>
        <statement>
          <p>The MythBusters decided a 3/7 split was "way outside a random sample" and so they needed to build a different toast-dropping rig. Do you agree with their conclusion from the pilot study? Write a short paragraph to the MythBusters justifying your answer. Include appropriate numerical evidence to support your argument.</p>
        </statement>
        <response/>
        <hint>
          <p>Consider both p-values you calculated (for Ï€=0.50 and Ï€=0.55).</p>
        </hint>
        <solution>
          <p>Based on the two-sided p-values, both 0.50 and 0.55 are plausible values for the probability of a piece of toast landing top side down. Because 0.50 is plausible (p-value = 0.3438), these data do not provide convincing evidence that there is a built-in bias with the mechanism and they could have continued to use it.</p>
        </solution>
      </exercise>
      
      <sidebyside widths="58% 38%">
        <stack>
          <p>After building a new rig (that they were more confident had no bias), they used the rig to drop buttered toast from the roof of a building. The Mythbusters weren't sure whether the toast would land butter-side down (as in the myth) or whether, like a curved leaf falling from a tree, the toast might try to "right itself" and land with the indented side (from being buttered) down. So again, they wanted to use a two-sided alternative hypothesis, allowing for either possibility to be of interest.</p>
        </stack>
        <image source="images/inv1.5After.png" width="100%" decorative="yes">
          <description>MythBusters dropping buttered toast from building</description>
        </image>
      </sidebyside>
      
      <p>They dropped 48 pieces of toast, with 19 landing butter-side-down.</p>
      
      <exercise xml:id="I1-5-15" label="I1.5.15">
        <title>Buttered Toast Two-Sided Test</title>
        <statement>
          <p>Use the applet to find the two-sided p-value for testing <m>H_0: \pi = 0.5</m> vs. <m>H_a: \pi \neq 0.50</m>. Do you have strong enough evidence to reject the null hypothesis and conclude Ï€ differs from 0.5? Why are you making this decision?</p>
        </statement>
        <response/>
        <hint>
          <p>Use n=48, observed=19, Ï€=0.5, and check the two-sided box.</p>
        </hint>
        <solution>
          <figure>
            <image source="images/inv1.5buttered.png" width="60%">
              <description>Two-sided binomial test for n=48, pi=0.5, observed=19</description>
            </image>
          </figure>
          <p>The p-value is not small (p-value = 0.1934, which is larger than 0.05), so we fail to reject the null hypothesis that Ï€ = 0.50. We conclude it is plausible that buttered toast is equally likely to land up or down when dropped from the top of a building.</p>
        </solution>
      </exercise>
      
      <assemblage xml:id="study-conclusions-1-5">
        <title>Study Conclusions</title>
        <p>These data (19 out of 48) do not provide convincing evidence against the null hypothesis that toast buttered on one side is equally likely to land butter side up or down (two-sided p-value = 0.1934). In other words, it is plausible that this is a 50/50 process. However, this analysis cannot be used as proof that Ï€ = 0.50, as other values could be plausible as well. The sample data allow for many (technically, infinitely many) plausible values of this probability, as you will explore in the next investigation.</p>
      </assemblage>
      
      <p><alert>Discussion:</alert> Recall that the process we are using to testing our hypotheses is to first assume the null hypothesis is true. For this reason, we can never use this process as evidence <em>for</em> the null hypothesis, only lack of evidence <em>against</em> it. Keep in mind the saying "Absence of evidence is not evidence of absence." Also, note that our evidence depends on the form of the alternative hypothesis. A more complete statement is that we do not have evidence in favor of the alternative that we specified, and that our strength of evidence could differ if we started with a different alternative hypothesis.</p>
      
      <p class="horizontal-rule"> </p>
      
      <paragraphs xml:id="tech-detour-two-sided">
        <title>Technology Detour â€“ Two-sided p-values</title>
        
        <exercise xml:id="tech-detour-two-sided-applet" label="Two-sided - Applet">
          <title>Two-sided p-values in One Proportion Inference applet</title>
          <statement>
            <p><ul>
              <li><p>Check the two-sided box</p></li>
              <li><p>For the "smallest tail probability" approach, set the pull-down menu to "Tails" (finds tail value on other side that is first below the one-sided p-value)</p></li>
              <li><p>For the "smallest p-value" approach, set the pull-down menu to "Individual" (sums all probabilities smaller than the observed)</p></li>
              <li><p>(These will match when the distribution is symmetric.)</p></li>
            </ul></p>
          </statement>
        </exercise>
        
        <exercise xml:id="tech-detour-two-sided-r" label="Two-sided - R">
          <title>Two-sided p-values in R</title>
          <statement>
            <p>Using the <c>iscambinomtest</c> function, specify <c>alternative = "two.sided"</c></p>
            <p>(Smallest p-value method)</p>
            <program language="r" interactive="sage">
              <input>
iscambinomtest(observed=19, n=48, hyp=0.5, alt="two.sided")
              </input>
            </program>
          </statement>
          <solution>
            <p>The output will show:</p>
            <ul>
              <li><p>The observed number of successes (19) and sample size (48)</p></li>
              <li><p>The hypothesized probability (0.5)</p></li>
              <li><p>The two-sided p-value: 0.1934</p></li>
              <li><p>A graph showing the binomial distribution with both tails shaded</p></li>
            </ul>
          </solution>
        </exercise>
        
        <exercise xml:id="tech-detour-two-sided-jmp" label="Two-sided - JMP">
          <title>Two-sided p-values in JMP</title>
          <statement>
            <p><alert>Note:</alert> The default two-sided test under Analyze > Distribution is not an "exact" binomial test.</p>
            
            <figure>
              <image source="images/JMPtwosided.png" width="60%">
                <description>JMP two-sided binomial test output</description>
              </image>
            </figure>
          </statement>
          <solution>
            <p>The output table will show the two-sided p-value for the exact binomial test. For the buttered toast example with 19 successes out of 48 trials and hypothesized probability of 0.5, the two-sided p-value should be approximately 0.1934.</p>
          </solution>
        </exercise>
      </paragraphs>
      
      <p class="horizontal-rule"> </p>
      
      <subsection xml:id="practice1-5">
        <title>Practice Problem 1.5</title>
        
        <p>There are other approaches for calculating the two-sided p-value. For example, we could consider an outcome k more extreme than the observed, if P(X = k) &lt; P(X = observed).</p>
        
        <exercise xml:id="PP1-5-1" label="PP1.5.1">
          <title>Explain Alternative Approach</title>
          <statement>
            <p>Explain the distinction in this approach and the one used above.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-5-2" label="PP1.5.2">
          <title>Apply Alternative Method</title>
          <statement>
            <p>Return to the pilot study with 3 successes out of n = 10 drops. Based on this new approach, which values above 5 would you consider more extreme than 3 when Ï€ = 0.55? Document your justification. What is the resulting two-sided p-value? [Hints: Use <em>As extreme as =</em> in the applet. Confirm your results by changing the pull-down menu from "tails" to "individual."]</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-5-3" label="PP1.5.3">
          <title>Strange Behavior with Extreme Observations</title>
          <statement>
            <p>Suppose n = 20 and you observed 0 successes. Find the two-sided p-values using the approach suggested in (b) for Ï€ = 0.13, Ï€ = 0.145, and Ï€ = 0.15. According to the two-sided p-values, which of these values are plausible for Ï€ at the 10% level of significance? What strange behavior do you observe?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-5-4" label="PP1.5.4">
          <title>Why Not Other Methods?</title>
          <statement>
            <p>Or we could choose to use x values that are the same number (or more) of standard deviations above the mean or double the one-sided p-value. Why do you think these methods are not recommended in general?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-5-5" label="PP1.5.5">
          <title>When to Use One-Sided Tests</title>
          <statement>
            <p>It's interesting that the one-sided p-value for the pilot study is also not statistically significant. If it had been, would it be reasonable for the Mythbusters to use the one-sided p-value instead to support their conclusion? Explain.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
    </subsection>
    
    <subsection xml:id="investigation-1-6">
      <title>Investigation 1.6: Kissing the Right Way</title>
      
      <insight>
        <p>In the previous investigation, you learned how to decide whether a hypothesized value of the parameter is plausible based on a two-sided p-value. The two-sided p-value is used when you do not have a prior suspicion or interest in whether the hypothesized value is too large or too small. In fact, in many studies we may not even really have a hypothesized value, but are more interested in using the sample data to estimate the value of the parameter. What are all the plausible values for the parameter?</p>
      </insight>
      
      <sidebyside widths="58% 38%">
        <p>Most people are right-handed and even the right eye is dominant for most people. Researchers have long believed that late-stage human embryos tend to turn their heads to the right. German bio-psychologist Onur GÃ¼ntÃ¼rkÃ¼n (<url href="https://www.nature.com/articles/421711a" target="_blank"><em>Nature</em>, 2003</url>) conjectured that this tendency to turn to the right manifests itself in other ways as well, so he studied kissing couples to see whether both people tend to lean their heads to the right more often than to their left (and if so, how strong the tendency is).</p>
        <image source="images/kissing-couples-intro.jpg" width="100%">
          <description>Kissing couples investigation introduction</description>
        </image>
      </sidebyside>
      
      <p>He and his researchers observed couples from age 13 to 70 in public places such as airports, train stations, beaches, and parks in the United States, Germany, and Turkey. The observers were careful not to include couples who were holding objects such as luggage that might have affected which direction they turned. We will model the overall decision-making process when kissing as a binomial random process.</p>
      
      <exercise xml:id="I1-6-1" label="I1.6.1">
        <title>Identify Sample, Variable, and Parameter</title>
        <statement>
          <p>Identify the sample and variable in this study, as well as the parameter of interest.</p>
          <p>Sample: <var width="50" /></p>
          <p>Variable: <var width="50" /></p>
          <p>Parameter: <var width="50" /></p>
        </statement>
        <response/>
        <hint>
          <p>What group was observed, what was measured, and what long-run proportion are we interested in?</p>
        </hint>
        <solution>
          <p>Sample: 124 observed kissing couples in public places</p>
          <p>Variable: Whether the couple leaned right or left</p>
          <p>Parameter: <m>\pi</m> = the long-run probability (proportion) that a kissing couple leans right</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-6-2" label="I1.6.2">
        <title>One-Sided or Two-Sided?</title>
        <statement>
          <p>If Dr. GÃ¼ntÃ¼rkÃ¼n wants to investigate whether a majority of kissing couples lean right in the long run, is this a one-sided or a two-sided test?</p>
        </statement>
        <choices randomize="no">
          <choice correct="yes">
            <statement><p>One-sided test</p></statement>
            <feedback><p>Correct! Testing for a "majority" means <m>\pi > 0.5</m>, which is a one-sided alternative.</p></feedback>
          </choice>
          <choice>
            <statement><p>Two-sided test</p></statement>
            <feedback><p>Not quite. A "majority" suggests a specific direction (greater than 0.5), so this is one-sided.</p></feedback>
          </choice>
        </choices>
        <hint>
          <p>Does "majority" suggest a specific direction?</p>
        </hint>
      </exercise>
      
      <exercise xml:id="I1-6-3" label="I1.6.3">
        <title>State Hypotheses for Two Conjectures</title>
        <statement>
          <sidebyside widths="60% 35%" margins="0% 5%">
            <stack>
              <p>Dr. GÃ¼ntÃ¼rkÃ¼n actually conjectured that 2/3 of kissing couples would lean right in the long run. A Tic-Tac ad once claimed 74% of kissing couples lean right. State appropriate null and alternative hypotheses for each conjecture.</p>
            </stack>
            <figure>
              <image source="images/tictac-ad.jpg">
                <description>Tic-Tac advertisement about kissing couples leaning right</description>
              </image>
            </figure>
          </sidebyside>
        </statement>
        <matches>
          <match order="1">
            <premise>Dr. GÃ¼ntÃ¼rkÃ¼n Alternative Hypothesis</premise>
            <response><m>\pi \neq 0.667</m></response>
          </match>
          <match order="2">
            <premise>Dr. GÃ¼ntÃ¼rkÃ¼n Null Hypothesis</premise>
            <response><m>\pi = 0.667</m></response>
          </match>
          <match order="3">
            <premise>Tic-Tac Alternative Hypothesis</premise>
            <response><m>\pi \neq 0.74</m></response>
          </match>
          <match order="4">
            <premise>Tic-Tac Null Hypothesis</premise>
            <response><m>\pi = 0.74</m></response>
          </match>
        </matches>
        <hint>
          <p>For each conjecture, we're testing whether the data support the specific claimed value using two-sided tests.</p>
        </hint>
      </exercise>
      
      <exercise xml:id="I1-6-4" label="I1.6.4">
        <title>Calculate Sample Proportion</title>
        <statement>
          <p>Dr. GÃ¼ntÃ¼rkÃ¼n found 80 out of 124 couples leaned right. Calculate the observed sample proportion <m>\hat{p}</m>. Round to three decimal places.</p>
          <p><m>\hat{p}</m> = <var name="$phat" width="10" /></p>
        </statement>
        <setup>
          <var>
            <condition number="0.645" tolerance="0.001">
              <feedback>
                <p>Correct! <m>\hat{p} = 80/124 = 0.645</m> (about 64.5%)</p>
              </feedback>
            </condition>
            <condition string=".*">
              <feedback>
                <p>Not quite. Calculate sample proportion = (number of successes)/(sample size) = 80/124</p>
              </feedback>
            </condition>
          </var>
        </setup>
        <hint>
          <p>Sample proportion = (number of successes)/(sample size)</p>
        </hint>
      </exercise>
      
      <exercise xml:id="I1-6-5" label="I1.6.5">
        <title>Predict Plausible Values</title>
        <statement>
          <p>Based on Dr. GÃ¼ntÃ¼rkÃ¼n's result, what is your best guess for <m>\pi</m>, the long-run probability a kissing couple leans right? Do you think 0.50 will be a plausible value for <m>\pi</m>? 2/3? 0.74? Explain your reasoning.</p>
        </statement>
        <response/>
        <hint>
          <p>The sample proportion provides a point estimate. Consider how far each hypothesized value is from the observed proportion.</p>
        </hint>
        <solution>
          <p>Best guess: <m>\pi \approx 0.645</m> (the sample proportion)</p>
          <p>0.50 seems too low - likely not plausible</p>
          <p>2/3 (0.667) is quite close - likely plausible</p>
          <p>0.74 is somewhat higher - might be plausible, but less certain</p>
        </solution>
      </exercise>
      
      <p>We could employ a "trial-and-error" type of approach to determine which values of <m>\pi</m> appear plausible based on what we observed in the sample. This involves testing different values of <m>\pi</m> and seeing whether the corresponding two-sided p-value is larger than some pre-specified cut-off, typically 0.05. (This cut-off is often called the level of significance.) That is, we will consider <m>\pi_0</m> a plausible value for <m>\pi</m> if assuming <m>\pi = \pi_0</m> does not make our sample statistic look surprising (yielding a small p-value).</p>
      
      <exercise xml:id="I1-6-6a" label="I1.6.6a">
        <title>Identify Plausible Values on Number Line</title>
        <statement>
          <p>Use the One Proportion Inference applet to test different values of <m>\pi_0</m> (multiples of 0.01). For each value below, determine if observing 80 of 124 successes yields a two-sided p-value greater than 0.05. Check all plausible values (p-value <m>\geq</m> 0.05):</p>
        </statement>
        <choices randomize="no">
          <choice>
            <statement><p>0.50</p></statement>
            <feedback><p>The p-value for <m>\pi_0 = 0.50</m> is very small (less than 0.05), so this is not plausible.</p></feedback>
          </choice>
          <choice>
            <statement><p>0.51</p></statement>
            <feedback><p>The p-value is still less than 0.05.</p></feedback>
          </choice>
          <choice>
            <statement><p>0.52</p></statement>
            <feedback><p>The p-value is still less than 0.05.</p></feedback>
          </choice>
          <choice>
            <statement><p>0.53</p></statement>
            <feedback><p>The p-value is still less than 0.05.</p></feedback>
          </choice>
          <choice>
            <statement><p>0.54</p></statement>
            <feedback><p>The p-value is still less than 0.05.</p></feedback>
          </choice>
          <choice>
            <statement><p>0.55</p></statement>
            <feedback><p>The p-value is still less than 0.05.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p>0.56</p></statement>
            <feedback><p>Correct! The p-value is greater than 0.05, making this plausible.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p>0.645</p></statement>
            <feedback><p>Correct! This is our observed sample proportion, definitely plausible.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p>0.72</p></statement>
            <feedback><p>Correct! The p-value is greater than 0.05, making this plausible.</p></feedback>
          </choice>
          <choice>
            <statement><p>0.73</p></statement>
            <feedback><p>The p-value is less than 0.05, so this is not plausible.</p></feedback>
          </choice>
        </choices>
        <hint>
          <p>Use the applet to find the two-sided p-value for each hypothesized value. Plausible values have p-values <m>\geq</m> 0.05.</p>
        </hint>
      </exercise>
      
      <exercise xml:id="I1-6-6" label="I1.6.6">
        <title>Find 95% Confidence Interval</title>
        <statement>
          <p>Use the One Proportion Inference applet to determine the values of <m>\pi_0</m> such that observing 80 of 124 successes or a result more extreme occurs in at least 5% of samples. [Hints: Use values of <m>\pi</m> that are multiples of 0.01 until you can find the boundaries where the exact two-sided p-values (using the tails of the binomial distribution) change from below 0.05 to above 0.05. Then feel free to "zoom in" to three decimal places of accuracy if you'd like.] On a number line, indicate which values are rejected (not plausible) and which values are not rejected and therefore considered plausible.</p>
        </statement>
        <response/>
        <hint>
          <p>Test values systematically: start with values like 0.50, 0.55, 0.60, etc., and find where the p-value crosses 0.05.</p>
        </hint>
        <solution>
          <p>The 95% confidence interval using the "smallest tail probability" (Blaker) approach is approximately <m>0.557</m> to <m>0.727</m>.</p>
          <p>Values below 0.557 and above 0.727 would have two-sided p-values less than 0.05 and would be rejected.</p>
          <p>Values between 0.557 and 0.727 would have two-sided p-values greater than 0.05 and are considered plausible.</p>
        </solution>
      </exercise>
      
      <assemblage xml:id="def-confidence-interval">
        <title>Definition: Confidence Interval</title>
        <p>A <term>confidence interval (CI)</term> specifies the plausible values of the parameter based on the sample result.</p>
      </assemblage>
      
      <p>What you found in the previous exercise will be called a "95% confidence interval" as it was derived using the <m>1 - 0.95 = 0.05</m> cut-off value/significance level.</p>
      
      <exercise xml:id="I1-6-7" label="I1.6.7">
        <title>Interpret 95% CI</title>
        <statement>
          <p>Interpret the confidence interval from the previous exercise. What are you 95% confident of?</p>
        </statement>
        <response/>
        <hint>
          <p>A confidence interval gives a range of plausible values for the parameter.</p>
        </hint>
        <solution>
          <p>We are 95% confident that the true probability that a kissing couple leans right is between 0.557 and 0.727 (or approximately 56% to 73%).</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-6-8" label="I1.6.8">
        <title>Find 99% Confidence Interval</title>
        <statement>
          <p>Use the One Proportion Inference applet to determine the 99% confidence interval by using 0.01 rather than 0.05 as the criterion for rejection/plausibility (level of significance). [Hints: You can check the Show sliders box in the applet and use the slider or edit the orange number to change the value of <m>\pi_0</m>. Keep in mind that you are changing the conjectured value of <m>\pi</m>, not the observed number of successes, which should stay at 80.]</p>
          <p>Using 0.01 as the significance level, test different values of <m>\pi_0</m> to determine which yield a two-sided p-value greater than 0.01. Check all plausible values (p-value <m>\geq</m> 0.01):</p>
        </statement>
        <choices randomize="no">
          <choice>
            <statement><p>0.49</p></statement>
            <feedback><p>The p-value is less than 0.01, so this is not plausible.</p></feedback>
          </choice>
          <choice>
            <statement><p>0.50</p></statement>
            <feedback><p>The p-value is less than 0.01, so this is not plausible.</p></feedback>
          </choice>
          <choice>
            <statement><p>0.51</p></statement>
            <feedback><p>The p-value is less than 0.01, so this is not plausible.</p></feedback>
          </choice>
          <choice>
            <statement><p>0.52</p></statement>
            <feedback><p>The p-value is less than 0.01, so this is not plausible.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p>0.53</p></statement>
            <feedback><p>Correct! The p-value is greater than 0.01, making this plausible in the 99% CI.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p>0.54</p></statement>
            <feedback><p>Correct! The p-value is greater than 0.01, making this plausible.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p>0.55</p></statement>
            <feedback><p>Correct! The p-value is greater than 0.01, making this plausible.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p>0.56</p></statement>
            <feedback><p>Correct! The p-value is greater than 0.01, making this plausible.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p>0.645</p></statement>
            <feedback><p>Correct! This is our observed sample proportion, definitely plausible.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p>0.72</p></statement>
            <feedback><p>Correct! The p-value is greater than 0.01, making this plausible.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p>0.73</p></statement>
            <feedback><p>Correct! The p-value is greater than 0.01, making this plausible.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p>0.74</p></statement>
            <feedback><p>Correct! The p-value is greater than 0.01, making this plausible in the 99% CI.</p></feedback>
          </choice>
          <choice correct="yes">
            <statement><p>0.75</p></statement>
            <feedback><p>Correct! The p-value is greater than 0.01, making this plausible.</p></feedback>
          </choice>
          <choice>
            <statement><p>0.76</p></statement>
            <feedback><p>The p-value is less than 0.01, so this is not plausible.</p></feedback>
          </choice>
          <choice>
            <statement><p>0.77</p></statement>
            <feedback><p>The p-value is less than 0.01, so this is not plausible.</p></feedback>
          </choice>
          <choice>
            <statement><p>0.78</p></statement>
            <feedback><p>The p-value is less than 0.01, so this is not plausible.</p></feedback>
          </choice>
        </choices>
        <hint>
          <p>Use the applet to find the two-sided p-value for each hypothesized value. Plausible values have p-values <m>\geq</m> 0.01.</p>
        </hint>
      </exercise>
      
      <exercise xml:id="I1-6-8b" label="I1.6.8b">
        <title>Compare 95% and 99% Confidence Intervals</title>
        <statement>
          <p>Does this "99% confidence interval" include more or fewer values than the 95% confidence interval? Explain why this makes intuitive sense.</p>
        </statement>
        <response/>
        <hint>
          <p>A higher confidence level means we want to be more certain, so we need a wider interval.</p>
        </hint>
        <solution>
          <p>The 99% confidence interval is approximately <m>0.529</m> to <m>0.749</m>.</p>
          <p>This interval includes <em>more</em> values than the 95% confidence interval (it's wider).</p>
          <p>Explanation: To be more confident (99% vs. 95%) that we've captured the true parameter value, we need to include more values, making the interval wider.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-6-9" label="I1.6.9">
        <title>Compare Intervals</title>
        <statement>
          <p>Identify a value that is captured in the 99% confidence interval but not the 95% confidence interval. Interpret the meaning of this observation. Explain what your analysis reveals about this value as a plausible value of <m>\pi</m>.</p>
        </statement>
        <response/>
        <hint>
          <p>Look at values near the endpoints of the 95% interval.</p>
        </hint>
        <solution>
          <p>For example, <m>\pi = 0.54</m> is in the 99% CI (0.529 to 0.749) but not in the 95% CI (0.557 to 0.727).</p>
          <p>This means that if we tested <m>H_0: \pi = 0.54</m> vs. <m>H_a: \pi \neq 0.54</m>:</p>
          <p><ul>
            <li><p>The two-sided p-value would be between 0.01 and 0.05</p></li>
            <li><p>We would reject <m>H_0</m> at the 0.05 significance level</p></li>
            <li><p>We would fail to reject <m>H_0</m> at the 0.01 significance level</p></li>
          </ul></p>
          <p>So 0.54 is "somewhat" plausible but not highly plausible.</p>
        </solution>
      </exercise>
      
      <assemblage xml:id="study-conclusions-1-6">
        <title>Study Conclusions</title>
        <p>The researchers are assuming they have a representative sample from a binomial random process and want to estimate <m>\pi</m>, the underlying probability that a randomly selected kissing couple leans to the right. Based on this sample of 124 observations, we estimate <m>\pi</m> to be close to <m>\hat{p} = 80/124 = 0.645</m>. However, we know there is some sampling variability, so we want to find an interval of values that appear to be plausible values of <m>\pi</m>. We do this by finding the values of <m>\pi_0</m> for which the two-sided p-value (<m>H_0: \pi = \pi_0</m> vs. <m>H_a: \pi \neq \pi_0</m>) is greater than 0.05. These are all the values of the parameter such that our sample result is not overly surprising. You should have found this "95% confidence interval," using the "smallest tail probability" approach, to be approximately 0.557 to 0.727 (results from using different software or the applet will differ slightly). Thus, based on these sample results, we are "confident" that the actual value of <m>\pi</m>, the probability a random kissing couple leans right, is between 0.56 and 0.73.</p>
        
        <p>A 99% confidence interval for <m>\pi</m> extends from 0.529 to 0.749 (a smaller lower endpoint and a larger upper endpoint, but a similar midpoint) and therefore includes additional plausible values of the parameter compared to the 95% interval. The 99% confidence interval is wider than the 95% interval because a higher level of confidence requires more "room for error." You will learn other methods for calculating confidence intervals for a binomial process in the next section.</p>
      </assemblage>
      
      <p><alert>Discussion:</alert> In this investigation you have learned a second type of "statistical inference": providing an interval of plausible values for the parameter based on an observed sample statistic. Confidence intervals provide a nice companion to tests of significance and are also very useful by themselves. Whereas a test of significance allows you to test the plausibility of a specific hypothesized value, if you reject the null hypothesis, the test of significance provides no information as to how different the actual parameter is from the hypothesized value. If you fail to reject the null hypothesis, you only know that the tested value is one of many plausible values. A confidence interval provides an estimate (with bounds) of the actual value of the parameter. You will learn some additional methods for finding confidence intervals later in this text, but do be aware that some software packages use different methods for finding the "exact" binomial two-sided p-values.</p>
      
      <exercise xml:id="I1-6-10" label="I1.6.10">
        <title>Alternative CI Method</title>
        <statement>
          <p>Alternatively, another way to define a binomial confidence interval is to find all the values of <m>\pi</m> such that P(X &lt; observed) &lt; (1 â€“ confidence level)/2 and P(X > observed) &lt; (1 â€“ confidence level)/2. Use the applet to find the 95% confidence interval using this approach. [Hints: Remember to use the one-sided p-value and change the direction of the tail probability between &lt; and >, but not =.]</p>
          <p>How does the resulting 95% confidence interval compare to the previous one? Which interval is "better"? Explain.</p>
        </statement>
        <response/>
        <hint>
          <p>This is the Clopper-Pearson method. For 95% confidence, use 0.025 as the cutoff for each tail.</p>
        </hint>
        <solution>
          <p>The Clopper-Pearson 95% confidence interval will be slightly different (typically slightly wider) than the Blaker interval.</p>
          <p>Neither is definitively "better" - they use different definitions of "more extreme." The Blaker method tends to produce slightly shorter intervals and is increasingly preferred.</p>
        </solution>
      </exercise>
      
      <assemblage xml:id="probability-detour-ci-methods">
        <title>Probability Detour â€“ Binomial Confidence Intervals</title>
        
        <p>Probably the most well-known binomial confidence interval method is the <term>Clopper-Pearson method</term> (Biometrika, 1934). Rather than using two-sided p-values, it will consider a value for <m>\pi</m> plausible as long as the one-sided tail probability is smaller than (1 â€“ confidence level)/2. One advantage of the Clopper-Pearson method is there is a simple computer algorithm for finding it, rather than needing to check all values as you have done here.</p>
        
        <p>The method we first showed you (keeping all values of <m>\pi</m> with a two-sided p-value larger than (1 â€“ confidence level) using the two-sided p-value based on the tail probabilities) is attributed to <term>Blaker</term> (The Canadian Journal of Statistics, 2000). We could refer to this as the "smallest tail probability" method.</p>
        
        <p>Another approach would be to use the "smallest p-value" approach for the two-sided p-value, switching to using P(X = x) to find values of x more extreme than observed in finding the two-sided p-value. This method, attributed to <term>Sterne</term> (Biometrika, 1954), has the disadvantage that the interval produced can have holes! For example, a value like 0.12 may be in the interval of plausible values, the value 0.13 may not, and the value 0.14 may be again.</p>
        
        <p>Many prefer the Blaker method to the holes of the Sterne method, and Blaker's method is now gaining favor over Clopper-Pearson because the intervals tend to be shorter. We will see some other methods later in this text as well. For now, keep in mind the likely duality between confidence intervals and tests of significance: The confidence interval is the set of values for which we would fail to reject the null hypothesis in favor of the two-sided alternative. So we can interpret the confidence interval as the set of plausible values for the parameter in that they are the values such that our observed sample result would not be surprising. Keep in mind that saying a value is <em>plausible</em> is not the same as saying a value is <em>probable</em>. We won't make probability statements about parameter values in this text.</p>
      </assemblage>
      
      <exercise xml:id="I1-6-11" label="I1.6.11">
        <title>Misinterpreting Confidence</title>
        <statement>
          <p>Explain why it is not appropriate to say "There is a 99% probability that between 52.6% and 75.2% of kissing couples lean right when they kiss."</p>
        </statement>
        <response/>
        <hint>
          <p>The parameter is fixed (not random), but the interval is random.</p>
        </hint>
        <solution>
          <p>The parameter <m>\pi</m> is a fixed value - it either is or isn't in the interval. The 99% refers to the confidence in our <em>method</em>: if we were to repeat this process many times, about 99% of the intervals we construct would contain the true parameter value. We cannot make a probability statement about this specific interval containing the parameter.</p>
        </solution>
      </exercise>
      
      <exercise xml:id="I1-6-12" label="I1.6.12">
        <title>Technology Comparison</title>
        <statement>
          <p>Use technology (see Technology Detour below) to determine the 95% and 99% Clopper-Pearson confidence intervals for the probability that a kissing couple leans to the right. Comment on how the 99% confidence interval compares to the 95% interval, examining both midpoints and widths. [Hint: Average the endpoints to find the midpoint; subtract the endpoints to find the width.]</p>
        </statement>
        <response/>
        <hint>
          <p>Use R's iscambinomtest function or JMP with the ISCAM Journal file.</p>
        </hint>
        <solution>
          <p>Using technology (e.g., R with <c>iscambinomtest(80, 124, conf.level=0.95)</c>):</p>
          <p>95% CI: approximately 0.556 to 0.725</p>
          <p>99% CI: approximately 0.528 to 0.751</p>
          <p>The 99% interval is wider (width â‰ˆ 0.223 vs. 0.169 for 95%) but has a similar midpoint (approximately 0.64).</p>
        </solution>
      </exercise>
      
      <paragraphs xml:id="tech-detour-exact-ci">
        <title>Technology Detour â€“ Exact Confidence Intervals</title>
        
        <p>Different software packages use different confidence interval methods, but you shouldn't see much distinction when the sample size is large.</p>
        
        <exercise xml:id="tech-detour-ci-r" label="CI - R">
          <title>Confidence Intervals in R</title>
          <statement>
            <p><alert>In R: Clopper-Pearson</alert> (tail probability &lt; (1-confidence)/2)</p>
            <program language="r" interactive="sage">
              <input>
iscambinomtest(observed, n, conf.level = )
              </input>
            </program>
            <p>Can enter either sample count or sample proportion for "observed."</p>
            <p>Be sure to label the confidence level. You can enter the proportion or the percentage value.</p>
            
          </statement>
          <solution>
            <p>For the kissing couples example with 80 successes out of 124 trials:</p>
            <program language="r">
              <input>
library(iscam)
iscambinomtest(80, 124, conf.level = 0.95)
              </input>
            </program>
            <p>This produces a 95% Clopper-Pearson confidence interval of approximately (0.556, 0.725).</p>
            <p>For a 99% confidence interval:</p>
            <program language="r">
              <input>
iscambinomtest(80, 124, conf.level = 0.99)
              </input>
            </program>
            <p>This produces a 99% confidence interval of approximately (0.528, 0.751).</p>
          </solution>
        </exercise>
        
        <exercise xml:id="tech-detour-ci-jmp" label="CI - JMP">
          <title>Confidence Intervals in JMP</title>
          <statement>
            <p><alert>In JMP: Clopper-Pearson</alert> (tail probability &lt; (1-confidence)/2)</p>
            <p>Using the ISCAM Journal file, select <em>Confidence Interval for One Proportion (with Summary Stats)</em>.</p>
            <p>(The raw data option does not give an exact binomial confidence interval.)</p>
            <p>With summarized data, specify the count and sample size, and select the Binomial radio button.</p>
          </statement>
          <solution>
            <p>For the kissing couples example:</p>
            <p><ul>
              <li><p>Enter Number of successes: 80</p></li>
              <li><p>Enter Sample size: 124</p></li>
              <li><p>Select the Binomial radio button</p></li>
              <li><p>The default confidence level is 95%</p></li>
            </ul></p>
            <p>The output will show a 95% Clopper-Pearson confidence interval of approximately (0.556, 0.725).</p>
            <p>You can change the confidence level to 99% in the dialog box to obtain the 99% confidence interval of approximately (0.528, 0.751).</p>
          </solution>
        </exercise>
      </paragraphs>
      
      <exercise xml:id="I1-6-13" label="I1.6.13">
        <title>Optional: Compare Methods</title>
        <statement>
          <p>Optional: Compare the Clopper-Pearson 99% interval to the Blaker 99% interval. Which is narrower?</p>
        </statement>
        <response/>
        <hint>
          <p>The Blaker method typically produces shorter intervals.</p>
        </hint>
        <solution>
          <p>The Blaker 99% interval is typically narrower than the Clopper-Pearson 99% interval, which is one reason it's gaining favor in practice.</p>
        </solution>
      </exercise>
      
      <paragraphs>
        <title>Output from R</title>
        <p>The <c>iscambinomtest</c> function includes some interesting graphs.</p>
        <p><ul>
          <li><p>The bottom graph illustrates the 95% confidence interval. The interval is centered at the observed sample proportion <m>\hat{p}</m> and displays the two endpoints of the interval of plausible values for the process probability.</p></li>
          <li><p>The top graph shows the distribution assuming the lower value of the confidence interval as the process probability. This is as far left as we can shift that null distribution before the area to the right of the observed number of successes, 80, dips below 0.025.</p></li>
          <li><p>The middle graph shows how far we can move that distribution to the right (largest plausible value of <m>\pi</m>) before the probability below 80 dips below 0.025.</p></li>
        </ul></p>
        
        <figure>
          <image source="images/r-binom-output.png" width="75%">
            <description>R output from iscambinomtest showing three graphs - top and middle showing binomial distributions at interval endpoints, bottom showing confidence interval</description>
          </image>
        </figure>
      </paragraphs>
      
      <subsection xml:id="practice1-6">
        <title>Practice Problem 1.6</title>
        
        <exercise xml:id="PP1-6-1" label="PP1.6.1">
          <title>St. George's Hospital CI</title>
          <statement>
            <p>Recall the 8 out of 10 statistic for St. George's Hospital (Investigation 1.4). Based on this result, what is an interval of plausible values for the underlying mortality rate at St. George's? [Hint: You can use a 95% confidence level if none is stated.] Describe how you found the interval and name the method used. Report the midpoint and width of this interval.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-6-2" label="PP1.6.2">
          <title>Larger Sample CI</title>
          <statement>
            <p>Use technology to calculate the 95% confidence interval based on the 71 deaths among 361 patients. Comment on how the width and midpoint of this interval differ from the interval in (a). Explain why these changes make sense.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-6-3" label="PP1.6.3">
          <title>CI and Hypothesis Test Duality</title>
          <statement>
            <p>Based on the interval in (b), if you were to test <m>H_0: \pi = 0.20</m> vs. <m>H_a: \pi \neq 0.20</m>, would you reject or fail to reject the null hypothesis? Explain how you know the conclusion based on the confidence interval without actually conducting the test.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <assemblage xml:id="summary-exact-binomial">
        <title>Summary of Exact Binomial Inference (Sampling from a Binomial Process)</title>
        
        <p>Let X represent the number of successes in the sample and <m>\pi</m> the probability of success for a binomial random process.</p>
        
        <p><alert>To test <m>H_0: \pi = \pi_0</m></alert></p>
        <p>We can calculate a p-value based on the binomial distribution with parameters n and <m>\pi_0</m>. The p-value can be one-sided or two-sided based on the statement of the research conjecture.</p>
        <p><ul>
          <li><p>If <m>H_a: \pi > \pi_0</m>: p-value = P(X â‰¥ observed)</p></li>
          <li><p>If <m>H_a: \pi &lt; \pi_0</m>: p-value = P(X â‰¤ observed)</p></li>
          <li><p>If <m>H_a: \pi \neq \pi_0</m>: p-value = sum of both tail probabilities using a method like "small p-values"</p></li>
        </ul></p>
        
        <p><alert>(100 Ã— C)% Confidence Interval for <m>\pi</m></alert></p>
        <p>The set of values such that the two-sided p-value based on the observed count is larger than the <m>(1 - C)</m> cut-off.</p>
        
        <p><alert>Technology</alert></p>
        <p><ul>
          <li><p>One Proportion Inference applet for approximate and exact binomial probability (p-value)</p></li>
          <li><p>R, ISCAM Workspace: <c>iscambinomtest(observed, n, hypothesized=Ï€_0, alternative="greater", "less," or "two.sided", conf.level)</c></p>
            <p>Can enter either sample count or sample proportion for "observed." If you don't specify a hypothesized value and alternative, be sure to label the confidence level.</p></li>
          <li><p>JMP:</p>
            <p>For a one-sided p-value: Analyze > Distribution (raw or tallied data using Freq)</p>
            <p>For a confidence interval: ISCAM Journal file > Confidence Interval for One Proportion using Summary Stats: specify the number of successes and the sample size</p></li>
        </ul></p>
      </assemblage>
      
      <paragraphs>
        <title>Handy Reminders</title>
        <p><ul>
          <li><p>In R: If you don't remember the inputs for a function, just use ? before the function, e.g., <c>?iscambinomtest</c>. Use the up arrow to return to earlier commands.</p></li>
          <li><p>In JMP: Remember to look under "hot spots" and that options will change across menu items.</p></li>
        </ul></p>
      </paragraphs>
    </subsection>
  </subsection>
    
    <subsection xml:id="section-2-normal-approximations">
      <title>Section 2: Normal Approximations for Sample Proportions</title>
      
      <p>So far, all the studies you have examined have involved one categorical binary variable and the relevant statistic has been the number of successes, or equivalently the proportion of successes, where "success" is defined as the outcome you count (e.g., number of heart transplantation deaths, number of helper toys, number of correct choices) in a particular sample. You have used simulation from a coin-tossing type process to approximate probabilities (p-value, error probabilities) and you calculated exact probabilities using the binomial distribution.</p>
      
      <p>Historically, when computers were less prevalent, these empirical and binomial probabilities were often cumbersome to determine and statisticians instead applied a far more convenient approximation method to estimate the probabilities of interest. In this section, you will see how the normal probability model can be used as a third method to approximate the p-values, confidence intervals, and error probabilities from the previous section. See the Probability Detour for more information about the normal distribution.</p>
      
      <subsection xml:id="investigation-1-7">
        <title>Investigation 1.7: Reese's Pieces (Optional)</title>
        
        <sidebyside widths="58% 38%">
          <stack>
            <p>Manufacturers often perform "quality checks" to ensure that their manufacturing process is operating under certain specifications. Suppose a manager at Hershey's is concerned that his manufacturing process is no longer producing the correct color proportions (orange, yellow, brown) in Reese's candies.</p>
          </stack>
          <image source="images/Reeses.jpg" width="80%"/>
        </sidebyside>
        
        <exercise xml:id="I1-7-a" label="I1.7a">
          <title>(a) Initial Prediction</title>
          <statement>
            <p>Prediction: A friend finds 10 orange candies in her bag. Does this convince you that the three colors are not equally likely? What other information would you want to know? What if she tells you these orange pieces were 50% of the candies in her bag?</p>
          </statement>
          <response/>
          <hint>
            <p>Consider: Knowing the total number of candies in the bag is crucial. What's the difference between 10 out of 20 versus 10 out of 100?</p>
          </hint>
          <solution>
            <p>Conjectures will vary. Knowing the total number of candies (sample size) is crucial. 10 out of 20 (50%) is much different from 10 out of 100 (10%). With 50% orange, this provides some evidence against equal proportions, but we would want more information about sampling variability.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-7-b" label="I1.7b">
          <title>(b) Record Your Sample</title>
          <statement>
            <p>Take a (presumably representative) sample of n = 25 Reese's Pieces candies and record the number of orange, yellow, and brown candies in your sample.</p>
            <p>Orange: <var width="5"/> Yellow: <var width="5"/> Brown: <var width="5"/></p>
          </statement>
          <solution>
            <p>Results will vary. Students should record their data and be prepared to share it with the class.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-7-c" label="I1.7c">
          <title>(c) Identify Sample and Variable</title>
          <statement>
            <p>Identify the sample/random process and variable for your sample.</p>
            <p>Sample/Random process: <var width="40"/></p>
            <p>Variable: <var width="40"/></p>
            <p>Type: <var width="20"/></p>
          </statement>
          <response/>
          <hint>
            <p>The random process is selecting candies. The variable is the color of each candy. Is this categorical or quantitative?</p>
          </hint>
          <solution>
            <p>Sample/Random process: The random process is selecting Reese's Pieces candies.</p>
            <p>Variable: The color of each candy</p>
            <p>Type: Categorical (with three possible values: orange, yellow, brown)</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-7-d" label="I1.7d">
          <title>(d) Assess Binomial Process</title>
          <statement>
            <p>Define "success" to be an orange candy and "failure" to be a non-orange candy. Is it reasonable to treat these data as observations from a binomial process? Explain.</p>
          </statement>
          <response/>
          <hint>
            <p>Consider: Are there two possible outcomes? Fixed number of trials? Independent trials? Constant probability of success?</p>
          </hint>
          <solution>
            <p>Yes, this is reasonably a binomial process: There are two possible outcomes (orange/not orange), a fixed number of trials (n = 25), the trials are independent (assuming sampling with replacement or from a very large population), and the probability of success (getting an orange candy) is constant for each trial. The main assumption to consider is whether the candies are well-mixed and randomly selected.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-7-e" label="I1.7e">
          <title>(e) Initial Assessment</title>
          <statement>
            <p>Prediction: Based on your data, do you think one-third is a plausible value for the probability Hershey's process produces an orange candy? How are you deciding? What more information do you need?</p>
          </statement>
          <response/>
          <solution>
            <p>Conjectures will vary. Students need more information about how much variability to expect in sample proportions when the true probability is one-third. A simulation will help determine whether the observed sample proportion is reasonably close to 1/3 or surprisingly far away.</p>
          </solution>
        </exercise>
        
        <p>Reporting the sample proportion as the statistic is often more informative than the sample count, but that means we need to know about the null distribution of sample proportions.</p>
        
        <exercise xml:id="I1-7-f" label="I1.7f">
          <title>(f) Initial Simulation</title>
          <statement>
            <p>Open the <url href="https://www.rossmanchance.com/applets/2021/oneprop/OneProp.htm?candy=1&amp;hideExtras=1" visual="rossmanchance.com/applets/2021/oneprop/OneProp.htm">Reese's Pieces applet</url>.</p>
            <image source="images/reesesapplet.png" width="70%"/>
            <p><ul>
              <li>Set the applet to assume a 0.333 process probability of a Reese's Pieces candy being orange. The applet is set to take a sample of n = 25 candies.</li>
              <li>Click the Draw Samples button.</li>
              <li>The applet will randomly select a sample of 25 candies, sort them, and report the sample number of orange candies.</li>
              <li>Click the Draw Samples button again.</li>
            </ul></p>
            <p>Did you get the same number of orange candies both times?</p>
          </statement>
          <choices>
            <choice correct="no">
              <statement>
                <p>Yes</p>
              </statement>
            </choice>
            <choice correct="yes">
              <statement>
                <p>No</p>
              </statement>
            </choice>
          </choices>
          <solution>
            <p>No, you typically get different numbers of orange candies. This demonstrates sampling variabilityâ€”even when the true probability is 0.333, individual samples produce different results due to random chance.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-7-g" label="I1.7g">
          <title>(g) Interpret Dotplot</title>
          <statement>
            <p><ul>
              <li>Change the Number of samples from 1 to 1998.</li>
              <li>Uncheck the Show animation box.</li>
              <li>Click the Draw Samples button again.</li>
              <li>Select the Proportion of orange radio button.</li>
              <li>What does each dot in this dotplot represent?</li>
            </ul></p>
          </statement>
          <response/>
          <hint>
            <p>Each dot represents the sample proportion of orange candies in one sample of 25 candies.</p>
          </hint>
          <solution>
            <p>Each dot represents the sample proportion of orange candies in one sample of 25 candies. The entire dotplot shows the distribution of sample proportions across many samples when the true probability is 0.333, illustrating the sampling distribution of the sample proportion.</p>
            <image source="images/inv1.7-dotplot-n25.png" width="80%">
              <description>Dotplot showing the distribution of sample proportions for n=25 candies with probability 0.333</description>
            </image>
          </solution>
        </exercise>
        
        <assemblage xml:id="binomial-random-variable-rules">
          <title>Binomial Random Variable Properties</title>
          <p>Recall that for a binomial random variable, <m>X</m>, the expected value <m>E(X) = n \times \pi</m> and the standard deviation <m>SD(X) = \sqrt{n \times \pi \times (1-\pi)}</m>. It can also be shown that random variables follow these rules:</p>
          <p><ul>
            <li>For any constant <m>c</m>, <m>E(cX) = c \times E(X)</m></li>
            <li>For any constant <m>c</m>, <m>SD(cX) = |c| \times SD(X)</m></li>
          </ul></p>
        </assemblage>
        
        <exercise xml:id="I1-7-h" label="I1.7h">
          <title>(h) Derive Formulas</title>
          <statement>
            <p>Use the above information, and the fact that <m>\hat{p} = X/n</m>, to derive formulas for <m>E(\hat{p})</m> and <m>SD(\hat{p})</m>.</p>
          </statement>
          <response/>
          <hint>
            <p>Start with <m>E(\hat{p}) = E(X/n) = E((1/n) \times X)</m> and apply the rule for constants.</p>
          </hint>
          <solution>
            <p><m>E(\hat{p}) = E(X/n) = (1/n) \times E(X) = (1/n) \times n\pi = \pi</m></p>
            <p><m>SD(\hat{p}) = SD(X/n) = (1/n) \times SD(X) = (1/n) \times \sqrt{n\pi(1-\pi)} = \sqrt{\frac{\pi(1-\pi)}{n}}</m></p>
            <image source="images/inv1.7-formulas.png" width="60%">
              <description>Mathematical formulas for expected value and standard deviation of sample proportion</description>
            </image>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-7-i" label="I1.7i">
          <title>(i) Verify Formulas</title>
          <statement>
            <p>Using <m>\pi = 0.333</m> and <m>n = 25</m>, verify that your formulas match the results from checking the Summary Statistics box in the applet.</p>
          </statement>
          <response/>
          <hint>
            <p>Calculate <m>E(\hat{p}) = 0.333</m> and <m>SD(\hat{p}) = \sqrt{\frac{0.333(0.667)}{25}}</m></p>
          </hint>
          <solution>
            <p><m>E(\hat{p}) = \pi = 0.333</m></p>
            <p><m>SD(\hat{p}) = \sqrt{\frac{\pi(1-\pi)}{n}} = \sqrt{\frac{0.333(0.667)}{25}} = \sqrt{\frac{0.222}{25}} = \sqrt{0.00888} \approx 0.094</m></p>
            <p>These values should match the mean and standard deviation shown in the applet's summary statistics.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-7-j" label="I1.7j">
          <title>(j) Predict Larger Sample</title>
          <statement>
            <p>Prediction: If we had instead taken 2,000 samples of size n = 100 candies, how do you think the distribution of the sample proportions would compare to the distribution where n = 25? Explain.</p>
          </statement>
          <response/>
          <hint>
            <p>Think about how sample size affects variability in sample proportions.</p>
          </hint>
          <solution>
            <p>With n = 100, we would expect less variability in the sample proportions compared to n = 25. The distribution should still be centered at 0.333 and roughly symmetric, but with much less spread. Larger sample sizes lead to more precise estimates of the population parameter.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-7-k" label="I1.7k">
          <title>(k) Compare Distributions</title>
          <statement>
            <p>In the applet: <ul>
              <li>Without pressing Reset, change the Number of candies in the applet to 100.</li>
              <li>Change the Number of samples to 2,000.</li>
              <li>Press Draw Samples to generate a new distribution.</li>
              <li>Check the Show previous results box to display the previous distribution in the background in light grey.</li>
              <li>Describe the behavior (shape, center, variability) of this (new) distribution and how it has changed from the previous.</li>
            </ul></p>
            <p>Focus on the most substantial change in the distribution. Is this what you expected?</p>
          </statement>
          <response/>
          <hint>
            <p>Pay special attention to the spread of the distribution - how has it changed?</p>
          </hint>
          <solution>
            <p>The center remains at approximately 0.333. The shape remains roughly symmetric and mound-shaped. The most substantial change is in variability: the distribution with n = 100 has much less spread than the distribution with n = 25. This makes sense because larger sample sizes lead to less sampling variability.</p>
            <image source="images/inv1.7-compare-n25-n100.png" width="80%">
              <description>Comparison of sampling distributions for n=25 and n=100 showing reduced variability with larger sample size</description>
            </image>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-7-l" label="I1.7l">
          <title>(l) Smaller Sample Size</title>
          <statement>
            <p>Repeat the previous questions (using the formulas, checking against the applet) for a sample size of <em>n</em> = 5 candies.</p>
          </statement>
          <response/>
          <hint>
            <p>Calculate the expected value and standard deviation for <em>n</em> = 5, then compare the distribution to n = 25.</p>
          </hint>
          <solution>
            <p>For n = 5:</p>
            <p><m>E(\hat{p}) = \pi = 0.333</m></p>
            <p><m>SD(\hat{p}) = \sqrt{\frac{0.333(0.667)}{5}} = \sqrt{0.0444} \approx 0.211</m></p>
            <p>The distribution with n = 5 has much more variability (SD â‰ˆ 0.211) compared to n = 25 (SD â‰ˆ 0.094). The center remains at 0.333, but smaller sample sizes produce much more spread in the sample proportions.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-7-m" label="I1.7m">
          <title>(m) Calculate Cut-offs</title>
          <statement>
            <p>Return to the scenario where n = 25 and <m>\pi = 0.333</m>. Earlier, you predict that in this scenario <m>E(\hat{p}) = 0.333</m> and <m>SD(\hat{p}) = 0.094</m>. Calculate the following "cut-offs":</p>
            <p><m>\pi - 2 \times SD(\hat{p})</m> = <var width="10"/> and <m>\pi + 2 \times SD(\hat{p})</m> = <var width="10"/></p>
          </statement>
          <setup>
            <var>
              <condition number="0.145" tolerance="0.005">
                <feedback><p>Correct! <m>0.333 - 2(0.094) = 0.145</m></p></feedback>
              </condition>
            </var>
            <var>
              <condition number="0.521" tolerance="0.005">
                <feedback><p>Correct! <m>0.333 + 2(0.094) = 0.521</m></p></feedback>
              </condition>
            </var>
          </setup>
          <solution>
            <p><m>\pi - 2 \times SD(\hat{p}) = 0.333 - 2(0.094) = 0.333 - 0.188 = 0.145</m></p>
            <p><m>\pi + 2 \times SD(\hat{p}) = 0.333 + 2(0.094) = 0.333 + 0.188 = 0.521</m></p>
            <p>These values represent the boundaries within which approximately 95% of sample proportions should fall when <m>\pi = 0.333</m> and <m>n = 25</m>.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-7-n" label="I1.7n">
          <title>(n) Percentage Within Two Standard Deviations</title>
          <statement>
            <p>Use the applet to determine the percentage of samples with a sample proportion within 2 standard deviations of the expected value.</p>
            <p><ul>
              <li>Set the probability of orange to 0.333 and the number of candies to 25.</li>
              <li>Generate 2,000 samples.</li>
              <li>Enter the first value from (m) in the As extreme as box.</li>
              <li>Check the Two-tailed box and then the between box.</li>
              <li>Enter the second value in the box that appears.</li>
            </ul></p>
            <p>Write a sentence reporting the percentage of samples with a proportion of orange candies between these two values.</p>
          </statement>
          <response/>
          <hint>
            <p>The percentage should be close to 95%.</p>
          </hint>
          <solution>
            <p>Approximately 95-96% of the samples have a sample proportion between 0.145 and 0.521 (within two standard deviations of 0.333). This percentage may vary slightly in different simulations due to random chance, but should consistently be close to 95%.</p>
            <image source="images/inv1.7-empirical-rule.png" width="80%">
              <description>Distribution showing approximately 95% of sample proportions falling within two standard deviations of the mean</description>
            </image>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-7-o" label="I1.7o">
          <title>(o) Compare for <em>n</em> = 100</title>
          <statement>
            <p>Repeat the previous two questions (calculating cut-offs and using the applet to find the percentage) for <em>n</em> = 100 (including using the new SD and new cut-offs). How does the percentage of samples within two standard deviations of 0.333 compare?</p>
          </statement>
          <response/>
          <hint>
            <p>The percentage should still be close to 95%, regardless of sample size.</p>
          </hint>
          <solution>
            <p>For n = 100: <m>SD(\hat{p}) = \sqrt{\frac{0.333(0.667)}{100}} \approx 0.047</m></p>
            <p>Cut-offs: <m>0.333 \pm 2(0.047)</m> gives (0.239, 0.427)</p>
            <p>The percentage of samples within these cut-offs is still approximately 95%. While the standard deviation is smaller (less variability), the percentage within two standard deviations remains consistent regardless of sample size. This demonstrates that the empirical rule applies to the sampling distribution regardless of sample size.</p>
          </solution>
        </exercise>
        
        <assemblage xml:id="empirical-rule">
          <title>Definition: The Empirical Rule</title>
          <p>The Empirical Rule or the 68-95-99.7 rule states that for a mound-shaped, symmetric distribution:</p>
          <p><ul>
            <li>the interval (mean â€“ SD, mean + SD) should capture approximately 68% of the distribution.</li>
            <li>the interval (mean â€“ 2 SD, mean + 2 SD) should capture approximately 95% of the distribution.</li>
            <li>the interval (mean â€“ 3 SD, mean + 3 SD) should capture approximately 99.7% of the distribution.</li>
          </ul></p>
          <image source="images/emprule1.png" width="80%"/>
        </assemblage>
        
        <exercise xml:id="I1-7-p" label="I1.7p">
          <title>(p) Verify Empirical Rule</title>
          <statement>
            <p>Do your simulation results agree with the empirical rule?</p>
          </statement>
          <response/>
          <solution>
            <p>Yes, the simulation results agree well with the empirical rule. Approximately 95% of the sample proportions fall within two standard deviations of the mean (0.333), which is consistent with the empirical rule's prediction for mound-shaped, symmetric distributions.</p>
          </solution>
        </exercise>
        
        <exercise xml:id="I1-7-q" label="I1.7q">
          <title>Complete Statements</title>
          <statement>
            <p>Complete the following statements:</p>
            <p>Roughly <var width="5"/>% of sample proportions fall within <var width="10"/> of the value of <m>\pi</m>.</p>
            <p>For roughly <var width="5"/>% of samples, <m>\pi</m> falls within <var width="10"/> of any sample proportion.</p>
          </statement>
          <hint>
            <p>Think about the empirical rule and standard deviations.</p>
          </hint>
          <solution>
            <p>Roughly 95% of sample proportions fall within 2 SD of the value of <m>\pi</m>.</p>
            <p>For roughly 95% of samples, <m>\pi</m> falls within 2 SD of any sample proportion.</p>
          </solution>
        </exercise>
        
        <paragraphs xml:id="discussion-1-7">
          <title>Discussion</title>
          <p>Notice that if we know the value of <m>\pi</m> and we know the sample size n, we can predict the value of the sample proportion fairly precisely. This will be very helpful to us in deciding whether an observed sample proportion is "far away" from a hypothesized value for <m>\pi</m>.</p>
        </paragraphs>
      </subsection>
      
      <subsection xml:id="practice1-7A">
        <title>Practice Problem 1.7A</title>
        
        <exercise xml:id="PP1-7A-1" label="PP1.7A.1">
          <title>Sample Proportions Range</title>
          <statement>
            <p>In this investigation, you took samples of 25 candies. Between what two values should 95% of the sample proportions fall when <m>\pi = 0.50</m>?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-7B">
        <title>Practice Problem 1.7B</title>
        
        <p>An expert witness in a paternity suit testifies that the length (in days) of pregnancy (the time from conception to delivery of the child) is approximately normally distributed with mean <m>\mu = 270</m> days and standard deviation <m>\sigma = 10</m> days. The defendant in the suit is able to prove that he was out of the country during a period that began 280 days before the birth of the child and ended 230 days before the birth of the child.</p>
        
        <exercise xml:id="PP1-7B-1" label="PP1.7B.1">
          <title>Normal Model Assumption</title>
          <statement>
            <p>Does a normal model seem to be a reasonable assumption here? Explain why or why not or how you might decide.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-7B-2" label="PP1.7B.2">
          <title>Probability Calculation</title>
          <statement>
            <p>If the defendant was the father of the child, what is the probability that the mother could have had the very long (more than 280 days) or the very short (less than 230 days) pregnancy indicated by the testimony?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>

      <subsection xml:id="investigation1-8">
        <title>Investigation 1.8: Halloween Treat Choices</title>
        
        <p>
          Obesity has become a widespread health concern, especially in children. Researchers believe that giving children easy access to food increases their likelihood of consuming extra calories. <url href="https://pubmed.ncbi.nlm.nih.gov/12859885/" visual="pubmed.ncbi.nlm.nih.gov/12859885">Schwartz, Chen, and Brownell (2003)</url> examined whether children would be willing to take a small toy instead of candy at when trick-or-treating on Halloween. They had seven homes in 5 different towns in Connecticut present children with a plate of 4 toys (stretch pumpkin men, large glow-in-the-dark insects, Halloween theme stickers, and Halloween theme pencils) and a plate of 4 different name brand candies (lollipops, fruit-flavored chewy candies, fruit-flavored crunchy wafers, and "sweet and tart" hard candies) to see whether children were more likely to choose the candy or the toy. The houses alternated whether the toys were on the left or on the right. Data were recorded for 284 children between the ages of 3 and 14 (who did not ask for both types of treats).
        </p>

        <exercise xml:id="I1-8-a" label="I1.8a">
          <title>Identify Sample and Variable</title>
          <statement>
            <p>
              Identify the sample/random process and variable of interest. Which outcome do you want to consider "success"?
            </p>
            <p>
              Sample/random process: <var width="40"/>
            </p>
            <p>
              Variable: <var width="40"/>
            </p>
            <p>
              Success: <var width="40"/>
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              Think about what is being randomly determined in this study - the choice each child makes when presented with toys and candy.
            </p>
          </hint>
          <solution>
            <p>
              Sample/random process: The 284 children who were trick-or-treating and presented with a choice between toys and candy.
            </p>
            <p>
              Variable: Whether the child chose a toy or candy (categorical).
            </p>
            <p>
              Success: Choosing a toy (or choosing candy - either can be defined as success).
            </p>
          </solution>
        </exercise>

        <exercise xml:id="I1-8-b" label="I1.8b">
          <title>Define Parameter</title>
          <statement>
            <p>
              Define (in words) the parameter of interest in this study.
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              What long-run proportion are we interested in learning about?
            </p>
          </hint>
          <solution>
            <p>
              The parameter of interest is the probability (or long-run proportion) that a child, when presented with a choice between toys and candy while trick-or-treating, will choose the toy.
            </p>
          </solution>
        </exercise>

        <exercise xml:id="I1-8-c" label="I1.8c">
          <title>State Hypotheses</title>
          <statement>
            <p>
              State an appropriate null and alternative hypothesis involving this parameter (in symbols and in words), for testing whether there is strong evidence of a preference for either the toys or the candy.
            </p>
            <p>
              <m>H_0</m>:
            </p>
            <p>
              <m>H_a</m>:
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              If there is no preference, what would you expect the probability to be? What would indicate a preference?
            </p>
          </hint>
          <solution>
            <p>
              <m>H_0: \pi = 0.5</m>. The probability that a child chooses a toy is 0.5 (no preference).
            </p>
            <p>
              <m>H_a: \pi \neq 0.5</m>. The probability that a child chooses a toy is not 0.5 (there is a preference).
            </p>
          </solution>
        </exercise>

        <exercise xml:id="I1-8-d" label="I1.8d">
          <title>Predict Distribution</title>
          <statement>
            <p>
              What does "theory" predict for the mean and standard deviation of the distribution of "number of successes" under the null hypothesis if we model this experiment as a binomial process? Do you expect this distribution to be symmetric and "filled in" or skewed and "gappy"?
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              For a binomial distribution, the mean is <m>n\pi</m> and the standard deviation is <m>\sqrt{n\pi(1-\pi)}</m>.
            </p>
          </hint>
          <solution>
            <p>
              Under the null hypothesis with <m>n = 284</m> and <m>\pi = 0.5</m>:
            </p>
            <p>
              Mean: <m>n\pi = 284(0.5) = 142</m>
            </p>
            <p>
              Standard deviation: <m>\sqrt{n\pi(1-\pi)} = \sqrt{284(0.5)(0.5)} = \sqrt{71} \approx 8.43</m>
            </p>
            <p>
              Because the sample size is large and <m>\pi = 0.5</m>, we expect the distribution to be symmetric and "filled in" (approximately normal).
            </p>
            <image source="images/inv1.8-null-dist.png" width="80%">
              <description>Binomial distribution showing approximately normal shape with mean 142 and standard deviation 8.43</description>
            </image>
          </solution>
        </exercise>

        <p>
          The normal distribution has many, many applications to quantitative variables in general (e.g., many biological variables like height are assumed to follow a normal distribution). For now, we will focus on using this mathematical model as an approximation to the null distribution.
        </p>

        <assemblage xml:id="central-limit-theorem">
          <title>Central Limit Theorem</title>
          <p>
            If the sample size is large enough, then the distribution of "number of successes" for a binomial random variable will be well-modeled by the normal probability distribution. The sample size is considered large enough if <m>n\times\pi\geq 10</m> and <m>n\times(1-\pi)\geq 10</m>.
          </p>
        </assemblage>

        <exercise xml:id="I1-8-e" label="I1.8e">
          <statement>
            <p>
              Why does the value of the process probability (<m>\pi</m>) matter when we check this condition?
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              Think about what happens when <m>\pi</m> is very close to 0 or 1.
            </p>
          </hint>
          <solution>
            <p>
              When <m>\pi</m> is close to 0 or 1, the binomial distribution becomes more skewed. We need both <m>n\pi</m> and <m>n(1-\pi)</m> to be large enough to ensure the distribution is symmetric enough to be well-approximated by a normal distribution. If <m>\pi</m> is very small, even with a large <m>n</m>, we might not have enough expected successes for the normal approximation to work well.
            </p>
          </solution>
        </exercise>

        <exercise xml:id="I1-8-f" label="I1.8f">
          <statement>
            <p>
              Does the Central Limit Theorem appear applicable for the Halloween study?
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              Check both conditions: <m>n\pi \geq 10</m> and <m>n(1-\pi) \geq 10</m>.
            </p>
          </hint>
          <solution>
            <p>
              Yes, the Central Limit Theorem is applicable.
            </p>
            <p>
              <m>n\pi = 284(0.5) = 142 \geq 10</m> âœ“
            </p>
            <p>
              <m>n(1-\pi) = 284(0.5) = 142 \geq 10</m> âœ“
            </p>
            <p>
              Both conditions are satisfied.
            </p>
          </solution>
        </exercise>

        <exercise xml:id="I1-8-g" label="I1.8g">
          <statement>
            <p>
              Use the One Proportion Inference applet to verify your answers to (d). Check the Normal Approximation box to verify your answer to (f).
            </p>
          </statement>
          <response/>
        </exercise>

        <p>
          There are actually some nice advantages to using the normal distribution rather than the binomial distribution, though less so as computers have become so advanced. For one, tail probabilities can be approximated by finding the area under the normal curve rather than summing binomial probabilities.
        </p>

        <paragraphs xml:id="finding-p-value-normal">
          <title>Finding a p-value with the normal approximation</title>
        </paragraphs>

        <exercise xml:id="I1-8-h" label="I1.8h">
          <statement>
            <p>
              In the sample, 135 children chose the toy and 149 chose the candy. Use the applet to find the following two-sided p-values, and explain briefly how each is found:
            </p>
            <p>
              Simulation:
            </p>
            <p>
              Exact binomial:
            </p>
            <p>
              Normal approximation:
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              Use the One Proportion Inference applet with <m>n = 284</m> and <m>\pi = 0.5</m>.
            </p>
          </hint>
          <solution>
            <p>
              With 135 children choosing the toy (fewer than expected under <m>H_0</m>):
            </p>
            <p>
              Simulation: Approximately 0.40 (will vary) - found by simulating many samples from a binomial distribution and counting the proportion as extreme or more extreme than 135.
            </p>
            <p>
              Exact binomial: Approximately 0.40 - found by calculating <m>P(X \leq 135) + P(X \geq 149)</m> using the binomial distribution.
            </p>
            <p>
              Normal approximation: Approximately 0.40 - found by calculating the area under the normal curve below 135 and above 149.
            </p>
            <image source="images/inv1.8-pvalue-comparison.png" width="80%">
              <description>Comparison of p-values from simulation, exact binomial, and normal approximation methods</description>
            </image>
          </solution>
        </exercise>

        <p>
          The normal approximation is typically applied to the null distribution of sample proportions rather than sample counts.
        </p>

        <exercise xml:id="I1-8-i" label="I1.8i">
          <statement>
            <p>
              Use the radio button to toggle the Choice of Statistic to Proportion of heads. What changes about the null distribution? What is the observed value of the statistic?
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              Convert the count to a proportion: <m>135/284</m>.
            </p>
          </hint>
          <solution>
            <p>
              When switching to proportions, the null distribution is centered at <m>\pi = 0.5</m> instead of 142, and the standard deviation becomes <m>\sqrt{\pi(1-\pi)/n} = \sqrt{0.5(0.5)/284} \approx 0.0297</m> instead of 8.43.
            </p>
            <p>
              The observed value of the statistic is <m>\hat{p} = 135/284 \approx 0.475</m>.
            </p>
          </solution>
        </exercise>

        <assemblage xml:id="sd-sample-proportion">
          <title>Key Result</title>
          <p>
            When the Central Limit Theorem applies, the distribution of sample proportions is approximately normal with mean equal to <m>\pi</m> and standard deviation equal to <m>SD(\hat{p}) = \sqrt{\pi(1-\pi)/n}</m>.
          </p>
        </assemblage>

        <p>
          When we are using the normal distribution, it is even more common to work with the "standardized statistic" by calculating how many standard deviations the statistic is from the expected value (mean) of the null distribution.
        </p>

        <exercise xml:id="I1-8-j" label="I1.8j">
          <statement>
            <p>
              Standardize the value of the statistic for the Halloween study by comparing to the mean and standard deviation of the distribution of sample proportions. Interpret your result in context.
            </p>
            <p>
              Standardized statistic <m>z = \frac{\text{observed statistic} - \text{expected value}}{SD \text{ of statistic}} = </m> <var width="10"/>
            </p>
            <p>
              Interpretation:
            </p>
          </statement>
          <setup>
            <var>
              <condition number="-0.84" tolerance="0.02">
                <feedback>
                  <p>
                    Correct! <m>z = \frac{0.475 - 0.5}{0.0297} \approx -0.84</m>
                  </p>
                </feedback>
              </condition>
            </var>
          </setup>
          <response/>
          <hint>
            <p>
              Use the formula: <m>z = \frac{\hat{p} - \pi_0}{\sqrt{\pi_0(1-\pi_0)/n}}</m>
            </p>
          </hint>
          <solution>
            <p>
              <m>z = \frac{0.475 - 0.5}{\sqrt{0.5(0.5)/284}} = \frac{-0.025}{0.0297} \approx -0.84</m>
            </p>
            <p>
              Interpretation: The observed sample proportion of 0.475 is 0.84 standard deviations below the expected value of 0.5 under the null hypothesis. This is not particularly unusual.
            </p>
          </solution>
        </exercise>

        <p>
          (What if we had used the sample count instead?)
        </p>

        <assemblage xml:id="one-proportion-z-test-definition">
          <title>Definition</title>
          <p>
            The One Proportion z-test calculates the standardized statistic as <m>z_0 = \frac{\hat{p} - \pi_0}{\sqrt{\pi_0(1-\pi_0)/n}}</m> and uses the standard normal distribution (mean 0, std dev 1) to find the p-value.
          </p>
        </assemblage>

        <exercise xml:id="I1-8-k" label="I1.8k">
          <statement>
            <p>
              What does the "zero" subscript tell you?
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              The subscript indicates this value is calculated under a specific assumption.
            </p>
          </hint>
          <solution>
            <p>
              The "zero" subscript indicates that this is the value calculated under the null hypothesis (using <m>\pi_0</m>, the hypothesized value of the parameter).
            </p>
          </solution>
        </exercise>

        <assemblage xml:id="two-sd-guideline-normal">
          <title>Key Result</title>
          <p>
            In any normal distribution with mean <m>\mu</m> and standard deviation <m>\sigma</m>, we expect the interval <m>(\mu - 2\sigma, \mu + 2\sigma)</m> to capture approximately 95% of the distribution. In other words, 95% of sample proportions should fall within <m>2 \times \sqrt{\pi(1-\pi)/n}</m> of <m>\pi</m>. So with a normal distribution, the two-standard deviation guideline matches up with a two-sided p-value below 0.05.
          </p>
        </assemblage>

        <exercise xml:id="I1-8-l" label="I1.8l">
          <statement>
            <p>
              What do you conclude about the plausibility of the null hypothesis based on this standardized statistic?
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              Is <m>|z| > 2</m>?
            </p>
          </hint>
          <solution>
            <p>
              Since <m>|z| = 0.84 &lt; 2</m>, the observed result is within 2 standard deviations of the expected value under the null hypothesis. This suggests the null hypothesis is plausible - we do not have strong evidence against it. The p-value should be greater than 0.05.
            </p>
          </solution>
        </exercise>

        <exercise xml:id="I1-8-m" label="I1.8m">
          <statement>
            <p>
              Use technology to find the corresponding p-value. [Hints: You can calculate the probability from the z-value using standard normal distribution (mean 0, SD 1), e.g., Normal Probability Calculator applet; or use the Technology Detour below to carry out a one-sample z-test.]
            </p>
            <p>
              p-value = <var width="10"/>
            </p>
          </statement>
          <setup>
            <var>
              <condition number="0.40" tolerance="0.02">
                <feedback>
                  <p>
                    Correct! For a two-sided test with <m>z = -0.84</m>, the p-value is approximately 0.40.
                  </p>
                </feedback>
              </condition>
            </var>
          </setup>
          <hint>
            <p>
              For a two-sided test, find <m>2P(Z &lt; -0.84)</m> or <m>2P(Z > 0.84)</m>.
            </p>
          </hint>
          <solution>
            <p>
              Using technology (Normal Probability Calculator or z-test function), the p-value is approximately 0.40 (or 0.401). This confirms our conclusion that the result is not statistically significant.
            </p>
          </solution>
        </exercise>

        <exercise xml:id="tech-detour-one-prop-z-applet" label="Tech1.8.applet">
          <title>Technology Detour â€“ One Proportion z-test (Theory-Based Inference Applet)</title>
          <statement>
            <p>
              Use the Theory-Based Inference applet to conduct a one proportion z-test:
            </p>
            <p>
              <ul>
                <li>Enter the sample size and either the count or the proportion of successes, press Calculate to display sample data.</li>
                <li>Check the box for Test of significance</li>
                <li>Specify the hypothesized value</li>
                <li>Use the button to specify the direction of the alternative.</li>
                <li>Press the Calculate button.</li>
              </ul>
            </p>
          </statement>
          <hint>
            <p>
              For the Halloween study, enter n = 284 and either 135 successes or 0.475 as the proportion. Set the hypothesized value to 0.5 and select a two-sided alternative.
            </p>
          </hint>
          <solution>
            <p>
              The applet will display:
            </p>
            <p>
              <ul>
                <li>Sample statistic: <m>\hat{p} = 0.475</m></li>
                <li>Standardized statistic: <m>z \approx -0.84</m></li>
                <li>Two-sided p-value: approximately 0.40</li>
                <li>A normal curve with the shaded rejection regions</li>
              </ul>
            </p>
            <p>
              The applet confirms that there is not strong evidence against the null hypothesis that children choose equally between toys and candy.
            </p>
          </solution>
        </exercise>

        <exercise xml:id="tech-detour-one-prop-z-r" label="Tech1.8.R">
          <title>Technology Detour â€“ One Proportion z-test (R)</title>
          <statement>
            <p>
              Use R to conduct a one proportion z-test. The <c>iscamonepropztest(observed, n, hypothesized, alternative)</c> function takes the following inputs:
            </p>
            <p>
              <ul>
                <li>observed = the observation of interest (count or proportion)</li>
                <li>n = the sample size</li>
                <li>hypothesized = the hypothesized process probability (<m>\pi</m>)</li>
                <li>alternative = "below," "above," or "two.sided"</li>
              </ul>
            </p>
          </statement>
          <hint>
            <p>
              For the Halloween study, you could use:
            </p>
            <p>
              <c>iscamonepropztest(135, 284, 0.5, "two.sided")</c>
            </p>
            <p>
              or
            </p>
            <p>
              <c>iscamonepropztest(0.475, 284, 0.5, "two.sided")</c>
            </p>
          </hint>
          <solution>
            <p>
              Running the command:
            </p>
            <program language="r">
              <input>
library(iscam)
iscamonepropztest(135, 284, 0.5, "two.sided")
              </input>
            </program>
            <p>
              Should produce output including:
            </p>
            <p>
              <ul>
                <li>Sample proportion: 0.4754</li>
                <li>z-statistic: -0.84</li>
                <li>Two-sided p-value: 0.40</li>
              </ul>
            </p>
            <p>
              The function will also display a graph showing the standard normal distribution with the test statistic and shaded p-value region.
            </p>
            <image source="images/inv1.8-R-output.png" width="80%">
              <description>R output showing one proportion z-test results with standard normal curve and shaded p-value regions</description>
            </image>
          </solution>
        </exercise>

        <exercise xml:id="tech-detour-one-prop-z-jmp" label="Tech1.8.JMP">
          <title>Technology Detour â€“ One Proportion z-test (JMP)</title>
          <statement>
            <p>
              Using the ISCAM Journal file in JMP, select Hypothesis Test for One Proportion:
            </p>
            <p>
              <ul>
                <li>Use Raw Data or Summary Stats</li>
                <li>Remember to specify a direction for the alternative, a hypothesized proportion, and a significance level (e.g., .05)</li>
              </ul>
            </p>
          </statement>
          <hint>
            <p>
              For the Halloween study:
            </p>
            <p>
              <ul>
                <li>Select Summary Stats</li>
                <li>Enter n = 284, number of successes = 135</li>
                <li>Hypothesized proportion = 0.5</li>
                <li>Select "not equal" for two-sided test</li>
                <li>Significance level = 0.05</li>
              </ul>
            </p>
          </hint>
          <solution>
            <p>
              JMP will display a comprehensive output including:
            </p>
            <p>
              <ul>
                <li>Sample proportion: 0.475</li>
                <li>Standard error: 0.0297</li>
                <li>z-statistic: -0.84</li>
                <li>Two-sided p-value: 0.40</li>
                <li>A visual representation of the test</li>
              </ul>
            </p>
            <p>
              The output will indicate that we fail to reject the null hypothesis at the 0.05 significance level.
            </p>
            <image source="images/inv1.8-JMP-output.png" width="80%">
              <description>JMP output showing one proportion z-test results with test statistics and visual representation</description>
            </image>
          </solution>
        </exercise>

        <exercise xml:id="I1-8-n" label="I1.8n">
          <statement>
            <p>
              Provide a one sentence interpretation of this p-value in context.
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              What does the p-value tell you about how unusual the observed result would be if the null hypothesis were true?
            </p>
          </hint>
          <solution>
            <p>
              If children were equally likely to choose toys or candy, we would observe a result as extreme as or more extreme than 135 out of 284 children choosing toys in about 40% of samples.
            </p>
          </solution>
        </exercise>

        <exercise xml:id="I1-8-o" label="I1.8o">
          <statement>
            <p>
              Do you think the researchers are pleased by the lack of significance in this test? Explain, in the context of the study, why such a result might be good news for them.
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              Consider what the researchers were hoping to demonstrate about offering toys as an alternative to candy.
            </p>
          </hint>
          <solution>
            <p>
              Yes, the researchers should be pleased! The lack of significance means there's no strong evidence that children prefer candy over toys. This is good news because it suggests that offering toys as an alternative to candy is viable - children are willing to accept toys instead of candy. If there had been strong evidence of a preference for candy, it would suggest that offering toys wouldn't be an effective strategy to reduce candy consumption.
            </p>
          </solution>
        </exercise>

        <paragraphs xml:id="improving-normal-approximation">
          <title>Improving the normal approximation</title>
          <p>
            Even though we passed the "validity conditions" for the normal approximation for this study, we could still use a "continuity correction" to improve the approximation.
          </p>
        </paragraphs>

        <exercise xml:id="I1-8-p" label="I1.8p">
          <title>Compare P-values</title>
          <statement>
            <p>
              Which p-value from the earlier comparison (exact binomial or normal approximation) is closer to your simulated p-value? Is this expected?
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              The exact binomial should match the simulation closely.
            </p>
          </hint>
          <solution>
            <p>
              The exact binomial p-value should be closer to the simulated p-value. This is expected because the simulation approximates the true binomial distribution, while the normal approximation is just that - an approximation to the binomial.
            </p>
          </solution>
        </exercise>

        <exercise xml:id="I1-8-q" label="I1.8q">
          <title>Compare Discrete and Continuous</title>
          <statement>
            <p>
              In the binomial distribution <m>P(X = 135) = 0.220</m>. What is <m>P(X = 135)</m> with the normal distribution? How do <m>P(X &lt; 135)</m> and <m>P(X \leq 135)</m> compare in each distribution?
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              For a continuous distribution, the probability of any exact value is 0.
            </p>
          </hint>
          <solution>
            <p>
              With the normal distribution (continuous), <m>P(X = 135) = 0</m> because the probability of any exact value is 0 for a continuous distribution.
            </p>
            <p>
              In the binomial distribution (discrete): <m>P(X \leq 135) = P(X &lt; 135) + P(X = 135)</m>, so these are different values.
            </p>
            <p>
              In the normal distribution (continuous): <m>P(X \leq 135) = P(X &lt; 135)</m> because <m>P(X = 135) = 0</m>.
            </p>
          </solution>
        </exercise>

        <p>
          To make the normal probability (which is finding <m>P(X &lt; 135)</m>) closer to the binomial probability, which finds <m>P(X \leq 135) = P(X &lt; 135) + P(X = 135)</m>, we want to include more of the area under the normal curve above 135 in our calculation. A continuity correction does this by using the normal distribution to find <m>P(X &lt; 135.5)</m> instead. This does not change the binomial probability but should enlarge the normal probability.
        </p>

        <exercise xml:id="I1-8-r" label="I1.8r">
          <title>Apply Continuity Correction</title>
          <statement>
            <p>
              In the One Proportion Inference applet, specify 135.5 in the As Extreme As box (if using number of successes as the statistic, otherwise use <m>135.5/284 \approx 0.477</m> instead) and press Count. What does the applet use for the right-side cut-off? Why? How does the p-value change? Is it now more similar to the binomial p-value?
            </p>
          </statement>
          <response/>
          <hint>
            <p>
              By symmetry, what value on the right side corresponds to 135.5 on the left side?
            </p>
          </hint>
          <solution>
            <p>
              The applet uses 148.5 for the right-side cut-off. This is because 135.5 is 6.5 below the mean of 142, so by symmetry, we need 6.5 above the mean: <m>142 + 6.5 = 148.5</m>.
            </p>
            <p>
              The p-value should increase slightly (become closer to 0.40) and should now be more similar to the exact binomial p-value. The continuity correction improves the normal approximation by accounting for the fact that the normal distribution is continuous while the binomial is discrete.
            </p>
          </solution>
        </exercise>

        <p>
          Many software programs allow you to apply this continuity correction for a one-sample z-test (e.g., using <m>\hat{p} = (X \pm 0.5)/n</m> as the input) or may do so by default. However, when n is large, you may not see much difference in the values.
        </p>

        <exercise xml:id="tech-detour-continuity-correction-applet" label="Tech1.8.CC.applet">
          <title>Technology Detour â€“ Continuity Correction (Theory-Based Inference Applet)</title>
          <statement>
            <p>
              Use the Theory-Based Inference applet to apply a continuity correction:
            </p>
            <p>
              <ul>
                <li>Check the continuity correction box to apply the continuity correction to the standardized statistic and p-value.</li>
              </ul>
            </p>
          </statement>
          <hint>
            <p>
              For the Halloween study, after entering the data (n = 284, 135 successes), check the continuity correction box and observe how the p-value changes.
            </p>
          </hint>
          <solution>
            <p>
              With the continuity correction applied:
            </p>
            <p>
              <ul>
                <li>The p-value changes from approximately 0.4061 to 0.4382</li>
                <li>This is much closer to the exact binomial p-value of 0.4405</li>
                <li>The continuity correction adjusts for the fact that we're using a continuous distribution (normal) to approximate a discrete distribution (binomial)</li>
              </ul>
            </p>
            <image source="images/inv1.8-continuity-correction.png" width="80%">
              <description>Comparison of normal approximation with and without continuity correction showing improved accuracy</description>
            </image>
          </solution>
        </exercise>

        <exercise xml:id="tech-detour-continuity-correction-r" label="Tech1.8.CC.R">
          <title>Technology Detour â€“ Continuity Correction (R)</title>
          <statement>
            <p>
              The <c>iscambinomnorm(k, n, prob, direction)</c> function gives a visual of the continuity correction. It takes the following inputs:
            </p>
            <p>
              <ul>
                <li>k = the observation of interest</li>
                <li>n = the sample size</li>
                <li>prob = the process probability (<m>\pi</m>)</li>
                <li>direction = "below," "above," or "two.sided"</li>
              </ul>
            </p>
          </statement>
          <hint>
            <p>
              For the Halloween study, try:
            </p>
            <p>
              <c>iscambinomnorm(135, 284, 0.5, "two.sided")</c>
            </p>
          </hint>
          <solution>
            <p>
              Running the command:
            </p>
            <program language="r">
              <input>
library(iscam)
iscambinomnorm(135, 284, 0.5, "two.sided")
              </input>
            </program>
            <p>
              This function creates a graph showing:
            </p>
            <p>
              <ul>
                <li>The binomial distribution (bars)</li>
                <li>The normal approximation (curve)</li>
                <li>The continuity correction boundaries at 135.5 and 148.5</li>
                <li>The corrected p-value of approximately 0.4382</li>
              </ul>
            </p>
            <p>
              The visualization clearly shows how the continuity correction includes more area under the normal curve to better match the binomial probabilities.
            </p>
          </solution>
        </exercise>

        <assemblage xml:id="study-conclusions-1-8">
          <title>Study Conclusions</title>
          <p>
            If we define <m>\pi</m> to be the probability that, when presented with a choice of candy or a toy while trick-or-treating, a child chooses the toy, and if we assume the null hypothesis (<m>H_0: \pi = 0.5</m>) is true, the above calculations tell us that we would observe at most 135 children choosing candy (or at least 149 choosing toy) or at most 135 of the 284 children choosing the toy in about 40% of all possible samples from such a process. Thus, this is not a surprising outcome when <m>\pi = 0.5</m>. We fail to reject the null hypothesis and conclude that it's plausible that children are equally likely to choose the toy or the candy.
          </p>
          <p>
            We do have some cautions with this study as it was conducted in only a few households in Connecticut, a "convenience sample," so we cannot claim that these results are representative of children in other neighborhoods. We also don't know if the children found the toys "novel" and whether their preference for toys could decrease as the novelty wears off (or if "better" candy choices were offered). Furthermore, when the children approached the door they were asked their age and gender, and for a description of their Halloween costume. The researchers caution that this may have cued the children that their behavior was being observed (even though their responses were recorded by another research member who was out of sight) or that they should behave a certain way. Still, these researchers were optimistic that alternatives could be presented to children, even at Halloween, to lessen their exposure to large amounts of candy.
          </p>
        </assemblage>

      </subsection>
      
      <subsection xml:id="practice1-8A">
        <title>Practice Problem 1.8A</title>
        
        <p>In Investigation 1.6, Dr. GÃ¼ntÃ¼rkÃ¼n conjectured that 2/3 of kissing couples lean right.</p>
        
        <exercise xml:id="PP1-8A-1" label="PP1.8A.1">
          <title>Normal Approximation Validity</title>
          <statement>
            <p>Would the normal approximation (Central Limit Theorem) be valid for the kissing study in Investigation 1.6? Justify your answer.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-8A-2" label="PP1.8A.2">
          <title>Z-test and P-value</title>
          <statement>
            <p>Dr. GÃ¼ntÃ¼rkÃ¼n found 80 out of 124 couples leaned right in his sample. Find the one-proportion z-test statistic and normal-based two-sided p-value. Do the standardized statistic and p-value agree? How does the normal-based p-value compare to the exact binomial p-value for this study?</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-8A-3" label="PP1.8A.3">
          <title>Continuity Correction</title>
          <statement>
            <p>Repeat the previous calculation using the continuity correction and compare the results.</p>
          </statement>
          <response/>
        </exercise>
      </subsection>
      
      <subsection xml:id="practice1-8B">
        <title>Practice Problem 1.8B</title>
        
        <p>A student wanted to assess whether her dog Muffin tends to chase her blue ball and her red ball equally often when they are rolled at the same time. The student rolled both balls a total of 96 times, each time keeping track of which ball Muffin chased. The student found that Muffin chased the blue ball 52 times and the red ball 44 times. Let's treat the blue ball as "success."</p>
        
        <exercise xml:id="PP1-8B-1" label="PP1.8B.1">
          <title>State Hypotheses</title>
          <statement>
            <p>State the appropriate null and alternative hypotheses in symbols. (Be sure to describe what the symbol represents in this context.)</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-8B-2" label="PP1.8B.2">
          <title>Calculate Test Statistic</title>
          <statement>
            <p>Report and interpret the values of the z-test statistic and normal-based p-value using a continuity correction.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-8B-3" label="PP1.8B.3">
          <title>Conclusion</title>
          <statement>
            <p>Summarize your conclusion about the student's question concerning her dog Muffin.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-8B-4" label="PP1.8B.4">
          <title>Explain Reasoning</title>
          <statement>
            <p>Explain the reasoning process behind your conclusion.</p>
          </statement>
          <response/>
        </exercise>
        
        <exercise xml:id="PP1-8B-5" label="PP1.8B.5">
          <title>Alternate Definition</title>
          <statement>
            <p>How would your answers to the previous questions change if we had used the red ball as success?</p>
          </statement>
          <response/>
        </exercise>
      </subsection>

      <subsection xml:id="summary1-8">
        <title>Summary</title>
        
        <assemblage xml:id="summary-one-proportion-z-test">
          <title>Summary of One Proportion z-test (Sampling from Binomial Process)</title>
          <p>
            Let <m>\pi</m> represent the (constant) probability of success for the binomial random process assumed by the null hypothesis.
          </p>
          <p>
            To test <m>H_0: \pi = \pi_0</m>
          </p>
          <p>
            We can calculate a p-value based on the normal distribution with mean equal to <m>\pi_0</m> and standard deviation equal to <m>\sqrt{\pi_0(1-\pi_0)/n}</m>
          </p>
          <p>
            <term>Standardized (Test) Statistic</term>: <m>z_0 = \frac{\hat{p} - \pi_0}{\sqrt{\pi_0(1-\pi_0)/n}}</m> which follows a <m>N(0,1)</m> distribution
          </p>
          <p>
            <term>p-value</term>:
          </p>
          <p>
            <ul>
              <li>if <m>H_a: \pi > \pi_0</m>: p-value = <m>P(Z > z_0)</m></li>
              <li>if <m>H_a: \pi &lt; \pi_0</m>: p-value = <m>P(Z &lt; z_0)</m></li>
              <li>if <m>H_a: \pi \neq \pi_0</m>: p-value = <m>2P(Z > |z_0|)</m></li>
            </ul>
          </p>
          <p>
            <term>Validity</term>: This procedure is considered valid as long as the sample size is large relative to the hypothesized probability (<m>n \times \pi_0 > 10</m> and <m>n \times (1 - \pi_0) > 10</m>), and you have a representative sample from the process of interest.
          </p>
          <p>
            <term>Technology</term>:
          </p>
          <p>
            <ul>
              <li>Theory-Based Inference applet: Specify the hypothesized value, use the button to specify the direction of the alternative (<m>&lt;</m>, <m>></m>, or <m>\neq</m> for not equal), enter the sample size and either the count or the proportion of successes. Press the Calculate button.</li>
              <li>R, ISCAM Workspace: <c>iscamonepropztest(observed, n, hypothesized = Ï€_0, alternative="greater","less", or "two.sided", conf.level)</c>. You can enter either the number of successes or the proportion of successes (<m>\hat{p}</m>) for the "observed" value.</li>
              <li>JMP: Using the ISCAM Journal file, select Hypothesis Test for One Proportion (with Normal Approximation radio button).</li>
            </ul>
          </p>
        </assemblage>

        <assemblage xml:id="prob-detour-normal-random-vars">
          <title>Probability Detour â€“ Normal Random Variables</title>
          <p>
            Many quantitative variables have a distribution that can be reasonably modeled with a normal probability curve. This is a continuous probability distribution (as opposed to the binomial, which is a discrete distribution) that is specified by two quantities:
          </p>
          <p>
            <ul>
              <li>Mean, denoted by <m>\mu</m> ("mu"), which is the peak and point of symmetry</li>
              <li>Standard deviation, denoted by <m>\sigma</m> ("sigma"), which is the distance between the mean and each inflection point</li>
            </ul>
          </p>
          <p>
            In other words, the mean determines the center of the distribution, and the standard deviation controls how variable (spread out) the distribution is. The standard deviation can be loosely interpreted as a typical distance of the observations from the mean.
          </p>
          <p>
            This normal curve is given by the following function:
          </p>
          <p>
            <m>N(\mu, \sigma): f(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}</m>, <m>-\infty &lt; x &lt; \infty</m>
          </p>
          <p>
            <term>Notes</term>: The symbol <m>\pi</m> is used here to refer to the irrational number <m>\approx 3.14159\ldots</m>. The constant in front of the exponential term ensures that the total area under any normal curve equals one.
          </p>
          <p>
            <term>Probability calculations</term>: Then the probability of an observation falling in any particular interval on the x-axis is determined by the area under the normal curve over that interval. In principle, this area could be determined by integrating the function <m>f(x)</m> above the interval. However, this particular function has no closed form anti-derivative, so we rely on technology to approximate these areas and therefore these normal probabilities.
          </p>
          <p>
            <term>The empirical rule</term>: For a mound-shaped, symmetric distribution (like the normal) with mean <m>\mu</m> and standard deviation <m>\sigma</m>,
          </p>
          <p>
            <ul>
              <li>the interval <m>(\mu - \sigma, \mu + \sigma)</m> should capture approximately 68% of the distribution.</li>
              <li>the interval <m>(\mu - 2\sigma, \mu + 2\sigma)</m> should capture approximately 95% of the distribution.</li>
              <li>the interval <m>(\mu - 3\sigma, \mu + 3\sigma)</m> should capture approximately 99.7% of the distribution.</li>
            </ul>
          </p>
        </assemblage>
      </subsection>
    </subsection>
    
</chapter>
